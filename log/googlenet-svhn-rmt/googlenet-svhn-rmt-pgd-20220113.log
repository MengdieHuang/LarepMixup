

---------------------------------------
Torch cuda is available
args.subcommand=run, run the command line
date: 20220114
blackbox attack
Experiment result save dir: /home/maggie/mmat/result/defense/rmt/pgd/basemixup-betasampler/googlenet-svhn/blackbox/20220114/00000
initilize the dataset loading parameters
Using downloaded and verified file: /home/data/maggie/svhn/train_32x32.mat
Loading *svhn* train dataloader finished !
Loading *svhn* test dataloader finished !
initlize classifier
learned calssify model != None
args.adv_datasetï¼š /home/maggie/mmat/result/attack/pgd/googlenet-svhn/20220113/00002-pgd-eps-0.02-acc-78.4496/attack-svhn-dataset/samples
Accuary of before rmt trained classifier on clean testset:93.8691%
Loss of before mmat trained classifier clean testset:0.24139124155044556
args.mix_mode: basemixup
args.mix_w_num: 2
args.beta_alpha: 2.0
args.dirichlet_gama: 1
cle_w_train.shape: torch.Size([24004, 8, 512])
cle_y_train.shape: torch.Size([24004, 8])
cle_x_test.shape: torch.Size([26032, 3, 32, 32])
cle_y_test.shape: torch.Size([26032])
adv_x_test.shape: torch.Size([26032, 3, 32, 32])
adv_y_test.shape: torch.Size([26032])
cle_train_dataloader.len: 287
Accuary of before rmt trained classifier on adversarial testset:78.4496%
Loss of before mmat trained classifier on adversarial testset:0.9558376669883728
w_trainset_len: 24004
batch_size: 256
w_batch_num: 94


0epoch learning rate:0.001
Setting up PyTorch plugin "bias_act_plugin"... /home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/utils/cpp_extension.py:286: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... /home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/utils/cpp_extension.py:286: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
Done.
[Epoch 1/40] [Batch 1/287] [Batch classify loss: 2.650220]
[Epoch 1/40] [Batch 2/287] [Batch classify loss: 1.654481]
[Epoch 1/40] [Batch 3/287] [Batch classify loss: 1.804985]
[Epoch 1/40] [Batch 4/287] [Batch classify loss: 1.444951]
[Epoch 1/40] [Batch 5/287] [Batch classify loss: 1.494215]
[Epoch 1/40] [Batch 6/287] [Batch classify loss: 1.434925]
[Epoch 1/40] [Batch 7/287] [Batch classify loss: 1.335602]
[Epoch 1/40] [Batch 8/287] [Batch classify loss: 1.309424]
[Epoch 1/40] [Batch 9/287] [Batch classify loss: 1.318715]
[Epoch 1/40] [Batch 10/287] [Batch classify loss: 1.341393]
[Epoch 1/40] [Batch 11/287] [Batch classify loss: 1.318786]
[Epoch 1/40] [Batch 12/287] [Batch classify loss: 1.301978]
[Epoch 1/40] [Batch 13/287] [Batch classify loss: 1.290846]
[Epoch 1/40] [Batch 14/287] [Batch classify loss: 1.250766]
[Epoch 1/40] [Batch 15/287] [Batch classify loss: 1.214774]
[Epoch 1/40] [Batch 16/287] [Batch classify loss: 1.238997]
[Epoch 1/40] [Batch 17/287] [Batch classify loss: 1.228597]
[Epoch 1/40] [Batch 18/287] [Batch classify loss: 1.252980]
[Epoch 1/40] [Batch 19/287] [Batch classify loss: 1.175923]
[Epoch 1/40] [Batch 20/287] [Batch classify loss: 1.189393]
[Epoch 1/40] [Batch 21/287] [Batch classify loss: 1.225500]
[Epoch 1/40] [Batch 22/287] [Batch classify loss: 1.190859]
[Epoch 1/40] [Batch 23/287] [Batch classify loss: 1.226852]
[Epoch 1/40] [Batch 24/287] [Batch classify loss: 1.244973]
[Epoch 1/40] [Batch 25/287] [Batch classify loss: 1.191056]
[Epoch 1/40] [Batch 26/287] [Batch classify loss: 1.164173]
[Epoch 1/40] [Batch 27/287] [Batch classify loss: 1.219353]
[Epoch 1/40] [Batch 28/287] [Batch classify loss: 1.162568]
[Epoch 1/40] [Batch 29/287] [Batch classify loss: 1.169821]
[Epoch 1/40] [Batch 30/287] [Batch classify loss: 1.168501]
[Epoch 1/40] [Batch 31/287] [Batch classify loss: 1.096891]
[Epoch 1/40] [Batch 32/287] [Batch classify loss: 1.199644]
[Epoch 1/40] [Batch 33/287] [Batch classify loss: 1.205456]
[Epoch 1/40] [Batch 34/287] [Batch classify loss: 1.233111]
[Epoch 1/40] [Batch 35/287] [Batch classify loss: 1.120121]
[Epoch 1/40] [Batch 36/287] [Batch classify loss: 1.157932]
[Epoch 1/40] [Batch 37/287] [Batch classify loss: 1.192458]
[Epoch 1/40] [Batch 38/287] [Batch classify loss: 1.100158]
[Epoch 1/40] [Batch 39/287] [Batch classify loss: 1.251662]
[Epoch 1/40] [Batch 40/287] [Batch classify loss: 1.190262]
[Epoch 1/40] [Batch 41/287] [Batch classify loss: 1.137609]
[Epoch 1/40] [Batch 42/287] [Batch classify loss: 1.160728]
[Epoch 1/40] [Batch 43/287] [Batch classify loss: 1.130591]
[Epoch 1/40] [Batch 44/287] [Batch classify loss: 1.120987]
[Epoch 1/40] [Batch 45/287] [Batch classify loss: 1.135467]
[Epoch 1/40] [Batch 46/287] [Batch classify loss: 1.231567]
[Epoch 1/40] [Batch 47/287] [Batch classify loss: 1.135976]
[Epoch 1/40] [Batch 48/287] [Batch classify loss: 1.241767]
[Epoch 1/40] [Batch 49/287] [Batch classify loss: 1.162875]
[Epoch 1/40] [Batch 50/287] [Batch classify loss: 1.173326]
[Epoch 1/40] [Batch 51/287] [Batch classify loss: 1.102020]
[Epoch 1/40] [Batch 52/287] [Batch classify loss: 1.168589]
[Epoch 1/40] [Batch 53/287] [Batch classify loss: 1.192327]
[Epoch 1/40] [Batch 54/287] [Batch classify loss: 1.167616]
[Epoch 1/40] [Batch 55/287] [Batch classify loss: 1.177496]
[Epoch 1/40] [Batch 56/287] [Batch classify loss: 1.186747]
