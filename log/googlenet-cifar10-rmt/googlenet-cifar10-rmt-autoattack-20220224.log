

---------------------------------------
Torch cuda is available
args.subcommand=run, run the command line
date: 20220224
blackbox attack
Experiment result save dir: /home/maggie/mmat/result/defense/rmt/autoattack/basemixup-betasampler/googlenet-cifar10/blackbox/20220224/00001
initilize the dataset loading parameters
load cifar10 dataset
Loading *cifar10* train dataloader finished !
Loading *cifar10* test dataloader finished !
initlize classifier
learned calssify model != None
args.adv_datasetï¼š /home/maggie/mmat/result/attack/autoattack/googlenet-cifar10/20220223/00000-eps0.02-acc52.68/attack-cifar10-dataset/samples
Accuary of before rmt trained classifier on clean testset:80.4500%
Loss of before mmat trained classifier clean testset:0.7182748913764954
args.mix_mode: basemixup
args.mix_w_num: 2
args.beta_alpha: 2.0
args.dirichlet_gama: 1
cle_w_train.shape: torch.Size([25397, 8, 512])
cle_y_train.shape: torch.Size([25397, 8])
cle_x_test.shape: torch.Size([10000, 3, 32, 32])
cle_y_test.shape: torch.Size([10000])
adv_x_test.shape: torch.Size([10000, 3, 32, 32])
adv_y_test.shape: torch.Size([10000])
cle_train_dataloader.len: 196
Accuary of before rmt trained classifier on adversarial testset:52.6800%
Loss of before mmat trained classifier on adversarial testset:1.5819549560546875
w_trainset_len: 25397
batch_size: 256
w_batch_num: 100


0epoch learning rate:0.001
Setting up PyTorch plugin "bias_act_plugin"... /home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/utils/cpp_extension.py:286: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... /home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/utils/cpp_extension.py:286: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
Done.
[Epoch 1/40] [Batch 1/196] [Batch classify loss: 2.028840]
[Epoch 1/40] [Batch 2/196] [Batch classify loss: 1.710307]
[Epoch 1/40] [Batch 3/196] [Batch classify loss: 1.651295]
[Epoch 1/40] [Batch 4/196] [Batch classify loss: 1.602528]
[Epoch 1/40] [Batch 5/196] [Batch classify loss: 1.437439]
[Epoch 1/40] [Batch 6/196] [Batch classify loss: 1.435963]
[Epoch 1/40] [Batch 7/196] [Batch classify loss: 1.343613]
[Epoch 1/40] [Batch 8/196] [Batch classify loss: 1.429174]
[Epoch 1/40] [Batch 9/196] [Batch classify loss: 1.327103]
[Epoch 1/40] [Batch 10/196] [Batch classify loss: 1.334389]
[Epoch 1/40] [Batch 11/196] [Batch classify loss: 1.365346]
[Epoch 1/40] [Batch 12/196] [Batch classify loss: 1.349000]
[Epoch 1/40] [Batch 13/196] [Batch classify loss: 1.288971]
[Epoch 1/40] [Batch 14/196] [Batch classify loss: 1.267897]
[Epoch 1/40] [Batch 15/196] [Batch classify loss: 1.204819]
[Epoch 1/40] [Batch 16/196] [Batch classify loss: 1.215306]
[Epoch 1/40] [Batch 17/196] [Batch classify loss: 1.217646]
[Epoch 1/40] [Batch 18/196] [Batch classify loss: 1.213137]
[Epoch 1/40] [Batch 19/196] [Batch classify loss: 1.212316]
[Epoch 1/40] [Batch 20/196] [Batch classify loss: 1.281447]
[Epoch 1/40] [Batch 21/196] [Batch classify loss: 1.180908]
[Epoch 1/40] [Batch 22/196] [Batch classify loss: 1.236664]
[Epoch 1/40] [Batch 23/196] [Batch classify loss: 1.171873]
[Epoch 1/40] [Batch 24/196] [Batch classify loss: 1.187455]
[Epoch 1/40] [Batch 25/196] [Batch classify loss: 1.211657]
[Epoch 1/40] [Batch 26/196] [Batch classify loss: 1.257053]
[Epoch 1/40] [Batch 27/196] [Batch classify loss: 1.201369]
[Epoch 1/40] [Batch 28/196] [Batch classify loss: 1.218860]
[Epoch 1/40] [Batch 29/196] [Batch classify loss: 1.168243]
[Epoch 1/40] [Batch 30/196] [Batch classify loss: 1.180666]
[Epoch 1/40] [Batch 31/196] [Batch classify loss: 1.188863]
[Epoch 1/40] [Batch 32/196] [Batch classify loss: 1.206178]
[Epoch 1/40] [Batch 33/196] [Batch classify loss: 1.195092]
[Epoch 1/40] [Batch 34/196] [Batch classify loss: 1.219803]
[Epoch 1/40] [Batch 35/196] [Batch classify loss: 1.229969]
[Epoch 1/40] [Batch 36/196] [Batch classify loss: 1.191230]
[Epoch 1/40] [Batch 37/196] [Batch classify loss: 1.129153]
[Epoch 1/40] [Batch 38/196] [Batch classify loss: 1.245145]
[Epoch 1/40] [Batch 39/196] [Batch classify loss: 1.111142]
[Epoch 1/40] [Batch 40/196] [Batch classify loss: 1.264668]
[Epoch 1/40] [Batch 41/196] [Batch classify loss: 1.191536]
[Epoch 1/40] [Batch 42/196] [Batch classify loss: 1.215427]
[Epoch 1/40] [Batch 43/196] [Batch classify loss: 1.144520]
[Epoch 1/40] [Batch 44/196] [Batch classify loss: 1.222967]
[Epoch 1/40] [Batch 45/196] [Batch classify loss: 1.224168]
[Epoch 1/40] [Batch 46/196] [Batch classify loss: 1.120443]
[Epoch 1/40] [Batch 47/196] [Batch classify loss: 1.163020]
[Epoch 1/40] [Batch 48/196] [Batch classify loss: 1.195215]
[Epoch 1/40] [Batch 49/196] [Batch classify loss: 1.172654]
[Epoch 1/40] [Batch 50/196] [Batch classify loss: 1.143728]
[Epoch 1/40] [Batch 51/196] [Batch classify loss: 1.210052]
[Epoch 1/40] [Batch 52/196] [Batch classify loss: 1.259489]
[Epoch 1/40] [Batch 53/196] [Batch classify loss: 1.160079]
[Epoch 1/40] [Batch 54/196] [Batch classify loss: 1.185242]
[Epoch 1/40] [Batch 55/196] [Batch classify loss: 1.198631]
[Epoch 1/40] [Batch 56/196] [Batch classify loss: 1.111525]
[Epoch 1/40] [Batch 57/196] [Batch classify loss: 1.192173]
[Epoch 1/40] [Batch 58/196] [Batch classify loss: 1.194351]
[Epoch 1/40] [Batch 59/196] [Batch classify loss: 1.169800]
[Epoch 1/40] [Batch 60/196] [Batch classify loss: 1.087812]
[Epoch 1/40] [Batch 61/196] [Batch classify loss: 1.218601]
[Epoch 1/40] [Batch 62/196] [Batch classify loss: 1.128813]
[Epoch 1/40] [Batch 63/196] [Batch classify loss: 1.158312]
[Epoch 1/40] [Batch 64/196] [Batch classify loss: 1.194213]
[Epoch 1/40] [Batch 65/196] [Batch classify loss: 1.160272]
[Epoch 1/40] [Batch 66/196] [Batch classify loss: 1.166653]
[Epoch 1/40] [Batch 67/196] [Batch classify loss: 1.225509]
[Epoch 1/40] [Batch 68/196] [Batch classify loss: 1.120401]
[Epoch 1/40] [Batch 69/196] [Batch classify loss: 1.249393]
[Epoch 1/40] [Batch 70/196] [Batch classify loss: 1.145463]
[Epoch 1/40] [Batch 71/196] [Batch classify loss: 1.274653]
[Epoch 1/40] [Batch 72/196] [Batch classify loss: 1.151930]
[Epoch 1/40] [Batch 73/196] [Batch classify loss: 1.211458]
[Epoch 1/40] [Batch 74/196] [Batch classify loss: 1.093511]
[Epoch 1/40] [Batch 75/196] [Batch classify loss: 1.153051]
[Epoch 1/40] [Batch 76/196] [Batch classify loss: 1.072370]
[Epoch 1/40] [Batch 77/196] [Batch classify loss: 1.206403]
[Epoch 1/40] [Batch 78/196] [Batch classify loss: 1.126251]
[Epoch 1/40] [Batch 79/196] [Batch classify loss: 1.140890]
[Epoch 1/40] [Batch 80/196] [Batch classify loss: 1.164638]
[Epoch 1/40] [Batch 81/196] [Batch classify loss: 1.187807]
[Epoch 1/40] [Batch 82/196] [Batch classify loss: 1.228172]
[Epoch 1/40] [Batch 83/196] [Batch classify loss: 1.179309]
[Epoch 1/40] [Batch 84/196] [Batch classify loss: 1.212894]
[Epoch 1/40] [Batch 85/196] [Batch classify loss: 1.176404]
[Epoch 1/40] [Batch 86/196] [Batch classify loss: 1.228966]
[Epoch 1/40] [Batch 87/196] [Batch classify loss: 1.212438]
[Epoch 1/40] [Batch 88/196] [Batch classify loss: 1.185953]
[Epoch 1/40] [Batch 89/196] [Batch classify loss: 1.175759]
[Epoch 1/40] [Batch 90/196] [Batch classify loss: 1.206674]
[Epoch 1/40] [Batch 91/196] [Batch classify loss: 1.206680]
[Epoch 1/40] [Batch 92/196] [Batch classify loss: 1.156180]
[Epoch 1/40] [Batch 93/196] [Batch classify loss: 1.197897]
[Epoch 1/40] [Batch 94/196] [Batch classify loss: 1.221300]
[Epoch 1/40] [Batch 95/196] [Batch classify loss: 1.144938]
[Epoch 1/40] [Batch 96/196] [Batch classify loss: 1.204281]
[Epoch 1/40] [Batch 97/196] [Batch classify loss: 1.205591]
[Epoch 1/40] [Batch 98/196] [Batch classify loss: 1.127253]
[Epoch 1/40] [Batch 99/196] [Batch classify loss: 1.184261]
[Epoch 1/40] [Batch 100/196] [Batch classify loss: 0.793052]
[Epoch 1/40] [Batch 101/196] [Batch classify loss: 1.108907]
[Epoch 1/40] [Batch 102/196] [Batch classify loss: 1.176774]
[Epoch 1/40] [Batch 103/196] [Batch classify loss: 1.183073]
[Epoch 1/40] [Batch 104/196] [Batch classify loss: 1.106575]
[Epoch 1/40] [Batch 105/196] [Batch classify loss: 1.158713]
[Epoch 1/40] [Batch 106/196] [Batch classify loss: 1.137940]
[Epoch 1/40] [Batch 107/196] [Batch classify loss: 1.133697]
[Epoch 1/40] [Batch 108/196] [Batch classify loss: 1.130197]
[Epoch 1/40] [Batch 109/196] [Batch classify loss: 1.159557]
[Epoch 1/40] [Batch 110/196] [Batch classify loss: 1.237226]
[Epoch 1/40] [Batch 111/196] [Batch classify loss: 1.099357]
[Epoch 1/40] [Batch 112/196] [Batch classify loss: 1.114533]
[Epoch 1/40] [Batch 113/196] [Batch classify loss: 1.121574]
[Epoch 1/40] [Batch 114/196] [Batch classify loss: 1.119050]
[Epoch 1/40] [Batch 115/196] [Batch classify loss: 1.124318]
[Epoch 1/40] [Batch 116/196] [Batch classify loss: 1.124907]
[Epoch 1/40] [Batch 117/196] [Batch classify loss: 1.141081]
[Epoch 1/40] [Batch 118/196] [Batch classify loss: 1.122034]
[Epoch 1/40] [Batch 119/196] [Batch classify loss: 1.108387]
[Epoch 1/40] [Batch 120/196] [Batch classify loss: 1.160310]
[Epoch 1/40] [Batch 121/196] [Batch classify loss: 1.129041]
[Epoch 1/40] [Batch 122/196] [Batch classify loss: 1.168370]
[Epoch 1/40] [Batch 123/196] [Batch classify loss: 1.157450]
[Epoch 1/40] [Batch 124/196] [Batch classify loss: 1.114038]
[Epoch 1/40] [Batch 125/196] [Batch classify loss: 1.152632]
[Epoch 1/40] [Batch 126/196] [Batch classify loss: 1.194408]
[Epoch 1/40] [Batch 127/196] [Batch classify loss: 1.082546]
[Epoch 1/40] [Batch 128/196] [Batch classify loss: 1.137138]
[Epoch 1/40] [Batch 129/196] [Batch classify loss: 1.065235]
[Epoch 1/40] [Batch 130/196] [Batch classify loss: 1.172726]
[Epoch 1/40] [Batch 131/196] [Batch classify loss: 1.129814]
[Epoch 1/40] [Batch 132/196] [Batch classify loss: 1.223682]
[Epoch 1/40] [Batch 133/196] [Batch classify loss: 1.110489]
[Epoch 1/40] [Batch 134/196] [Batch classify loss: 1.192952]
[Epoch 1/40] [Batch 135/196] [Batch classify loss: 1.146824]
[Epoch 1/40] [Batch 136/196] [Batch classify loss: 1.167246]
[Epoch 1/40] [Batch 137/196] [Batch classify loss: 1.166121]
[Epoch 1/40] [Batch 138/196] [Batch classify loss: 1.166282]
[Epoch 1/40] [Batch 139/196] [Batch classify loss: 1.094762]
[Epoch 1/40] [Batch 140/196] [Batch classify loss: 1.289575]
[Epoch 1/40] [Batch 141/196] [Batch classify loss: 1.155132]
[Epoch 1/40] [Batch 142/196] [Batch classify loss: 1.180043]
[Epoch 1/40] [Batch 143/196] [Batch classify loss: 1.105430]
[Epoch 1/40] [Batch 144/196] [Batch classify loss: 1.133628]
[Epoch 1/40] [Batch 145/196] [Batch classify loss: 1.096138]
[Epoch 1/40] [Batch 146/196] [Batch classify loss: 1.189598]
[Epoch 1/40] [Batch 147/196] [Batch classify loss: 1.158654]
[Epoch 1/40] [Batch 148/196] [Batch classify loss: 1.115693]
[Epoch 1/40] [Batch 149/196] [Batch classify loss: 1.153502]
[Epoch 1/40] [Batch 150/196] [Batch classify loss: 1.093402]
[Epoch 1/40] [Batch 151/196] [Batch classify loss: 1.126723]
[Epoch 1/40] [Batch 152/196] [Batch classify loss: 1.104368]
[Epoch 1/40] [Batch 153/196] [Batch classify loss: 1.157084]
[Epoch 1/40] [Batch 154/196] [Batch classify loss: 1.135420]
[Epoch 1/40] [Batch 155/196] [Batch classify loss: 1.133415]
[Epoch 1/40] [Batch 156/196] [Batch classify loss: 1.150509]
[Epoch 1/40] [Batch 157/196] [Batch classify loss: 1.162363]
[Epoch 1/40] [Batch 158/196] [Batch classify loss: 1.083203]
[Epoch 1/40] [Batch 159/196] [Batch classify loss: 1.154332]
[Epoch 1/40] [Batch 160/196] [Batch classify loss: 1.194206]
[Epoch 1/40] [Batch 161/196] [Batch classify loss: 1.207667]
[Epoch 1/40] [Batch 162/196] [Batch classify loss: 1.115251]
[Epoch 1/40] [Batch 163/196] [Batch classify loss: 1.139821]
[Epoch 1/40] [Batch 164/196] [Batch classify loss: 1.110347]
[Epoch 1/40] [Batch 165/196] [Batch classify loss: 1.135224]
[Epoch 1/40] [Batch 166/196] [Batch classify loss: 1.127771]
[Epoch 1/40] [Batch 167/196] [Batch classify loss: 1.158333]
[Epoch 1/40] [Batch 168/196] [Batch classify loss: 1.171975]
[Epoch 1/40] [Batch 169/196] [Batch classify loss: 1.170922]
[Epoch 1/40] [Batch 170/196] [Batch classify loss: 1.134707]
[Epoch 1/40] [Batch 171/196] [Batch classify loss: 1.124116]
[Epoch 1/40] [Batch 172/196] [Batch classify loss: 1.156104]
[Epoch 1/40] [Batch 173/196] [Batch classify loss: 1.113985]
[Epoch 1/40] [Batch 174/196] [Batch classify loss: 1.192732]
[Epoch 1/40] [Batch 175/196] [Batch classify loss: 1.188313]
[Epoch 1/40] [Batch 176/196] [Batch classify loss: 1.096856]
[Epoch 1/40] [Batch 177/196] [Batch classify loss: 1.196192]
[Epoch 1/40] [Batch 178/196] [Batch classify loss: 1.070047]
[Epoch 1/40] [Batch 179/196] [Batch classify loss: 1.070822]
[Epoch 1/40] [Batch 180/196] [Batch classify loss: 1.174261]
[Epoch 1/40] [Batch 181/196] [Batch classify loss: 1.130751]
[Epoch 1/40] [Batch 182/196] [Batch classify loss: 1.127911]
[Epoch 1/40] [Batch 183/196] [Batch classify loss: 1.130880]
[Epoch 1/40] [Batch 184/196] [Batch classify loss: 1.145687]
[Epoch 1/40] [Batch 185/196] [Batch classify loss: 1.109513]
[Epoch 1/40] [Batch 186/196] [Batch classify loss: 1.101930]
[Epoch 1/40] [Batch 187/196] [Batch classify loss: 1.174397]
[Epoch 1/40] [Batch 188/196] [Batch classify loss: 1.177353]
[Epoch 1/40] [Batch 189/196] [Batch classify loss: 1.166622]
[Epoch 1/40] [Batch 190/196] [Batch classify loss: 1.172682]
[Epoch 1/40] [Batch 191/196] [Batch classify loss: 1.116291]
[Epoch 1/40] [Batch 192/196] [Batch classify loss: 1.200221]
[Epoch 1/40] [Batch 193/196] [Batch classify loss: 1.135441]
[Epoch 1/40] [Batch 194/196] [Batch classify loss: 1.144624]
[Epoch 1/40] [Batch 195/196] [Batch classify loss: 1.140512]
[Epoch 1/40] [Batch 196/196] [Batch classify loss: 1.586096]
0001 epoch rmt trained classifier accuary on the clean testing examples:75.2400%
0001 epoch rmt trained classifier loss on the clean testing examples:0.7993
0001 epoch rmt trained classifier accuary on adversarial testset:68.7200%
0001 epoch rmt trained classifier loss on adversarial testset:0.9554735422134399


1epoch learning rate:0.001
[Epoch 2/40] [Batch 1/196] [Batch classify loss: 1.084043]
[Epoch 2/40] [Batch 2/196] [Batch classify loss: 1.034156]
[Epoch 2/40] [Batch 3/196] [Batch classify loss: 1.120013]
[Epoch 2/40] [Batch 4/196] [Batch classify loss: 1.090440]
[Epoch 2/40] [Batch 5/196] [Batch classify loss: 1.099375]
[Epoch 2/40] [Batch 6/196] [Batch classify loss: 1.046316]
[Epoch 2/40] [Batch 7/196] [Batch classify loss: 1.029553]
[Epoch 2/40] [Batch 8/196] [Batch classify loss: 1.038875]
[Epoch 2/40] [Batch 9/196] [Batch classify loss: 1.095791]
[Epoch 2/40] [Batch 10/196] [Batch classify loss: 1.168127]
[Epoch 2/40] [Batch 11/196] [Batch classify loss: 1.056228]
[Epoch 2/40] [Batch 12/196] [Batch classify loss: 1.143445]
[Epoch 2/40] [Batch 13/196] [Batch classify loss: 1.057564]
[Epoch 2/40] [Batch 14/196] [Batch classify loss: 1.045923]
[Epoch 2/40] [Batch 15/196] [Batch classify loss: 1.109671]
[Epoch 2/40] [Batch 16/196] [Batch classify loss: 1.062717]
[Epoch 2/40] [Batch 17/196] [Batch classify loss: 1.001847]
[Epoch 2/40] [Batch 18/196] [Batch classify loss: 1.023257]
[Epoch 2/40] [Batch 19/196] [Batch classify loss: 1.024913]
[Epoch 2/40] [Batch 20/196] [Batch classify loss: 1.103662]
[Epoch 2/40] [Batch 21/196] [Batch classify loss: 1.114466]
[Epoch 2/40] [Batch 22/196] [Batch classify loss: 1.069353]
[Epoch 2/40] [Batch 23/196] [Batch classify loss: 1.094616]
[Epoch 2/40] [Batch 24/196] [Batch classify loss: 1.068496]
[Epoch 2/40] [Batch 25/196] [Batch classify loss: 1.069992]
[Epoch 2/40] [Batch 26/196] [Batch classify loss: 1.090919]
[Epoch 2/40] [Batch 27/196] [Batch classify loss: 1.110010]
[Epoch 2/40] [Batch 28/196] [Batch classify loss: 1.080710]
[Epoch 2/40] [Batch 29/196] [Batch classify loss: 1.041945]
[Epoch 2/40] [Batch 30/196] [Batch classify loss: 1.078840]
[Epoch 2/40] [Batch 31/196] [Batch classify loss: 1.069863]
[Epoch 2/40] [Batch 32/196] [Batch classify loss: 1.113341]
[Epoch 2/40] [Batch 33/196] [Batch classify loss: 1.107678]
[Epoch 2/40] [Batch 34/196] [Batch classify loss: 1.135725]
[Epoch 2/40] [Batch 35/196] [Batch classify loss: 1.074221]
[Epoch 2/40] [Batch 36/196] [Batch classify loss: 1.092083]
[Epoch 2/40] [Batch 37/196] [Batch classify loss: 1.091006]
[Epoch 2/40] [Batch 38/196] [Batch classify loss: 1.066907]
[Epoch 2/40] [Batch 39/196] [Batch classify loss: 1.033189]
[Epoch 2/40] [Batch 40/196] [Batch classify loss: 1.094868]
[Epoch 2/40] [Batch 41/196] [Batch classify loss: 1.089168]
[Epoch 2/40] [Batch 42/196] [Batch classify loss: 1.126432]
[Epoch 2/40] [Batch 43/196] [Batch classify loss: 1.084644]
[Epoch 2/40] [Batch 44/196] [Batch classify loss: 1.140476]
[Epoch 2/40] [Batch 45/196] [Batch classify loss: 1.094609]
[Epoch 2/40] [Batch 46/196] [Batch classify loss: 1.066872]
[Epoch 2/40] [Batch 47/196] [Batch classify loss: 1.111401]
[Epoch 2/40] [Batch 48/196] [Batch classify loss: 1.102082]
[Epoch 2/40] [Batch 49/196] [Batch classify loss: 1.104384]
[Epoch 2/40] [Batch 50/196] [Batch classify loss: 1.057563]
[Epoch 2/40] [Batch 51/196] [Batch classify loss: 1.166364]
[Epoch 2/40] [Batch 52/196] [Batch classify loss: 1.114513]
[Epoch 2/40] [Batch 53/196] [Batch classify loss: 1.088971]
[Epoch 2/40] [Batch 54/196] [Batch classify loss: 1.175900]
[Epoch 2/40] [Batch 55/196] [Batch classify loss: 1.121202]
[Epoch 2/40] [Batch 56/196] [Batch classify loss: 1.089860]
[Epoch 2/40] [Batch 57/196] [Batch classify loss: 1.048575]
[Epoch 2/40] [Batch 58/196] [Batch classify loss: 1.081970]
[Epoch 2/40] [Batch 59/196] [Batch classify loss: 1.071703]
[Epoch 2/40] [Batch 60/196] [Batch classify loss: 1.090806]
[Epoch 2/40] [Batch 61/196] [Batch classify loss: 1.013319]
[Epoch 2/40] [Batch 62/196] [Batch classify loss: 1.143095]
[Epoch 2/40] [Batch 63/196] [Batch classify loss: 1.099151]
[Epoch 2/40] [Batch 64/196] [Batch classify loss: 1.070180]
[Epoch 2/40] [Batch 65/196] [Batch classify loss: 1.053271]
[Epoch 2/40] [Batch 66/196] [Batch classify loss: 1.049768]
[Epoch 2/40] [Batch 67/196] [Batch classify loss: 1.073693]
[Epoch 2/40] [Batch 68/196] [Batch classify loss: 1.090220]
[Epoch 2/40] [Batch 69/196] [Batch classify loss: 1.163598]
[Epoch 2/40] [Batch 70/196] [Batch classify loss: 1.109896]
[Epoch 2/40] [Batch 71/196] [Batch classify loss: 1.111162]
[Epoch 2/40] [Batch 72/196] [Batch classify loss: 1.030997]
[Epoch 2/40] [Batch 73/196] [Batch classify loss: 1.093631]
[Epoch 2/40] [Batch 74/196] [Batch classify loss: 1.109964]
[Epoch 2/40] [Batch 75/196] [Batch classify loss: 1.164092]
[Epoch 2/40] [Batch 76/196] [Batch classify loss: 1.068809]
[Epoch 2/40] [Batch 77/196] [Batch classify loss: 1.012068]
[Epoch 2/40] [Batch 78/196] [Batch classify loss: 1.110378]
[Epoch 2/40] [Batch 79/196] [Batch classify loss: 1.145003]
[Epoch 2/40] [Batch 80/196] [Batch classify loss: 1.082570]
[Epoch 2/40] [Batch 81/196] [Batch classify loss: 1.147688]
[Epoch 2/40] [Batch 82/196] [Batch classify loss: 1.072346]
[Epoch 2/40] [Batch 83/196] [Batch classify loss: 1.109044]
[Epoch 2/40] [Batch 84/196] [Batch classify loss: 1.082464]
[Epoch 2/40] [Batch 85/196] [Batch classify loss: 1.060556]
[Epoch 2/40] [Batch 86/196] [Batch classify loss: 1.140436]
[Epoch 2/40] [Batch 87/196] [Batch classify loss: 1.122465]
[Epoch 2/40] [Batch 88/196] [Batch classify loss: 1.027504]
[Epoch 2/40] [Batch 89/196] [Batch classify loss: 1.136517]
[Epoch 2/40] [Batch 90/196] [Batch classify loss: 1.093065]
[Epoch 2/40] [Batch 91/196] [Batch classify loss: 1.156308]
[Epoch 2/40] [Batch 92/196] [Batch classify loss: 1.101090]
[Epoch 2/40] [Batch 93/196] [Batch classify loss: 1.136615]
[Epoch 2/40] [Batch 94/196] [Batch classify loss: 1.139276]
[Epoch 2/40] [Batch 95/196] [Batch classify loss: 1.108069]
[Epoch 2/40] [Batch 96/196] [Batch classify loss: 1.133370]
[Epoch 2/40] [Batch 97/196] [Batch classify loss: 1.194376]
[Epoch 2/40] [Batch 98/196] [Batch classify loss: 1.102707]
[Epoch 2/40] [Batch 99/196] [Batch classify loss: 1.144231]
[Epoch 2/40] [Batch 100/196] [Batch classify loss: 0.712447]
[Epoch 2/40] [Batch 101/196] [Batch classify loss: 1.046121]
[Epoch 2/40] [Batch 102/196] [Batch classify loss: 1.100055]
[Epoch 2/40] [Batch 103/196] [Batch classify loss: 1.054018]
[Epoch 2/40] [Batch 104/196] [Batch classify loss: 1.111210]
[Epoch 2/40] [Batch 105/196] [Batch classify loss: 1.069306]
[Epoch 2/40] [Batch 106/196] [Batch classify loss: 1.038692]
[Epoch 2/40] [Batch 107/196] [Batch classify loss: 1.051666]
[Epoch 2/40] [Batch 108/196] [Batch classify loss: 1.075680]
[Epoch 2/40] [Batch 109/196] [Batch classify loss: 1.038309]
[Epoch 2/40] [Batch 110/196] [Batch classify loss: 1.135062]
[Epoch 2/40] [Batch 111/196] [Batch classify loss: 1.120271]
[Epoch 2/40] [Batch 112/196] [Batch classify loss: 1.078221]
[Epoch 2/40] [Batch 113/196] [Batch classify loss: 1.085351]
[Epoch 2/40] [Batch 114/196] [Batch classify loss: 1.069849]
[Epoch 2/40] [Batch 115/196] [Batch classify loss: 1.099393]
[Epoch 2/40] [Batch 116/196] [Batch classify loss: 1.067332]
[Epoch 2/40] [Batch 117/196] [Batch classify loss: 1.068305]
[Epoch 2/40] [Batch 118/196] [Batch classify loss: 1.091032]
[Epoch 2/40] [Batch 119/196] [Batch classify loss: 1.070530]
[Epoch 2/40] [Batch 120/196] [Batch classify loss: 1.042588]
[Epoch 2/40] [Batch 121/196] [Batch classify loss: 1.120331]
[Epoch 2/40] [Batch 122/196] [Batch classify loss: 1.109405]
[Epoch 2/40] [Batch 123/196] [Batch classify loss: 1.073025]
[Epoch 2/40] [Batch 124/196] [Batch classify loss: 1.111120]
[Epoch 2/40] [Batch 125/196] [Batch classify loss: 1.081344]
[Epoch 2/40] [Batch 126/196] [Batch classify loss: 1.036328]
[Epoch 2/40] [Batch 127/196] [Batch classify loss: 1.139373]
[Epoch 2/40] [Batch 128/196] [Batch classify loss: 1.041322]
[Epoch 2/40] [Batch 129/196] [Batch classify loss: 1.087295]
[Epoch 2/40] [Batch 130/196] [Batch classify loss: 1.104587]
[Epoch 2/40] [Batch 131/196] [Batch classify loss: 1.131257]
[Epoch 2/40] [Batch 132/196] [Batch classify loss: 1.089281]
[Epoch 2/40] [Batch 133/196] [Batch classify loss: 1.110058]
[Epoch 2/40] [Batch 134/196] [Batch classify loss: 1.091318]
[Epoch 2/40] [Batch 135/196] [Batch classify loss: 1.018667]
[Epoch 2/40] [Batch 136/196] [Batch classify loss: 1.090728]
[Epoch 2/40] [Batch 137/196] [Batch classify loss: 1.082225]
[Epoch 2/40] [Batch 138/196] [Batch classify loss: 1.052011]
[Epoch 2/40] [Batch 139/196] [Batch classify loss: 1.058344]
[Epoch 2/40] [Batch 140/196] [Batch classify loss: 1.071470]
[Epoch 2/40] [Batch 141/196] [Batch classify loss: 1.088072]
[Epoch 2/40] [Batch 142/196] [Batch classify loss: 1.054729]
[Epoch 2/40] [Batch 143/196] [Batch classify loss: 1.144560]
[Epoch 2/40] [Batch 144/196] [Batch classify loss: 1.111046]
[Epoch 2/40] [Batch 145/196] [Batch classify loss: 1.050110]
[Epoch 2/40] [Batch 146/196] [Batch classify loss: 1.099157]
[Epoch 2/40] [Batch 147/196] [Batch classify loss: 1.122411]
[Epoch 2/40] [Batch 148/196] [Batch classify loss: 1.106815]
[Epoch 2/40] [Batch 149/196] [Batch classify loss: 1.073418]
[Epoch 2/40] [Batch 150/196] [Batch classify loss: 1.039690]
[Epoch 2/40] [Batch 151/196] [Batch classify loss: 1.122888]
[Epoch 2/40] [Batch 152/196] [Batch classify loss: 1.132524]
[Epoch 2/40] [Batch 153/196] [Batch classify loss: 1.072591]
[Epoch 2/40] [Batch 154/196] [Batch classify loss: 1.111515]
[Epoch 2/40] [Batch 155/196] [Batch classify loss: 1.077634]
[Epoch 2/40] [Batch 156/196] [Batch classify loss: 1.035858]
[Epoch 2/40] [Batch 157/196] [Batch classify loss: 1.082623]
[Epoch 2/40] [Batch 158/196] [Batch classify loss: 1.142475]
[Epoch 2/40] [Batch 159/196] [Batch classify loss: 1.148334]
[Epoch 2/40] [Batch 160/196] [Batch classify loss: 1.099174]
[Epoch 2/40] [Batch 161/196] [Batch classify loss: 1.028197]
[Epoch 2/40] [Batch 162/196] [Batch classify loss: 1.112016]
[Epoch 2/40] [Batch 163/196] [Batch classify loss: 1.076656]
[Epoch 2/40] [Batch 164/196] [Batch classify loss: 1.091116]
[Epoch 2/40] [Batch 165/196] [Batch classify loss: 1.072985]
[Epoch 2/40] [Batch 166/196] [Batch classify loss: 1.086302]
[Epoch 2/40] [Batch 167/196] [Batch classify loss: 1.065673]
[Epoch 2/40] [Batch 168/196] [Batch classify loss: 1.102878]
[Epoch 2/40] [Batch 169/196] [Batch classify loss: 1.124112]
[Epoch 2/40] [Batch 170/196] [Batch classify loss: 1.136491]
[Epoch 2/40] [Batch 171/196] [Batch classify loss: 1.146524]
[Epoch 2/40] [Batch 172/196] [Batch classify loss: 1.116676]
[Epoch 2/40] [Batch 173/196] [Batch classify loss: 1.099268]
[Epoch 2/40] [Batch 174/196] [Batch classify loss: 1.092608]
[Epoch 2/40] [Batch 175/196] [Batch classify loss: 1.107017]
[Epoch 2/40] [Batch 176/196] [Batch classify loss: 1.127571]
[Epoch 2/40] [Batch 177/196] [Batch classify loss: 1.085265]
[Epoch 2/40] [Batch 178/196] [Batch classify loss: 1.076607]
[Epoch 2/40] [Batch 179/196] [Batch classify loss: 1.167899]
[Epoch 2/40] [Batch 180/196] [Batch classify loss: 1.088717]
[Epoch 2/40] [Batch 181/196] [Batch classify loss: 1.096009]
[Epoch 2/40] [Batch 182/196] [Batch classify loss: 1.035383]
[Epoch 2/40] [Batch 183/196] [Batch classify loss: 1.132263]
[Epoch 2/40] [Batch 184/196] [Batch classify loss: 1.041831]
[Epoch 2/40] [Batch 185/196] [Batch classify loss: 1.097199]
[Epoch 2/40] [Batch 186/196] [Batch classify loss: 1.132601]
[Epoch 2/40] [Batch 187/196] [Batch classify loss: 1.124098]
[Epoch 2/40] [Batch 188/196] [Batch classify loss: 1.102413]
[Epoch 2/40] [Batch 189/196] [Batch classify loss: 1.128617]
[Epoch 2/40] [Batch 190/196] [Batch classify loss: 1.091930]
[Epoch 2/40] [Batch 191/196] [Batch classify loss: 1.131016]
[Epoch 2/40] [Batch 192/196] [Batch classify loss: 1.171420]
[Epoch 2/40] [Batch 193/196] [Batch classify loss: 1.154667]
[Epoch 2/40] [Batch 194/196] [Batch classify loss: 1.127364]
[Epoch 2/40] [Batch 195/196] [Batch classify loss: 1.109254]
[Epoch 2/40] [Batch 196/196] [Batch classify loss: 1.599379]
0002 epoch rmt trained classifier accuary on the clean testing examples:77.0300%
0002 epoch rmt trained classifier loss on the clean testing examples:0.7507
0002 epoch rmt trained classifier accuary on adversarial testset:70.6500%
0002 epoch rmt trained classifier loss on adversarial testset:0.9099173545837402


2epoch learning rate:0.001
[Epoch 3/40] [Batch 1/196] [Batch classify loss: 0.980976]
[Epoch 3/40] [Batch 2/196] [Batch classify loss: 0.946093]
[Epoch 3/40] [Batch 3/196] [Batch classify loss: 0.973725]
[Epoch 3/40] [Batch 4/196] [Batch classify loss: 0.941219]
[Epoch 3/40] [Batch 5/196] [Batch classify loss: 0.969106]
[Epoch 3/40] [Batch 6/196] [Batch classify loss: 0.985942]
[Epoch 3/40] [Batch 7/196] [Batch classify loss: 0.941795]
[Epoch 3/40] [Batch 8/196] [Batch classify loss: 0.952966]
[Epoch 3/40] [Batch 9/196] [Batch classify loss: 0.967334]
[Epoch 3/40] [Batch 10/196] [Batch classify loss: 1.053890]
[Epoch 3/40] [Batch 11/196] [Batch classify loss: 0.969537]
[Epoch 3/40] [Batch 12/196] [Batch classify loss: 1.032994]
[Epoch 3/40] [Batch 13/196] [Batch classify loss: 0.938116]
[Epoch 3/40] [Batch 14/196] [Batch classify loss: 0.999401]
[Epoch 3/40] [Batch 15/196] [Batch classify loss: 1.018029]
[Epoch 3/40] [Batch 16/196] [Batch classify loss: 1.070370]
[Epoch 3/40] [Batch 17/196] [Batch classify loss: 0.976025]
[Epoch 3/40] [Batch 18/196] [Batch classify loss: 0.971086]
[Epoch 3/40] [Batch 19/196] [Batch classify loss: 1.007397]
[Epoch 3/40] [Batch 20/196] [Batch classify loss: 1.056814]
[Epoch 3/40] [Batch 21/196] [Batch classify loss: 0.995026]
[Epoch 3/40] [Batch 22/196] [Batch classify loss: 1.028490]
[Epoch 3/40] [Batch 23/196] [Batch classify loss: 1.007808]
[Epoch 3/40] [Batch 24/196] [Batch classify loss: 1.021390]
[Epoch 3/40] [Batch 25/196] [Batch classify loss: 1.065102]
[Epoch 3/40] [Batch 26/196] [Batch classify loss: 0.978078]
[Epoch 3/40] [Batch 27/196] [Batch classify loss: 0.984591]
[Epoch 3/40] [Batch 28/196] [Batch classify loss: 1.025111]
[Epoch 3/40] [Batch 29/196] [Batch classify loss: 0.956598]
[Epoch 3/40] [Batch 30/196] [Batch classify loss: 1.046905]
[Epoch 3/40] [Batch 31/196] [Batch classify loss: 1.000200]
[Epoch 3/40] [Batch 32/196] [Batch classify loss: 1.031400]
[Epoch 3/40] [Batch 33/196] [Batch classify loss: 1.040446]
[Epoch 3/40] [Batch 34/196] [Batch classify loss: 1.031293]
[Epoch 3/40] [Batch 35/196] [Batch classify loss: 0.971596]
[Epoch 3/40] [Batch 36/196] [Batch classify loss: 1.005397]
[Epoch 3/40] [Batch 37/196] [Batch classify loss: 1.022943]
[Epoch 3/40] [Batch 38/196] [Batch classify loss: 1.021185]
[Epoch 3/40] [Batch 39/196] [Batch classify loss: 1.011294]
[Epoch 3/40] [Batch 40/196] [Batch classify loss: 0.964112]
[Epoch 3/40] [Batch 41/196] [Batch classify loss: 0.993116]
[Epoch 3/40] [Batch 42/196] [Batch classify loss: 1.048571]
[Epoch 3/40] [Batch 43/196] [Batch classify loss: 0.989797]
[Epoch 3/40] [Batch 44/196] [Batch classify loss: 0.984681]
[Epoch 3/40] [Batch 45/196] [Batch classify loss: 0.993542]
[Epoch 3/40] [Batch 46/196] [Batch classify loss: 0.998744]
[Epoch 3/40] [Batch 47/196] [Batch classify loss: 1.017608]
[Epoch 3/40] [Batch 48/196] [Batch classify loss: 1.016769]
[Epoch 3/40] [Batch 49/196] [Batch classify loss: 1.076623]
[Epoch 3/40] [Batch 50/196] [Batch classify loss: 0.990702]
[Epoch 3/40] [Batch 51/196] [Batch classify loss: 1.041772]
[Epoch 3/40] [Batch 52/196] [Batch classify loss: 0.966403]
[Epoch 3/40] [Batch 53/196] [Batch classify loss: 1.018436]
[Epoch 3/40] [Batch 54/196] [Batch classify loss: 1.074371]
[Epoch 3/40] [Batch 55/196] [Batch classify loss: 1.047459]
[Epoch 3/40] [Batch 56/196] [Batch classify loss: 0.999541]
[Epoch 3/40] [Batch 57/196] [Batch classify loss: 1.031477]
[Epoch 3/40] [Batch 58/196] [Batch classify loss: 0.981495]
[Epoch 3/40] [Batch 59/196] [Batch classify loss: 1.063856]
[Epoch 3/40] [Batch 60/196] [Batch classify loss: 1.036439]
[Epoch 3/40] [Batch 61/196] [Batch classify loss: 1.057329]
[Epoch 3/40] [Batch 62/196] [Batch classify loss: 1.092068]
[Epoch 3/40] [Batch 63/196] [Batch classify loss: 1.041965]
[Epoch 3/40] [Batch 64/196] [Batch classify loss: 1.089265]
[Epoch 3/40] [Batch 65/196] [Batch classify loss: 1.068767]
[Epoch 3/40] [Batch 66/196] [Batch classify loss: 1.090937]
[Epoch 3/40] [Batch 67/196] [Batch classify loss: 1.005465]
[Epoch 3/40] [Batch 68/196] [Batch classify loss: 1.033475]
[Epoch 3/40] [Batch 69/196] [Batch classify loss: 0.983244]
[Epoch 3/40] [Batch 70/196] [Batch classify loss: 1.058355]
[Epoch 3/40] [Batch 71/196] [Batch classify loss: 1.015347]
[Epoch 3/40] [Batch 72/196] [Batch classify loss: 1.034698]
[Epoch 3/40] [Batch 73/196] [Batch classify loss: 1.025769]
[Epoch 3/40] [Batch 74/196] [Batch classify loss: 0.988912]
