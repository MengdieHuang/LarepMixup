

---------------------------------------
Torch cuda is available
args.subcommand=run, run the command line
date: 20220224
blackbox attack
Experiment result save dir: /home/maggie/mmat/result/defense/rmt/autoattack/basemixup-betasampler/googlenet-cifar10/blackbox/20220224/00002
initilize the dataset loading parameters
load cifar10 dataset
Loading *cifar10* train dataloader finished !
Loading *cifar10* test dataloader finished !
initlize classifier
learned calssify model != None
args.adv_datasetï¼š /home/maggie/mmat/result/attack/autoattack/googlenet-cifar10/20220224/00000-eps0.1-acc4.18/attack-cifar10-dataset/samples
Accuary of before rmt trained classifier on clean testset:80.4500%
Loss of before mmat trained classifier clean testset:0.7182748913764954
args.mix_mode: basemixup
args.mix_w_num: 2
args.beta_alpha: 2.0
args.dirichlet_gama: 1
cle_w_train.shape: torch.Size([25397, 8, 512])
cle_y_train.shape: torch.Size([25397, 8])
cle_x_test.shape: torch.Size([10000, 3, 32, 32])
cle_y_test.shape: torch.Size([10000])
adv_x_test.shape: torch.Size([10000, 3, 32, 32])
adv_y_test.shape: torch.Size([10000])
cle_train_dataloader.len: 196
Accuary of before rmt trained classifier on adversarial testset:4.1800%
Loss of before mmat trained classifier on adversarial testset:10.201979637145996
w_trainset_len: 25397
batch_size: 256
w_batch_num: 100


0epoch learning rate:0.001
Setting up PyTorch plugin "bias_act_plugin"... /home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/utils/cpp_extension.py:286: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... /home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/utils/cpp_extension.py:286: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
Done.
[Epoch 1/40] [Batch 1/196] [Batch classify loss: 2.052255]
[Epoch 1/40] [Batch 2/196] [Batch classify loss: 1.895553]
[Epoch 1/40] [Batch 3/196] [Batch classify loss: 1.723211]
[Epoch 1/40] [Batch 4/196] [Batch classify loss: 1.611639]
[Epoch 1/40] [Batch 5/196] [Batch classify loss: 1.459375]
[Epoch 1/40] [Batch 6/196] [Batch classify loss: 1.372609]
[Epoch 1/40] [Batch 7/196] [Batch classify loss: 1.368206]
[Epoch 1/40] [Batch 8/196] [Batch classify loss: 1.356555]
[Epoch 1/40] [Batch 9/196] [Batch classify loss: 1.336075]
[Epoch 1/40] [Batch 10/196] [Batch classify loss: 1.329201]
[Epoch 1/40] [Batch 11/196] [Batch classify loss: 1.300427]
[Epoch 1/40] [Batch 12/196] [Batch classify loss: 1.331291]
[Epoch 1/40] [Batch 13/196] [Batch classify loss: 1.403774]
[Epoch 1/40] [Batch 14/196] [Batch classify loss: 1.274677]
[Epoch 1/40] [Batch 15/196] [Batch classify loss: 1.363436]
[Epoch 1/40] [Batch 16/196] [Batch classify loss: 1.245713]
[Epoch 1/40] [Batch 17/196] [Batch classify loss: 1.242008]
[Epoch 1/40] [Batch 18/196] [Batch classify loss: 1.241165]
[Epoch 1/40] [Batch 19/196] [Batch classify loss: 1.198856]
[Epoch 1/40] [Batch 20/196] [Batch classify loss: 1.187829]
[Epoch 1/40] [Batch 21/196] [Batch classify loss: 1.250955]
[Epoch 1/40] [Batch 22/196] [Batch classify loss: 1.196157]
[Epoch 1/40] [Batch 23/196] [Batch classify loss: 1.230488]
[Epoch 1/40] [Batch 24/196] [Batch classify loss: 1.192626]
[Epoch 1/40] [Batch 25/196] [Batch classify loss: 1.253152]
[Epoch 1/40] [Batch 26/196] [Batch classify loss: 1.227466]
[Epoch 1/40] [Batch 27/196] [Batch classify loss: 1.238575]
[Epoch 1/40] [Batch 28/196] [Batch classify loss: 1.196330]
[Epoch 1/40] [Batch 29/196] [Batch classify loss: 1.269254]
[Epoch 1/40] [Batch 30/196] [Batch classify loss: 1.228004]
[Epoch 1/40] [Batch 31/196] [Batch classify loss: 1.164485]
[Epoch 1/40] [Batch 32/196] [Batch classify loss: 1.261901]
[Epoch 1/40] [Batch 33/196] [Batch classify loss: 1.148035]
[Epoch 1/40] [Batch 34/196] [Batch classify loss: 1.110458]
[Epoch 1/40] [Batch 35/196] [Batch classify loss: 1.171490]
[Epoch 1/40] [Batch 36/196] [Batch classify loss: 1.224847]
[Epoch 1/40] [Batch 37/196] [Batch classify loss: 1.185541]
[Epoch 1/40] [Batch 38/196] [Batch classify loss: 1.076369]
[Epoch 1/40] [Batch 39/196] [Batch classify loss: 1.199112]
[Epoch 1/40] [Batch 40/196] [Batch classify loss: 1.179482]
[Epoch 1/40] [Batch 41/196] [Batch classify loss: 1.132538]
[Epoch 1/40] [Batch 42/196] [Batch classify loss: 1.149323]
[Epoch 1/40] [Batch 43/196] [Batch classify loss: 1.232583]
[Epoch 1/40] [Batch 44/196] [Batch classify loss: 1.207599]
[Epoch 1/40] [Batch 45/196] [Batch classify loss: 1.221721]
[Epoch 1/40] [Batch 46/196] [Batch classify loss: 1.163843]
[Epoch 1/40] [Batch 47/196] [Batch classify loss: 1.155410]
[Epoch 1/40] [Batch 48/196] [Batch classify loss: 1.150861]
[Epoch 1/40] [Batch 49/196] [Batch classify loss: 1.217017]
[Epoch 1/40] [Batch 50/196] [Batch classify loss: 1.126334]
[Epoch 1/40] [Batch 51/196] [Batch classify loss: 1.177566]
[Epoch 1/40] [Batch 52/196] [Batch classify loss: 1.184225]
[Epoch 1/40] [Batch 53/196] [Batch classify loss: 1.112200]
[Epoch 1/40] [Batch 54/196] [Batch classify loss: 1.277942]
[Epoch 1/40] [Batch 55/196] [Batch classify loss: 1.233544]
[Epoch 1/40] [Batch 56/196] [Batch classify loss: 1.200576]
[Epoch 1/40] [Batch 57/196] [Batch classify loss: 1.167533]
[Epoch 1/40] [Batch 58/196] [Batch classify loss: 1.225716]
[Epoch 1/40] [Batch 59/196] [Batch classify loss: 1.187179]
[Epoch 1/40] [Batch 60/196] [Batch classify loss: 1.169379]
[Epoch 1/40] [Batch 61/196] [Batch classify loss: 1.198737]
[Epoch 1/40] [Batch 62/196] [Batch classify loss: 1.185120]
[Epoch 1/40] [Batch 63/196] [Batch classify loss: 1.212631]
[Epoch 1/40] [Batch 64/196] [Batch classify loss: 1.153279]
[Epoch 1/40] [Batch 65/196] [Batch classify loss: 1.196124]
[Epoch 1/40] [Batch 66/196] [Batch classify loss: 1.155273]
[Epoch 1/40] [Batch 67/196] [Batch classify loss: 1.101242]
[Epoch 1/40] [Batch 68/196] [Batch classify loss: 1.285933]
[Epoch 1/40] [Batch 69/196] [Batch classify loss: 1.191503]
[Epoch 1/40] [Batch 70/196] [Batch classify loss: 1.186285]
[Epoch 1/40] [Batch 71/196] [Batch classify loss: 1.094240]
[Epoch 1/40] [Batch 72/196] [Batch classify loss: 1.127513]
[Epoch 1/40] [Batch 73/196] [Batch classify loss: 1.070604]
[Epoch 1/40] [Batch 74/196] [Batch classify loss: 1.134423]
[Epoch 1/40] [Batch 75/196] [Batch classify loss: 1.164708]
[Epoch 1/40] [Batch 76/196] [Batch classify loss: 1.128970]
[Epoch 1/40] [Batch 77/196] [Batch classify loss: 1.231802]
[Epoch 1/40] [Batch 78/196] [Batch classify loss: 1.104810]
[Epoch 1/40] [Batch 79/196] [Batch classify loss: 1.172691]
[Epoch 1/40] [Batch 80/196] [Batch classify loss: 1.232035]
[Epoch 1/40] [Batch 81/196] [Batch classify loss: 1.099337]
[Epoch 1/40] [Batch 82/196] [Batch classify loss: 1.160318]
[Epoch 1/40] [Batch 83/196] [Batch classify loss: 1.207989]
[Epoch 1/40] [Batch 84/196] [Batch classify loss: 1.102969]
[Epoch 1/40] [Batch 85/196] [Batch classify loss: 1.127865]
[Epoch 1/40] [Batch 86/196] [Batch classify loss: 1.200206]
[Epoch 1/40] [Batch 87/196] [Batch classify loss: 1.141283]
[Epoch 1/40] [Batch 88/196] [Batch classify loss: 1.200001]
[Epoch 1/40] [Batch 89/196] [Batch classify loss: 1.258055]
[Epoch 1/40] [Batch 90/196] [Batch classify loss: 1.150078]
[Epoch 1/40] [Batch 91/196] [Batch classify loss: 1.139573]
[Epoch 1/40] [Batch 92/196] [Batch classify loss: 1.118384]
[Epoch 1/40] [Batch 93/196] [Batch classify loss: 1.162742]
[Epoch 1/40] [Batch 94/196] [Batch classify loss: 1.094922]
[Epoch 1/40] [Batch 95/196] [Batch classify loss: 1.221901]
[Epoch 1/40] [Batch 96/196] [Batch classify loss: 1.207671]
[Epoch 1/40] [Batch 97/196] [Batch classify loss: 1.116362]
[Epoch 1/40] [Batch 98/196] [Batch classify loss: 1.149720]
[Epoch 1/40] [Batch 99/196] [Batch classify loss: 1.165166]
[Epoch 1/40] [Batch 100/196] [Batch classify loss: 0.761957]
[Epoch 1/40] [Batch 101/196] [Batch classify loss: 1.155815]
[Epoch 1/40] [Batch 102/196] [Batch classify loss: 1.131748]
[Epoch 1/40] [Batch 103/196] [Batch classify loss: 1.137103]
[Epoch 1/40] [Batch 104/196] [Batch classify loss: 1.158814]
[Epoch 1/40] [Batch 105/196] [Batch classify loss: 1.116494]
[Epoch 1/40] [Batch 106/196] [Batch classify loss: 1.201342]
[Epoch 1/40] [Batch 107/196] [Batch classify loss: 1.200974]
[Epoch 1/40] [Batch 108/196] [Batch classify loss: 1.157007]
[Epoch 1/40] [Batch 109/196] [Batch classify loss: 1.164548]
[Epoch 1/40] [Batch 110/196] [Batch classify loss: 1.183589]
[Epoch 1/40] [Batch 111/196] [Batch classify loss: 1.081648]
[Epoch 1/40] [Batch 112/196] [Batch classify loss: 1.131263]
[Epoch 1/40] [Batch 113/196] [Batch classify loss: 1.119087]
[Epoch 1/40] [Batch 114/196] [Batch classify loss: 1.149033]
[Epoch 1/40] [Batch 115/196] [Batch classify loss: 1.164928]
[Epoch 1/40] [Batch 116/196] [Batch classify loss: 1.132567]
[Epoch 1/40] [Batch 117/196] [Batch classify loss: 1.235737]
[Epoch 1/40] [Batch 118/196] [Batch classify loss: 1.161898]
[Epoch 1/40] [Batch 119/196] [Batch classify loss: 1.207275]
[Epoch 1/40] [Batch 120/196] [Batch classify loss: 1.194271]
[Epoch 1/40] [Batch 121/196] [Batch classify loss: 1.133794]
[Epoch 1/40] [Batch 122/196] [Batch classify loss: 1.092866]
[Epoch 1/40] [Batch 123/196] [Batch classify loss: 1.168656]
[Epoch 1/40] [Batch 124/196] [Batch classify loss: 1.122307]
[Epoch 1/40] [Batch 125/196] [Batch classify loss: 1.124699]
[Epoch 1/40] [Batch 126/196] [Batch classify loss: 1.216045]
[Epoch 1/40] [Batch 127/196] [Batch classify loss: 1.141101]
[Epoch 1/40] [Batch 128/196] [Batch classify loss: 1.193002]
[Epoch 1/40] [Batch 129/196] [Batch classify loss: 1.194996]
[Epoch 1/40] [Batch 130/196] [Batch classify loss: 1.110122]
[Epoch 1/40] [Batch 131/196] [Batch classify loss: 1.082563]
[Epoch 1/40] [Batch 132/196] [Batch classify loss: 1.185146]
[Epoch 1/40] [Batch 133/196] [Batch classify loss: 1.108583]
[Epoch 1/40] [Batch 134/196] [Batch classify loss: 1.094125]
[Epoch 1/40] [Batch 135/196] [Batch classify loss: 1.125053]
[Epoch 1/40] [Batch 136/196] [Batch classify loss: 1.145483]
[Epoch 1/40] [Batch 137/196] [Batch classify loss: 1.179778]
[Epoch 1/40] [Batch 138/196] [Batch classify loss: 1.154936]
[Epoch 1/40] [Batch 139/196] [Batch classify loss: 1.100076]
[Epoch 1/40] [Batch 140/196] [Batch classify loss: 1.148017]
[Epoch 1/40] [Batch 141/196] [Batch classify loss: 1.119763]
[Epoch 1/40] [Batch 142/196] [Batch classify loss: 1.138864]
[Epoch 1/40] [Batch 143/196] [Batch classify loss: 1.150364]
[Epoch 1/40] [Batch 144/196] [Batch classify loss: 1.095368]
[Epoch 1/40] [Batch 145/196] [Batch classify loss: 1.154139]
[Epoch 1/40] [Batch 146/196] [Batch classify loss: 1.179995]
[Epoch 1/40] [Batch 147/196] [Batch classify loss: 1.135151]
[Epoch 1/40] [Batch 148/196] [Batch classify loss: 1.125986]
[Epoch 1/40] [Batch 149/196] [Batch classify loss: 1.164668]
[Epoch 1/40] [Batch 150/196] [Batch classify loss: 1.191561]
[Epoch 1/40] [Batch 151/196] [Batch classify loss: 1.146623]
[Epoch 1/40] [Batch 152/196] [Batch classify loss: 1.172307]
[Epoch 1/40] [Batch 153/196] [Batch classify loss: 1.120994]
[Epoch 1/40] [Batch 154/196] [Batch classify loss: 1.141374]
[Epoch 1/40] [Batch 155/196] [Batch classify loss: 1.180723]
[Epoch 1/40] [Batch 156/196] [Batch classify loss: 1.231279]
[Epoch 1/40] [Batch 157/196] [Batch classify loss: 1.226113]
[Epoch 1/40] [Batch 158/196] [Batch classify loss: 1.168814]
[Epoch 1/40] [Batch 159/196] [Batch classify loss: 1.177420]
[Epoch 1/40] [Batch 160/196] [Batch classify loss: 1.129232]
[Epoch 1/40] [Batch 161/196] [Batch classify loss: 1.177391]
[Epoch 1/40] [Batch 162/196] [Batch classify loss: 1.102845]
[Epoch 1/40] [Batch 163/196] [Batch classify loss: 1.171428]
[Epoch 1/40] [Batch 164/196] [Batch classify loss: 1.180231]
[Epoch 1/40] [Batch 165/196] [Batch classify loss: 1.119047]
[Epoch 1/40] [Batch 166/196] [Batch classify loss: 1.072067]
[Epoch 1/40] [Batch 167/196] [Batch classify loss: 1.118907]
[Epoch 1/40] [Batch 168/196] [Batch classify loss: 1.111164]
[Epoch 1/40] [Batch 169/196] [Batch classify loss: 1.139052]
[Epoch 1/40] [Batch 170/196] [Batch classify loss: 1.195658]
[Epoch 1/40] [Batch 171/196] [Batch classify loss: 1.069298]
[Epoch 1/40] [Batch 172/196] [Batch classify loss: 1.131226]
[Epoch 1/40] [Batch 173/196] [Batch classify loss: 1.089029]
[Epoch 1/40] [Batch 174/196] [Batch classify loss: 1.179984]
[Epoch 1/40] [Batch 175/196] [Batch classify loss: 1.148981]
[Epoch 1/40] [Batch 176/196] [Batch classify loss: 1.222572]
[Epoch 1/40] [Batch 177/196] [Batch classify loss: 1.163966]
[Epoch 1/40] [Batch 178/196] [Batch classify loss: 1.204103]
[Epoch 1/40] [Batch 179/196] [Batch classify loss: 1.122883]
[Epoch 1/40] [Batch 180/196] [Batch classify loss: 1.197963]
[Epoch 1/40] [Batch 181/196] [Batch classify loss: 1.057502]
[Epoch 1/40] [Batch 182/196] [Batch classify loss: 1.183427]
[Epoch 1/40] [Batch 183/196] [Batch classify loss: 1.165841]
[Epoch 1/40] [Batch 184/196] [Batch classify loss: 1.111721]
[Epoch 1/40] [Batch 185/196] [Batch classify loss: 1.153089]
[Epoch 1/40] [Batch 186/196] [Batch classify loss: 1.217559]
[Epoch 1/40] [Batch 187/196] [Batch classify loss: 1.114817]
[Epoch 1/40] [Batch 188/196] [Batch classify loss: 1.172004]
[Epoch 1/40] [Batch 189/196] [Batch classify loss: 1.112887]
[Epoch 1/40] [Batch 190/196] [Batch classify loss: 1.152055]
[Epoch 1/40] [Batch 191/196] [Batch classify loss: 1.194872]
[Epoch 1/40] [Batch 192/196] [Batch classify loss: 1.204723]
[Epoch 1/40] [Batch 193/196] [Batch classify loss: 1.066074]
[Epoch 1/40] [Batch 194/196] [Batch classify loss: 1.127412]
[Epoch 1/40] [Batch 195/196] [Batch classify loss: 1.104053]
[Epoch 1/40] [Batch 196/196] [Batch classify loss: 1.590564]
0001 epoch rmt trained classifier accuary on the clean testing examples:74.9900%
0001 epoch rmt trained classifier loss on the clean testing examples:0.8491
0001 epoch rmt trained classifier accuary on adversarial testset:18.0900%
0001 epoch rmt trained classifier loss on adversarial testset:2.9007480144500732


1epoch learning rate:0.001
[Epoch 2/40] [Batch 1/196] [Batch classify loss: 1.129731]
[Epoch 2/40] [Batch 2/196] [Batch classify loss: 1.100142]
[Epoch 2/40] [Batch 3/196] [Batch classify loss: 1.118104]
[Epoch 2/40] [Batch 4/196] [Batch classify loss: 1.110792]
[Epoch 2/40] [Batch 5/196] [Batch classify loss: 1.103640]
[Epoch 2/40] [Batch 6/196] [Batch classify loss: 1.141464]
[Epoch 2/40] [Batch 7/196] [Batch classify loss: 1.101641]
[Epoch 2/40] [Batch 8/196] [Batch classify loss: 1.111877]
[Epoch 2/40] [Batch 9/196] [Batch classify loss: 1.145874]
[Epoch 2/40] [Batch 10/196] [Batch classify loss: 1.093907]
[Epoch 2/40] [Batch 11/196] [Batch classify loss: 1.102757]
[Epoch 2/40] [Batch 12/196] [Batch classify loss: 1.102700]
[Epoch 2/40] [Batch 13/196] [Batch classify loss: 1.082821]
[Epoch 2/40] [Batch 14/196] [Batch classify loss: 1.075002]
[Epoch 2/40] [Batch 15/196] [Batch classify loss: 1.023309]
[Epoch 2/40] [Batch 16/196] [Batch classify loss: 1.079755]
[Epoch 2/40] [Batch 17/196] [Batch classify loss: 1.127323]
[Epoch 2/40] [Batch 18/196] [Batch classify loss: 1.108812]
[Epoch 2/40] [Batch 19/196] [Batch classify loss: 1.156278]
[Epoch 2/40] [Batch 20/196] [Batch classify loss: 1.021351]
[Epoch 2/40] [Batch 21/196] [Batch classify loss: 1.081899]
[Epoch 2/40] [Batch 22/196] [Batch classify loss: 1.114135]
[Epoch 2/40] [Batch 23/196] [Batch classify loss: 1.065049]
[Epoch 2/40] [Batch 24/196] [Batch classify loss: 1.074237]
[Epoch 2/40] [Batch 25/196] [Batch classify loss: 1.074197]
[Epoch 2/40] [Batch 26/196] [Batch classify loss: 1.033973]
[Epoch 2/40] [Batch 27/196] [Batch classify loss: 1.087938]
[Epoch 2/40] [Batch 28/196] [Batch classify loss: 1.141029]
[Epoch 2/40] [Batch 29/196] [Batch classify loss: 1.064092]
[Epoch 2/40] [Batch 30/196] [Batch classify loss: 1.162451]
[Epoch 2/40] [Batch 31/196] [Batch classify loss: 1.163031]
[Epoch 2/40] [Batch 32/196] [Batch classify loss: 1.085446]
[Epoch 2/40] [Batch 33/196] [Batch classify loss: 1.055039]
[Epoch 2/40] [Batch 34/196] [Batch classify loss: 1.081120]
[Epoch 2/40] [Batch 35/196] [Batch classify loss: 1.095579]
[Epoch 2/40] [Batch 36/196] [Batch classify loss: 1.127397]
[Epoch 2/40] [Batch 37/196] [Batch classify loss: 1.100023]
[Epoch 2/40] [Batch 38/196] [Batch classify loss: 1.101333]
[Epoch 2/40] [Batch 39/196] [Batch classify loss: 1.006401]
[Epoch 2/40] [Batch 40/196] [Batch classify loss: 1.074756]
[Epoch 2/40] [Batch 41/196] [Batch classify loss: 1.100399]
[Epoch 2/40] [Batch 42/196] [Batch classify loss: 1.072577]
[Epoch 2/40] [Batch 43/196] [Batch classify loss: 1.136932]
[Epoch 2/40] [Batch 44/196] [Batch classify loss: 1.055314]
[Epoch 2/40] [Batch 45/196] [Batch classify loss: 1.098824]
[Epoch 2/40] [Batch 46/196] [Batch classify loss: 1.065312]
[Epoch 2/40] [Batch 47/196] [Batch classify loss: 1.044787]
[Epoch 2/40] [Batch 48/196] [Batch classify loss: 1.034649]
[Epoch 2/40] [Batch 49/196] [Batch classify loss: 1.082724]
[Epoch 2/40] [Batch 50/196] [Batch classify loss: 1.054910]
[Epoch 2/40] [Batch 51/196] [Batch classify loss: 1.083532]
[Epoch 2/40] [Batch 52/196] [Batch classify loss: 1.126539]
[Epoch 2/40] [Batch 53/196] [Batch classify loss: 1.128030]
[Epoch 2/40] [Batch 54/196] [Batch classify loss: 1.162700]
[Epoch 2/40] [Batch 55/196] [Batch classify loss: 1.111242]
[Epoch 2/40] [Batch 56/196] [Batch classify loss: 1.101267]
[Epoch 2/40] [Batch 57/196] [Batch classify loss: 1.081422]
[Epoch 2/40] [Batch 58/196] [Batch classify loss: 1.130722]
[Epoch 2/40] [Batch 59/196] [Batch classify loss: 1.061176]
[Epoch 2/40] [Batch 60/196] [Batch classify loss: 1.023897]
[Epoch 2/40] [Batch 61/196] [Batch classify loss: 1.092818]
[Epoch 2/40] [Batch 62/196] [Batch classify loss: 1.117742]
[Epoch 2/40] [Batch 63/196] [Batch classify loss: 1.199046]
[Epoch 2/40] [Batch 64/196] [Batch classify loss: 1.090940]
[Epoch 2/40] [Batch 65/196] [Batch classify loss: 1.163502]
[Epoch 2/40] [Batch 66/196] [Batch classify loss: 1.116519]
[Epoch 2/40] [Batch 67/196] [Batch classify loss: 1.110737]
[Epoch 2/40] [Batch 68/196] [Batch classify loss: 1.107484]
[Epoch 2/40] [Batch 69/196] [Batch classify loss: 1.172489]
[Epoch 2/40] [Batch 70/196] [Batch classify loss: 1.131971]
[Epoch 2/40] [Batch 71/196] [Batch classify loss: 1.184980]
[Epoch 2/40] [Batch 72/196] [Batch classify loss: 1.060975]
[Epoch 2/40] [Batch 73/196] [Batch classify loss: 1.108248]
[Epoch 2/40] [Batch 74/196] [Batch classify loss: 1.208036]
[Epoch 2/40] [Batch 75/196] [Batch classify loss: 1.094342]
[Epoch 2/40] [Batch 76/196] [Batch classify loss: 1.141679]
[Epoch 2/40] [Batch 77/196] [Batch classify loss: 1.117318]
[Epoch 2/40] [Batch 78/196] [Batch classify loss: 1.079740]
[Epoch 2/40] [Batch 79/196] [Batch classify loss: 1.094902]
[Epoch 2/40] [Batch 80/196] [Batch classify loss: 1.097518]
[Epoch 2/40] [Batch 81/196] [Batch classify loss: 1.081758]
[Epoch 2/40] [Batch 82/196] [Batch classify loss: 1.088764]
[Epoch 2/40] [Batch 83/196] [Batch classify loss: 1.187536]
[Epoch 2/40] [Batch 84/196] [Batch classify loss: 1.109523]
[Epoch 2/40] [Batch 85/196] [Batch classify loss: 1.072192]
[Epoch 2/40] [Batch 86/196] [Batch classify loss: 1.157187]
[Epoch 2/40] [Batch 87/196] [Batch classify loss: 1.059192]
[Epoch 2/40] [Batch 88/196] [Batch classify loss: 1.114178]
[Epoch 2/40] [Batch 89/196] [Batch classify loss: 1.073591]
[Epoch 2/40] [Batch 90/196] [Batch classify loss: 1.059161]
[Epoch 2/40] [Batch 91/196] [Batch classify loss: 1.094611]
[Epoch 2/40] [Batch 92/196] [Batch classify loss: 1.083023]
[Epoch 2/40] [Batch 93/196] [Batch classify loss: 1.022763]
[Epoch 2/40] [Batch 94/196] [Batch classify loss: 1.075769]
[Epoch 2/40] [Batch 95/196] [Batch classify loss: 1.069647]
[Epoch 2/40] [Batch 96/196] [Batch classify loss: 1.121961]
[Epoch 2/40] [Batch 97/196] [Batch classify loss: 1.191279]
[Epoch 2/40] [Batch 98/196] [Batch classify loss: 1.147831]
[Epoch 2/40] [Batch 99/196] [Batch classify loss: 1.180628]
[Epoch 2/40] [Batch 100/196] [Batch classify loss: 0.695672]
[Epoch 2/40] [Batch 101/196] [Batch classify loss: 1.058374]
[Epoch 2/40] [Batch 102/196] [Batch classify loss: 1.084300]
[Epoch 2/40] [Batch 103/196] [Batch classify loss: 1.077683]
[Epoch 2/40] [Batch 104/196] [Batch classify loss: 1.120773]
[Epoch 2/40] [Batch 105/196] [Batch classify loss: 1.132493]
[Epoch 2/40] [Batch 106/196] [Batch classify loss: 1.095435]
[Epoch 2/40] [Batch 107/196] [Batch classify loss: 1.051110]
[Epoch 2/40] [Batch 108/196] [Batch classify loss: 1.100724]
[Epoch 2/40] [Batch 109/196] [Batch classify loss: 1.052386]
[Epoch 2/40] [Batch 110/196] [Batch classify loss: 1.041708]
[Epoch 2/40] [Batch 111/196] [Batch classify loss: 1.102451]
[Epoch 2/40] [Batch 112/196] [Batch classify loss: 1.046935]
[Epoch 2/40] [Batch 113/196] [Batch classify loss: 1.111843]
[Epoch 2/40] [Batch 114/196] [Batch classify loss: 1.096746]
[Epoch 2/40] [Batch 115/196] [Batch classify loss: 1.108238]
[Epoch 2/40] [Batch 116/196] [Batch classify loss: 1.068331]
[Epoch 2/40] [Batch 117/196] [Batch classify loss: 1.117776]
[Epoch 2/40] [Batch 118/196] [Batch classify loss: 1.115256]
[Epoch 2/40] [Batch 119/196] [Batch classify loss: 1.130261]
[Epoch 2/40] [Batch 120/196] [Batch classify loss: 1.115727]
[Epoch 2/40] [Batch 121/196] [Batch classify loss: 1.112259]
[Epoch 2/40] [Batch 122/196] [Batch classify loss: 1.094794]
[Epoch 2/40] [Batch 123/196] [Batch classify loss: 1.047829]
[Epoch 2/40] [Batch 124/196] [Batch classify loss: 1.092693]
[Epoch 2/40] [Batch 125/196] [Batch classify loss: 1.135607]
[Epoch 2/40] [Batch 126/196] [Batch classify loss: 1.085606]
[Epoch 2/40] [Batch 127/196] [Batch classify loss: 1.063412]
[Epoch 2/40] [Batch 128/196] [Batch classify loss: 1.045884]
[Epoch 2/40] [Batch 129/196] [Batch classify loss: 1.139556]
[Epoch 2/40] [Batch 130/196] [Batch classify loss: 1.061788]
[Epoch 2/40] [Batch 131/196] [Batch classify loss: 1.125329]
[Epoch 2/40] [Batch 132/196] [Batch classify loss: 1.087371]
[Epoch 2/40] [Batch 133/196] [Batch classify loss: 1.093751]
[Epoch 2/40] [Batch 134/196] [Batch classify loss: 1.020075]
[Epoch 2/40] [Batch 135/196] [Batch classify loss: 1.110832]
[Epoch 2/40] [Batch 136/196] [Batch classify loss: 1.078814]
[Epoch 2/40] [Batch 137/196] [Batch classify loss: 1.075410]
[Epoch 2/40] [Batch 138/196] [Batch classify loss: 1.111597]
[Epoch 2/40] [Batch 139/196] [Batch classify loss: 1.070572]
[Epoch 2/40] [Batch 140/196] [Batch classify loss: 1.143566]
[Epoch 2/40] [Batch 141/196] [Batch classify loss: 1.095230]
[Epoch 2/40] [Batch 142/196] [Batch classify loss: 1.142955]
[Epoch 2/40] [Batch 143/196] [Batch classify loss: 1.160521]
[Epoch 2/40] [Batch 144/196] [Batch classify loss: 1.069205]
[Epoch 2/40] [Batch 145/196] [Batch classify loss: 1.128530]
[Epoch 2/40] [Batch 146/196] [Batch classify loss: 1.176480]
[Epoch 2/40] [Batch 147/196] [Batch classify loss: 1.070357]
[Epoch 2/40] [Batch 148/196] [Batch classify loss: 1.143750]
[Epoch 2/40] [Batch 149/196] [Batch classify loss: 1.099545]
[Epoch 2/40] [Batch 150/196] [Batch classify loss: 1.034824]
[Epoch 2/40] [Batch 151/196] [Batch classify loss: 1.124648]
[Epoch 2/40] [Batch 152/196] [Batch classify loss: 1.094276]
[Epoch 2/40] [Batch 153/196] [Batch classify loss: 1.090776]
[Epoch 2/40] [Batch 154/196] [Batch classify loss: 1.134367]
[Epoch 2/40] [Batch 155/196] [Batch classify loss: 1.127457]
[Epoch 2/40] [Batch 156/196] [Batch classify loss: 1.041593]
[Epoch 2/40] [Batch 157/196] [Batch classify loss: 1.080331]
[Epoch 2/40] [Batch 158/196] [Batch classify loss: 1.039751]
[Epoch 2/40] [Batch 159/196] [Batch classify loss: 1.046349]
[Epoch 2/40] [Batch 160/196] [Batch classify loss: 1.039173]
[Epoch 2/40] [Batch 161/196] [Batch classify loss: 1.103820]
[Epoch 2/40] [Batch 162/196] [Batch classify loss: 1.113647]
[Epoch 2/40] [Batch 163/196] [Batch classify loss: 1.066301]
[Epoch 2/40] [Batch 164/196] [Batch classify loss: 1.089609]
[Epoch 2/40] [Batch 165/196] [Batch classify loss: 1.129473]
[Epoch 2/40] [Batch 166/196] [Batch classify loss: 1.088875]
[Epoch 2/40] [Batch 167/196] [Batch classify loss: 1.079676]
[Epoch 2/40] [Batch 168/196] [Batch classify loss: 1.022246]
[Epoch 2/40] [Batch 169/196] [Batch classify loss: 1.110685]
[Epoch 2/40] [Batch 170/196] [Batch classify loss: 1.084288]
[Epoch 2/40] [Batch 171/196] [Batch classify loss: 1.152458]
[Epoch 2/40] [Batch 172/196] [Batch classify loss: 1.080521]
[Epoch 2/40] [Batch 173/196] [Batch classify loss: 1.105054]
[Epoch 2/40] [Batch 174/196] [Batch classify loss: 1.148551]
[Epoch 2/40] [Batch 175/196] [Batch classify loss: 1.135130]
[Epoch 2/40] [Batch 176/196] [Batch classify loss: 1.105031]
[Epoch 2/40] [Batch 177/196] [Batch classify loss: 1.046749]
[Epoch 2/40] [Batch 178/196] [Batch classify loss: 1.109298]
[Epoch 2/40] [Batch 179/196] [Batch classify loss: 1.117577]
[Epoch 2/40] [Batch 180/196] [Batch classify loss: 1.159736]
[Epoch 2/40] [Batch 181/196] [Batch classify loss: 1.078935]
[Epoch 2/40] [Batch 182/196] [Batch classify loss: 1.083230]
[Epoch 2/40] [Batch 183/196] [Batch classify loss: 1.097081]
[Epoch 2/40] [Batch 184/196] [Batch classify loss: 1.106925]
