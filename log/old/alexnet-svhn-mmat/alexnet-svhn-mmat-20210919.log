

---------------------------------------
Torch cuda is available
args.subcommand=run, run the command line
date: 20210919
Experiment result save dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002
initilize the dataset loading parameters
Using downloaded and verified file: /home/data/maggie/svhn/train_32x32.mat
Loading *svhn* train dataloader finished !
Loading *svhn* test dataloader finished !
initlize classifier
learned calssify model != None
standard trained classifier *accuary* on adversarial testset:40.0392%
standard trained classifier *accuary* on clean testset:94.7257%
gen_network_pkl:  abc test
load mixed sampels from /home/maggie/mmat/result/interpolate/2mixup/basemixup/uniformsampler/stylegan2ada-svhn/20210917/00000/generate-svhn-trainset
cle_x_test.shape: torch.Size([26032, 3, 32, 32])
cle_y_test.shape: torch.Size([26032])
only using clean samples
aug_x_train.shape: (70000, 3, 32, 32)
aug_y_train.shape: (70000, 10)
use 70000/70000 clean sampels，0/70000 mixed samples
/home/maggie/mmat/clamodels/classifier.py:913: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._adv_test_tensorset_x = torch.tensor(x_test_adv)
/home/maggie/mmat/clamodels/classifier.py:914: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._adv_test_tensorset_y = torch.tensor(y_test_adv)
/home/maggie/mmat/clamodels/classifier.py:916: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._cle_test_tensorset_x = torch.tensor(cle_x_test)
/home/maggie/mmat/clamodels/classifier.py:917: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._cle_test_tensorset_y = torch.tensor(cle_y_test)
self._train_tensorset_x.shape: torch.Size([70000, 3, 32, 32])
self._train_tensorset_y.shape: torch.Size([70000, 10])
self._adv_test_tensorset_x.shape: torch.Size([26032, 3, 32, 32])
self._adv_test_tensorset_y.shape: torch.Size([26032])
self._cle_test_tensorset_x.shape: torch.Size([26032, 3, 32, 32])
self._cle_test_tensorset_y.shape: torch.Size([26032])
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
before mmat trained classifier accuary on adversarial testset:40.3273%
before mmat trained classifier loss on adversarial testset:4.5237650871276855
0epoch learning rate:0.01
[Epoch 1/20] [Batch 1/274] [Batch classify loss: 0.034327] 
[Epoch 1/20] [Batch 2/274] [Batch classify loss: 0.074140] 
[Epoch 1/20] [Batch 3/274] [Batch classify loss: 0.064005] 
[Epoch 1/20] [Batch 4/274] [Batch classify loss: 0.071525] 
[Epoch 1/20] [Batch 5/274] [Batch classify loss: 0.073671] 
[Epoch 1/20] [Batch 6/274] [Batch classify loss: 0.071161] 
[Epoch 1/20] [Batch 7/274] [Batch classify loss: 0.030040] 
[Epoch 1/20] [Batch 8/274] [Batch classify loss: 0.078403] 
[Epoch 1/20] [Batch 9/274] [Batch classify loss: 0.030499] 
[Epoch 1/20] [Batch 10/274] [Batch classify loss: 0.042483] 
[Epoch 1/20] [Batch 11/274] [Batch classify loss: 0.130792] 
[Epoch 1/20] [Batch 12/274] [Batch classify loss: 0.035020] 
[Epoch 1/20] [Batch 13/274] [Batch classify loss: 0.031637] 
[Epoch 1/20] [Batch 14/274] [Batch classify loss: 0.021978] 
[Epoch 1/20] [Batch 15/274] [Batch classify loss: 0.074116] 
[Epoch 1/20] [Batch 16/274] [Batch classify loss: 0.018313] 
[Epoch 1/20] [Batch 17/274] [Batch classify loss: 0.098396] 
[Epoch 1/20] [Batch 18/274] [Batch classify loss: 0.062398] 
[Epoch 1/20] [Batch 19/274] [Batch classify loss: 0.093250] 
[Epoch 1/20] [Batch 20/274] [Batch classify loss: 0.055551] 
[Epoch 1/20] [Batch 21/274] [Batch classify loss: 0.065981] 
[Epoch 1/20] [Batch 22/274] [Batch classify loss: 0.042280] 
[Epoch 1/20] [Batch 23/274] [Batch classify loss: 0.044638] 
[Epoch 1/20] [Batch 24/274] [Batch classify loss: 0.034700] 
[Epoch 1/20] [Batch 25/274] [Batch classify loss: 0.077469] 
[Epoch 1/20] [Batch 26/274] [Batch classify loss: 0.031591] 
[Epoch 1/20] [Batch 27/274] [Batch classify loss: 0.066977] 
[Epoch 1/20] [Batch 28/274] [Batch classify loss: 0.049763] 
[Epoch 1/20] [Batch 29/274] [Batch classify loss: 0.062700] 
[Epoch 1/20] [Batch 30/274] [Batch classify loss: 0.022344] 
[Epoch 1/20] [Batch 31/274] [Batch classify loss: 0.065588] 
[Epoch 1/20] [Batch 32/274] [Batch classify loss: 0.022838] 
[Epoch 1/20] [Batch 33/274] [Batch classify loss: 0.034728] 
[Epoch 1/20] [Batch 34/274] [Batch classify loss: 0.031266] 
[Epoch 1/20] [Batch 35/274] [Batch classify loss: 0.044255] 
[Epoch 1/20] [Batch 36/274] [Batch classify loss: 0.060631] 
[Epoch 1/20] [Batch 37/274] [Batch classify loss: 0.025310] 
[Epoch 1/20] [Batch 38/274] [Batch classify loss: 0.040798] 
[Epoch 1/20] [Batch 39/274] [Batch classify loss: 0.038190] 
[Epoch 1/20] [Batch 40/274] [Batch classify loss: 0.069697] 
[Epoch 1/20] [Batch 41/274] [Batch classify loss: 0.081383] 
[Epoch 1/20] [Batch 42/274] [Batch classify loss: 0.069865] 
[Epoch 1/20] [Batch 43/274] [Batch classify loss: 0.069371] 
[Epoch 1/20] [Batch 44/274] [Batch classify loss: 0.085976] 
[Epoch 1/20] [Batch 45/274] [Batch classify loss: 0.089286] 
[Epoch 1/20] [Batch 46/274] [Batch classify loss: 0.026250] 
[Epoch 1/20] [Batch 47/274] [Batch classify loss: 0.050289] 
[Epoch 1/20] [Batch 48/274] [Batch classify loss: 0.037518] 
[Epoch 1/20] [Batch 49/274] [Batch classify loss: 0.043818] 
[Epoch 1/20] [Batch 50/274] [Batch classify loss: 0.019992] 
[Epoch 1/20] [Batch 51/274] [Batch classify loss: 0.073038] 
[Epoch 1/20] [Batch 52/274] [Batch classify loss: 0.049769] 
[Epoch 1/20] [Batch 53/274] [Batch classify loss: 0.033593] 
[Epoch 1/20] [Batch 54/274] [Batch classify loss: 0.032483] 
[Epoch 1/20] [Batch 55/274] [Batch classify loss: 0.035138] 
[Epoch 1/20] [Batch 56/274] [Batch classify loss: 0.076008] 
[Epoch 1/20] [Batch 57/274] [Batch classify loss: 0.075679] 
[Epoch 1/20] [Batch 58/274] [Batch classify loss: 0.087262] 
[Epoch 1/20] [Batch 59/274] [Batch classify loss: 0.073501] 
[Epoch 1/20] [Batch 60/274] [Batch classify loss: 0.025876] 
[Epoch 1/20] [Batch 61/274] [Batch classify loss: 0.039099] 
[Epoch 1/20] [Batch 62/274] [Batch classify loss: 0.107211] 
[Epoch 1/20] [Batch 63/274] [Batch classify loss: 0.067070] 
[Epoch 1/20] [Batch 64/274] [Batch classify loss: 0.036423] 
[Epoch 1/20] [Batch 65/274] [Batch classify loss: 0.087792] 
[Epoch 1/20] [Batch 66/274] [Batch classify loss: 0.041167] 
[Epoch 1/20] [Batch 67/274] [Batch classify loss: 0.050736] 
[Epoch 1/20] [Batch 68/274] [Batch classify loss: 0.042991] 
[Epoch 1/20] [Batch 69/274] [Batch classify loss: 0.031947] 
[Epoch 1/20] [Batch 70/274] [Batch classify loss: 0.099555] 
[Epoch 1/20] [Batch 71/274] [Batch classify loss: 0.038977] 
[Epoch 1/20] [Batch 72/274] [Batch classify loss: 0.089612] 
[Epoch 1/20] [Batch 73/274] [Batch classify loss: 0.025905] 
[Epoch 1/20] [Batch 74/274] [Batch classify loss: 0.079250] 
[Epoch 1/20] [Batch 75/274] [Batch classify loss: 0.056216] 
[Epoch 1/20] [Batch 76/274] [Batch classify loss: 0.030256] 
[Epoch 1/20] [Batch 77/274] [Batch classify loss: 0.055680] 
[Epoch 1/20] [Batch 78/274] [Batch classify loss: 0.049238] 
[Epoch 1/20] [Batch 79/274] [Batch classify loss: 0.061279] 
[Epoch 1/20] [Batch 80/274] [Batch classify loss: 0.064138] 
[Epoch 1/20] [Batch 81/274] [Batch classify loss: 0.044047] 
[Epoch 1/20] [Batch 82/274] [Batch classify loss: 0.020429] 
[Epoch 1/20] [Batch 83/274] [Batch classify loss: 0.076308] 
[Epoch 1/20] [Batch 84/274] [Batch classify loss: 0.075634] 
[Epoch 1/20] [Batch 85/274] [Batch classify loss: 0.039736] 
[Epoch 1/20] [Batch 86/274] [Batch classify loss: 0.068805] 
[Epoch 1/20] [Batch 87/274] [Batch classify loss: 0.047054] 
[Epoch 1/20] [Batch 88/274] [Batch classify loss: 0.076618] 
[Epoch 1/20] [Batch 89/274] [Batch classify loss: 0.047723] 
[Epoch 1/20] [Batch 90/274] [Batch classify loss: 0.095738] 
[Epoch 1/20] [Batch 91/274] [Batch classify loss: 0.042523] 
[Epoch 1/20] [Batch 92/274] [Batch classify loss: 0.072241] 
[Epoch 1/20] [Batch 93/274] [Batch classify loss: 0.014698] 
[Epoch 1/20] [Batch 94/274] [Batch classify loss: 0.019344] 
[Epoch 1/20] [Batch 95/274] [Batch classify loss: 0.025442] 
[Epoch 1/20] [Batch 96/274] [Batch classify loss: 0.062161] 
[Epoch 1/20] [Batch 97/274] [Batch classify loss: 0.048447] 
[Epoch 1/20] [Batch 98/274] [Batch classify loss: 0.044888] 
[Epoch 1/20] [Batch 99/274] [Batch classify loss: 0.100711] 
[Epoch 1/20] [Batch 100/274] [Batch classify loss: 0.112002] 
[Epoch 1/20] [Batch 101/274] [Batch classify loss: 0.035821] 
[Epoch 1/20] [Batch 102/274] [Batch classify loss: 0.071086] 
[Epoch 1/20] [Batch 103/274] [Batch classify loss: 0.107141] 
[Epoch 1/20] [Batch 104/274] [Batch classify loss: 0.046858] 
[Epoch 1/20] [Batch 105/274] [Batch classify loss: 0.062702] 
[Epoch 1/20] [Batch 106/274] [Batch classify loss: 0.071107] 
[Epoch 1/20] [Batch 107/274] [Batch classify loss: 0.114143] 
[Epoch 1/20] [Batch 108/274] [Batch classify loss: 0.023721] 
[Epoch 1/20] [Batch 109/274] [Batch classify loss: 0.070572] 
[Epoch 1/20] [Batch 110/274] [Batch classify loss: 0.090836] 
[Epoch 1/20] [Batch 111/274] [Batch classify loss: 0.090214] 
[Epoch 1/20] [Batch 112/274] [Batch classify loss: 0.061652] 
[Epoch 1/20] [Batch 113/274] [Batch classify loss: 0.064669] 
[Epoch 1/20] [Batch 114/274] [Batch classify loss: 0.028587] 
[Epoch 1/20] [Batch 115/274] [Batch classify loss: 0.068652] 
[Epoch 1/20] [Batch 116/274] [Batch classify loss: 0.032177] 
[Epoch 1/20] [Batch 117/274] [Batch classify loss: 0.105924] 
[Epoch 1/20] [Batch 118/274] [Batch classify loss: 0.045624] 
[Epoch 1/20] [Batch 119/274] [Batch classify loss: 0.048399] 
[Epoch 1/20] [Batch 120/274] [Batch classify loss: 0.146959] 
[Epoch 1/20] [Batch 121/274] [Batch classify loss: 0.031279] 
[Epoch 1/20] [Batch 122/274] [Batch classify loss: 0.057304] 
[Epoch 1/20] [Batch 123/274] [Batch classify loss: 0.044933] 
[Epoch 1/20] [Batch 124/274] [Batch classify loss: 0.036201] 
[Epoch 1/20] [Batch 125/274] [Batch classify loss: 0.085524] 
[Epoch 1/20] [Batch 126/274] [Batch classify loss: 0.068805] 
[Epoch 1/20] [Batch 127/274] [Batch classify loss: 0.020581] 
[Epoch 1/20] [Batch 128/274] [Batch classify loss: 0.036143] 
[Epoch 1/20] [Batch 129/274] [Batch classify loss: 0.078986] 
[Epoch 1/20] [Batch 130/274] [Batch classify loss: 0.094256] 
[Epoch 1/20] [Batch 131/274] [Batch classify loss: 0.017827] 
[Epoch 1/20] [Batch 132/274] [Batch classify loss: 0.052822] 
[Epoch 1/20] [Batch 133/274] [Batch classify loss: 0.046388] 
[Epoch 1/20] [Batch 134/274] [Batch classify loss: 0.072657] 
[Epoch 1/20] [Batch 135/274] [Batch classify loss: 0.088937] 
[Epoch 1/20] [Batch 136/274] [Batch classify loss: 0.032783] 
[Epoch 1/20] [Batch 137/274] [Batch classify loss: 0.044207] 
[Epoch 1/20] [Batch 138/274] [Batch classify loss: 0.071775] 
[Epoch 1/20] [Batch 139/274] [Batch classify loss: 0.087879] 
[Epoch 1/20] [Batch 140/274] [Batch classify loss: 0.055476] 
[Epoch 1/20] [Batch 141/274] [Batch classify loss: 0.072948] 
[Epoch 1/20] [Batch 142/274] [Batch classify loss: 0.084325] 
[Epoch 1/20] [Batch 143/274] [Batch classify loss: 0.051358] 
[Epoch 1/20] [Batch 144/274] [Batch classify loss: 0.041034] 
[Epoch 1/20] [Batch 145/274] [Batch classify loss: 0.067671] 
[Epoch 1/20] [Batch 146/274] [Batch classify loss: 0.033578] 
[Epoch 1/20] [Batch 147/274] [Batch classify loss: 0.076826] 
[Epoch 1/20] [Batch 148/274] [Batch classify loss: 0.052128] 
[Epoch 1/20] [Batch 149/274] [Batch classify loss: 0.055218] 
[Epoch 1/20] [Batch 150/274] [Batch classify loss: 0.043558] 
[Epoch 1/20] [Batch 151/274] [Batch classify loss: 0.065761] 
[Epoch 1/20] [Batch 152/274] [Batch classify loss: 0.048216] 
[Epoch 1/20] [Batch 153/274] [Batch classify loss: 0.027127] 
[Epoch 1/20] [Batch 154/274] [Batch classify loss: 0.029402] 
[Epoch 1/20] [Batch 155/274] [Batch classify loss: 0.021677] 
[Epoch 1/20] [Batch 156/274] [Batch classify loss: 0.069218] 
[Epoch 1/20] [Batch 157/274] [Batch classify loss: 0.038593] 
[Epoch 1/20] [Batch 158/274] [Batch classify loss: 0.041417] 
[Epoch 1/20] [Batch 159/274] [Batch classify loss: 0.053948] 
[Epoch 1/20] [Batch 160/274] [Batch classify loss: 0.064904] 
[Epoch 1/20] [Batch 161/274] [Batch classify loss: 0.056579] 
[Epoch 1/20] [Batch 162/274] [Batch classify loss: 0.064755] 
[Epoch 1/20] [Batch 163/274] [Batch classify loss: 0.067672] 
[Epoch 1/20] [Batch 164/274] [Batch classify loss: 0.068855] 
[Epoch 1/20] [Batch 165/274] [Batch classify loss: 0.066991] 
[Epoch 1/20] [Batch 166/274] [Batch classify loss: 0.057523] 
[Epoch 1/20] [Batch 167/274] [Batch classify loss: 0.045774] 
[Epoch 1/20] [Batch 168/274] [Batch classify loss: 0.101127] 
[Epoch 1/20] [Batch 169/274] [Batch classify loss: 0.034805] 
[Epoch 1/20] [Batch 170/274] [Batch classify loss: 0.049176] 
[Epoch 1/20] [Batch 171/274] [Batch classify loss: 0.057552] 
[Epoch 1/20] [Batch 172/274] [Batch classify loss: 0.068969] 
[Epoch 1/20] [Batch 173/274] [Batch classify loss: 0.039138] 
[Epoch 1/20] [Batch 174/274] [Batch classify loss: 0.055088] 
[Epoch 1/20] [Batch 175/274] [Batch classify loss: 0.015247] 
[Epoch 1/20] [Batch 176/274] [Batch classify loss: 0.034256] 
[Epoch 1/20] [Batch 177/274] [Batch classify loss: 0.021639] 
[Epoch 1/20] [Batch 178/274] [Batch classify loss: 0.032737] 
[Epoch 1/20] [Batch 179/274] [Batch classify loss: 0.111486] 
[Epoch 1/20] [Batch 180/274] [Batch classify loss: 0.051885] 
[Epoch 1/20] [Batch 181/274] [Batch classify loss: 0.035004] 
[Epoch 1/20] [Batch 182/274] [Batch classify loss: 0.035058] 
[Epoch 1/20] [Batch 183/274] [Batch classify loss: 0.046183] 
[Epoch 1/20] [Batch 184/274] [Batch classify loss: 0.030597] 
[Epoch 1/20] [Batch 185/274] [Batch classify loss: 0.034814] 
[Epoch 1/20] [Batch 186/274] [Batch classify loss: 0.043421] 
[Epoch 1/20] [Batch 187/274] [Batch classify loss: 0.054339] 
[Epoch 1/20] [Batch 188/274] [Batch classify loss: 0.126214] 
[Epoch 1/20] [Batch 189/274] [Batch classify loss: 0.060972] 
[Epoch 1/20] [Batch 190/274] [Batch classify loss: 0.035319] 
[Epoch 1/20] [Batch 191/274] [Batch classify loss: 0.027464] 
[Epoch 1/20] [Batch 192/274] [Batch classify loss: 0.051603] 
[Epoch 1/20] [Batch 193/274] [Batch classify loss: 0.065418] 
[Epoch 1/20] [Batch 194/274] [Batch classify loss: 0.096716] 
[Epoch 1/20] [Batch 195/274] [Batch classify loss: 0.066045] 
[Epoch 1/20] [Batch 196/274] [Batch classify loss: 0.026366] 
[Epoch 1/20] [Batch 197/274] [Batch classify loss: 0.091719] 
[Epoch 1/20] [Batch 198/274] [Batch classify loss: 0.056711] 
[Epoch 1/20] [Batch 199/274] [Batch classify loss: 0.060559] 
[Epoch 1/20] [Batch 200/274] [Batch classify loss: 0.031049] 
[Epoch 1/20] [Batch 201/274] [Batch classify loss: 0.021756] 
[Epoch 1/20] [Batch 202/274] [Batch classify loss: 0.059361] 
[Epoch 1/20] [Batch 203/274] [Batch classify loss: 0.072046] 
[Epoch 1/20] [Batch 204/274] [Batch classify loss: 0.041586] 
[Epoch 1/20] [Batch 205/274] [Batch classify loss: 0.060933] 
[Epoch 1/20] [Batch 206/274] [Batch classify loss: 0.058036] 
[Epoch 1/20] [Batch 207/274] [Batch classify loss: 0.035664] 
[Epoch 1/20] [Batch 208/274] [Batch classify loss: 0.083900] 
[Epoch 1/20] [Batch 209/274] [Batch classify loss: 0.067760] 
[Epoch 1/20] [Batch 210/274] [Batch classify loss: 0.080630] 
[Epoch 1/20] [Batch 211/274] [Batch classify loss: 0.074974] 
[Epoch 1/20] [Batch 212/274] [Batch classify loss: 0.023015] 
[Epoch 1/20] [Batch 213/274] [Batch classify loss: 0.050463] 
[Epoch 1/20] [Batch 214/274] [Batch classify loss: 0.060520] 
[Epoch 1/20] [Batch 215/274] [Batch classify loss: 0.059235] 
[Epoch 1/20] [Batch 216/274] [Batch classify loss: 0.057016] 
[Epoch 1/20] [Batch 217/274] [Batch classify loss: 0.048843] 
[Epoch 1/20] [Batch 218/274] [Batch classify loss: 0.045244] 
[Epoch 1/20] [Batch 219/274] [Batch classify loss: 0.045593] 
[Epoch 1/20] [Batch 220/274] [Batch classify loss: 0.058546] 
[Epoch 1/20] [Batch 221/274] [Batch classify loss: 0.048618] 
[Epoch 1/20] [Batch 222/274] [Batch classify loss: 0.025867] 
[Epoch 1/20] [Batch 223/274] [Batch classify loss: 0.022061] 
[Epoch 1/20] [Batch 224/274] [Batch classify loss: 0.090615] 
[Epoch 1/20] [Batch 225/274] [Batch classify loss: 0.037240] 
[Epoch 1/20] [Batch 226/274] [Batch classify loss: 0.027271] 
[Epoch 1/20] [Batch 227/274] [Batch classify loss: 0.044600] 
[Epoch 1/20] [Batch 228/274] [Batch classify loss: 0.016069] 
[Epoch 1/20] [Batch 229/274] [Batch classify loss: 0.156909] 
[Epoch 1/20] [Batch 230/274] [Batch classify loss: 0.116404] 
[Epoch 1/20] [Batch 231/274] [Batch classify loss: 0.031888] 
[Epoch 1/20] [Batch 232/274] [Batch classify loss: 0.077132] 
[Epoch 1/20] [Batch 233/274] [Batch classify loss: 0.028025] 
[Epoch 1/20] [Batch 234/274] [Batch classify loss: 0.056805] 
[Epoch 1/20] [Batch 235/274] [Batch classify loss: 0.041623] 
[Epoch 1/20] [Batch 236/274] [Batch classify loss: 0.041527] 
[Epoch 1/20] [Batch 237/274] [Batch classify loss: 0.016788] 
[Epoch 1/20] [Batch 238/274] [Batch classify loss: 0.032084] 
[Epoch 1/20] [Batch 239/274] [Batch classify loss: 0.063157] 
[Epoch 1/20] [Batch 240/274] [Batch classify loss: 0.048896] 
[Epoch 1/20] [Batch 241/274] [Batch classify loss: 0.027395] 
[Epoch 1/20] [Batch 242/274] [Batch classify loss: 0.033104] 
[Epoch 1/20] [Batch 243/274] [Batch classify loss: 0.044259] 
[Epoch 1/20] [Batch 244/274] [Batch classify loss: 0.091365] 
[Epoch 1/20] [Batch 245/274] [Batch classify loss: 0.067390] 
[Epoch 1/20] [Batch 246/274] [Batch classify loss: 0.016654] 
[Epoch 1/20] [Batch 247/274] [Batch classify loss: 0.073195] 
[Epoch 1/20] [Batch 248/274] [Batch classify loss: 0.024595] 
[Epoch 1/20] [Batch 249/274] [Batch classify loss: 0.057601] 
[Epoch 1/20] [Batch 250/274] [Batch classify loss: 0.029037] 
[Epoch 1/20] [Batch 251/274] [Batch classify loss: 0.020019] 
[Epoch 1/20] [Batch 252/274] [Batch classify loss: 0.051397] 
[Epoch 1/20] [Batch 253/274] [Batch classify loss: 0.067538] 
[Epoch 1/20] [Batch 254/274] [Batch classify loss: 0.073486] 
[Epoch 1/20] [Batch 255/274] [Batch classify loss: 0.086999] 
[Epoch 1/20] [Batch 256/274] [Batch classify loss: 0.062346] 
[Epoch 1/20] [Batch 257/274] [Batch classify loss: 0.117236] 
[Epoch 1/20] [Batch 258/274] [Batch classify loss: 0.053630] 
[Epoch 1/20] [Batch 259/274] [Batch classify loss: 0.039507] 
[Epoch 1/20] [Batch 260/274] [Batch classify loss: 0.053337] 
[Epoch 1/20] [Batch 261/274] [Batch classify loss: 0.044315] 
[Epoch 1/20] [Batch 262/274] [Batch classify loss: 0.062603] 
[Epoch 1/20] [Batch 263/274] [Batch classify loss: 0.078703] 
[Epoch 1/20] [Batch 264/274] [Batch classify loss: 0.037594] 
[Epoch 1/20] [Batch 265/274] [Batch classify loss: 0.066016] 
[Epoch 1/20] [Batch 266/274] [Batch classify loss: 0.019207] 
[Epoch 1/20] [Batch 267/274] [Batch classify loss: 0.079300] 
[Epoch 1/20] [Batch 268/274] [Batch classify loss: 0.033321] 
[Epoch 1/20] [Batch 269/274] [Batch classify loss: 0.050918] 
[Epoch 1/20] [Batch 270/274] [Batch classify loss: 0.051363] 
[Epoch 1/20] [Batch 271/274] [Batch classify loss: 0.037732] 
[Epoch 1/20] [Batch 272/274] [Batch classify loss: 0.025775] 
[Epoch 1/20] [Batch 273/274] [Batch classify loss: 0.076284] 
[Epoch 1/20] [Batch 274/274] [Batch classify loss: 0.169265] 
0001 epoch mmat trained classifier accuary on the clean testing examples:94.6835%
0001 epoch mmat trained classifier loss on the clean testing examples:0.2239
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.1314%
mmat trained classifier loss on adversarial testset:4.532327651977539
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
1epoch learning rate:0.01
[Epoch 2/20] [Batch 1/274] [Batch classify loss: 0.042861] 
[Epoch 2/20] [Batch 2/274] [Batch classify loss: 0.014767] 
[Epoch 2/20] [Batch 3/274] [Batch classify loss: 0.025604] 
[Epoch 2/20] [Batch 4/274] [Batch classify loss: 0.061901] 
[Epoch 2/20] [Batch 5/274] [Batch classify loss: 0.044347] 
[Epoch 2/20] [Batch 6/274] [Batch classify loss: 0.074301] 
[Epoch 2/20] [Batch 7/274] [Batch classify loss: 0.023101] 
[Epoch 2/20] [Batch 8/274] [Batch classify loss: 0.034565] 
[Epoch 2/20] [Batch 9/274] [Batch classify loss: 0.047665] 
[Epoch 2/20] [Batch 10/274] [Batch classify loss: 0.037865] 
[Epoch 2/20] [Batch 11/274] [Batch classify loss: 0.086858] 
[Epoch 2/20] [Batch 12/274] [Batch classify loss: 0.046298] 
[Epoch 2/20] [Batch 13/274] [Batch classify loss: 0.037304] 
[Epoch 2/20] [Batch 14/274] [Batch classify loss: 0.020057] 
[Epoch 2/20] [Batch 15/274] [Batch classify loss: 0.087942] 
[Epoch 2/20] [Batch 16/274] [Batch classify loss: 0.065286] 
[Epoch 2/20] [Batch 17/274] [Batch classify loss: 0.044023] 
[Epoch 2/20] [Batch 18/274] [Batch classify loss: 0.082044] 
[Epoch 2/20] [Batch 19/274] [Batch classify loss: 0.040079] 
[Epoch 2/20] [Batch 20/274] [Batch classify loss: 0.120214] 
[Epoch 2/20] [Batch 21/274] [Batch classify loss: 0.028288] 
[Epoch 2/20] [Batch 22/274] [Batch classify loss: 0.023304] 
[Epoch 2/20] [Batch 23/274] [Batch classify loss: 0.034382] 
[Epoch 2/20] [Batch 24/274] [Batch classify loss: 0.056986] 
[Epoch 2/20] [Batch 25/274] [Batch classify loss: 0.084288] 
[Epoch 2/20] [Batch 26/274] [Batch classify loss: 0.089764] 
[Epoch 2/20] [Batch 27/274] [Batch classify loss: 0.094960] 
[Epoch 2/20] [Batch 28/274] [Batch classify loss: 0.105981] 
[Epoch 2/20] [Batch 29/274] [Batch classify loss: 0.027763] 
[Epoch 2/20] [Batch 30/274] [Batch classify loss: 0.089640] 
[Epoch 2/20] [Batch 31/274] [Batch classify loss: 0.081076] 
[Epoch 2/20] [Batch 32/274] [Batch classify loss: 0.030971] 
[Epoch 2/20] [Batch 33/274] [Batch classify loss: 0.097302] 
[Epoch 2/20] [Batch 34/274] [Batch classify loss: 0.075890] 
[Epoch 2/20] [Batch 35/274] [Batch classify loss: 0.063911] 
[Epoch 2/20] [Batch 36/274] [Batch classify loss: 0.044068] 
[Epoch 2/20] [Batch 37/274] [Batch classify loss: 0.058086] 
[Epoch 2/20] [Batch 38/274] [Batch classify loss: 0.063993] 
[Epoch 2/20] [Batch 39/274] [Batch classify loss: 0.013778] 
[Epoch 2/20] [Batch 40/274] [Batch classify loss: 0.045896] 
[Epoch 2/20] [Batch 41/274] [Batch classify loss: 0.051307] 
[Epoch 2/20] [Batch 42/274] [Batch classify loss: 0.060991] 
[Epoch 2/20] [Batch 43/274] [Batch classify loss: 0.039162] 
[Epoch 2/20] [Batch 44/274] [Batch classify loss: 0.071383] 
[Epoch 2/20] [Batch 45/274] [Batch classify loss: 0.053309] 
[Epoch 2/20] [Batch 46/274] [Batch classify loss: 0.034173] 
[Epoch 2/20] [Batch 47/274] [Batch classify loss: 0.032335] 
[Epoch 2/20] [Batch 48/274] [Batch classify loss: 0.032267] 
[Epoch 2/20] [Batch 49/274] [Batch classify loss: 0.053553] 
[Epoch 2/20] [Batch 50/274] [Batch classify loss: 0.025175] 
[Epoch 2/20] [Batch 51/274] [Batch classify loss: 0.155209] 
[Epoch 2/20] [Batch 52/274] [Batch classify loss: 0.037890] 
[Epoch 2/20] [Batch 53/274] [Batch classify loss: 0.085632] 
[Epoch 2/20] [Batch 54/274] [Batch classify loss: 0.023965] 
[Epoch 2/20] [Batch 55/274] [Batch classify loss: 0.041226] 
[Epoch 2/20] [Batch 56/274] [Batch classify loss: 0.046224] 
[Epoch 2/20] [Batch 57/274] [Batch classify loss: 0.086190] 
[Epoch 2/20] [Batch 58/274] [Batch classify loss: 0.050959] 
[Epoch 2/20] [Batch 59/274] [Batch classify loss: 0.047634] 
[Epoch 2/20] [Batch 60/274] [Batch classify loss: 0.080297] 
[Epoch 2/20] [Batch 61/274] [Batch classify loss: 0.060604] 
[Epoch 2/20] [Batch 62/274] [Batch classify loss: 0.018229] 
[Epoch 2/20] [Batch 63/274] [Batch classify loss: 0.064368] 
[Epoch 2/20] [Batch 64/274] [Batch classify loss: 0.049571] 
[Epoch 2/20] [Batch 65/274] [Batch classify loss: 0.079246] 
[Epoch 2/20] [Batch 66/274] [Batch classify loss: 0.068156] 
[Epoch 2/20] [Batch 67/274] [Batch classify loss: 0.018650] 
[Epoch 2/20] [Batch 68/274] [Batch classify loss: 0.042341] 
[Epoch 2/20] [Batch 69/274] [Batch classify loss: 0.069832] 
[Epoch 2/20] [Batch 70/274] [Batch classify loss: 0.080386] 
[Epoch 2/20] [Batch 71/274] [Batch classify loss: 0.071888] 
[Epoch 2/20] [Batch 72/274] [Batch classify loss: 0.031122] 
[Epoch 2/20] [Batch 73/274] [Batch classify loss: 0.062009] 
[Epoch 2/20] [Batch 74/274] [Batch classify loss: 0.026840] 
[Epoch 2/20] [Batch 75/274] [Batch classify loss: 0.064055] 
[Epoch 2/20] [Batch 76/274] [Batch classify loss: 0.052594] 
[Epoch 2/20] [Batch 77/274] [Batch classify loss: 0.020187] 
[Epoch 2/20] [Batch 78/274] [Batch classify loss: 0.074394] 
[Epoch 2/20] [Batch 79/274] [Batch classify loss: 0.009659] 
[Epoch 2/20] [Batch 80/274] [Batch classify loss: 0.048627] 
[Epoch 2/20] [Batch 81/274] [Batch classify loss: 0.041951] 
[Epoch 2/20] [Batch 82/274] [Batch classify loss: 0.084082] 
[Epoch 2/20] [Batch 83/274] [Batch classify loss: 0.052993] 
[Epoch 2/20] [Batch 84/274] [Batch classify loss: 0.016024] 
[Epoch 2/20] [Batch 85/274] [Batch classify loss: 0.188075] 
[Epoch 2/20] [Batch 86/274] [Batch classify loss: 0.059986] 
[Epoch 2/20] [Batch 87/274] [Batch classify loss: 0.079380] 
[Epoch 2/20] [Batch 88/274] [Batch classify loss: 0.037559] 
[Epoch 2/20] [Batch 89/274] [Batch classify loss: 0.013046] 
[Epoch 2/20] [Batch 90/274] [Batch classify loss: 0.028340] 
[Epoch 2/20] [Batch 91/274] [Batch classify loss: 0.079379] 
[Epoch 2/20] [Batch 92/274] [Batch classify loss: 0.029284] 
[Epoch 2/20] [Batch 93/274] [Batch classify loss: 0.115611] 
[Epoch 2/20] [Batch 94/274] [Batch classify loss: 0.051499] 
[Epoch 2/20] [Batch 95/274] [Batch classify loss: 0.065949] 
[Epoch 2/20] [Batch 96/274] [Batch classify loss: 0.039256] 
[Epoch 2/20] [Batch 97/274] [Batch classify loss: 0.031299] 
[Epoch 2/20] [Batch 98/274] [Batch classify loss: 0.039986] 
[Epoch 2/20] [Batch 99/274] [Batch classify loss: 0.040391] 
[Epoch 2/20] [Batch 100/274] [Batch classify loss: 0.044741] 
[Epoch 2/20] [Batch 101/274] [Batch classify loss: 0.091092] 
[Epoch 2/20] [Batch 102/274] [Batch classify loss: 0.042527] 
[Epoch 2/20] [Batch 103/274] [Batch classify loss: 0.030861] 
[Epoch 2/20] [Batch 104/274] [Batch classify loss: 0.097267] 
[Epoch 2/20] [Batch 105/274] [Batch classify loss: 0.071869] 
[Epoch 2/20] [Batch 106/274] [Batch classify loss: 0.069506] 
[Epoch 2/20] [Batch 107/274] [Batch classify loss: 0.027178] 
[Epoch 2/20] [Batch 108/274] [Batch classify loss: 0.066704] 
[Epoch 2/20] [Batch 109/274] [Batch classify loss: 0.012496] 
[Epoch 2/20] [Batch 110/274] [Batch classify loss: 0.122449] 
[Epoch 2/20] [Batch 111/274] [Batch classify loss: 0.036037] 
[Epoch 2/20] [Batch 112/274] [Batch classify loss: 0.066252] 
[Epoch 2/20] [Batch 113/274] [Batch classify loss: 0.047520] 
[Epoch 2/20] [Batch 114/274] [Batch classify loss: 0.036772] 
[Epoch 2/20] [Batch 115/274] [Batch classify loss: 0.041360] 
[Epoch 2/20] [Batch 116/274] [Batch classify loss: 0.097144] 
[Epoch 2/20] [Batch 117/274] [Batch classify loss: 0.042988] 
[Epoch 2/20] [Batch 118/274] [Batch classify loss: 0.040468] 
[Epoch 2/20] [Batch 119/274] [Batch classify loss: 0.052100] 
[Epoch 2/20] [Batch 120/274] [Batch classify loss: 0.024958] 
[Epoch 2/20] [Batch 121/274] [Batch classify loss: 0.058967] 
[Epoch 2/20] [Batch 122/274] [Batch classify loss: 0.124809] 
[Epoch 2/20] [Batch 123/274] [Batch classify loss: 0.028668] 
[Epoch 2/20] [Batch 124/274] [Batch classify loss: 0.027880] 
[Epoch 2/20] [Batch 125/274] [Batch classify loss: 0.065958] 
[Epoch 2/20] [Batch 126/274] [Batch classify loss: 0.087739] 
[Epoch 2/20] [Batch 127/274] [Batch classify loss: 0.096668] 
[Epoch 2/20] [Batch 128/274] [Batch classify loss: 0.019644] 
[Epoch 2/20] [Batch 129/274] [Batch classify loss: 0.030562] 
[Epoch 2/20] [Batch 130/274] [Batch classify loss: 0.041996] 
[Epoch 2/20] [Batch 131/274] [Batch classify loss: 0.085073] 
[Epoch 2/20] [Batch 132/274] [Batch classify loss: 0.108246] 
[Epoch 2/20] [Batch 133/274] [Batch classify loss: 0.110375] 
[Epoch 2/20] [Batch 134/274] [Batch classify loss: 0.051021] 
[Epoch 2/20] [Batch 135/274] [Batch classify loss: 0.092653] 
[Epoch 2/20] [Batch 136/274] [Batch classify loss: 0.042827] 
[Epoch 2/20] [Batch 137/274] [Batch classify loss: 0.024853] 
[Epoch 2/20] [Batch 138/274] [Batch classify loss: 0.020258] 
[Epoch 2/20] [Batch 139/274] [Batch classify loss: 0.068643] 
[Epoch 2/20] [Batch 140/274] [Batch classify loss: 0.017115] 
[Epoch 2/20] [Batch 141/274] [Batch classify loss: 0.087163] 
[Epoch 2/20] [Batch 142/274] [Batch classify loss: 0.024864] 
[Epoch 2/20] [Batch 143/274] [Batch classify loss: 0.090235] 
[Epoch 2/20] [Batch 144/274] [Batch classify loss: 0.092967] 
[Epoch 2/20] [Batch 145/274] [Batch classify loss: 0.019746] 
[Epoch 2/20] [Batch 146/274] [Batch classify loss: 0.048286] 
[Epoch 2/20] [Batch 147/274] [Batch classify loss: 0.035155] 
[Epoch 2/20] [Batch 148/274] [Batch classify loss: 0.042762] 
[Epoch 2/20] [Batch 149/274] [Batch classify loss: 0.039125] 
[Epoch 2/20] [Batch 150/274] [Batch classify loss: 0.083054] 
[Epoch 2/20] [Batch 151/274] [Batch classify loss: 0.102909] 
[Epoch 2/20] [Batch 152/274] [Batch classify loss: 0.043186] 
[Epoch 2/20] [Batch 153/274] [Batch classify loss: 0.065308] 
[Epoch 2/20] [Batch 154/274] [Batch classify loss: 0.051194] 
[Epoch 2/20] [Batch 155/274] [Batch classify loss: 0.060025] 
[Epoch 2/20] [Batch 156/274] [Batch classify loss: 0.048033] 
[Epoch 2/20] [Batch 157/274] [Batch classify loss: 0.040732] 
[Epoch 2/20] [Batch 158/274] [Batch classify loss: 0.044617] 
[Epoch 2/20] [Batch 159/274] [Batch classify loss: 0.090588] 
[Epoch 2/20] [Batch 160/274] [Batch classify loss: 0.098180] 
[Epoch 2/20] [Batch 161/274] [Batch classify loss: 0.059034] 
[Epoch 2/20] [Batch 162/274] [Batch classify loss: 0.078536] 
[Epoch 2/20] [Batch 163/274] [Batch classify loss: 0.056925] 
[Epoch 2/20] [Batch 164/274] [Batch classify loss: 0.065697] 
[Epoch 2/20] [Batch 165/274] [Batch classify loss: 0.168277] 
[Epoch 2/20] [Batch 166/274] [Batch classify loss: 0.035730] 
[Epoch 2/20] [Batch 167/274] [Batch classify loss: 0.066803] 
[Epoch 2/20] [Batch 168/274] [Batch classify loss: 0.019999] 
[Epoch 2/20] [Batch 169/274] [Batch classify loss: 0.101379] 
[Epoch 2/20] [Batch 170/274] [Batch classify loss: 0.037279] 
[Epoch 2/20] [Batch 171/274] [Batch classify loss: 0.016185] 
[Epoch 2/20] [Batch 172/274] [Batch classify loss: 0.080641] 
[Epoch 2/20] [Batch 173/274] [Batch classify loss: 0.091600] 
[Epoch 2/20] [Batch 174/274] [Batch classify loss: 0.055597] 
[Epoch 2/20] [Batch 175/274] [Batch classify loss: 0.035393] 
[Epoch 2/20] [Batch 176/274] [Batch classify loss: 0.038702] 
[Epoch 2/20] [Batch 177/274] [Batch classify loss: 0.063160] 
[Epoch 2/20] [Batch 178/274] [Batch classify loss: 0.049508] 
[Epoch 2/20] [Batch 179/274] [Batch classify loss: 0.062799] 
[Epoch 2/20] [Batch 180/274] [Batch classify loss: 0.027548] 
[Epoch 2/20] [Batch 181/274] [Batch classify loss: 0.041064] 
[Epoch 2/20] [Batch 182/274] [Batch classify loss: 0.060595] 
[Epoch 2/20] [Batch 183/274] [Batch classify loss: 0.065090] 
[Epoch 2/20] [Batch 184/274] [Batch classify loss: 0.045517] 
[Epoch 2/20] [Batch 185/274] [Batch classify loss: 0.049429] 
[Epoch 2/20] [Batch 186/274] [Batch classify loss: 0.029746] 
[Epoch 2/20] [Batch 187/274] [Batch classify loss: 0.023415] 
[Epoch 2/20] [Batch 188/274] [Batch classify loss: 0.057506] 
[Epoch 2/20] [Batch 189/274] [Batch classify loss: 0.042230] 
[Epoch 2/20] [Batch 190/274] [Batch classify loss: 0.046837] 
[Epoch 2/20] [Batch 191/274] [Batch classify loss: 0.062529] 
[Epoch 2/20] [Batch 192/274] [Batch classify loss: 0.055509] 
[Epoch 2/20] [Batch 193/274] [Batch classify loss: 0.098612] 
[Epoch 2/20] [Batch 194/274] [Batch classify loss: 0.052805] 
[Epoch 2/20] [Batch 195/274] [Batch classify loss: 0.034362] 
[Epoch 2/20] [Batch 196/274] [Batch classify loss: 0.077058] 
[Epoch 2/20] [Batch 197/274] [Batch classify loss: 0.016075] 
[Epoch 2/20] [Batch 198/274] [Batch classify loss: 0.032192] 
[Epoch 2/20] [Batch 199/274] [Batch classify loss: 0.034464] 
[Epoch 2/20] [Batch 200/274] [Batch classify loss: 0.017550] 
[Epoch 2/20] [Batch 201/274] [Batch classify loss: 0.040104] 
[Epoch 2/20] [Batch 202/274] [Batch classify loss: 0.046298] 
[Epoch 2/20] [Batch 203/274] [Batch classify loss: 0.068410] 
[Epoch 2/20] [Batch 204/274] [Batch classify loss: 0.042311] 
[Epoch 2/20] [Batch 205/274] [Batch classify loss: 0.054153] 
[Epoch 2/20] [Batch 206/274] [Batch classify loss: 0.026975] 
[Epoch 2/20] [Batch 207/274] [Batch classify loss: 0.039318] 
[Epoch 2/20] [Batch 208/274] [Batch classify loss: 0.026603] 
[Epoch 2/20] [Batch 209/274] [Batch classify loss: 0.050687] 
[Epoch 2/20] [Batch 210/274] [Batch classify loss: 0.020131] 
[Epoch 2/20] [Batch 211/274] [Batch classify loss: 0.047754] 
[Epoch 2/20] [Batch 212/274] [Batch classify loss: 0.048757] 
[Epoch 2/20] [Batch 213/274] [Batch classify loss: 0.159062] 
[Epoch 2/20] [Batch 214/274] [Batch classify loss: 0.091667] 
[Epoch 2/20] [Batch 215/274] [Batch classify loss: 0.017161] 
[Epoch 2/20] [Batch 216/274] [Batch classify loss: 0.080626] 
[Epoch 2/20] [Batch 217/274] [Batch classify loss: 0.075200] 
[Epoch 2/20] [Batch 218/274] [Batch classify loss: 0.070205] 
[Epoch 2/20] [Batch 219/274] [Batch classify loss: 0.047545] 
[Epoch 2/20] [Batch 220/274] [Batch classify loss: 0.098989] 
[Epoch 2/20] [Batch 221/274] [Batch classify loss: 0.091213] 
[Epoch 2/20] [Batch 222/274] [Batch classify loss: 0.052856] 
[Epoch 2/20] [Batch 223/274] [Batch classify loss: 0.023150] 
[Epoch 2/20] [Batch 224/274] [Batch classify loss: 0.052113] 
[Epoch 2/20] [Batch 225/274] [Batch classify loss: 0.018862] 
[Epoch 2/20] [Batch 226/274] [Batch classify loss: 0.064749] 
[Epoch 2/20] [Batch 227/274] [Batch classify loss: 0.056845] 
[Epoch 2/20] [Batch 228/274] [Batch classify loss: 0.018542] 
[Epoch 2/20] [Batch 229/274] [Batch classify loss: 0.049098] 
[Epoch 2/20] [Batch 230/274] [Batch classify loss: 0.028289] 
[Epoch 2/20] [Batch 231/274] [Batch classify loss: 0.022464] 
[Epoch 2/20] [Batch 232/274] [Batch classify loss: 0.017111] 
[Epoch 2/20] [Batch 233/274] [Batch classify loss: 0.053977] 
[Epoch 2/20] [Batch 234/274] [Batch classify loss: 0.058575] 
[Epoch 2/20] [Batch 235/274] [Batch classify loss: 0.053594] 
[Epoch 2/20] [Batch 236/274] [Batch classify loss: 0.045130] 
[Epoch 2/20] [Batch 237/274] [Batch classify loss: 0.158917] 
[Epoch 2/20] [Batch 238/274] [Batch classify loss: 0.077586] 
[Epoch 2/20] [Batch 239/274] [Batch classify loss: 0.068727] 
[Epoch 2/20] [Batch 240/274] [Batch classify loss: 0.052314] 
[Epoch 2/20] [Batch 241/274] [Batch classify loss: 0.073291] 
[Epoch 2/20] [Batch 242/274] [Batch classify loss: 0.035427] 
[Epoch 2/20] [Batch 243/274] [Batch classify loss: 0.050941] 
[Epoch 2/20] [Batch 244/274] [Batch classify loss: 0.048843] 
[Epoch 2/20] [Batch 245/274] [Batch classify loss: 0.089045] 
[Epoch 2/20] [Batch 246/274] [Batch classify loss: 0.049096] 
[Epoch 2/20] [Batch 247/274] [Batch classify loss: 0.042441] 
[Epoch 2/20] [Batch 248/274] [Batch classify loss: 0.071138] 
[Epoch 2/20] [Batch 249/274] [Batch classify loss: 0.036214] 
[Epoch 2/20] [Batch 250/274] [Batch classify loss: 0.038692] 
[Epoch 2/20] [Batch 251/274] [Batch classify loss: 0.071582] 
[Epoch 2/20] [Batch 252/274] [Batch classify loss: 0.043997] 
[Epoch 2/20] [Batch 253/274] [Batch classify loss: 0.036780] 
[Epoch 2/20] [Batch 254/274] [Batch classify loss: 0.094959] 
[Epoch 2/20] [Batch 255/274] [Batch classify loss: 0.107340] 
[Epoch 2/20] [Batch 256/274] [Batch classify loss: 0.053564] 
[Epoch 2/20] [Batch 257/274] [Batch classify loss: 0.036357] 
[Epoch 2/20] [Batch 258/274] [Batch classify loss: 0.115259] 
[Epoch 2/20] [Batch 259/274] [Batch classify loss: 0.118449] 
[Epoch 2/20] [Batch 260/274] [Batch classify loss: 0.032389] 
[Epoch 2/20] [Batch 261/274] [Batch classify loss: 0.033701] 
[Epoch 2/20] [Batch 262/274] [Batch classify loss: 0.026274] 
[Epoch 2/20] [Batch 263/274] [Batch classify loss: 0.047269] 
[Epoch 2/20] [Batch 264/274] [Batch classify loss: 0.046923] 
[Epoch 2/20] [Batch 265/274] [Batch classify loss: 0.040261] 
[Epoch 2/20] [Batch 266/274] [Batch classify loss: 0.035366] 
[Epoch 2/20] [Batch 267/274] [Batch classify loss: 0.034239] 
[Epoch 2/20] [Batch 268/274] [Batch classify loss: 0.022687] 
[Epoch 2/20] [Batch 269/274] [Batch classify loss: 0.034522] 
[Epoch 2/20] [Batch 270/274] [Batch classify loss: 0.088265] 
[Epoch 2/20] [Batch 271/274] [Batch classify loss: 0.048935] 
[Epoch 2/20] [Batch 272/274] [Batch classify loss: 0.026907] 
[Epoch 2/20] [Batch 273/274] [Batch classify loss: 0.061910] 
[Epoch 2/20] [Batch 274/274] [Batch classify loss: 0.073976] 
0002 epoch mmat trained classifier accuary on the clean testing examples:94.7641%
0002 epoch mmat trained classifier loss on the clean testing examples:0.2235
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3580%
mmat trained classifier loss on adversarial testset:4.512573719024658
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
2epoch learning rate:0.01
[Epoch 3/20] [Batch 1/274] [Batch classify loss: 0.021573] 
[Epoch 3/20] [Batch 2/274] [Batch classify loss: 0.022110] 
[Epoch 3/20] [Batch 3/274] [Batch classify loss: 0.037224] 
[Epoch 3/20] [Batch 4/274] [Batch classify loss: 0.019627] 
[Epoch 3/20] [Batch 5/274] [Batch classify loss: 0.041066] 
[Epoch 3/20] [Batch 6/274] [Batch classify loss: 0.056878] 
[Epoch 3/20] [Batch 7/274] [Batch classify loss: 0.028275] 
[Epoch 3/20] [Batch 8/274] [Batch classify loss: 0.063501] 
[Epoch 3/20] [Batch 9/274] [Batch classify loss: 0.040397] 
[Epoch 3/20] [Batch 10/274] [Batch classify loss: 0.040414] 
[Epoch 3/20] [Batch 11/274] [Batch classify loss: 0.042846] 
[Epoch 3/20] [Batch 12/274] [Batch classify loss: 0.012796] 
[Epoch 3/20] [Batch 13/274] [Batch classify loss: 0.027395] 
[Epoch 3/20] [Batch 14/274] [Batch classify loss: 0.024482] 
[Epoch 3/20] [Batch 15/274] [Batch classify loss: 0.059772] 
[Epoch 3/20] [Batch 16/274] [Batch classify loss: 0.024028] 
[Epoch 3/20] [Batch 17/274] [Batch classify loss: 0.041386] 
[Epoch 3/20] [Batch 18/274] [Batch classify loss: 0.030590] 
[Epoch 3/20] [Batch 19/274] [Batch classify loss: 0.089782] 
[Epoch 3/20] [Batch 20/274] [Batch classify loss: 0.079266] 
[Epoch 3/20] [Batch 21/274] [Batch classify loss: 0.072098] 
[Epoch 3/20] [Batch 22/274] [Batch classify loss: 0.042281] 
[Epoch 3/20] [Batch 23/274] [Batch classify loss: 0.063320] 
[Epoch 3/20] [Batch 24/274] [Batch classify loss: 0.092415] 
[Epoch 3/20] [Batch 25/274] [Batch classify loss: 0.047215] 
[Epoch 3/20] [Batch 26/274] [Batch classify loss: 0.046278] 
[Epoch 3/20] [Batch 27/274] [Batch classify loss: 0.017396] 
[Epoch 3/20] [Batch 28/274] [Batch classify loss: 0.018287] 
[Epoch 3/20] [Batch 29/274] [Batch classify loss: 0.049894] 
[Epoch 3/20] [Batch 30/274] [Batch classify loss: 0.045497] 
[Epoch 3/20] [Batch 31/274] [Batch classify loss: 0.015076] 
[Epoch 3/20] [Batch 32/274] [Batch classify loss: 0.036749] 
[Epoch 3/20] [Batch 33/274] [Batch classify loss: 0.046747] 
[Epoch 3/20] [Batch 34/274] [Batch classify loss: 0.091839] 
[Epoch 3/20] [Batch 35/274] [Batch classify loss: 0.033243] 
[Epoch 3/20] [Batch 36/274] [Batch classify loss: 0.084531] 
[Epoch 3/20] [Batch 37/274] [Batch classify loss: 0.041007] 
[Epoch 3/20] [Batch 38/274] [Batch classify loss: 0.032105] 
[Epoch 3/20] [Batch 39/274] [Batch classify loss: 0.059498] 
[Epoch 3/20] [Batch 40/274] [Batch classify loss: 0.056168] 
[Epoch 3/20] [Batch 41/274] [Batch classify loss: 0.066188] 
[Epoch 3/20] [Batch 42/274] [Batch classify loss: 0.083179] 
[Epoch 3/20] [Batch 43/274] [Batch classify loss: 0.054528] 
[Epoch 3/20] [Batch 44/274] [Batch classify loss: 0.059476] 
[Epoch 3/20] [Batch 45/274] [Batch classify loss: 0.055394] 
[Epoch 3/20] [Batch 46/274] [Batch classify loss: 0.075679] 
[Epoch 3/20] [Batch 47/274] [Batch classify loss: 0.069197] 
[Epoch 3/20] [Batch 48/274] [Batch classify loss: 0.014313] 
[Epoch 3/20] [Batch 49/274] [Batch classify loss: 0.019654] 
[Epoch 3/20] [Batch 50/274] [Batch classify loss: 0.037657] 
[Epoch 3/20] [Batch 51/274] [Batch classify loss: 0.063819] 
[Epoch 3/20] [Batch 52/274] [Batch classify loss: 0.023238] 
[Epoch 3/20] [Batch 53/274] [Batch classify loss: 0.028911] 
[Epoch 3/20] [Batch 54/274] [Batch classify loss: 0.043684] 
[Epoch 3/20] [Batch 55/274] [Batch classify loss: 0.103865] 
[Epoch 3/20] [Batch 56/274] [Batch classify loss: 0.043203] 
[Epoch 3/20] [Batch 57/274] [Batch classify loss: 0.073110] 
[Epoch 3/20] [Batch 58/274] [Batch classify loss: 0.070499] 
[Epoch 3/20] [Batch 59/274] [Batch classify loss: 0.041233] 
[Epoch 3/20] [Batch 60/274] [Batch classify loss: 0.071223] 
[Epoch 3/20] [Batch 61/274] [Batch classify loss: 0.018566] 
[Epoch 3/20] [Batch 62/274] [Batch classify loss: 0.070214] 
[Epoch 3/20] [Batch 63/274] [Batch classify loss: 0.025866] 
[Epoch 3/20] [Batch 64/274] [Batch classify loss: 0.057546] 
[Epoch 3/20] [Batch 65/274] [Batch classify loss: 0.042277] 
[Epoch 3/20] [Batch 66/274] [Batch classify loss: 0.092068] 
[Epoch 3/20] [Batch 67/274] [Batch classify loss: 0.072441] 
[Epoch 3/20] [Batch 68/274] [Batch classify loss: 0.040158] 
[Epoch 3/20] [Batch 69/274] [Batch classify loss: 0.028827] 
[Epoch 3/20] [Batch 70/274] [Batch classify loss: 0.071502] 
[Epoch 3/20] [Batch 71/274] [Batch classify loss: 0.078021] 
[Epoch 3/20] [Batch 72/274] [Batch classify loss: 0.059956] 
[Epoch 3/20] [Batch 73/274] [Batch classify loss: 0.107174] 
[Epoch 3/20] [Batch 74/274] [Batch classify loss: 0.049054] 
[Epoch 3/20] [Batch 75/274] [Batch classify loss: 0.069693] 
[Epoch 3/20] [Batch 76/274] [Batch classify loss: 0.100227] 
[Epoch 3/20] [Batch 77/274] [Batch classify loss: 0.036089] 
[Epoch 3/20] [Batch 78/274] [Batch classify loss: 0.038462] 
[Epoch 3/20] [Batch 79/274] [Batch classify loss: 0.050926] 
[Epoch 3/20] [Batch 80/274] [Batch classify loss: 0.061588] 
[Epoch 3/20] [Batch 81/274] [Batch classify loss: 0.019031] 
[Epoch 3/20] [Batch 82/274] [Batch classify loss: 0.039498] 
[Epoch 3/20] [Batch 83/274] [Batch classify loss: 0.029637] 
[Epoch 3/20] [Batch 84/274] [Batch classify loss: 0.069909] 
[Epoch 3/20] [Batch 85/274] [Batch classify loss: 0.020234] 
[Epoch 3/20] [Batch 86/274] [Batch classify loss: 0.025182] 
[Epoch 3/20] [Batch 87/274] [Batch classify loss: 0.041553] 
[Epoch 3/20] [Batch 88/274] [Batch classify loss: 0.045079] 
[Epoch 3/20] [Batch 89/274] [Batch classify loss: 0.147664] 
[Epoch 3/20] [Batch 90/274] [Batch classify loss: 0.018175] 
[Epoch 3/20] [Batch 91/274] [Batch classify loss: 0.100823] 
[Epoch 3/20] [Batch 92/274] [Batch classify loss: 0.033123] 
[Epoch 3/20] [Batch 93/274] [Batch classify loss: 0.025193] 
[Epoch 3/20] [Batch 94/274] [Batch classify loss: 0.061803] 
[Epoch 3/20] [Batch 95/274] [Batch classify loss: 0.047570] 
[Epoch 3/20] [Batch 96/274] [Batch classify loss: 0.042873] 
[Epoch 3/20] [Batch 97/274] [Batch classify loss: 0.082702] 
[Epoch 3/20] [Batch 98/274] [Batch classify loss: 0.018175] 
[Epoch 3/20] [Batch 99/274] [Batch classify loss: 0.102847] 
[Epoch 3/20] [Batch 100/274] [Batch classify loss: 0.077991] 
[Epoch 3/20] [Batch 101/274] [Batch classify loss: 0.110725] 
[Epoch 3/20] [Batch 102/274] [Batch classify loss: 0.036831] 
[Epoch 3/20] [Batch 103/274] [Batch classify loss: 0.071221] 
[Epoch 3/20] [Batch 104/274] [Batch classify loss: 0.041876] 
[Epoch 3/20] [Batch 105/274] [Batch classify loss: 0.036889] 
[Epoch 3/20] [Batch 106/274] [Batch classify loss: 0.055714] 
[Epoch 3/20] [Batch 107/274] [Batch classify loss: 0.052034] 
[Epoch 3/20] [Batch 108/274] [Batch classify loss: 0.086970] 
[Epoch 3/20] [Batch 109/274] [Batch classify loss: 0.040380] 
[Epoch 3/20] [Batch 110/274] [Batch classify loss: 0.020832] 
[Epoch 3/20] [Batch 111/274] [Batch classify loss: 0.066047] 
[Epoch 3/20] [Batch 112/274] [Batch classify loss: 0.096769] 
[Epoch 3/20] [Batch 113/274] [Batch classify loss: 0.050147] 
[Epoch 3/20] [Batch 114/274] [Batch classify loss: 0.083877] 
[Epoch 3/20] [Batch 115/274] [Batch classify loss: 0.061977] 
[Epoch 3/20] [Batch 116/274] [Batch classify loss: 0.027792] 
[Epoch 3/20] [Batch 117/274] [Batch classify loss: 0.062092] 
[Epoch 3/20] [Batch 118/274] [Batch classify loss: 0.024747] 
[Epoch 3/20] [Batch 119/274] [Batch classify loss: 0.110659] 
[Epoch 3/20] [Batch 120/274] [Batch classify loss: 0.102688] 
[Epoch 3/20] [Batch 121/274] [Batch classify loss: 0.041003] 
[Epoch 3/20] [Batch 122/274] [Batch classify loss: 0.039965] 
[Epoch 3/20] [Batch 123/274] [Batch classify loss: 0.015183] 
[Epoch 3/20] [Batch 124/274] [Batch classify loss: 0.151310] 
[Epoch 3/20] [Batch 125/274] [Batch classify loss: 0.021256] 
[Epoch 3/20] [Batch 126/274] [Batch classify loss: 0.038145] 
[Epoch 3/20] [Batch 127/274] [Batch classify loss: 0.071285] 
[Epoch 3/20] [Batch 128/274] [Batch classify loss: 0.117238] 
[Epoch 3/20] [Batch 129/274] [Batch classify loss: 0.058660] 
[Epoch 3/20] [Batch 130/274] [Batch classify loss: 0.038227] 
[Epoch 3/20] [Batch 131/274] [Batch classify loss: 0.050537] 
[Epoch 3/20] [Batch 132/274] [Batch classify loss: 0.033889] 
[Epoch 3/20] [Batch 133/274] [Batch classify loss: 0.074176] 
[Epoch 3/20] [Batch 134/274] [Batch classify loss: 0.071496] 
[Epoch 3/20] [Batch 135/274] [Batch classify loss: 0.095875] 
[Epoch 3/20] [Batch 136/274] [Batch classify loss: 0.114884] 
[Epoch 3/20] [Batch 137/274] [Batch classify loss: 0.048315] 
[Epoch 3/20] [Batch 138/274] [Batch classify loss: 0.033115] 
[Epoch 3/20] [Batch 139/274] [Batch classify loss: 0.026981] 
[Epoch 3/20] [Batch 140/274] [Batch classify loss: 0.074508] 
[Epoch 3/20] [Batch 141/274] [Batch classify loss: 0.035867] 
[Epoch 3/20] [Batch 142/274] [Batch classify loss: 0.085686] 
[Epoch 3/20] [Batch 143/274] [Batch classify loss: 0.033721] 
[Epoch 3/20] [Batch 144/274] [Batch classify loss: 0.066534] 
[Epoch 3/20] [Batch 145/274] [Batch classify loss: 0.044534] 
[Epoch 3/20] [Batch 146/274] [Batch classify loss: 0.015867] 
[Epoch 3/20] [Batch 147/274] [Batch classify loss: 0.037187] 
[Epoch 3/20] [Batch 148/274] [Batch classify loss: 0.043796] 
[Epoch 3/20] [Batch 149/274] [Batch classify loss: 0.063895] 
[Epoch 3/20] [Batch 150/274] [Batch classify loss: 0.062279] 
[Epoch 3/20] [Batch 151/274] [Batch classify loss: 0.080910] 
[Epoch 3/20] [Batch 152/274] [Batch classify loss: 0.037846] 
[Epoch 3/20] [Batch 153/274] [Batch classify loss: 0.050947] 
[Epoch 3/20] [Batch 154/274] [Batch classify loss: 0.014569] 
[Epoch 3/20] [Batch 155/274] [Batch classify loss: 0.052599] 
[Epoch 3/20] [Batch 156/274] [Batch classify loss: 0.145950] 
[Epoch 3/20] [Batch 157/274] [Batch classify loss: 0.035130] 
[Epoch 3/20] [Batch 158/274] [Batch classify loss: 0.023799] 
[Epoch 3/20] [Batch 159/274] [Batch classify loss: 0.071676] 
[Epoch 3/20] [Batch 160/274] [Batch classify loss: 0.039824] 
[Epoch 3/20] [Batch 161/274] [Batch classify loss: 0.069092] 
[Epoch 3/20] [Batch 162/274] [Batch classify loss: 0.033289] 
[Epoch 3/20] [Batch 163/274] [Batch classify loss: 0.097314] 
[Epoch 3/20] [Batch 164/274] [Batch classify loss: 0.022132] 
[Epoch 3/20] [Batch 165/274] [Batch classify loss: 0.054019] 
[Epoch 3/20] [Batch 166/274] [Batch classify loss: 0.080762] 
[Epoch 3/20] [Batch 167/274] [Batch classify loss: 0.073955] 
[Epoch 3/20] [Batch 168/274] [Batch classify loss: 0.076094] 
[Epoch 3/20] [Batch 169/274] [Batch classify loss: 0.026875] 
[Epoch 3/20] [Batch 170/274] [Batch classify loss: 0.072504] 
[Epoch 3/20] [Batch 171/274] [Batch classify loss: 0.094424] 
[Epoch 3/20] [Batch 172/274] [Batch classify loss: 0.084828] 
[Epoch 3/20] [Batch 173/274] [Batch classify loss: 0.030073] 
[Epoch 3/20] [Batch 174/274] [Batch classify loss: 0.061013] 
[Epoch 3/20] [Batch 175/274] [Batch classify loss: 0.059902] 
[Epoch 3/20] [Batch 176/274] [Batch classify loss: 0.072921] 
[Epoch 3/20] [Batch 177/274] [Batch classify loss: 0.075902] 
[Epoch 3/20] [Batch 178/274] [Batch classify loss: 0.014912] 
[Epoch 3/20] [Batch 179/274] [Batch classify loss: 0.034554] 
[Epoch 3/20] [Batch 180/274] [Batch classify loss: 0.041811] 
[Epoch 3/20] [Batch 181/274] [Batch classify loss: 0.111941] 
[Epoch 3/20] [Batch 182/274] [Batch classify loss: 0.073386] 
[Epoch 3/20] [Batch 183/274] [Batch classify loss: 0.058107] 
[Epoch 3/20] [Batch 184/274] [Batch classify loss: 0.076765] 
[Epoch 3/20] [Batch 185/274] [Batch classify loss: 0.018489] 
[Epoch 3/20] [Batch 186/274] [Batch classify loss: 0.028780] 
[Epoch 3/20] [Batch 187/274] [Batch classify loss: 0.088590] 
[Epoch 3/20] [Batch 188/274] [Batch classify loss: 0.085850] 
[Epoch 3/20] [Batch 189/274] [Batch classify loss: 0.103095] 
[Epoch 3/20] [Batch 190/274] [Batch classify loss: 0.045117] 
[Epoch 3/20] [Batch 191/274] [Batch classify loss: 0.052926] 
[Epoch 3/20] [Batch 192/274] [Batch classify loss: 0.083567] 
[Epoch 3/20] [Batch 193/274] [Batch classify loss: 0.030987] 
[Epoch 3/20] [Batch 194/274] [Batch classify loss: 0.027506] 
[Epoch 3/20] [Batch 195/274] [Batch classify loss: 0.032363] 
[Epoch 3/20] [Batch 196/274] [Batch classify loss: 0.062053] 
[Epoch 3/20] [Batch 197/274] [Batch classify loss: 0.031846] 
[Epoch 3/20] [Batch 198/274] [Batch classify loss: 0.095582] 
[Epoch 3/20] [Batch 199/274] [Batch classify loss: 0.086642] 
[Epoch 3/20] [Batch 200/274] [Batch classify loss: 0.114710] 
[Epoch 3/20] [Batch 201/274] [Batch classify loss: 0.062381] 
[Epoch 3/20] [Batch 202/274] [Batch classify loss: 0.050708] 
[Epoch 3/20] [Batch 203/274] [Batch classify loss: 0.058352] 
[Epoch 3/20] [Batch 204/274] [Batch classify loss: 0.026623] 
[Epoch 3/20] [Batch 205/274] [Batch classify loss: 0.053206] 
[Epoch 3/20] [Batch 206/274] [Batch classify loss: 0.025620] 
[Epoch 3/20] [Batch 207/274] [Batch classify loss: 0.066538] 
[Epoch 3/20] [Batch 208/274] [Batch classify loss: 0.028703] 
[Epoch 3/20] [Batch 209/274] [Batch classify loss: 0.078304] 
[Epoch 3/20] [Batch 210/274] [Batch classify loss: 0.048166] 
[Epoch 3/20] [Batch 211/274] [Batch classify loss: 0.057006] 
[Epoch 3/20] [Batch 212/274] [Batch classify loss: 0.059039] 
[Epoch 3/20] [Batch 213/274] [Batch classify loss: 0.040850] 
[Epoch 3/20] [Batch 214/274] [Batch classify loss: 0.067515] 
[Epoch 3/20] [Batch 215/274] [Batch classify loss: 0.062534] 
[Epoch 3/20] [Batch 216/274] [Batch classify loss: 0.043541] 
[Epoch 3/20] [Batch 217/274] [Batch classify loss: 0.023936] 
[Epoch 3/20] [Batch 218/274] [Batch classify loss: 0.023548] 
[Epoch 3/20] [Batch 219/274] [Batch classify loss: 0.080768] 
[Epoch 3/20] [Batch 220/274] [Batch classify loss: 0.067957] 
[Epoch 3/20] [Batch 221/274] [Batch classify loss: 0.032413] 
[Epoch 3/20] [Batch 222/274] [Batch classify loss: 0.047975] 
[Epoch 3/20] [Batch 223/274] [Batch classify loss: 0.047195] 
[Epoch 3/20] [Batch 224/274] [Batch classify loss: 0.042698] 
[Epoch 3/20] [Batch 225/274] [Batch classify loss: 0.036674] 
[Epoch 3/20] [Batch 226/274] [Batch classify loss: 0.050558] 
[Epoch 3/20] [Batch 227/274] [Batch classify loss: 0.041298] 
[Epoch 3/20] [Batch 228/274] [Batch classify loss: 0.056101] 
[Epoch 3/20] [Batch 229/274] [Batch classify loss: 0.044210] 
[Epoch 3/20] [Batch 230/274] [Batch classify loss: 0.094636] 
[Epoch 3/20] [Batch 231/274] [Batch classify loss: 0.049867] 
[Epoch 3/20] [Batch 232/274] [Batch classify loss: 0.047324] 
[Epoch 3/20] [Batch 233/274] [Batch classify loss: 0.024994] 
[Epoch 3/20] [Batch 234/274] [Batch classify loss: 0.102532] 
[Epoch 3/20] [Batch 235/274] [Batch classify loss: 0.033072] 
[Epoch 3/20] [Batch 236/274] [Batch classify loss: 0.078689] 
[Epoch 3/20] [Batch 237/274] [Batch classify loss: 0.020839] 
[Epoch 3/20] [Batch 238/274] [Batch classify loss: 0.046474] 
[Epoch 3/20] [Batch 239/274] [Batch classify loss: 0.052435] 
[Epoch 3/20] [Batch 240/274] [Batch classify loss: 0.052947] 
[Epoch 3/20] [Batch 241/274] [Batch classify loss: 0.054912] 
[Epoch 3/20] [Batch 242/274] [Batch classify loss: 0.044087] 
[Epoch 3/20] [Batch 243/274] [Batch classify loss: 0.049254] 
[Epoch 3/20] [Batch 244/274] [Batch classify loss: 0.069083] 
[Epoch 3/20] [Batch 245/274] [Batch classify loss: 0.043487] 
[Epoch 3/20] [Batch 246/274] [Batch classify loss: 0.027938] 
[Epoch 3/20] [Batch 247/274] [Batch classify loss: 0.036749] 
[Epoch 3/20] [Batch 248/274] [Batch classify loss: 0.040053] 
[Epoch 3/20] [Batch 249/274] [Batch classify loss: 0.036130] 
[Epoch 3/20] [Batch 250/274] [Batch classify loss: 0.034883] 
[Epoch 3/20] [Batch 251/274] [Batch classify loss: 0.038100] 
[Epoch 3/20] [Batch 252/274] [Batch classify loss: 0.029151] 
[Epoch 3/20] [Batch 253/274] [Batch classify loss: 0.046132] 
[Epoch 3/20] [Batch 254/274] [Batch classify loss: 0.032692] 
[Epoch 3/20] [Batch 255/274] [Batch classify loss: 0.080308] 
[Epoch 3/20] [Batch 256/274] [Batch classify loss: 0.063829] 
[Epoch 3/20] [Batch 257/274] [Batch classify loss: 0.071345] 
[Epoch 3/20] [Batch 258/274] [Batch classify loss: 0.062094] 
[Epoch 3/20] [Batch 259/274] [Batch classify loss: 0.060571] 
[Epoch 3/20] [Batch 260/274] [Batch classify loss: 0.046074] 
[Epoch 3/20] [Batch 261/274] [Batch classify loss: 0.062278] 
[Epoch 3/20] [Batch 262/274] [Batch classify loss: 0.032171] 
[Epoch 3/20] [Batch 263/274] [Batch classify loss: 0.026255] 
[Epoch 3/20] [Batch 264/274] [Batch classify loss: 0.045142] 
[Epoch 3/20] [Batch 265/274] [Batch classify loss: 0.091289] 
[Epoch 3/20] [Batch 266/274] [Batch classify loss: 0.031910] 
[Epoch 3/20] [Batch 267/274] [Batch classify loss: 0.054936] 
[Epoch 3/20] [Batch 268/274] [Batch classify loss: 0.085351] 
[Epoch 3/20] [Batch 269/274] [Batch classify loss: 0.032603] 
[Epoch 3/20] [Batch 270/274] [Batch classify loss: 0.074213] 
[Epoch 3/20] [Batch 271/274] [Batch classify loss: 0.043292] 
[Epoch 3/20] [Batch 272/274] [Batch classify loss: 0.035229] 
[Epoch 3/20] [Batch 273/274] [Batch classify loss: 0.086273] 
[Epoch 3/20] [Batch 274/274] [Batch classify loss: 0.028732] 
0003 epoch mmat trained classifier accuary on the clean testing examples:94.8256%
0003 epoch mmat trained classifier loss on the clean testing examples:0.2209
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3234%
mmat trained classifier loss on adversarial testset:4.5208539962768555
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
3epoch learning rate:0.01
[Epoch 4/20] [Batch 1/274] [Batch classify loss: 0.024134] 
[Epoch 4/20] [Batch 2/274] [Batch classify loss: 0.016285] 
[Epoch 4/20] [Batch 3/274] [Batch classify loss: 0.013916] 
[Epoch 4/20] [Batch 4/274] [Batch classify loss: 0.018477] 
[Epoch 4/20] [Batch 5/274] [Batch classify loss: 0.051452] 
[Epoch 4/20] [Batch 6/274] [Batch classify loss: 0.027757] 
[Epoch 4/20] [Batch 7/274] [Batch classify loss: 0.046614] 
[Epoch 4/20] [Batch 8/274] [Batch classify loss: 0.065729] 
[Epoch 4/20] [Batch 9/274] [Batch classify loss: 0.072204] 
[Epoch 4/20] [Batch 10/274] [Batch classify loss: 0.034340] 
[Epoch 4/20] [Batch 11/274] [Batch classify loss: 0.037794] 
[Epoch 4/20] [Batch 12/274] [Batch classify loss: 0.027838] 
[Epoch 4/20] [Batch 13/274] [Batch classify loss: 0.017002] 
[Epoch 4/20] [Batch 14/274] [Batch classify loss: 0.036096] 
[Epoch 4/20] [Batch 15/274] [Batch classify loss: 0.024486] 
[Epoch 4/20] [Batch 16/274] [Batch classify loss: 0.018871] 
[Epoch 4/20] [Batch 17/274] [Batch classify loss: 0.080985] 
[Epoch 4/20] [Batch 18/274] [Batch classify loss: 0.069554] 
[Epoch 4/20] [Batch 19/274] [Batch classify loss: 0.014064] 
[Epoch 4/20] [Batch 20/274] [Batch classify loss: 0.046965] 
[Epoch 4/20] [Batch 21/274] [Batch classify loss: 0.023934] 
[Epoch 4/20] [Batch 22/274] [Batch classify loss: 0.030137] 
[Epoch 4/20] [Batch 23/274] [Batch classify loss: 0.027442] 
[Epoch 4/20] [Batch 24/274] [Batch classify loss: 0.037390] 
[Epoch 4/20] [Batch 25/274] [Batch classify loss: 0.041023] 
[Epoch 4/20] [Batch 26/274] [Batch classify loss: 0.035388] 
[Epoch 4/20] [Batch 27/274] [Batch classify loss: 0.057865] 
[Epoch 4/20] [Batch 28/274] [Batch classify loss: 0.034877] 
[Epoch 4/20] [Batch 29/274] [Batch classify loss: 0.043288] 
[Epoch 4/20] [Batch 30/274] [Batch classify loss: 0.033184] 
[Epoch 4/20] [Batch 31/274] [Batch classify loss: 0.052942] 
[Epoch 4/20] [Batch 32/274] [Batch classify loss: 0.056009] 
[Epoch 4/20] [Batch 33/274] [Batch classify loss: 0.031220] 
[Epoch 4/20] [Batch 34/274] [Batch classify loss: 0.019862] 
[Epoch 4/20] [Batch 35/274] [Batch classify loss: 0.049599] 
[Epoch 4/20] [Batch 36/274] [Batch classify loss: 0.041471] 
[Epoch 4/20] [Batch 37/274] [Batch classify loss: 0.007521] 
[Epoch 4/20] [Batch 38/274] [Batch classify loss: 0.031921] 
[Epoch 4/20] [Batch 39/274] [Batch classify loss: 0.029176] 
[Epoch 4/20] [Batch 40/274] [Batch classify loss: 0.020092] 
[Epoch 4/20] [Batch 41/274] [Batch classify loss: 0.039941] 
[Epoch 4/20] [Batch 42/274] [Batch classify loss: 0.060014] 
[Epoch 4/20] [Batch 43/274] [Batch classify loss: 0.027379] 
[Epoch 4/20] [Batch 44/274] [Batch classify loss: 0.093619] 
[Epoch 4/20] [Batch 45/274] [Batch classify loss: 0.110312] 
[Epoch 4/20] [Batch 46/274] [Batch classify loss: 0.020177] 
[Epoch 4/20] [Batch 47/274] [Batch classify loss: 0.089086] 
[Epoch 4/20] [Batch 48/274] [Batch classify loss: 0.010629] 
[Epoch 4/20] [Batch 49/274] [Batch classify loss: 0.043456] 
[Epoch 4/20] [Batch 50/274] [Batch classify loss: 0.047324] 
[Epoch 4/20] [Batch 51/274] [Batch classify loss: 0.034882] 
[Epoch 4/20] [Batch 52/274] [Batch classify loss: 0.018688] 
[Epoch 4/20] [Batch 53/274] [Batch classify loss: 0.019857] 
[Epoch 4/20] [Batch 54/274] [Batch classify loss: 0.030167] 
[Epoch 4/20] [Batch 55/274] [Batch classify loss: 0.039981] 
[Epoch 4/20] [Batch 56/274] [Batch classify loss: 0.046138] 
[Epoch 4/20] [Batch 57/274] [Batch classify loss: 0.079859] 
[Epoch 4/20] [Batch 58/274] [Batch classify loss: 0.035650] 
[Epoch 4/20] [Batch 59/274] [Batch classify loss: 0.037457] 
[Epoch 4/20] [Batch 60/274] [Batch classify loss: 0.079402] 
[Epoch 4/20] [Batch 61/274] [Batch classify loss: 0.018862] 
[Epoch 4/20] [Batch 62/274] [Batch classify loss: 0.066007] 
[Epoch 4/20] [Batch 63/274] [Batch classify loss: 0.019509] 
[Epoch 4/20] [Batch 64/274] [Batch classify loss: 0.036036] 
[Epoch 4/20] [Batch 65/274] [Batch classify loss: 0.045669] 
[Epoch 4/20] [Batch 66/274] [Batch classify loss: 0.015838] 
[Epoch 4/20] [Batch 67/274] [Batch classify loss: 0.071426] 
[Epoch 4/20] [Batch 68/274] [Batch classify loss: 0.048671] 
[Epoch 4/20] [Batch 69/274] [Batch classify loss: 0.032071] 
[Epoch 4/20] [Batch 70/274] [Batch classify loss: 0.046721] 
[Epoch 4/20] [Batch 71/274] [Batch classify loss: 0.022136] 
[Epoch 4/20] [Batch 72/274] [Batch classify loss: 0.030517] 
[Epoch 4/20] [Batch 73/274] [Batch classify loss: 0.021609] 
[Epoch 4/20] [Batch 74/274] [Batch classify loss: 0.063565] 
[Epoch 4/20] [Batch 75/274] [Batch classify loss: 0.024777] 
[Epoch 4/20] [Batch 76/274] [Batch classify loss: 0.022024] 
[Epoch 4/20] [Batch 77/274] [Batch classify loss: 0.047634] 
[Epoch 4/20] [Batch 78/274] [Batch classify loss: 0.030780] 
[Epoch 4/20] [Batch 79/274] [Batch classify loss: 0.075939] 
[Epoch 4/20] [Batch 80/274] [Batch classify loss: 0.028050] 
[Epoch 4/20] [Batch 81/274] [Batch classify loss: 0.096281] 
[Epoch 4/20] [Batch 82/274] [Batch classify loss: 0.051626] 
[Epoch 4/20] [Batch 83/274] [Batch classify loss: 0.054724] 
[Epoch 4/20] [Batch 84/274] [Batch classify loss: 0.048805] 
[Epoch 4/20] [Batch 85/274] [Batch classify loss: 0.096775] 
[Epoch 4/20] [Batch 86/274] [Batch classify loss: 0.041531] 
[Epoch 4/20] [Batch 87/274] [Batch classify loss: 0.046603] 
[Epoch 4/20] [Batch 88/274] [Batch classify loss: 0.120778] 
[Epoch 4/20] [Batch 89/274] [Batch classify loss: 0.037255] 
[Epoch 4/20] [Batch 90/274] [Batch classify loss: 0.029587] 
[Epoch 4/20] [Batch 91/274] [Batch classify loss: 0.079900] 
[Epoch 4/20] [Batch 92/274] [Batch classify loss: 0.024497] 
[Epoch 4/20] [Batch 93/274] [Batch classify loss: 0.015463] 
[Epoch 4/20] [Batch 94/274] [Batch classify loss: 0.039035] 
[Epoch 4/20] [Batch 95/274] [Batch classify loss: 0.018787] 
[Epoch 4/20] [Batch 96/274] [Batch classify loss: 0.075326] 
[Epoch 4/20] [Batch 97/274] [Batch classify loss: 0.037894] 
[Epoch 4/20] [Batch 98/274] [Batch classify loss: 0.077216] 
[Epoch 4/20] [Batch 99/274] [Batch classify loss: 0.041366] 
[Epoch 4/20] [Batch 100/274] [Batch classify loss: 0.055349] 
[Epoch 4/20] [Batch 101/274] [Batch classify loss: 0.086600] 
[Epoch 4/20] [Batch 102/274] [Batch classify loss: 0.038372] 
[Epoch 4/20] [Batch 103/274] [Batch classify loss: 0.032998] 
[Epoch 4/20] [Batch 104/274] [Batch classify loss: 0.020757] 
[Epoch 4/20] [Batch 105/274] [Batch classify loss: 0.032936] 
[Epoch 4/20] [Batch 106/274] [Batch classify loss: 0.038327] 
[Epoch 4/20] [Batch 107/274] [Batch classify loss: 0.019119] 
[Epoch 4/20] [Batch 108/274] [Batch classify loss: 0.093150] 
[Epoch 4/20] [Batch 109/274] [Batch classify loss: 0.027926] 
[Epoch 4/20] [Batch 110/274] [Batch classify loss: 0.027464] 
[Epoch 4/20] [Batch 111/274] [Batch classify loss: 0.019507] 
[Epoch 4/20] [Batch 112/274] [Batch classify loss: 0.035629] 
[Epoch 4/20] [Batch 113/274] [Batch classify loss: 0.036318] 
[Epoch 4/20] [Batch 114/274] [Batch classify loss: 0.034309] 
[Epoch 4/20] [Batch 115/274] [Batch classify loss: 0.062505] 
[Epoch 4/20] [Batch 116/274] [Batch classify loss: 0.022343] 
[Epoch 4/20] [Batch 117/274] [Batch classify loss: 0.055147] 
[Epoch 4/20] [Batch 118/274] [Batch classify loss: 0.035288] 
[Epoch 4/20] [Batch 119/274] [Batch classify loss: 0.063648] 
[Epoch 4/20] [Batch 120/274] [Batch classify loss: 0.034427] 
[Epoch 4/20] [Batch 121/274] [Batch classify loss: 0.050821] 
[Epoch 4/20] [Batch 122/274] [Batch classify loss: 0.037706] 
[Epoch 4/20] [Batch 123/274] [Batch classify loss: 0.085588] 
[Epoch 4/20] [Batch 124/274] [Batch classify loss: 0.052374] 
[Epoch 4/20] [Batch 125/274] [Batch classify loss: 0.032602] 
[Epoch 4/20] [Batch 126/274] [Batch classify loss: 0.031844] 
[Epoch 4/20] [Batch 127/274] [Batch classify loss: 0.058180] 
[Epoch 4/20] [Batch 128/274] [Batch classify loss: 0.060160] 
[Epoch 4/20] [Batch 129/274] [Batch classify loss: 0.036979] 
[Epoch 4/20] [Batch 130/274] [Batch classify loss: 0.022162] 
[Epoch 4/20] [Batch 131/274] [Batch classify loss: 0.088712] 
[Epoch 4/20] [Batch 132/274] [Batch classify loss: 0.052804] 
[Epoch 4/20] [Batch 133/274] [Batch classify loss: 0.073609] 
[Epoch 4/20] [Batch 134/274] [Batch classify loss: 0.021349] 
[Epoch 4/20] [Batch 135/274] [Batch classify loss: 0.100324] 
[Epoch 4/20] [Batch 136/274] [Batch classify loss: 0.020815] 
[Epoch 4/20] [Batch 137/274] [Batch classify loss: 0.047639] 
[Epoch 4/20] [Batch 138/274] [Batch classify loss: 0.046641] 
[Epoch 4/20] [Batch 139/274] [Batch classify loss: 0.035782] 
[Epoch 4/20] [Batch 140/274] [Batch classify loss: 0.052734] 
[Epoch 4/20] [Batch 141/274] [Batch classify loss: 0.024967] 
[Epoch 4/20] [Batch 142/274] [Batch classify loss: 0.034348] 
[Epoch 4/20] [Batch 143/274] [Batch classify loss: 0.064380] 
[Epoch 4/20] [Batch 144/274] [Batch classify loss: 0.085359] 
[Epoch 4/20] [Batch 145/274] [Batch classify loss: 0.031618] 
[Epoch 4/20] [Batch 146/274] [Batch classify loss: 0.059319] 
[Epoch 4/20] [Batch 147/274] [Batch classify loss: 0.051266] 
[Epoch 4/20] [Batch 148/274] [Batch classify loss: 0.031664] 
[Epoch 4/20] [Batch 149/274] [Batch classify loss: 0.068798] 
[Epoch 4/20] [Batch 150/274] [Batch classify loss: 0.012598] 
[Epoch 4/20] [Batch 151/274] [Batch classify loss: 0.028683] 
[Epoch 4/20] [Batch 152/274] [Batch classify loss: 0.062603] 
[Epoch 4/20] [Batch 153/274] [Batch classify loss: 0.083187] 
[Epoch 4/20] [Batch 154/274] [Batch classify loss: 0.103642] 
[Epoch 4/20] [Batch 155/274] [Batch classify loss: 0.040413] 
[Epoch 4/20] [Batch 156/274] [Batch classify loss: 0.066186] 
[Epoch 4/20] [Batch 157/274] [Batch classify loss: 0.095848] 
[Epoch 4/20] [Batch 158/274] [Batch classify loss: 0.036035] 
[Epoch 4/20] [Batch 159/274] [Batch classify loss: 0.043913] 
[Epoch 4/20] [Batch 160/274] [Batch classify loss: 0.036810] 
[Epoch 4/20] [Batch 161/274] [Batch classify loss: 0.053070] 
[Epoch 4/20] [Batch 162/274] [Batch classify loss: 0.034488] 
[Epoch 4/20] [Batch 163/274] [Batch classify loss: 0.021947] 
[Epoch 4/20] [Batch 164/274] [Batch classify loss: 0.047105] 
[Epoch 4/20] [Batch 165/274] [Batch classify loss: 0.061774] 
[Epoch 4/20] [Batch 166/274] [Batch classify loss: 0.137716] 
[Epoch 4/20] [Batch 167/274] [Batch classify loss: 0.084879] 
[Epoch 4/20] [Batch 168/274] [Batch classify loss: 0.048438] 
[Epoch 4/20] [Batch 169/274] [Batch classify loss: 0.087196] 
[Epoch 4/20] [Batch 170/274] [Batch classify loss: 0.013154] 
[Epoch 4/20] [Batch 171/274] [Batch classify loss: 0.036863] 
[Epoch 4/20] [Batch 172/274] [Batch classify loss: 0.029664] 
[Epoch 4/20] [Batch 173/274] [Batch classify loss: 0.079659] 
[Epoch 4/20] [Batch 174/274] [Batch classify loss: 0.028458] 
[Epoch 4/20] [Batch 175/274] [Batch classify loss: 0.020584] 
[Epoch 4/20] [Batch 176/274] [Batch classify loss: 0.112315] 
[Epoch 4/20] [Batch 177/274] [Batch classify loss: 0.026157] 
[Epoch 4/20] [Batch 178/274] [Batch classify loss: 0.060700] 
[Epoch 4/20] [Batch 179/274] [Batch classify loss: 0.029231] 
[Epoch 4/20] [Batch 180/274] [Batch classify loss: 0.016352] 
[Epoch 4/20] [Batch 181/274] [Batch classify loss: 0.037700] 
[Epoch 4/20] [Batch 182/274] [Batch classify loss: 0.057089] 
[Epoch 4/20] [Batch 183/274] [Batch classify loss: 0.057217] 
[Epoch 4/20] [Batch 184/274] [Batch classify loss: 0.048275] 
[Epoch 4/20] [Batch 185/274] [Batch classify loss: 0.063285] 
[Epoch 4/20] [Batch 186/274] [Batch classify loss: 0.030312] 
[Epoch 4/20] [Batch 187/274] [Batch classify loss: 0.071684] 
[Epoch 4/20] [Batch 188/274] [Batch classify loss: 0.107904] 
[Epoch 4/20] [Batch 189/274] [Batch classify loss: 0.037229] 
[Epoch 4/20] [Batch 190/274] [Batch classify loss: 0.053524] 
[Epoch 4/20] [Batch 191/274] [Batch classify loss: 0.016870] 
[Epoch 4/20] [Batch 192/274] [Batch classify loss: 0.071270] 
[Epoch 4/20] [Batch 193/274] [Batch classify loss: 0.076097] 
[Epoch 4/20] [Batch 194/274] [Batch classify loss: 0.066690] 
[Epoch 4/20] [Batch 195/274] [Batch classify loss: 0.078521] 
[Epoch 4/20] [Batch 196/274] [Batch classify loss: 0.033224] 
[Epoch 4/20] [Batch 197/274] [Batch classify loss: 0.029423] 
[Epoch 4/20] [Batch 198/274] [Batch classify loss: 0.120977] 
[Epoch 4/20] [Batch 199/274] [Batch classify loss: 0.012226] 
[Epoch 4/20] [Batch 200/274] [Batch classify loss: 0.068889] 
[Epoch 4/20] [Batch 201/274] [Batch classify loss: 0.112215] 
[Epoch 4/20] [Batch 202/274] [Batch classify loss: 0.054154] 
[Epoch 4/20] [Batch 203/274] [Batch classify loss: 0.075806] 
[Epoch 4/20] [Batch 204/274] [Batch classify loss: 0.099485] 
[Epoch 4/20] [Batch 205/274] [Batch classify loss: 0.068923] 
[Epoch 4/20] [Batch 206/274] [Batch classify loss: 0.070878] 
[Epoch 4/20] [Batch 207/274] [Batch classify loss: 0.051655] 
[Epoch 4/20] [Batch 208/274] [Batch classify loss: 0.050006] 
[Epoch 4/20] [Batch 209/274] [Batch classify loss: 0.041294] 
[Epoch 4/20] [Batch 210/274] [Batch classify loss: 0.057237] 
[Epoch 4/20] [Batch 211/274] [Batch classify loss: 0.013408] 
[Epoch 4/20] [Batch 212/274] [Batch classify loss: 0.052320] 
[Epoch 4/20] [Batch 213/274] [Batch classify loss: 0.118576] 
[Epoch 4/20] [Batch 214/274] [Batch classify loss: 0.023475] 
[Epoch 4/20] [Batch 215/274] [Batch classify loss: 0.030967] 
[Epoch 4/20] [Batch 216/274] [Batch classify loss: 0.031894] 
[Epoch 4/20] [Batch 217/274] [Batch classify loss: 0.095768] 
[Epoch 4/20] [Batch 218/274] [Batch classify loss: 0.046776] 
[Epoch 4/20] [Batch 219/274] [Batch classify loss: 0.022317] 
[Epoch 4/20] [Batch 220/274] [Batch classify loss: 0.053318] 
[Epoch 4/20] [Batch 221/274] [Batch classify loss: 0.010877] 
[Epoch 4/20] [Batch 222/274] [Batch classify loss: 0.084037] 
[Epoch 4/20] [Batch 223/274] [Batch classify loss: 0.032232] 
[Epoch 4/20] [Batch 224/274] [Batch classify loss: 0.044641] 
[Epoch 4/20] [Batch 225/274] [Batch classify loss: 0.050568] 
[Epoch 4/20] [Batch 226/274] [Batch classify loss: 0.078381] 
[Epoch 4/20] [Batch 227/274] [Batch classify loss: 0.067209] 
[Epoch 4/20] [Batch 228/274] [Batch classify loss: 0.054282] 
[Epoch 4/20] [Batch 229/274] [Batch classify loss: 0.048621] 
[Epoch 4/20] [Batch 230/274] [Batch classify loss: 0.050634] 
[Epoch 4/20] [Batch 231/274] [Batch classify loss: 0.061220] 
[Epoch 4/20] [Batch 232/274] [Batch classify loss: 0.038447] 
[Epoch 4/20] [Batch 233/274] [Batch classify loss: 0.019993] 
[Epoch 4/20] [Batch 234/274] [Batch classify loss: 0.067490] 
[Epoch 4/20] [Batch 235/274] [Batch classify loss: 0.032804] 
[Epoch 4/20] [Batch 236/274] [Batch classify loss: 0.077145] 
[Epoch 4/20] [Batch 237/274] [Batch classify loss: 0.054862] 
[Epoch 4/20] [Batch 238/274] [Batch classify loss: 0.036833] 
[Epoch 4/20] [Batch 239/274] [Batch classify loss: 0.029632] 
[Epoch 4/20] [Batch 240/274] [Batch classify loss: 0.057764] 
[Epoch 4/20] [Batch 241/274] [Batch classify loss: 0.040650] 
[Epoch 4/20] [Batch 242/274] [Batch classify loss: 0.036461] 
[Epoch 4/20] [Batch 243/274] [Batch classify loss: 0.024040] 
[Epoch 4/20] [Batch 244/274] [Batch classify loss: 0.044929] 
[Epoch 4/20] [Batch 245/274] [Batch classify loss: 0.069038] 
[Epoch 4/20] [Batch 246/274] [Batch classify loss: 0.035593] 
[Epoch 4/20] [Batch 247/274] [Batch classify loss: 0.057675] 
[Epoch 4/20] [Batch 248/274] [Batch classify loss: 0.040110] 
[Epoch 4/20] [Batch 249/274] [Batch classify loss: 0.030959] 
[Epoch 4/20] [Batch 250/274] [Batch classify loss: 0.028250] 
[Epoch 4/20] [Batch 251/274] [Batch classify loss: 0.056534] 
[Epoch 4/20] [Batch 252/274] [Batch classify loss: 0.067321] 
[Epoch 4/20] [Batch 253/274] [Batch classify loss: 0.060527] 
[Epoch 4/20] [Batch 254/274] [Batch classify loss: 0.036453] 
[Epoch 4/20] [Batch 255/274] [Batch classify loss: 0.047921] 
[Epoch 4/20] [Batch 256/274] [Batch classify loss: 0.033047] 
[Epoch 4/20] [Batch 257/274] [Batch classify loss: 0.059479] 
[Epoch 4/20] [Batch 258/274] [Batch classify loss: 0.037176] 
[Epoch 4/20] [Batch 259/274] [Batch classify loss: 0.081935] 
[Epoch 4/20] [Batch 260/274] [Batch classify loss: 0.062679] 
[Epoch 4/20] [Batch 261/274] [Batch classify loss: 0.038687] 
[Epoch 4/20] [Batch 262/274] [Batch classify loss: 0.025846] 
[Epoch 4/20] [Batch 263/274] [Batch classify loss: 0.010956] 
[Epoch 4/20] [Batch 264/274] [Batch classify loss: 0.064424] 
[Epoch 4/20] [Batch 265/274] [Batch classify loss: 0.037174] 
[Epoch 4/20] [Batch 266/274] [Batch classify loss: 0.019319] 
[Epoch 4/20] [Batch 267/274] [Batch classify loss: 0.035825] 
[Epoch 4/20] [Batch 268/274] [Batch classify loss: 0.014180] 
[Epoch 4/20] [Batch 269/274] [Batch classify loss: 0.066628] 
[Epoch 4/20] [Batch 270/274] [Batch classify loss: 0.041643] 
[Epoch 4/20] [Batch 271/274] [Batch classify loss: 0.077149] 
[Epoch 4/20] [Batch 272/274] [Batch classify loss: 0.067324] 
[Epoch 4/20] [Batch 273/274] [Batch classify loss: 0.063226] 
[Epoch 4/20] [Batch 274/274] [Batch classify loss: 0.098294] 
0004 epoch mmat trained classifier accuary on the clean testing examples:94.6758%
0004 epoch mmat trained classifier loss on the clean testing examples:0.2234
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3427%
mmat trained classifier loss on adversarial testset:4.534373760223389
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
4epoch learning rate:0.01
[Epoch 5/20] [Batch 1/274] [Batch classify loss: 0.114161] 
[Epoch 5/20] [Batch 2/274] [Batch classify loss: 0.019284] 
[Epoch 5/20] [Batch 3/274] [Batch classify loss: 0.031168] 
[Epoch 5/20] [Batch 4/274] [Batch classify loss: 0.018283] 
[Epoch 5/20] [Batch 5/274] [Batch classify loss: 0.014854] 
[Epoch 5/20] [Batch 6/274] [Batch classify loss: 0.018440] 
[Epoch 5/20] [Batch 7/274] [Batch classify loss: 0.023366] 
[Epoch 5/20] [Batch 8/274] [Batch classify loss: 0.010432] 
[Epoch 5/20] [Batch 9/274] [Batch classify loss: 0.047523] 
[Epoch 5/20] [Batch 10/274] [Batch classify loss: 0.030899] 
[Epoch 5/20] [Batch 11/274] [Batch classify loss: 0.031417] 
[Epoch 5/20] [Batch 12/274] [Batch classify loss: 0.059448] 
[Epoch 5/20] [Batch 13/274] [Batch classify loss: 0.039875] 
[Epoch 5/20] [Batch 14/274] [Batch classify loss: 0.043563] 
[Epoch 5/20] [Batch 15/274] [Batch classify loss: 0.021770] 
[Epoch 5/20] [Batch 16/274] [Batch classify loss: 0.017516] 
[Epoch 5/20] [Batch 17/274] [Batch classify loss: 0.024042] 
[Epoch 5/20] [Batch 18/274] [Batch classify loss: 0.029464] 
[Epoch 5/20] [Batch 19/274] [Batch classify loss: 0.015155] 
[Epoch 5/20] [Batch 20/274] [Batch classify loss: 0.025026] 
[Epoch 5/20] [Batch 21/274] [Batch classify loss: 0.033562] 
[Epoch 5/20] [Batch 22/274] [Batch classify loss: 0.032287] 
[Epoch 5/20] [Batch 23/274] [Batch classify loss: 0.045231] 
[Epoch 5/20] [Batch 24/274] [Batch classify loss: 0.015310] 
[Epoch 5/20] [Batch 25/274] [Batch classify loss: 0.028660] 
[Epoch 5/20] [Batch 26/274] [Batch classify loss: 0.024427] 
[Epoch 5/20] [Batch 27/274] [Batch classify loss: 0.030336] 
[Epoch 5/20] [Batch 28/274] [Batch classify loss: 0.044477] 
[Epoch 5/20] [Batch 29/274] [Batch classify loss: 0.086835] 
[Epoch 5/20] [Batch 30/274] [Batch classify loss: 0.024253] 
[Epoch 5/20] [Batch 31/274] [Batch classify loss: 0.064069] 
[Epoch 5/20] [Batch 32/274] [Batch classify loss: 0.060861] 
[Epoch 5/20] [Batch 33/274] [Batch classify loss: 0.032040] 
[Epoch 5/20] [Batch 34/274] [Batch classify loss: 0.013127] 
[Epoch 5/20] [Batch 35/274] [Batch classify loss: 0.052689] 
[Epoch 5/20] [Batch 36/274] [Batch classify loss: 0.021407] 
[Epoch 5/20] [Batch 37/274] [Batch classify loss: 0.044492] 
[Epoch 5/20] [Batch 38/274] [Batch classify loss: 0.025395] 
[Epoch 5/20] [Batch 39/274] [Batch classify loss: 0.041581] 
[Epoch 5/20] [Batch 40/274] [Batch classify loss: 0.022511] 
[Epoch 5/20] [Batch 41/274] [Batch classify loss: 0.023249] 
[Epoch 5/20] [Batch 42/274] [Batch classify loss: 0.020078] 
[Epoch 5/20] [Batch 43/274] [Batch classify loss: 0.035913] 
[Epoch 5/20] [Batch 44/274] [Batch classify loss: 0.035395] 
[Epoch 5/20] [Batch 45/274] [Batch classify loss: 0.042528] 
[Epoch 5/20] [Batch 46/274] [Batch classify loss: 0.037360] 
[Epoch 5/20] [Batch 47/274] [Batch classify loss: 0.050388] 
[Epoch 5/20] [Batch 48/274] [Batch classify loss: 0.055513] 
[Epoch 5/20] [Batch 49/274] [Batch classify loss: 0.042744] 
[Epoch 5/20] [Batch 50/274] [Batch classify loss: 0.018664] 
[Epoch 5/20] [Batch 51/274] [Batch classify loss: 0.045598] 
[Epoch 5/20] [Batch 52/274] [Batch classify loss: 0.055942] 
[Epoch 5/20] [Batch 53/274] [Batch classify loss: 0.057032] 
[Epoch 5/20] [Batch 54/274] [Batch classify loss: 0.052347] 
[Epoch 5/20] [Batch 55/274] [Batch classify loss: 0.039866] 
[Epoch 5/20] [Batch 56/274] [Batch classify loss: 0.015760] 
[Epoch 5/20] [Batch 57/274] [Batch classify loss: 0.013513] 
[Epoch 5/20] [Batch 58/274] [Batch classify loss: 0.038079] 
[Epoch 5/20] [Batch 59/274] [Batch classify loss: 0.037889] 
[Epoch 5/20] [Batch 60/274] [Batch classify loss: 0.033759] 
[Epoch 5/20] [Batch 61/274] [Batch classify loss: 0.043684] 
[Epoch 5/20] [Batch 62/274] [Batch classify loss: 0.076741] 
[Epoch 5/20] [Batch 63/274] [Batch classify loss: 0.014758] 
[Epoch 5/20] [Batch 64/274] [Batch classify loss: 0.067693] 
[Epoch 5/20] [Batch 65/274] [Batch classify loss: 0.036927] 
[Epoch 5/20] [Batch 66/274] [Batch classify loss: 0.018254] 
[Epoch 5/20] [Batch 67/274] [Batch classify loss: 0.025502] 
[Epoch 5/20] [Batch 68/274] [Batch classify loss: 0.030438] 
[Epoch 5/20] [Batch 69/274] [Batch classify loss: 0.078098] 
[Epoch 5/20] [Batch 70/274] [Batch classify loss: 0.064821] 
[Epoch 5/20] [Batch 71/274] [Batch classify loss: 0.039263] 
[Epoch 5/20] [Batch 72/274] [Batch classify loss: 0.049877] 
[Epoch 5/20] [Batch 73/274] [Batch classify loss: 0.042826] 
[Epoch 5/20] [Batch 74/274] [Batch classify loss: 0.010273] 
[Epoch 5/20] [Batch 75/274] [Batch classify loss: 0.024572] 
[Epoch 5/20] [Batch 76/274] [Batch classify loss: 0.030979] 
[Epoch 5/20] [Batch 77/274] [Batch classify loss: 0.015624] 
[Epoch 5/20] [Batch 78/274] [Batch classify loss: 0.019428] 
[Epoch 5/20] [Batch 79/274] [Batch classify loss: 0.067202] 
[Epoch 5/20] [Batch 80/274] [Batch classify loss: 0.032587] 
[Epoch 5/20] [Batch 81/274] [Batch classify loss: 0.048562] 
[Epoch 5/20] [Batch 82/274] [Batch classify loss: 0.030347] 
[Epoch 5/20] [Batch 83/274] [Batch classify loss: 0.050242] 
[Epoch 5/20] [Batch 84/274] [Batch classify loss: 0.059122] 
[Epoch 5/20] [Batch 85/274] [Batch classify loss: 0.065187] 
[Epoch 5/20] [Batch 86/274] [Batch classify loss: 0.039688] 
[Epoch 5/20] [Batch 87/274] [Batch classify loss: 0.027070] 
[Epoch 5/20] [Batch 88/274] [Batch classify loss: 0.028018] 
[Epoch 5/20] [Batch 89/274] [Batch classify loss: 0.045698] 
[Epoch 5/20] [Batch 90/274] [Batch classify loss: 0.070389] 
[Epoch 5/20] [Batch 91/274] [Batch classify loss: 0.014144] 
[Epoch 5/20] [Batch 92/274] [Batch classify loss: 0.021581] 
[Epoch 5/20] [Batch 93/274] [Batch classify loss: 0.036202] 
[Epoch 5/20] [Batch 94/274] [Batch classify loss: 0.035051] 
[Epoch 5/20] [Batch 95/274] [Batch classify loss: 0.017544] 
[Epoch 5/20] [Batch 96/274] [Batch classify loss: 0.041969] 
[Epoch 5/20] [Batch 97/274] [Batch classify loss: 0.024386] 
[Epoch 5/20] [Batch 98/274] [Batch classify loss: 0.024487] 
[Epoch 5/20] [Batch 99/274] [Batch classify loss: 0.027429] 
[Epoch 5/20] [Batch 100/274] [Batch classify loss: 0.037851] 
[Epoch 5/20] [Batch 101/274] [Batch classify loss: 0.042672] 
[Epoch 5/20] [Batch 102/274] [Batch classify loss: 0.048393] 
[Epoch 5/20] [Batch 103/274] [Batch classify loss: 0.019014] 
[Epoch 5/20] [Batch 104/274] [Batch classify loss: 0.016824] 
[Epoch 5/20] [Batch 105/274] [Batch classify loss: 0.028248] 
[Epoch 5/20] [Batch 106/274] [Batch classify loss: 0.033462] 
[Epoch 5/20] [Batch 107/274] [Batch classify loss: 0.028989] 
[Epoch 5/20] [Batch 108/274] [Batch classify loss: 0.014191] 
[Epoch 5/20] [Batch 109/274] [Batch classify loss: 0.060471] 
[Epoch 5/20] [Batch 110/274] [Batch classify loss: 0.042275] 
[Epoch 5/20] [Batch 111/274] [Batch classify loss: 0.045567] 
[Epoch 5/20] [Batch 112/274] [Batch classify loss: 0.021718] 
[Epoch 5/20] [Batch 113/274] [Batch classify loss: 0.012975] 
[Epoch 5/20] [Batch 114/274] [Batch classify loss: 0.022905] 
[Epoch 5/20] [Batch 115/274] [Batch classify loss: 0.058377] 
[Epoch 5/20] [Batch 116/274] [Batch classify loss: 0.010643] 
[Epoch 5/20] [Batch 117/274] [Batch classify loss: 0.031258] 
[Epoch 5/20] [Batch 118/274] [Batch classify loss: 0.022723] 
[Epoch 5/20] [Batch 119/274] [Batch classify loss: 0.091513] 
[Epoch 5/20] [Batch 120/274] [Batch classify loss: 0.023665] 
[Epoch 5/20] [Batch 121/274] [Batch classify loss: 0.058510] 
[Epoch 5/20] [Batch 122/274] [Batch classify loss: 0.080320] 
[Epoch 5/20] [Batch 123/274] [Batch classify loss: 0.032033] 
[Epoch 5/20] [Batch 124/274] [Batch classify loss: 0.051604] 
[Epoch 5/20] [Batch 125/274] [Batch classify loss: 0.042136] 
[Epoch 5/20] [Batch 126/274] [Batch classify loss: 0.049675] 
[Epoch 5/20] [Batch 127/274] [Batch classify loss: 0.037993] 
[Epoch 5/20] [Batch 128/274] [Batch classify loss: 0.047421] 
[Epoch 5/20] [Batch 129/274] [Batch classify loss: 0.063957] 
[Epoch 5/20] [Batch 130/274] [Batch classify loss: 0.016911] 
[Epoch 5/20] [Batch 131/274] [Batch classify loss: 0.038432] 
[Epoch 5/20] [Batch 132/274] [Batch classify loss: 0.059909] 
[Epoch 5/20] [Batch 133/274] [Batch classify loss: 0.072516] 
[Epoch 5/20] [Batch 134/274] [Batch classify loss: 0.047844] 
[Epoch 5/20] [Batch 135/274] [Batch classify loss: 0.057756] 
[Epoch 5/20] [Batch 136/274] [Batch classify loss: 0.044425] 
[Epoch 5/20] [Batch 137/274] [Batch classify loss: 0.034158] 
[Epoch 5/20] [Batch 138/274] [Batch classify loss: 0.032703] 
[Epoch 5/20] [Batch 139/274] [Batch classify loss: 0.015923] 
[Epoch 5/20] [Batch 140/274] [Batch classify loss: 0.038463] 
[Epoch 5/20] [Batch 141/274] [Batch classify loss: 0.099070] 
[Epoch 5/20] [Batch 142/274] [Batch classify loss: 0.041808] 
[Epoch 5/20] [Batch 143/274] [Batch classify loss: 0.073320] 
[Epoch 5/20] [Batch 144/274] [Batch classify loss: 0.017625] 
[Epoch 5/20] [Batch 145/274] [Batch classify loss: 0.054249] 
[Epoch 5/20] [Batch 146/274] [Batch classify loss: 0.038981] 
[Epoch 5/20] [Batch 147/274] [Batch classify loss: 0.052118] 
[Epoch 5/20] [Batch 148/274] [Batch classify loss: 0.025003] 
[Epoch 5/20] [Batch 149/274] [Batch classify loss: 0.061766] 
[Epoch 5/20] [Batch 150/274] [Batch classify loss: 0.034048] 
[Epoch 5/20] [Batch 151/274] [Batch classify loss: 0.042129] 
[Epoch 5/20] [Batch 152/274] [Batch classify loss: 0.062619] 
[Epoch 5/20] [Batch 153/274] [Batch classify loss: 0.012882] 
[Epoch 5/20] [Batch 154/274] [Batch classify loss: 0.055123] 
[Epoch 5/20] [Batch 155/274] [Batch classify loss: 0.048219] 
[Epoch 5/20] [Batch 156/274] [Batch classify loss: 0.016905] 
[Epoch 5/20] [Batch 157/274] [Batch classify loss: 0.051177] 
[Epoch 5/20] [Batch 158/274] [Batch classify loss: 0.072952] 
[Epoch 5/20] [Batch 159/274] [Batch classify loss: 0.049739] 
[Epoch 5/20] [Batch 160/274] [Batch classify loss: 0.033498] 
[Epoch 5/20] [Batch 161/274] [Batch classify loss: 0.107087] 
[Epoch 5/20] [Batch 162/274] [Batch classify loss: 0.046205] 
[Epoch 5/20] [Batch 163/274] [Batch classify loss: 0.026628] 
[Epoch 5/20] [Batch 164/274] [Batch classify loss: 0.048832] 
[Epoch 5/20] [Batch 165/274] [Batch classify loss: 0.012821] 
[Epoch 5/20] [Batch 166/274] [Batch classify loss: 0.024141] 
[Epoch 5/20] [Batch 167/274] [Batch classify loss: 0.024510] 
[Epoch 5/20] [Batch 168/274] [Batch classify loss: 0.052560] 
[Epoch 5/20] [Batch 169/274] [Batch classify loss: 0.023612] 
[Epoch 5/20] [Batch 170/274] [Batch classify loss: 0.053427] 
[Epoch 5/20] [Batch 171/274] [Batch classify loss: 0.027072] 
[Epoch 5/20] [Batch 172/274] [Batch classify loss: 0.049142] 
[Epoch 5/20] [Batch 173/274] [Batch classify loss: 0.064878] 
[Epoch 5/20] [Batch 174/274] [Batch classify loss: 0.057798] 
[Epoch 5/20] [Batch 175/274] [Batch classify loss: 0.052050] 
[Epoch 5/20] [Batch 176/274] [Batch classify loss: 0.020807] 
[Epoch 5/20] [Batch 177/274] [Batch classify loss: 0.101692] 
[Epoch 5/20] [Batch 178/274] [Batch classify loss: 0.032551] 
[Epoch 5/20] [Batch 179/274] [Batch classify loss: 0.017858] 
[Epoch 5/20] [Batch 180/274] [Batch classify loss: 0.020635] 
[Epoch 5/20] [Batch 181/274] [Batch classify loss: 0.014921] 
[Epoch 5/20] [Batch 182/274] [Batch classify loss: 0.052051] 
[Epoch 5/20] [Batch 183/274] [Batch classify loss: 0.026668] 
[Epoch 5/20] [Batch 184/274] [Batch classify loss: 0.038663] 
[Epoch 5/20] [Batch 185/274] [Batch classify loss: 0.042939] 
[Epoch 5/20] [Batch 186/274] [Batch classify loss: 0.025120] 
[Epoch 5/20] [Batch 187/274] [Batch classify loss: 0.022898] 
[Epoch 5/20] [Batch 188/274] [Batch classify loss: 0.062452] 
[Epoch 5/20] [Batch 189/274] [Batch classify loss: 0.021517] 
[Epoch 5/20] [Batch 190/274] [Batch classify loss: 0.034468] 
[Epoch 5/20] [Batch 191/274] [Batch classify loss: 0.047883] 
[Epoch 5/20] [Batch 192/274] [Batch classify loss: 0.033818] 
[Epoch 5/20] [Batch 193/274] [Batch classify loss: 0.094774] 
[Epoch 5/20] [Batch 194/274] [Batch classify loss: 0.134304] 
[Epoch 5/20] [Batch 195/274] [Batch classify loss: 0.022597] 
[Epoch 5/20] [Batch 196/274] [Batch classify loss: 0.043799] 
[Epoch 5/20] [Batch 197/274] [Batch classify loss: 0.047546] 
[Epoch 5/20] [Batch 198/274] [Batch classify loss: 0.054832] 
[Epoch 5/20] [Batch 199/274] [Batch classify loss: 0.076764] 
[Epoch 5/20] [Batch 200/274] [Batch classify loss: 0.011939] 
[Epoch 5/20] [Batch 201/274] [Batch classify loss: 0.031201] 
[Epoch 5/20] [Batch 202/274] [Batch classify loss: 0.036666] 
[Epoch 5/20] [Batch 203/274] [Batch classify loss: 0.027044] 
[Epoch 5/20] [Batch 204/274] [Batch classify loss: 0.051438] 
[Epoch 5/20] [Batch 205/274] [Batch classify loss: 0.024680] 
[Epoch 5/20] [Batch 206/274] [Batch classify loss: 0.025750] 
[Epoch 5/20] [Batch 207/274] [Batch classify loss: 0.046067] 
[Epoch 5/20] [Batch 208/274] [Batch classify loss: 0.024059] 
[Epoch 5/20] [Batch 209/274] [Batch classify loss: 0.027402] 
[Epoch 5/20] [Batch 210/274] [Batch classify loss: 0.023347] 
[Epoch 5/20] [Batch 211/274] [Batch classify loss: 0.061622] 
[Epoch 5/20] [Batch 212/274] [Batch classify loss: 0.038680] 
[Epoch 5/20] [Batch 213/274] [Batch classify loss: 0.018604] 
[Epoch 5/20] [Batch 214/274] [Batch classify loss: 0.078219] 
[Epoch 5/20] [Batch 215/274] [Batch classify loss: 0.069219] 
[Epoch 5/20] [Batch 216/274] [Batch classify loss: 0.053766] 
[Epoch 5/20] [Batch 217/274] [Batch classify loss: 0.030369] 
[Epoch 5/20] [Batch 218/274] [Batch classify loss: 0.030408] 
[Epoch 5/20] [Batch 219/274] [Batch classify loss: 0.057304] 
[Epoch 5/20] [Batch 220/274] [Batch classify loss: 0.026355] 
[Epoch 5/20] [Batch 221/274] [Batch classify loss: 0.044711] 
[Epoch 5/20] [Batch 222/274] [Batch classify loss: 0.093436] 
[Epoch 5/20] [Batch 223/274] [Batch classify loss: 0.030671] 
[Epoch 5/20] [Batch 224/274] [Batch classify loss: 0.032403] 
[Epoch 5/20] [Batch 225/274] [Batch classify loss: 0.063983] 
[Epoch 5/20] [Batch 226/274] [Batch classify loss: 0.059426] 
[Epoch 5/20] [Batch 227/274] [Batch classify loss: 0.021026] 
[Epoch 5/20] [Batch 228/274] [Batch classify loss: 0.008118] 
[Epoch 5/20] [Batch 229/274] [Batch classify loss: 0.017484] 
[Epoch 5/20] [Batch 230/274] [Batch classify loss: 0.094101] 
[Epoch 5/20] [Batch 231/274] [Batch classify loss: 0.092095] 
[Epoch 5/20] [Batch 232/274] [Batch classify loss: 0.034624] 
[Epoch 5/20] [Batch 233/274] [Batch classify loss: 0.051656] 
[Epoch 5/20] [Batch 234/274] [Batch classify loss: 0.020339] 
[Epoch 5/20] [Batch 235/274] [Batch classify loss: 0.075517] 
[Epoch 5/20] [Batch 236/274] [Batch classify loss: 0.052095] 
[Epoch 5/20] [Batch 237/274] [Batch classify loss: 0.059871] 
[Epoch 5/20] [Batch 238/274] [Batch classify loss: 0.069959] 
[Epoch 5/20] [Batch 239/274] [Batch classify loss: 0.028884] 
[Epoch 5/20] [Batch 240/274] [Batch classify loss: 0.017003] 
[Epoch 5/20] [Batch 241/274] [Batch classify loss: 0.046199] 
[Epoch 5/20] [Batch 242/274] [Batch classify loss: 0.022207] 
[Epoch 5/20] [Batch 243/274] [Batch classify loss: 0.060932] 
[Epoch 5/20] [Batch 244/274] [Batch classify loss: 0.041769] 
[Epoch 5/20] [Batch 245/274] [Batch classify loss: 0.055216] 
[Epoch 5/20] [Batch 246/274] [Batch classify loss: 0.017935] 
[Epoch 5/20] [Batch 247/274] [Batch classify loss: 0.037980] 
[Epoch 5/20] [Batch 248/274] [Batch classify loss: 0.065755] 
[Epoch 5/20] [Batch 249/274] [Batch classify loss: 0.120587] 
[Epoch 5/20] [Batch 250/274] [Batch classify loss: 0.054870] 
[Epoch 5/20] [Batch 251/274] [Batch classify loss: 0.034272] 
[Epoch 5/20] [Batch 252/274] [Batch classify loss: 0.031815] 
[Epoch 5/20] [Batch 253/274] [Batch classify loss: 0.019730] 
[Epoch 5/20] [Batch 254/274] [Batch classify loss: 0.018690] 
[Epoch 5/20] [Batch 255/274] [Batch classify loss: 0.015668] 
[Epoch 5/20] [Batch 256/274] [Batch classify loss: 0.087852] 
[Epoch 5/20] [Batch 257/274] [Batch classify loss: 0.039717] 
[Epoch 5/20] [Batch 258/274] [Batch classify loss: 0.045296] 
[Epoch 5/20] [Batch 259/274] [Batch classify loss: 0.037512] 
[Epoch 5/20] [Batch 260/274] [Batch classify loss: 0.031524] 
[Epoch 5/20] [Batch 261/274] [Batch classify loss: 0.013177] 
[Epoch 5/20] [Batch 262/274] [Batch classify loss: 0.041530] 
[Epoch 5/20] [Batch 263/274] [Batch classify loss: 0.082792] 
[Epoch 5/20] [Batch 264/274] [Batch classify loss: 0.054295] 
[Epoch 5/20] [Batch 265/274] [Batch classify loss: 0.045511] 
[Epoch 5/20] [Batch 266/274] [Batch classify loss: 0.034889] 
[Epoch 5/20] [Batch 267/274] [Batch classify loss: 0.019065] 
[Epoch 5/20] [Batch 268/274] [Batch classify loss: 0.047857] 
[Epoch 5/20] [Batch 269/274] [Batch classify loss: 0.047481] 
[Epoch 5/20] [Batch 270/274] [Batch classify loss: 0.047791] 
[Epoch 5/20] [Batch 271/274] [Batch classify loss: 0.028518] 
[Epoch 5/20] [Batch 272/274] [Batch classify loss: 0.042480] 
[Epoch 5/20] [Batch 273/274] [Batch classify loss: 0.045528] 
[Epoch 5/20] [Batch 274/274] [Batch classify loss: 0.023663] 
0005 epoch mmat trained classifier accuary on the clean testing examples:94.7795%
0005 epoch mmat trained classifier loss on the clean testing examples:0.2182
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.1967%
mmat trained classifier loss on adversarial testset:4.512901782989502
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
5epoch learning rate:0.01
[Epoch 6/20] [Batch 1/274] [Batch classify loss: 0.200950] 
[Epoch 6/20] [Batch 2/274] [Batch classify loss: 0.046109] 
[Epoch 6/20] [Batch 3/274] [Batch classify loss: 0.049218] 
[Epoch 6/20] [Batch 4/274] [Batch classify loss: 0.027572] 
[Epoch 6/20] [Batch 5/274] [Batch classify loss: 0.024316] 
[Epoch 6/20] [Batch 6/274] [Batch classify loss: 0.027945] 
[Epoch 6/20] [Batch 7/274] [Batch classify loss: 0.034521] 
[Epoch 6/20] [Batch 8/274] [Batch classify loss: 0.035065] 
[Epoch 6/20] [Batch 9/274] [Batch classify loss: 0.026522] 
[Epoch 6/20] [Batch 10/274] [Batch classify loss: 0.016932] 
[Epoch 6/20] [Batch 11/274] [Batch classify loss: 0.021779] 
[Epoch 6/20] [Batch 12/274] [Batch classify loss: 0.018898] 
[Epoch 6/20] [Batch 13/274] [Batch classify loss: 0.073142] 
[Epoch 6/20] [Batch 14/274] [Batch classify loss: 0.022288] 
[Epoch 6/20] [Batch 15/274] [Batch classify loss: 0.046135] 
[Epoch 6/20] [Batch 16/274] [Batch classify loss: 0.019695] 
[Epoch 6/20] [Batch 17/274] [Batch classify loss: 0.040197] 
[Epoch 6/20] [Batch 18/274] [Batch classify loss: 0.048044] 
[Epoch 6/20] [Batch 19/274] [Batch classify loss: 0.040559] 
[Epoch 6/20] [Batch 20/274] [Batch classify loss: 0.030066] 
[Epoch 6/20] [Batch 21/274] [Batch classify loss: 0.061948] 
[Epoch 6/20] [Batch 22/274] [Batch classify loss: 0.012816] 
[Epoch 6/20] [Batch 23/274] [Batch classify loss: 0.011974] 
[Epoch 6/20] [Batch 24/274] [Batch classify loss: 0.021317] 
[Epoch 6/20] [Batch 25/274] [Batch classify loss: 0.019645] 
[Epoch 6/20] [Batch 26/274] [Batch classify loss: 0.020256] 
[Epoch 6/20] [Batch 27/274] [Batch classify loss: 0.024919] 
[Epoch 6/20] [Batch 28/274] [Batch classify loss: 0.028148] 
[Epoch 6/20] [Batch 29/274] [Batch classify loss: 0.051887] 
[Epoch 6/20] [Batch 30/274] [Batch classify loss: 0.025244] 
[Epoch 6/20] [Batch 31/274] [Batch classify loss: 0.055688] 
[Epoch 6/20] [Batch 32/274] [Batch classify loss: 0.033506] 
[Epoch 6/20] [Batch 33/274] [Batch classify loss: 0.009064] 
[Epoch 6/20] [Batch 34/274] [Batch classify loss: 0.034650] 
[Epoch 6/20] [Batch 35/274] [Batch classify loss: 0.029597] 
[Epoch 6/20] [Batch 36/274] [Batch classify loss: 0.026137] 
[Epoch 6/20] [Batch 37/274] [Batch classify loss: 0.021371] 
[Epoch 6/20] [Batch 38/274] [Batch classify loss: 0.065562] 
[Epoch 6/20] [Batch 39/274] [Batch classify loss: 0.028683] 
[Epoch 6/20] [Batch 40/274] [Batch classify loss: 0.027403] 
[Epoch 6/20] [Batch 41/274] [Batch classify loss: 0.017812] 
[Epoch 6/20] [Batch 42/274] [Batch classify loss: 0.029487] 
[Epoch 6/20] [Batch 43/274] [Batch classify loss: 0.027492] 
[Epoch 6/20] [Batch 44/274] [Batch classify loss: 0.011297] 
[Epoch 6/20] [Batch 45/274] [Batch classify loss: 0.031934] 
[Epoch 6/20] [Batch 46/274] [Batch classify loss: 0.034850] 
[Epoch 6/20] [Batch 47/274] [Batch classify loss: 0.042944] 
[Epoch 6/20] [Batch 48/274] [Batch classify loss: 0.021778] 
[Epoch 6/20] [Batch 49/274] [Batch classify loss: 0.043151] 
[Epoch 6/20] [Batch 50/274] [Batch classify loss: 0.022747] 
[Epoch 6/20] [Batch 51/274] [Batch classify loss: 0.029833] 
[Epoch 6/20] [Batch 52/274] [Batch classify loss: 0.016353] 
[Epoch 6/20] [Batch 53/274] [Batch classify loss: 0.024862] 
[Epoch 6/20] [Batch 54/274] [Batch classify loss: 0.037080] 
[Epoch 6/20] [Batch 55/274] [Batch classify loss: 0.013507] 
[Epoch 6/20] [Batch 56/274] [Batch classify loss: 0.035376] 
[Epoch 6/20] [Batch 57/274] [Batch classify loss: 0.022542] 
[Epoch 6/20] [Batch 58/274] [Batch classify loss: 0.028095] 
[Epoch 6/20] [Batch 59/274] [Batch classify loss: 0.032538] 
[Epoch 6/20] [Batch 60/274] [Batch classify loss: 0.072955] 
[Epoch 6/20] [Batch 61/274] [Batch classify loss: 0.061243] 
[Epoch 6/20] [Batch 62/274] [Batch classify loss: 0.032820] 
[Epoch 6/20] [Batch 63/274] [Batch classify loss: 0.035323] 
[Epoch 6/20] [Batch 64/274] [Batch classify loss: 0.079111] 
[Epoch 6/20] [Batch 65/274] [Batch classify loss: 0.038417] 
[Epoch 6/20] [Batch 66/274] [Batch classify loss: 0.015820] 
[Epoch 6/20] [Batch 67/274] [Batch classify loss: 0.031406] 
[Epoch 6/20] [Batch 68/274] [Batch classify loss: 0.026289] 
[Epoch 6/20] [Batch 69/274] [Batch classify loss: 0.058954] 
[Epoch 6/20] [Batch 70/274] [Batch classify loss: 0.023222] 
[Epoch 6/20] [Batch 71/274] [Batch classify loss: 0.033720] 
[Epoch 6/20] [Batch 72/274] [Batch classify loss: 0.071774] 
[Epoch 6/20] [Batch 73/274] [Batch classify loss: 0.070990] 
[Epoch 6/20] [Batch 74/274] [Batch classify loss: 0.055551] 
[Epoch 6/20] [Batch 75/274] [Batch classify loss: 0.046143] 
[Epoch 6/20] [Batch 76/274] [Batch classify loss: 0.032012] 
[Epoch 6/20] [Batch 77/274] [Batch classify loss: 0.018188] 
[Epoch 6/20] [Batch 78/274] [Batch classify loss: 0.053138] 
[Epoch 6/20] [Batch 79/274] [Batch classify loss: 0.078224] 
[Epoch 6/20] [Batch 80/274] [Batch classify loss: 0.026023] 
[Epoch 6/20] [Batch 81/274] [Batch classify loss: 0.016435] 
[Epoch 6/20] [Batch 82/274] [Batch classify loss: 0.015094] 
[Epoch 6/20] [Batch 83/274] [Batch classify loss: 0.052242] 
[Epoch 6/20] [Batch 84/274] [Batch classify loss: 0.040147] 
[Epoch 6/20] [Batch 85/274] [Batch classify loss: 0.020980] 
[Epoch 6/20] [Batch 86/274] [Batch classify loss: 0.065831] 
[Epoch 6/20] [Batch 87/274] [Batch classify loss: 0.039637] 
[Epoch 6/20] [Batch 88/274] [Batch classify loss: 0.026923] 
[Epoch 6/20] [Batch 89/274] [Batch classify loss: 0.026003] 
[Epoch 6/20] [Batch 90/274] [Batch classify loss: 0.027540] 
[Epoch 6/20] [Batch 91/274] [Batch classify loss: 0.029944] 
[Epoch 6/20] [Batch 92/274] [Batch classify loss: 0.023776] 
[Epoch 6/20] [Batch 93/274] [Batch classify loss: 0.024085] 
[Epoch 6/20] [Batch 94/274] [Batch classify loss: 0.055814] 
[Epoch 6/20] [Batch 95/274] [Batch classify loss: 0.027406] 
[Epoch 6/20] [Batch 96/274] [Batch classify loss: 0.011416] 
[Epoch 6/20] [Batch 97/274] [Batch classify loss: 0.036143] 
[Epoch 6/20] [Batch 98/274] [Batch classify loss: 0.074029] 
[Epoch 6/20] [Batch 99/274] [Batch classify loss: 0.040845] 
[Epoch 6/20] [Batch 100/274] [Batch classify loss: 0.019190] 
[Epoch 6/20] [Batch 101/274] [Batch classify loss: 0.024644] 
[Epoch 6/20] [Batch 102/274] [Batch classify loss: 0.015347] 
[Epoch 6/20] [Batch 103/274] [Batch classify loss: 0.040579] 
[Epoch 6/20] [Batch 104/274] [Batch classify loss: 0.028087] 
[Epoch 6/20] [Batch 105/274] [Batch classify loss: 0.020516] 
[Epoch 6/20] [Batch 106/274] [Batch classify loss: 0.045572] 
[Epoch 6/20] [Batch 107/274] [Batch classify loss: 0.019970] 
[Epoch 6/20] [Batch 108/274] [Batch classify loss: 0.029358] 
[Epoch 6/20] [Batch 109/274] [Batch classify loss: 0.045533] 
[Epoch 6/20] [Batch 110/274] [Batch classify loss: 0.037030] 
[Epoch 6/20] [Batch 111/274] [Batch classify loss: 0.026056] 
[Epoch 6/20] [Batch 112/274] [Batch classify loss: 0.051892] 
[Epoch 6/20] [Batch 113/274] [Batch classify loss: 0.037020] 
[Epoch 6/20] [Batch 114/274] [Batch classify loss: 0.031611] 
[Epoch 6/20] [Batch 115/274] [Batch classify loss: 0.054515] 
[Epoch 6/20] [Batch 116/274] [Batch classify loss: 0.032065] 
[Epoch 6/20] [Batch 117/274] [Batch classify loss: 0.012519] 
[Epoch 6/20] [Batch 118/274] [Batch classify loss: 0.046568] 
[Epoch 6/20] [Batch 119/274] [Batch classify loss: 0.063697] 
[Epoch 6/20] [Batch 120/274] [Batch classify loss: 0.009112] 
[Epoch 6/20] [Batch 121/274] [Batch classify loss: 0.019476] 
[Epoch 6/20] [Batch 122/274] [Batch classify loss: 0.037481] 
[Epoch 6/20] [Batch 123/274] [Batch classify loss: 0.038084] 
[Epoch 6/20] [Batch 124/274] [Batch classify loss: 0.055865] 
[Epoch 6/20] [Batch 125/274] [Batch classify loss: 0.043072] 
[Epoch 6/20] [Batch 126/274] [Batch classify loss: 0.037225] 
[Epoch 6/20] [Batch 127/274] [Batch classify loss: 0.034488] 
[Epoch 6/20] [Batch 128/274] [Batch classify loss: 0.017044] 
[Epoch 6/20] [Batch 129/274] [Batch classify loss: 0.018031] 
[Epoch 6/20] [Batch 130/274] [Batch classify loss: 0.016960] 
[Epoch 6/20] [Batch 131/274] [Batch classify loss: 0.036268] 
[Epoch 6/20] [Batch 132/274] [Batch classify loss: 0.077789] 
[Epoch 6/20] [Batch 133/274] [Batch classify loss: 0.016567] 
[Epoch 6/20] [Batch 134/274] [Batch classify loss: 0.026526] 
[Epoch 6/20] [Batch 135/274] [Batch classify loss: 0.017816] 
[Epoch 6/20] [Batch 136/274] [Batch classify loss: 0.050274] 
[Epoch 6/20] [Batch 137/274] [Batch classify loss: 0.024502] 
[Epoch 6/20] [Batch 138/274] [Batch classify loss: 0.073341] 
[Epoch 6/20] [Batch 139/274] [Batch classify loss: 0.057603] 
[Epoch 6/20] [Batch 140/274] [Batch classify loss: 0.021565] 
[Epoch 6/20] [Batch 141/274] [Batch classify loss: 0.016408] 
[Epoch 6/20] [Batch 142/274] [Batch classify loss: 0.015263] 
[Epoch 6/20] [Batch 143/274] [Batch classify loss: 0.037456] 
[Epoch 6/20] [Batch 144/274] [Batch classify loss: 0.044788] 
[Epoch 6/20] [Batch 145/274] [Batch classify loss: 0.055376] 
[Epoch 6/20] [Batch 146/274] [Batch classify loss: 0.026092] 
[Epoch 6/20] [Batch 147/274] [Batch classify loss: 0.069562] 
[Epoch 6/20] [Batch 148/274] [Batch classify loss: 0.055232] 
[Epoch 6/20] [Batch 149/274] [Batch classify loss: 0.027511] 
[Epoch 6/20] [Batch 150/274] [Batch classify loss: 0.016332] 
[Epoch 6/20] [Batch 151/274] [Batch classify loss: 0.029567] 
[Epoch 6/20] [Batch 152/274] [Batch classify loss: 0.013985] 
[Epoch 6/20] [Batch 153/274] [Batch classify loss: 0.014960] 
[Epoch 6/20] [Batch 154/274] [Batch classify loss: 0.018008] 
[Epoch 6/20] [Batch 155/274] [Batch classify loss: 0.030005] 
[Epoch 6/20] [Batch 156/274] [Batch classify loss: 0.034311] 
[Epoch 6/20] [Batch 157/274] [Batch classify loss: 0.042513] 
[Epoch 6/20] [Batch 158/274] [Batch classify loss: 0.043166] 
[Epoch 6/20] [Batch 159/274] [Batch classify loss: 0.016948] 
[Epoch 6/20] [Batch 160/274] [Batch classify loss: 0.052767] 
[Epoch 6/20] [Batch 161/274] [Batch classify loss: 0.033930] 
[Epoch 6/20] [Batch 162/274] [Batch classify loss: 0.014440] 
[Epoch 6/20] [Batch 163/274] [Batch classify loss: 0.022399] 
[Epoch 6/20] [Batch 164/274] [Batch classify loss: 0.026667] 
[Epoch 6/20] [Batch 165/274] [Batch classify loss: 0.057709] 
[Epoch 6/20] [Batch 166/274] [Batch classify loss: 0.031443] 
[Epoch 6/20] [Batch 167/274] [Batch classify loss: 0.011073] 
[Epoch 6/20] [Batch 168/274] [Batch classify loss: 0.046761] 
[Epoch 6/20] [Batch 169/274] [Batch classify loss: 0.041527] 
[Epoch 6/20] [Batch 170/274] [Batch classify loss: 0.034107] 
[Epoch 6/20] [Batch 171/274] [Batch classify loss: 0.071546] 
[Epoch 6/20] [Batch 172/274] [Batch classify loss: 0.021788] 
[Epoch 6/20] [Batch 173/274] [Batch classify loss: 0.021272] 
[Epoch 6/20] [Batch 174/274] [Batch classify loss: 0.066420] 
[Epoch 6/20] [Batch 175/274] [Batch classify loss: 0.033694] 
[Epoch 6/20] [Batch 176/274] [Batch classify loss: 0.055358] 
[Epoch 6/20] [Batch 177/274] [Batch classify loss: 0.064547] 
[Epoch 6/20] [Batch 178/274] [Batch classify loss: 0.070796] 
[Epoch 6/20] [Batch 179/274] [Batch classify loss: 0.010458] 
[Epoch 6/20] [Batch 180/274] [Batch classify loss: 0.030495] 
[Epoch 6/20] [Batch 181/274] [Batch classify loss: 0.060525] 
[Epoch 6/20] [Batch 182/274] [Batch classify loss: 0.048474] 
[Epoch 6/20] [Batch 183/274] [Batch classify loss: 0.016183] 
[Epoch 6/20] [Batch 184/274] [Batch classify loss: 0.025446] 
[Epoch 6/20] [Batch 185/274] [Batch classify loss: 0.033426] 
[Epoch 6/20] [Batch 186/274] [Batch classify loss: 0.056247] 
[Epoch 6/20] [Batch 187/274] [Batch classify loss: 0.040624] 
[Epoch 6/20] [Batch 188/274] [Batch classify loss: 0.022770] 
[Epoch 6/20] [Batch 189/274] [Batch classify loss: 0.043660] 
[Epoch 6/20] [Batch 190/274] [Batch classify loss: 0.028812] 
[Epoch 6/20] [Batch 191/274] [Batch classify loss: 0.042149] 
[Epoch 6/20] [Batch 192/274] [Batch classify loss: 0.035933] 
[Epoch 6/20] [Batch 193/274] [Batch classify loss: 0.023164] 
[Epoch 6/20] [Batch 194/274] [Batch classify loss: 0.021726] 
[Epoch 6/20] [Batch 195/274] [Batch classify loss: 0.047884] 
[Epoch 6/20] [Batch 196/274] [Batch classify loss: 0.020042] 
[Epoch 6/20] [Batch 197/274] [Batch classify loss: 0.042261] 
[Epoch 6/20] [Batch 198/274] [Batch classify loss: 0.034259] 
[Epoch 6/20] [Batch 199/274] [Batch classify loss: 0.019377] 
[Epoch 6/20] [Batch 200/274] [Batch classify loss: 0.084309] 
[Epoch 6/20] [Batch 201/274] [Batch classify loss: 0.026071] 
[Epoch 6/20] [Batch 202/274] [Batch classify loss: 0.057095] 
[Epoch 6/20] [Batch 203/274] [Batch classify loss: 0.027604] 
[Epoch 6/20] [Batch 204/274] [Batch classify loss: 0.052461] 
[Epoch 6/20] [Batch 205/274] [Batch classify loss: 0.011125] 
[Epoch 6/20] [Batch 206/274] [Batch classify loss: 0.052592] 
[Epoch 6/20] [Batch 207/274] [Batch classify loss: 0.015501] 
[Epoch 6/20] [Batch 208/274] [Batch classify loss: 0.032882] 
[Epoch 6/20] [Batch 209/274] [Batch classify loss: 0.021750] 
[Epoch 6/20] [Batch 210/274] [Batch classify loss: 0.066820] 
[Epoch 6/20] [Batch 211/274] [Batch classify loss: 0.029658] 
[Epoch 6/20] [Batch 212/274] [Batch classify loss: 0.050500] 
[Epoch 6/20] [Batch 213/274] [Batch classify loss: 0.017593] 
[Epoch 6/20] [Batch 214/274] [Batch classify loss: 0.021484] 
[Epoch 6/20] [Batch 215/274] [Batch classify loss: 0.021420] 
[Epoch 6/20] [Batch 216/274] [Batch classify loss: 0.028964] 
[Epoch 6/20] [Batch 217/274] [Batch classify loss: 0.030431] 
[Epoch 6/20] [Batch 218/274] [Batch classify loss: 0.041482] 
[Epoch 6/20] [Batch 219/274] [Batch classify loss: 0.019344] 
[Epoch 6/20] [Batch 220/274] [Batch classify loss: 0.009751] 
[Epoch 6/20] [Batch 221/274] [Batch classify loss: 0.025951] 
[Epoch 6/20] [Batch 222/274] [Batch classify loss: 0.029551] 
[Epoch 6/20] [Batch 223/274] [Batch classify loss: 0.016117] 
[Epoch 6/20] [Batch 224/274] [Batch classify loss: 0.029880] 
[Epoch 6/20] [Batch 225/274] [Batch classify loss: 0.016786] 
[Epoch 6/20] [Batch 226/274] [Batch classify loss: 0.010800] 
[Epoch 6/20] [Batch 227/274] [Batch classify loss: 0.026571] 
[Epoch 6/20] [Batch 228/274] [Batch classify loss: 0.022973] 
[Epoch 6/20] [Batch 229/274] [Batch classify loss: 0.035711] 
[Epoch 6/20] [Batch 230/274] [Batch classify loss: 0.028099] 
[Epoch 6/20] [Batch 231/274] [Batch classify loss: 0.039318] 
[Epoch 6/20] [Batch 232/274] [Batch classify loss: 0.041968] 
[Epoch 6/20] [Batch 233/274] [Batch classify loss: 0.043720] 
[Epoch 6/20] [Batch 234/274] [Batch classify loss: 0.062544] 
[Epoch 6/20] [Batch 235/274] [Batch classify loss: 0.025254] 
[Epoch 6/20] [Batch 236/274] [Batch classify loss: 0.090528] 
[Epoch 6/20] [Batch 237/274] [Batch classify loss: 0.065762] 
[Epoch 6/20] [Batch 238/274] [Batch classify loss: 0.090626] 
[Epoch 6/20] [Batch 239/274] [Batch classify loss: 0.054588] 
[Epoch 6/20] [Batch 240/274] [Batch classify loss: 0.011942] 
[Epoch 6/20] [Batch 241/274] [Batch classify loss: 0.078704] 
[Epoch 6/20] [Batch 242/274] [Batch classify loss: 0.064312] 
[Epoch 6/20] [Batch 243/274] [Batch classify loss: 0.017674] 
[Epoch 6/20] [Batch 244/274] [Batch classify loss: 0.017386] 
[Epoch 6/20] [Batch 245/274] [Batch classify loss: 0.012115] 
[Epoch 6/20] [Batch 246/274] [Batch classify loss: 0.034992] 
[Epoch 6/20] [Batch 247/274] [Batch classify loss: 0.022986] 
[Epoch 6/20] [Batch 248/274] [Batch classify loss: 0.107684] 
[Epoch 6/20] [Batch 249/274] [Batch classify loss: 0.046040] 
[Epoch 6/20] [Batch 250/274] [Batch classify loss: 0.031286] 
[Epoch 6/20] [Batch 251/274] [Batch classify loss: 0.018721] 
[Epoch 6/20] [Batch 252/274] [Batch classify loss: 0.042107] 
[Epoch 6/20] [Batch 253/274] [Batch classify loss: 0.014502] 
[Epoch 6/20] [Batch 254/274] [Batch classify loss: 0.062702] 
[Epoch 6/20] [Batch 255/274] [Batch classify loss: 0.025031] 
[Epoch 6/20] [Batch 256/274] [Batch classify loss: 0.042184] 
[Epoch 6/20] [Batch 257/274] [Batch classify loss: 0.047680] 
[Epoch 6/20] [Batch 258/274] [Batch classify loss: 0.031081] 
[Epoch 6/20] [Batch 259/274] [Batch classify loss: 0.054175] 
[Epoch 6/20] [Batch 260/274] [Batch classify loss: 0.039306] 
[Epoch 6/20] [Batch 261/274] [Batch classify loss: 0.025894] 
[Epoch 6/20] [Batch 262/274] [Batch classify loss: 0.020039] 
[Epoch 6/20] [Batch 263/274] [Batch classify loss: 0.035414] 
[Epoch 6/20] [Batch 264/274] [Batch classify loss: 0.065774] 
[Epoch 6/20] [Batch 265/274] [Batch classify loss: 0.022418] 
[Epoch 6/20] [Batch 266/274] [Batch classify loss: 0.030602] 
[Epoch 6/20] [Batch 267/274] [Batch classify loss: 0.021580] 
[Epoch 6/20] [Batch 268/274] [Batch classify loss: 0.029642] 
[Epoch 6/20] [Batch 269/274] [Batch classify loss: 0.052694] 
[Epoch 6/20] [Batch 270/274] [Batch classify loss: 0.081115] 
[Epoch 6/20] [Batch 271/274] [Batch classify loss: 0.046918] 
[Epoch 6/20] [Batch 272/274] [Batch classify loss: 0.066927] 
[Epoch 6/20] [Batch 273/274] [Batch classify loss: 0.037578] 
[Epoch 6/20] [Batch 274/274] [Batch classify loss: 0.043686] 
0006 epoch mmat trained classifier accuary on the clean testing examples:94.7833%
0006 epoch mmat trained classifier loss on the clean testing examples:0.2216
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3350%
mmat trained classifier loss on adversarial testset:4.5327067375183105
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
6epoch learning rate:0.01
[Epoch 7/20] [Batch 1/274] [Batch classify loss: 0.227680] 
[Epoch 7/20] [Batch 2/274] [Batch classify loss: 0.140299] 
[Epoch 7/20] [Batch 3/274] [Batch classify loss: 0.141552] 
[Epoch 7/20] [Batch 4/274] [Batch classify loss: 0.097566] 
[Epoch 7/20] [Batch 5/274] [Batch classify loss: 0.030861] 
[Epoch 7/20] [Batch 6/274] [Batch classify loss: 0.043284] 
[Epoch 7/20] [Batch 7/274] [Batch classify loss: 0.056325] 
[Epoch 7/20] [Batch 8/274] [Batch classify loss: 0.044452] 
[Epoch 7/20] [Batch 9/274] [Batch classify loss: 0.032410] 
[Epoch 7/20] [Batch 10/274] [Batch classify loss: 0.044188] 
[Epoch 7/20] [Batch 11/274] [Batch classify loss: 0.026236] 
[Epoch 7/20] [Batch 12/274] [Batch classify loss: 0.030527] 
[Epoch 7/20] [Batch 13/274] [Batch classify loss: 0.039491] 
[Epoch 7/20] [Batch 14/274] [Batch classify loss: 0.025004] 
[Epoch 7/20] [Batch 15/274] [Batch classify loss: 0.026710] 
[Epoch 7/20] [Batch 16/274] [Batch classify loss: 0.025982] 
[Epoch 7/20] [Batch 17/274] [Batch classify loss: 0.032870] 
[Epoch 7/20] [Batch 18/274] [Batch classify loss: 0.045849] 
[Epoch 7/20] [Batch 19/274] [Batch classify loss: 0.027058] 
[Epoch 7/20] [Batch 20/274] [Batch classify loss: 0.012908] 
[Epoch 7/20] [Batch 21/274] [Batch classify loss: 0.044335] 
[Epoch 7/20] [Batch 22/274] [Batch classify loss: 0.026869] 
[Epoch 7/20] [Batch 23/274] [Batch classify loss: 0.069186] 
[Epoch 7/20] [Batch 24/274] [Batch classify loss: 0.027502] 
[Epoch 7/20] [Batch 25/274] [Batch classify loss: 0.021868] 
[Epoch 7/20] [Batch 26/274] [Batch classify loss: 0.016591] 
[Epoch 7/20] [Batch 27/274] [Batch classify loss: 0.025980] 
[Epoch 7/20] [Batch 28/274] [Batch classify loss: 0.039965] 
[Epoch 7/20] [Batch 29/274] [Batch classify loss: 0.028786] 
[Epoch 7/20] [Batch 30/274] [Batch classify loss: 0.013429] 
[Epoch 7/20] [Batch 31/274] [Batch classify loss: 0.048172] 
[Epoch 7/20] [Batch 32/274] [Batch classify loss: 0.040673] 
[Epoch 7/20] [Batch 33/274] [Batch classify loss: 0.018775] 
[Epoch 7/20] [Batch 34/274] [Batch classify loss: 0.032280] 
[Epoch 7/20] [Batch 35/274] [Batch classify loss: 0.032611] 
[Epoch 7/20] [Batch 36/274] [Batch classify loss: 0.024245] 
[Epoch 7/20] [Batch 37/274] [Batch classify loss: 0.040115] 
[Epoch 7/20] [Batch 38/274] [Batch classify loss: 0.012648] 
[Epoch 7/20] [Batch 39/274] [Batch classify loss: 0.030621] 
[Epoch 7/20] [Batch 40/274] [Batch classify loss: 0.049221] 
[Epoch 7/20] [Batch 41/274] [Batch classify loss: 0.027676] 
[Epoch 7/20] [Batch 42/274] [Batch classify loss: 0.026788] 
[Epoch 7/20] [Batch 43/274] [Batch classify loss: 0.036424] 
[Epoch 7/20] [Batch 44/274] [Batch classify loss: 0.032699] 
[Epoch 7/20] [Batch 45/274] [Batch classify loss: 0.014288] 
[Epoch 7/20] [Batch 46/274] [Batch classify loss: 0.030657] 
[Epoch 7/20] [Batch 47/274] [Batch classify loss: 0.032630] 
[Epoch 7/20] [Batch 48/274] [Batch classify loss: 0.046162] 
[Epoch 7/20] [Batch 49/274] [Batch classify loss: 0.073499] 
[Epoch 7/20] [Batch 50/274] [Batch classify loss: 0.039396] 
[Epoch 7/20] [Batch 51/274] [Batch classify loss: 0.043493] 
[Epoch 7/20] [Batch 52/274] [Batch classify loss: 0.014724] 
[Epoch 7/20] [Batch 53/274] [Batch classify loss: 0.049803] 
[Epoch 7/20] [Batch 54/274] [Batch classify loss: 0.046913] 
[Epoch 7/20] [Batch 55/274] [Batch classify loss: 0.008841] 
[Epoch 7/20] [Batch 56/274] [Batch classify loss: 0.018827] 
[Epoch 7/20] [Batch 57/274] [Batch classify loss: 0.038725] 
[Epoch 7/20] [Batch 58/274] [Batch classify loss: 0.049894] 
[Epoch 7/20] [Batch 59/274] [Batch classify loss: 0.022198] 
[Epoch 7/20] [Batch 60/274] [Batch classify loss: 0.031669] 
[Epoch 7/20] [Batch 61/274] [Batch classify loss: 0.023664] 
[Epoch 7/20] [Batch 62/274] [Batch classify loss: 0.037123] 
[Epoch 7/20] [Batch 63/274] [Batch classify loss: 0.042062] 
[Epoch 7/20] [Batch 64/274] [Batch classify loss: 0.016576] 
[Epoch 7/20] [Batch 65/274] [Batch classify loss: 0.036510] 
[Epoch 7/20] [Batch 66/274] [Batch classify loss: 0.032885] 
[Epoch 7/20] [Batch 67/274] [Batch classify loss: 0.038859] 
[Epoch 7/20] [Batch 68/274] [Batch classify loss: 0.062932] 
[Epoch 7/20] [Batch 69/274] [Batch classify loss: 0.037238] 
[Epoch 7/20] [Batch 70/274] [Batch classify loss: 0.068390] 
[Epoch 7/20] [Batch 71/274] [Batch classify loss: 0.010812] 
[Epoch 7/20] [Batch 72/274] [Batch classify loss: 0.031396] 
[Epoch 7/20] [Batch 73/274] [Batch classify loss: 0.039312] 
[Epoch 7/20] [Batch 74/274] [Batch classify loss: 0.038465] 
[Epoch 7/20] [Batch 75/274] [Batch classify loss: 0.030673] 
[Epoch 7/20] [Batch 76/274] [Batch classify loss: 0.041629] 
[Epoch 7/20] [Batch 77/274] [Batch classify loss: 0.019549] 
[Epoch 7/20] [Batch 78/274] [Batch classify loss: 0.019333] 
[Epoch 7/20] [Batch 79/274] [Batch classify loss: 0.024284] 
[Epoch 7/20] [Batch 80/274] [Batch classify loss: 0.054438] 
[Epoch 7/20] [Batch 81/274] [Batch classify loss: 0.066309] 
[Epoch 7/20] [Batch 82/274] [Batch classify loss: 0.074426] 
[Epoch 7/20] [Batch 83/274] [Batch classify loss: 0.037169] 
[Epoch 7/20] [Batch 84/274] [Batch classify loss: 0.059306] 
[Epoch 7/20] [Batch 85/274] [Batch classify loss: 0.039502] 
[Epoch 7/20] [Batch 86/274] [Batch classify loss: 0.046195] 
[Epoch 7/20] [Batch 87/274] [Batch classify loss: 0.014832] 
[Epoch 7/20] [Batch 88/274] [Batch classify loss: 0.035490] 
[Epoch 7/20] [Batch 89/274] [Batch classify loss: 0.015121] 
[Epoch 7/20] [Batch 90/274] [Batch classify loss: 0.037473] 
[Epoch 7/20] [Batch 91/274] [Batch classify loss: 0.042680] 
[Epoch 7/20] [Batch 92/274] [Batch classify loss: 0.031078] 
[Epoch 7/20] [Batch 93/274] [Batch classify loss: 0.019280] 
[Epoch 7/20] [Batch 94/274] [Batch classify loss: 0.023312] 
[Epoch 7/20] [Batch 95/274] [Batch classify loss: 0.026650] 
[Epoch 7/20] [Batch 96/274] [Batch classify loss: 0.035948] 
[Epoch 7/20] [Batch 97/274] [Batch classify loss: 0.015181] 
[Epoch 7/20] [Batch 98/274] [Batch classify loss: 0.044007] 
[Epoch 7/20] [Batch 99/274] [Batch classify loss: 0.031883] 
[Epoch 7/20] [Batch 100/274] [Batch classify loss: 0.059666] 
[Epoch 7/20] [Batch 101/274] [Batch classify loss: 0.069344] 
[Epoch 7/20] [Batch 102/274] [Batch classify loss: 0.013527] 
[Epoch 7/20] [Batch 103/274] [Batch classify loss: 0.027919] 
[Epoch 7/20] [Batch 104/274] [Batch classify loss: 0.047766] 
[Epoch 7/20] [Batch 105/274] [Batch classify loss: 0.039141] 
[Epoch 7/20] [Batch 106/274] [Batch classify loss: 0.051175] 
[Epoch 7/20] [Batch 107/274] [Batch classify loss: 0.028969] 
[Epoch 7/20] [Batch 108/274] [Batch classify loss: 0.037098] 
[Epoch 7/20] [Batch 109/274] [Batch classify loss: 0.025221] 
[Epoch 7/20] [Batch 110/274] [Batch classify loss: 0.033856] 
[Epoch 7/20] [Batch 111/274] [Batch classify loss: 0.057682] 
[Epoch 7/20] [Batch 112/274] [Batch classify loss: 0.043541] 
[Epoch 7/20] [Batch 113/274] [Batch classify loss: 0.025736] 
[Epoch 7/20] [Batch 114/274] [Batch classify loss: 0.026386] 
[Epoch 7/20] [Batch 115/274] [Batch classify loss: 0.041592] 
[Epoch 7/20] [Batch 116/274] [Batch classify loss: 0.033998] 
[Epoch 7/20] [Batch 117/274] [Batch classify loss: 0.019069] 
[Epoch 7/20] [Batch 118/274] [Batch classify loss: 0.012556] 
[Epoch 7/20] [Batch 119/274] [Batch classify loss: 0.039838] 
[Epoch 7/20] [Batch 120/274] [Batch classify loss: 0.026040] 
[Epoch 7/20] [Batch 121/274] [Batch classify loss: 0.019081] 
[Epoch 7/20] [Batch 122/274] [Batch classify loss: 0.015563] 
[Epoch 7/20] [Batch 123/274] [Batch classify loss: 0.035290] 
[Epoch 7/20] [Batch 124/274] [Batch classify loss: 0.023906] 
[Epoch 7/20] [Batch 125/274] [Batch classify loss: 0.021519] 
[Epoch 7/20] [Batch 126/274] [Batch classify loss: 0.040611] 
[Epoch 7/20] [Batch 127/274] [Batch classify loss: 0.055895] 
[Epoch 7/20] [Batch 128/274] [Batch classify loss: 0.020167] 
[Epoch 7/20] [Batch 129/274] [Batch classify loss: 0.026906] 
[Epoch 7/20] [Batch 130/274] [Batch classify loss: 0.037349] 
[Epoch 7/20] [Batch 131/274] [Batch classify loss: 0.063710] 
[Epoch 7/20] [Batch 132/274] [Batch classify loss: 0.056017] 
[Epoch 7/20] [Batch 133/274] [Batch classify loss: 0.042888] 
[Epoch 7/20] [Batch 134/274] [Batch classify loss: 0.027710] 
[Epoch 7/20] [Batch 135/274] [Batch classify loss: 0.064769] 
[Epoch 7/20] [Batch 136/274] [Batch classify loss: 0.104317] 
[Epoch 7/20] [Batch 137/274] [Batch classify loss: 0.058531] 
[Epoch 7/20] [Batch 138/274] [Batch classify loss: 0.014034] 
[Epoch 7/20] [Batch 139/274] [Batch classify loss: 0.026110] 
[Epoch 7/20] [Batch 140/274] [Batch classify loss: 0.039926] 
[Epoch 7/20] [Batch 141/274] [Batch classify loss: 0.037715] 
[Epoch 7/20] [Batch 142/274] [Batch classify loss: 0.037813] 
[Epoch 7/20] [Batch 143/274] [Batch classify loss: 0.017305] 
[Epoch 7/20] [Batch 144/274] [Batch classify loss: 0.027900] 
[Epoch 7/20] [Batch 145/274] [Batch classify loss: 0.030066] 
[Epoch 7/20] [Batch 146/274] [Batch classify loss: 0.025725] 
[Epoch 7/20] [Batch 147/274] [Batch classify loss: 0.024996] 
[Epoch 7/20] [Batch 148/274] [Batch classify loss: 0.026493] 
[Epoch 7/20] [Batch 149/274] [Batch classify loss: 0.069372] 
[Epoch 7/20] [Batch 150/274] [Batch classify loss: 0.049438] 
[Epoch 7/20] [Batch 151/274] [Batch classify loss: 0.021421] 
[Epoch 7/20] [Batch 152/274] [Batch classify loss: 0.024408] 
[Epoch 7/20] [Batch 153/274] [Batch classify loss: 0.017884] 
[Epoch 7/20] [Batch 154/274] [Batch classify loss: 0.035064] 
[Epoch 7/20] [Batch 155/274] [Batch classify loss: 0.035337] 
[Epoch 7/20] [Batch 156/274] [Batch classify loss: 0.035053] 
[Epoch 7/20] [Batch 157/274] [Batch classify loss: 0.032176] 
[Epoch 7/20] [Batch 158/274] [Batch classify loss: 0.046549] 
[Epoch 7/20] [Batch 159/274] [Batch classify loss: 0.072132] 
[Epoch 7/20] [Batch 160/274] [Batch classify loss: 0.034097] 
[Epoch 7/20] [Batch 161/274] [Batch classify loss: 0.020278] 
[Epoch 7/20] [Batch 162/274] [Batch classify loss: 0.067167] 
[Epoch 7/20] [Batch 163/274] [Batch classify loss: 0.024940] 
[Epoch 7/20] [Batch 164/274] [Batch classify loss: 0.032142] 
[Epoch 7/20] [Batch 165/274] [Batch classify loss: 0.030080] 
[Epoch 7/20] [Batch 166/274] [Batch classify loss: 0.037213] 
[Epoch 7/20] [Batch 167/274] [Batch classify loss: 0.036485] 
[Epoch 7/20] [Batch 168/274] [Batch classify loss: 0.017695] 
[Epoch 7/20] [Batch 169/274] [Batch classify loss: 0.036627] 
[Epoch 7/20] [Batch 170/274] [Batch classify loss: 0.033103] 
[Epoch 7/20] [Batch 171/274] [Batch classify loss: 0.009995] 
[Epoch 7/20] [Batch 172/274] [Batch classify loss: 0.013490] 
[Epoch 7/20] [Batch 173/274] [Batch classify loss: 0.028703] 
[Epoch 7/20] [Batch 174/274] [Batch classify loss: 0.015760] 
[Epoch 7/20] [Batch 175/274] [Batch classify loss: 0.028331] 
[Epoch 7/20] [Batch 176/274] [Batch classify loss: 0.025351] 
[Epoch 7/20] [Batch 177/274] [Batch classify loss: 0.035000] 
[Epoch 7/20] [Batch 178/274] [Batch classify loss: 0.012754] 
[Epoch 7/20] [Batch 179/274] [Batch classify loss: 0.024683] 
[Epoch 7/20] [Batch 180/274] [Batch classify loss: 0.050783] 
[Epoch 7/20] [Batch 181/274] [Batch classify loss: 0.015291] 
[Epoch 7/20] [Batch 182/274] [Batch classify loss: 0.018756] 
[Epoch 7/20] [Batch 183/274] [Batch classify loss: 0.029700] 
[Epoch 7/20] [Batch 184/274] [Batch classify loss: 0.032496] 
[Epoch 7/20] [Batch 185/274] [Batch classify loss: 0.031884] 
[Epoch 7/20] [Batch 186/274] [Batch classify loss: 0.034557] 
[Epoch 7/20] [Batch 187/274] [Batch classify loss: 0.011590] 
[Epoch 7/20] [Batch 188/274] [Batch classify loss: 0.047944] 
[Epoch 7/20] [Batch 189/274] [Batch classify loss: 0.055130] 
[Epoch 7/20] [Batch 190/274] [Batch classify loss: 0.039804] 
[Epoch 7/20] [Batch 191/274] [Batch classify loss: 0.021953] 
[Epoch 7/20] [Batch 192/274] [Batch classify loss: 0.055417] 
[Epoch 7/20] [Batch 193/274] [Batch classify loss: 0.036537] 
[Epoch 7/20] [Batch 194/274] [Batch classify loss: 0.039905] 
[Epoch 7/20] [Batch 195/274] [Batch classify loss: 0.036362] 
[Epoch 7/20] [Batch 196/274] [Batch classify loss: 0.020951] 
[Epoch 7/20] [Batch 197/274] [Batch classify loss: 0.018267] 
[Epoch 7/20] [Batch 198/274] [Batch classify loss: 0.018786] 
[Epoch 7/20] [Batch 199/274] [Batch classify loss: 0.030523] 
[Epoch 7/20] [Batch 200/274] [Batch classify loss: 0.011778] 
[Epoch 7/20] [Batch 201/274] [Batch classify loss: 0.019496] 
[Epoch 7/20] [Batch 202/274] [Batch classify loss: 0.025835] 
[Epoch 7/20] [Batch 203/274] [Batch classify loss: 0.017527] 
[Epoch 7/20] [Batch 204/274] [Batch classify loss: 0.021537] 
[Epoch 7/20] [Batch 205/274] [Batch classify loss: 0.026439] 
[Epoch 7/20] [Batch 206/274] [Batch classify loss: 0.066838] 
[Epoch 7/20] [Batch 207/274] [Batch classify loss: 0.020664] 
[Epoch 7/20] [Batch 208/274] [Batch classify loss: 0.031435] 
[Epoch 7/20] [Batch 209/274] [Batch classify loss: 0.053745] 
[Epoch 7/20] [Batch 210/274] [Batch classify loss: 0.097748] 
[Epoch 7/20] [Batch 211/274] [Batch classify loss: 0.048576] 
[Epoch 7/20] [Batch 212/274] [Batch classify loss: 0.048028] 
[Epoch 7/20] [Batch 213/274] [Batch classify loss: 0.032166] 
[Epoch 7/20] [Batch 214/274] [Batch classify loss: 0.024782] 
[Epoch 7/20] [Batch 215/274] [Batch classify loss: 0.029639] 
[Epoch 7/20] [Batch 216/274] [Batch classify loss: 0.038698] 
[Epoch 7/20] [Batch 217/274] [Batch classify loss: 0.040741] 
[Epoch 7/20] [Batch 218/274] [Batch classify loss: 0.008787] 
[Epoch 7/20] [Batch 219/274] [Batch classify loss: 0.023988] 
[Epoch 7/20] [Batch 220/274] [Batch classify loss: 0.024602] 
[Epoch 7/20] [Batch 221/274] [Batch classify loss: 0.044310] 
[Epoch 7/20] [Batch 222/274] [Batch classify loss: 0.041683] 
[Epoch 7/20] [Batch 223/274] [Batch classify loss: 0.060926] 
[Epoch 7/20] [Batch 224/274] [Batch classify loss: 0.040484] 
[Epoch 7/20] [Batch 225/274] [Batch classify loss: 0.038537] 
[Epoch 7/20] [Batch 226/274] [Batch classify loss: 0.021138] 
[Epoch 7/20] [Batch 227/274] [Batch classify loss: 0.046017] 
[Epoch 7/20] [Batch 228/274] [Batch classify loss: 0.021230] 
[Epoch 7/20] [Batch 229/274] [Batch classify loss: 0.030686] 
[Epoch 7/20] [Batch 230/274] [Batch classify loss: 0.050981] 
[Epoch 7/20] [Batch 231/274] [Batch classify loss: 0.059110] 
[Epoch 7/20] [Batch 232/274] [Batch classify loss: 0.030507] 
[Epoch 7/20] [Batch 233/274] [Batch classify loss: 0.030924] 
[Epoch 7/20] [Batch 234/274] [Batch classify loss: 0.029705] 
[Epoch 7/20] [Batch 235/274] [Batch classify loss: 0.049224] 
[Epoch 7/20] [Batch 236/274] [Batch classify loss: 0.033336] 
[Epoch 7/20] [Batch 237/274] [Batch classify loss: 0.034762] 
[Epoch 7/20] [Batch 238/274] [Batch classify loss: 0.012571] 
[Epoch 7/20] [Batch 239/274] [Batch classify loss: 0.055844] 
[Epoch 7/20] [Batch 240/274] [Batch classify loss: 0.033435] 
[Epoch 7/20] [Batch 241/274] [Batch classify loss: 0.020263] 
[Epoch 7/20] [Batch 242/274] [Batch classify loss: 0.023743] 
[Epoch 7/20] [Batch 243/274] [Batch classify loss: 0.027906] 
[Epoch 7/20] [Batch 244/274] [Batch classify loss: 0.017986] 
[Epoch 7/20] [Batch 245/274] [Batch classify loss: 0.090158] 
[Epoch 7/20] [Batch 246/274] [Batch classify loss: 0.056120] 
[Epoch 7/20] [Batch 247/274] [Batch classify loss: 0.029557] 
[Epoch 7/20] [Batch 248/274] [Batch classify loss: 0.034626] 
[Epoch 7/20] [Batch 249/274] [Batch classify loss: 0.018244] 
[Epoch 7/20] [Batch 250/274] [Batch classify loss: 0.025973] 
[Epoch 7/20] [Batch 251/274] [Batch classify loss: 0.066969] 
[Epoch 7/20] [Batch 252/274] [Batch classify loss: 0.050543] 
[Epoch 7/20] [Batch 253/274] [Batch classify loss: 0.022668] 
[Epoch 7/20] [Batch 254/274] [Batch classify loss: 0.040082] 
[Epoch 7/20] [Batch 255/274] [Batch classify loss: 0.056552] 
[Epoch 7/20] [Batch 256/274] [Batch classify loss: 0.032044] 
[Epoch 7/20] [Batch 257/274] [Batch classify loss: 0.043335] 
[Epoch 7/20] [Batch 258/274] [Batch classify loss: 0.031339] 
[Epoch 7/20] [Batch 259/274] [Batch classify loss: 0.024984] 
[Epoch 7/20] [Batch 260/274] [Batch classify loss: 0.063085] 
[Epoch 7/20] [Batch 261/274] [Batch classify loss: 0.038107] 
[Epoch 7/20] [Batch 262/274] [Batch classify loss: 0.016350] 
[Epoch 7/20] [Batch 263/274] [Batch classify loss: 0.061946] 
[Epoch 7/20] [Batch 264/274] [Batch classify loss: 0.038090] 
[Epoch 7/20] [Batch 265/274] [Batch classify loss: 0.082484] 
[Epoch 7/20] [Batch 266/274] [Batch classify loss: 0.062523] 
[Epoch 7/20] [Batch 267/274] [Batch classify loss: 0.017138] 
[Epoch 7/20] [Batch 268/274] [Batch classify loss: 0.027333] 
[Epoch 7/20] [Batch 269/274] [Batch classify loss: 0.022039] 
[Epoch 7/20] [Batch 270/274] [Batch classify loss: 0.029234] 
[Epoch 7/20] [Batch 271/274] [Batch classify loss: 0.028812] 
[Epoch 7/20] [Batch 272/274] [Batch classify loss: 0.032432] 
[Epoch 7/20] [Batch 273/274] [Batch classify loss: 0.029876] 
[Epoch 7/20] [Batch 274/274] [Batch classify loss: 0.010607] 
0007 epoch mmat trained classifier accuary on the clean testing examples:94.6950%
0007 epoch mmat trained classifier loss on the clean testing examples:0.2215
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.4003%
mmat trained classifier loss on adversarial testset:4.527561187744141
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
7epoch learning rate:0.01
[Epoch 8/20] [Batch 1/274] [Batch classify loss: 0.189514] 
[Epoch 8/20] [Batch 2/274] [Batch classify loss: 0.249869] 
[Epoch 8/20] [Batch 3/274] [Batch classify loss: 0.173529] 
[Epoch 8/20] [Batch 4/274] [Batch classify loss: 0.195850] 
[Epoch 8/20] [Batch 5/274] [Batch classify loss: 0.128977] 
[Epoch 8/20] [Batch 6/274] [Batch classify loss: 0.119001] 
[Epoch 8/20] [Batch 7/274] [Batch classify loss: 0.063942] 
[Epoch 8/20] [Batch 8/274] [Batch classify loss: 0.053228] 
[Epoch 8/20] [Batch 9/274] [Batch classify loss: 0.119957] 
[Epoch 8/20] [Batch 10/274] [Batch classify loss: 0.083123] 
[Epoch 8/20] [Batch 11/274] [Batch classify loss: 0.033429] 
[Epoch 8/20] [Batch 12/274] [Batch classify loss: 0.067010] 
[Epoch 8/20] [Batch 13/274] [Batch classify loss: 0.082962] 
[Epoch 8/20] [Batch 14/274] [Batch classify loss: 0.043571] 
[Epoch 8/20] [Batch 15/274] [Batch classify loss: 0.056358] 
[Epoch 8/20] [Batch 16/274] [Batch classify loss: 0.058043] 
[Epoch 8/20] [Batch 17/274] [Batch classify loss: 0.032629] 
[Epoch 8/20] [Batch 18/274] [Batch classify loss: 0.075039] 
[Epoch 8/20] [Batch 19/274] [Batch classify loss: 0.078082] 
[Epoch 8/20] [Batch 20/274] [Batch classify loss: 0.059288] 
[Epoch 8/20] [Batch 21/274] [Batch classify loss: 0.049997] 
[Epoch 8/20] [Batch 22/274] [Batch classify loss: 0.061833] 
[Epoch 8/20] [Batch 23/274] [Batch classify loss: 0.069285] 
[Epoch 8/20] [Batch 24/274] [Batch classify loss: 0.144150] 
[Epoch 8/20] [Batch 25/274] [Batch classify loss: 0.070763] 
[Epoch 8/20] [Batch 26/274] [Batch classify loss: 0.030770] 
[Epoch 8/20] [Batch 27/274] [Batch classify loss: 0.041975] 
[Epoch 8/20] [Batch 28/274] [Batch classify loss: 0.066201] 
[Epoch 8/20] [Batch 29/274] [Batch classify loss: 0.021734] 
[Epoch 8/20] [Batch 30/274] [Batch classify loss: 0.062608] 
[Epoch 8/20] [Batch 31/274] [Batch classify loss: 0.053213] 
[Epoch 8/20] [Batch 32/274] [Batch classify loss: 0.044928] 
[Epoch 8/20] [Batch 33/274] [Batch classify loss: 0.033496] 
[Epoch 8/20] [Batch 34/274] [Batch classify loss: 0.026565] 
[Epoch 8/20] [Batch 35/274] [Batch classify loss: 0.035678] 
[Epoch 8/20] [Batch 36/274] [Batch classify loss: 0.028105] 
[Epoch 8/20] [Batch 37/274] [Batch classify loss: 0.030562] 
[Epoch 8/20] [Batch 38/274] [Batch classify loss: 0.029320] 
[Epoch 8/20] [Batch 39/274] [Batch classify loss: 0.026404] 
[Epoch 8/20] [Batch 40/274] [Batch classify loss: 0.061068] 
[Epoch 8/20] [Batch 41/274] [Batch classify loss: 0.053920] 
[Epoch 8/20] [Batch 42/274] [Batch classify loss: 0.060527] 
[Epoch 8/20] [Batch 43/274] [Batch classify loss: 0.042765] 
[Epoch 8/20] [Batch 44/274] [Batch classify loss: 0.022930] 
[Epoch 8/20] [Batch 45/274] [Batch classify loss: 0.012807] 
[Epoch 8/20] [Batch 46/274] [Batch classify loss: 0.018563] 
[Epoch 8/20] [Batch 47/274] [Batch classify loss: 0.037971] 
[Epoch 8/20] [Batch 48/274] [Batch classify loss: 0.035347] 
[Epoch 8/20] [Batch 49/274] [Batch classify loss: 0.054179] 
[Epoch 8/20] [Batch 50/274] [Batch classify loss: 0.022467] 
[Epoch 8/20] [Batch 51/274] [Batch classify loss: 0.036318] 
[Epoch 8/20] [Batch 52/274] [Batch classify loss: 0.030448] 
[Epoch 8/20] [Batch 53/274] [Batch classify loss: 0.027000] 
[Epoch 8/20] [Batch 54/274] [Batch classify loss: 0.033634] 
[Epoch 8/20] [Batch 55/274] [Batch classify loss: 0.013499] 
[Epoch 8/20] [Batch 56/274] [Batch classify loss: 0.020581] 
[Epoch 8/20] [Batch 57/274] [Batch classify loss: 0.053746] 
[Epoch 8/20] [Batch 58/274] [Batch classify loss: 0.030751] 
[Epoch 8/20] [Batch 59/274] [Batch classify loss: 0.014384] 
[Epoch 8/20] [Batch 60/274] [Batch classify loss: 0.028353] 
[Epoch 8/20] [Batch 61/274] [Batch classify loss: 0.035590] 
[Epoch 8/20] [Batch 62/274] [Batch classify loss: 0.032648] 
[Epoch 8/20] [Batch 63/274] [Batch classify loss: 0.016468] 
[Epoch 8/20] [Batch 64/274] [Batch classify loss: 0.028749] 
[Epoch 8/20] [Batch 65/274] [Batch classify loss: 0.036230] 
[Epoch 8/20] [Batch 66/274] [Batch classify loss: 0.046408] 
[Epoch 8/20] [Batch 67/274] [Batch classify loss: 0.040549] 
[Epoch 8/20] [Batch 68/274] [Batch classify loss: 0.029013] 
[Epoch 8/20] [Batch 69/274] [Batch classify loss: 0.023950] 
[Epoch 8/20] [Batch 70/274] [Batch classify loss: 0.050216] 
[Epoch 8/20] [Batch 71/274] [Batch classify loss: 0.035665] 
[Epoch 8/20] [Batch 72/274] [Batch classify loss: 0.051033] 
[Epoch 8/20] [Batch 73/274] [Batch classify loss: 0.018178] 
[Epoch 8/20] [Batch 74/274] [Batch classify loss: 0.030230] 
[Epoch 8/20] [Batch 75/274] [Batch classify loss: 0.028409] 
[Epoch 8/20] [Batch 76/274] [Batch classify loss: 0.014644] 
[Epoch 8/20] [Batch 77/274] [Batch classify loss: 0.032714] 
[Epoch 8/20] [Batch 78/274] [Batch classify loss: 0.028115] 
[Epoch 8/20] [Batch 79/274] [Batch classify loss: 0.018059] 
[Epoch 8/20] [Batch 80/274] [Batch classify loss: 0.046466] 
[Epoch 8/20] [Batch 81/274] [Batch classify loss: 0.024406] 
[Epoch 8/20] [Batch 82/274] [Batch classify loss: 0.032482] 
[Epoch 8/20] [Batch 83/274] [Batch classify loss: 0.035898] 
[Epoch 8/20] [Batch 84/274] [Batch classify loss: 0.038929] 
[Epoch 8/20] [Batch 85/274] [Batch classify loss: 0.023822] 
[Epoch 8/20] [Batch 86/274] [Batch classify loss: 0.026073] 
[Epoch 8/20] [Batch 87/274] [Batch classify loss: 0.061467] 
[Epoch 8/20] [Batch 88/274] [Batch classify loss: 0.032284] 
[Epoch 8/20] [Batch 89/274] [Batch classify loss: 0.067916] 
[Epoch 8/20] [Batch 90/274] [Batch classify loss: 0.044090] 
[Epoch 8/20] [Batch 91/274] [Batch classify loss: 0.066294] 
[Epoch 8/20] [Batch 92/274] [Batch classify loss: 0.055945] 
[Epoch 8/20] [Batch 93/274] [Batch classify loss: 0.045678] 
[Epoch 8/20] [Batch 94/274] [Batch classify loss: 0.031005] 
[Epoch 8/20] [Batch 95/274] [Batch classify loss: 0.026095] 
[Epoch 8/20] [Batch 96/274] [Batch classify loss: 0.037007] 
[Epoch 8/20] [Batch 97/274] [Batch classify loss: 0.025059] 
[Epoch 8/20] [Batch 98/274] [Batch classify loss: 0.018112] 
[Epoch 8/20] [Batch 99/274] [Batch classify loss: 0.045745] 
[Epoch 8/20] [Batch 100/274] [Batch classify loss: 0.037054] 
[Epoch 8/20] [Batch 101/274] [Batch classify loss: 0.067194] 
[Epoch 8/20] [Batch 102/274] [Batch classify loss: 0.034980] 
[Epoch 8/20] [Batch 103/274] [Batch classify loss: 0.013431] 
[Epoch 8/20] [Batch 104/274] [Batch classify loss: 0.026013] 
[Epoch 8/20] [Batch 105/274] [Batch classify loss: 0.090317] 
[Epoch 8/20] [Batch 106/274] [Batch classify loss: 0.025918] 
[Epoch 8/20] [Batch 107/274] [Batch classify loss: 0.033620] 
[Epoch 8/20] [Batch 108/274] [Batch classify loss: 0.049939] 
[Epoch 8/20] [Batch 109/274] [Batch classify loss: 0.045084] 
[Epoch 8/20] [Batch 110/274] [Batch classify loss: 0.049668] 
[Epoch 8/20] [Batch 111/274] [Batch classify loss: 0.031409] 
[Epoch 8/20] [Batch 112/274] [Batch classify loss: 0.018679] 
[Epoch 8/20] [Batch 113/274] [Batch classify loss: 0.063977] 
[Epoch 8/20] [Batch 114/274] [Batch classify loss: 0.051395] 
[Epoch 8/20] [Batch 115/274] [Batch classify loss: 0.013021] 
[Epoch 8/20] [Batch 116/274] [Batch classify loss: 0.046227] 
[Epoch 8/20] [Batch 117/274] [Batch classify loss: 0.031573] 
[Epoch 8/20] [Batch 118/274] [Batch classify loss: 0.074931] 
[Epoch 8/20] [Batch 119/274] [Batch classify loss: 0.038360] 
[Epoch 8/20] [Batch 120/274] [Batch classify loss: 0.013853] 
[Epoch 8/20] [Batch 121/274] [Batch classify loss: 0.024687] 
[Epoch 8/20] [Batch 122/274] [Batch classify loss: 0.031365] 
[Epoch 8/20] [Batch 123/274] [Batch classify loss: 0.026385] 
[Epoch 8/20] [Batch 124/274] [Batch classify loss: 0.048954] 
[Epoch 8/20] [Batch 125/274] [Batch classify loss: 0.047157] 
[Epoch 8/20] [Batch 126/274] [Batch classify loss: 0.023466] 
[Epoch 8/20] [Batch 127/274] [Batch classify loss: 0.040151] 
[Epoch 8/20] [Batch 128/274] [Batch classify loss: 0.054816] 
[Epoch 8/20] [Batch 129/274] [Batch classify loss: 0.030106] 
[Epoch 8/20] [Batch 130/274] [Batch classify loss: 0.021549] 
[Epoch 8/20] [Batch 131/274] [Batch classify loss: 0.043414] 
[Epoch 8/20] [Batch 132/274] [Batch classify loss: 0.092594] 
[Epoch 8/20] [Batch 133/274] [Batch classify loss: 0.025901] 
[Epoch 8/20] [Batch 134/274] [Batch classify loss: 0.031788] 
[Epoch 8/20] [Batch 135/274] [Batch classify loss: 0.033365] 
[Epoch 8/20] [Batch 136/274] [Batch classify loss: 0.008576] 
[Epoch 8/20] [Batch 137/274] [Batch classify loss: 0.028729] 
[Epoch 8/20] [Batch 138/274] [Batch classify loss: 0.042753] 
[Epoch 8/20] [Batch 139/274] [Batch classify loss: 0.056890] 
[Epoch 8/20] [Batch 140/274] [Batch classify loss: 0.021992] 
[Epoch 8/20] [Batch 141/274] [Batch classify loss: 0.025876] 
[Epoch 8/20] [Batch 142/274] [Batch classify loss: 0.046498] 
[Epoch 8/20] [Batch 143/274] [Batch classify loss: 0.009051] 
[Epoch 8/20] [Batch 144/274] [Batch classify loss: 0.012878] 
[Epoch 8/20] [Batch 145/274] [Batch classify loss: 0.021935] 
[Epoch 8/20] [Batch 146/274] [Batch classify loss: 0.023144] 
[Epoch 8/20] [Batch 147/274] [Batch classify loss: 0.055963] 
[Epoch 8/20] [Batch 148/274] [Batch classify loss: 0.047007] 
[Epoch 8/20] [Batch 149/274] [Batch classify loss: 0.052170] 
[Epoch 8/20] [Batch 150/274] [Batch classify loss: 0.024087] 
[Epoch 8/20] [Batch 151/274] [Batch classify loss: 0.051282] 
[Epoch 8/20] [Batch 152/274] [Batch classify loss: 0.010935] 
[Epoch 8/20] [Batch 153/274] [Batch classify loss: 0.048014] 
[Epoch 8/20] [Batch 154/274] [Batch classify loss: 0.025904] 
[Epoch 8/20] [Batch 155/274] [Batch classify loss: 0.037853] 
[Epoch 8/20] [Batch 156/274] [Batch classify loss: 0.028961] 
[Epoch 8/20] [Batch 157/274] [Batch classify loss: 0.037895] 
[Epoch 8/20] [Batch 158/274] [Batch classify loss: 0.072823] 
[Epoch 8/20] [Batch 159/274] [Batch classify loss: 0.013883] 
[Epoch 8/20] [Batch 160/274] [Batch classify loss: 0.039001] 
[Epoch 8/20] [Batch 161/274] [Batch classify loss: 0.014461] 
[Epoch 8/20] [Batch 162/274] [Batch classify loss: 0.052326] 
[Epoch 8/20] [Batch 163/274] [Batch classify loss: 0.050051] 
[Epoch 8/20] [Batch 164/274] [Batch classify loss: 0.032006] 
[Epoch 8/20] [Batch 165/274] [Batch classify loss: 0.073260] 
[Epoch 8/20] [Batch 166/274] [Batch classify loss: 0.036794] 
[Epoch 8/20] [Batch 167/274] [Batch classify loss: 0.055795] 
[Epoch 8/20] [Batch 168/274] [Batch classify loss: 0.018526] 
[Epoch 8/20] [Batch 169/274] [Batch classify loss: 0.046096] 
[Epoch 8/20] [Batch 170/274] [Batch classify loss: 0.009770] 
[Epoch 8/20] [Batch 171/274] [Batch classify loss: 0.016047] 
[Epoch 8/20] [Batch 172/274] [Batch classify loss: 0.044577] 
[Epoch 8/20] [Batch 173/274] [Batch classify loss: 0.018547] 
[Epoch 8/20] [Batch 174/274] [Batch classify loss: 0.045168] 
[Epoch 8/20] [Batch 175/274] [Batch classify loss: 0.027178] 
[Epoch 8/20] [Batch 176/274] [Batch classify loss: 0.034435] 
[Epoch 8/20] [Batch 177/274] [Batch classify loss: 0.031409] 
[Epoch 8/20] [Batch 178/274] [Batch classify loss: 0.065679] 
[Epoch 8/20] [Batch 179/274] [Batch classify loss: 0.044412] 
[Epoch 8/20] [Batch 180/274] [Batch classify loss: 0.072342] 
[Epoch 8/20] [Batch 181/274] [Batch classify loss: 0.026972] 
[Epoch 8/20] [Batch 182/274] [Batch classify loss: 0.034805] 
[Epoch 8/20] [Batch 183/274] [Batch classify loss: 0.049079] 
[Epoch 8/20] [Batch 184/274] [Batch classify loss: 0.022418] 
[Epoch 8/20] [Batch 185/274] [Batch classify loss: 0.051841] 
[Epoch 8/20] [Batch 186/274] [Batch classify loss: 0.057953] 
[Epoch 8/20] [Batch 187/274] [Batch classify loss: 0.040286] 
[Epoch 8/20] [Batch 188/274] [Batch classify loss: 0.012684] 
[Epoch 8/20] [Batch 189/274] [Batch classify loss: 0.024745] 
[Epoch 8/20] [Batch 190/274] [Batch classify loss: 0.016822] 
[Epoch 8/20] [Batch 191/274] [Batch classify loss: 0.032705] 
[Epoch 8/20] [Batch 192/274] [Batch classify loss: 0.029151] 
[Epoch 8/20] [Batch 193/274] [Batch classify loss: 0.016232] 
[Epoch 8/20] [Batch 194/274] [Batch classify loss: 0.027207] 
[Epoch 8/20] [Batch 195/274] [Batch classify loss: 0.039885] 
[Epoch 8/20] [Batch 196/274] [Batch classify loss: 0.033717] 
[Epoch 8/20] [Batch 197/274] [Batch classify loss: 0.030382] 
[Epoch 8/20] [Batch 198/274] [Batch classify loss: 0.033002] 
[Epoch 8/20] [Batch 199/274] [Batch classify loss: 0.018723] 
[Epoch 8/20] [Batch 200/274] [Batch classify loss: 0.045826] 
[Epoch 8/20] [Batch 201/274] [Batch classify loss: 0.043671] 
[Epoch 8/20] [Batch 202/274] [Batch classify loss: 0.105009] 
[Epoch 8/20] [Batch 203/274] [Batch classify loss: 0.031483] 
[Epoch 8/20] [Batch 204/274] [Batch classify loss: 0.047089] 
[Epoch 8/20] [Batch 205/274] [Batch classify loss: 0.027166] 
[Epoch 8/20] [Batch 206/274] [Batch classify loss: 0.025638] 
[Epoch 8/20] [Batch 207/274] [Batch classify loss: 0.038560] 
[Epoch 8/20] [Batch 208/274] [Batch classify loss: 0.039003] 
[Epoch 8/20] [Batch 209/274] [Batch classify loss: 0.050605] 
[Epoch 8/20] [Batch 210/274] [Batch classify loss: 0.029190] 
[Epoch 8/20] [Batch 211/274] [Batch classify loss: 0.031244] 
[Epoch 8/20] [Batch 212/274] [Batch classify loss: 0.044970] 
[Epoch 8/20] [Batch 213/274] [Batch classify loss: 0.040604] 
[Epoch 8/20] [Batch 214/274] [Batch classify loss: 0.039679] 
[Epoch 8/20] [Batch 215/274] [Batch classify loss: 0.026279] 
[Epoch 8/20] [Batch 216/274] [Batch classify loss: 0.049629] 
[Epoch 8/20] [Batch 217/274] [Batch classify loss: 0.023239] 
[Epoch 8/20] [Batch 218/274] [Batch classify loss: 0.031643] 
[Epoch 8/20] [Batch 219/274] [Batch classify loss: 0.029996] 
[Epoch 8/20] [Batch 220/274] [Batch classify loss: 0.019322] 
[Epoch 8/20] [Batch 221/274] [Batch classify loss: 0.029740] 
[Epoch 8/20] [Batch 222/274] [Batch classify loss: 0.023989] 
[Epoch 8/20] [Batch 223/274] [Batch classify loss: 0.055359] 
[Epoch 8/20] [Batch 224/274] [Batch classify loss: 0.017672] 
[Epoch 8/20] [Batch 225/274] [Batch classify loss: 0.024364] 
[Epoch 8/20] [Batch 226/274] [Batch classify loss: 0.033503] 
[Epoch 8/20] [Batch 227/274] [Batch classify loss: 0.028375] 
[Epoch 8/20] [Batch 228/274] [Batch classify loss: 0.049422] 
[Epoch 8/20] [Batch 229/274] [Batch classify loss: 0.016863] 
[Epoch 8/20] [Batch 230/274] [Batch classify loss: 0.019375] 
[Epoch 8/20] [Batch 231/274] [Batch classify loss: 0.039318] 
[Epoch 8/20] [Batch 232/274] [Batch classify loss: 0.041589] 
[Epoch 8/20] [Batch 233/274] [Batch classify loss: 0.021955] 
[Epoch 8/20] [Batch 234/274] [Batch classify loss: 0.065588] 
[Epoch 8/20] [Batch 235/274] [Batch classify loss: 0.024861] 
[Epoch 8/20] [Batch 236/274] [Batch classify loss: 0.025041] 
[Epoch 8/20] [Batch 237/274] [Batch classify loss: 0.038196] 
[Epoch 8/20] [Batch 238/274] [Batch classify loss: 0.036771] 
[Epoch 8/20] [Batch 239/274] [Batch classify loss: 0.016646] 
[Epoch 8/20] [Batch 240/274] [Batch classify loss: 0.038728] 
[Epoch 8/20] [Batch 241/274] [Batch classify loss: 0.030354] 
[Epoch 8/20] [Batch 242/274] [Batch classify loss: 0.030049] 
[Epoch 8/20] [Batch 243/274] [Batch classify loss: 0.033362] 
[Epoch 8/20] [Batch 244/274] [Batch classify loss: 0.013075] 
[Epoch 8/20] [Batch 245/274] [Batch classify loss: 0.038753] 
[Epoch 8/20] [Batch 246/274] [Batch classify loss: 0.079355] 
[Epoch 8/20] [Batch 247/274] [Batch classify loss: 0.030642] 
[Epoch 8/20] [Batch 248/274] [Batch classify loss: 0.032907] 
[Epoch 8/20] [Batch 249/274] [Batch classify loss: 0.040585] 
[Epoch 8/20] [Batch 250/274] [Batch classify loss: 0.017700] 
[Epoch 8/20] [Batch 251/274] [Batch classify loss: 0.055562] 
[Epoch 8/20] [Batch 252/274] [Batch classify loss: 0.009915] 
[Epoch 8/20] [Batch 253/274] [Batch classify loss: 0.037689] 
[Epoch 8/20] [Batch 254/274] [Batch classify loss: 0.075447] 
[Epoch 8/20] [Batch 255/274] [Batch classify loss: 0.046981] 
[Epoch 8/20] [Batch 256/274] [Batch classify loss: 0.026214] 
[Epoch 8/20] [Batch 257/274] [Batch classify loss: 0.043228] 
[Epoch 8/20] [Batch 258/274] [Batch classify loss: 0.051173] 
[Epoch 8/20] [Batch 259/274] [Batch classify loss: 0.030756] 
[Epoch 8/20] [Batch 260/274] [Batch classify loss: 0.032491] 
[Epoch 8/20] [Batch 261/274] [Batch classify loss: 0.016098] 
[Epoch 8/20] [Batch 262/274] [Batch classify loss: 0.023654] 
[Epoch 8/20] [Batch 263/274] [Batch classify loss: 0.036569] 
[Epoch 8/20] [Batch 264/274] [Batch classify loss: 0.025931] 
[Epoch 8/20] [Batch 265/274] [Batch classify loss: 0.048540] 
[Epoch 8/20] [Batch 266/274] [Batch classify loss: 0.050781] 
[Epoch 8/20] [Batch 267/274] [Batch classify loss: 0.044604] 
[Epoch 8/20] [Batch 268/274] [Batch classify loss: 0.038251] 
[Epoch 8/20] [Batch 269/274] [Batch classify loss: 0.033792] 
[Epoch 8/20] [Batch 270/274] [Batch classify loss: 0.020361] 
[Epoch 8/20] [Batch 271/274] [Batch classify loss: 0.065633] 
[Epoch 8/20] [Batch 272/274] [Batch classify loss: 0.065326] 
[Epoch 8/20] [Batch 273/274] [Batch classify loss: 0.022281] 
[Epoch 8/20] [Batch 274/274] [Batch classify loss: 0.082221] 
0008 epoch mmat trained classifier accuary on the clean testing examples:94.6182%
0008 epoch mmat trained classifier loss on the clean testing examples:0.2192
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.1621%
mmat trained classifier loss on adversarial testset:4.514747619628906
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
8epoch learning rate:0.01
[Epoch 9/20] [Batch 1/274] [Batch classify loss: 0.163957] 
[Epoch 9/20] [Batch 2/274] [Batch classify loss: 0.142074] 
[Epoch 9/20] [Batch 3/274] [Batch classify loss: 0.237121] 
[Epoch 9/20] [Batch 4/274] [Batch classify loss: 0.331691] 
[Epoch 9/20] [Batch 5/274] [Batch classify loss: 0.213913] 
[Epoch 9/20] [Batch 6/274] [Batch classify loss: 0.164452] 
[Epoch 9/20] [Batch 7/274] [Batch classify loss: 0.200716] 
[Epoch 9/20] [Batch 8/274] [Batch classify loss: 0.189364] 
[Epoch 9/20] [Batch 9/274] [Batch classify loss: 0.111616] 
[Epoch 9/20] [Batch 10/274] [Batch classify loss: 0.139119] 
[Epoch 9/20] [Batch 11/274] [Batch classify loss: 0.128283] 
[Epoch 9/20] [Batch 12/274] [Batch classify loss: 0.192591] 
[Epoch 9/20] [Batch 13/274] [Batch classify loss: 0.129552] 
[Epoch 9/20] [Batch 14/274] [Batch classify loss: 0.117526] 
[Epoch 9/20] [Batch 15/274] [Batch classify loss: 0.134123] 
[Epoch 9/20] [Batch 16/274] [Batch classify loss: 0.052076] 
[Epoch 9/20] [Batch 17/274] [Batch classify loss: 0.096917] 
[Epoch 9/20] [Batch 18/274] [Batch classify loss: 0.122192] 
[Epoch 9/20] [Batch 19/274] [Batch classify loss: 0.115341] 
[Epoch 9/20] [Batch 20/274] [Batch classify loss: 0.060462] 
[Epoch 9/20] [Batch 21/274] [Batch classify loss: 0.195062] 
[Epoch 9/20] [Batch 22/274] [Batch classify loss: 0.083589] 
[Epoch 9/20] [Batch 23/274] [Batch classify loss: 0.058826] 
[Epoch 9/20] [Batch 24/274] [Batch classify loss: 0.056890] 
[Epoch 9/20] [Batch 25/274] [Batch classify loss: 0.028550] 
[Epoch 9/20] [Batch 26/274] [Batch classify loss: 0.082829] 
[Epoch 9/20] [Batch 27/274] [Batch classify loss: 0.050187] 
[Epoch 9/20] [Batch 28/274] [Batch classify loss: 0.093744] 
[Epoch 9/20] [Batch 29/274] [Batch classify loss: 0.042109] 
[Epoch 9/20] [Batch 30/274] [Batch classify loss: 0.037035] 
[Epoch 9/20] [Batch 31/274] [Batch classify loss: 0.057255] 
[Epoch 9/20] [Batch 32/274] [Batch classify loss: 0.045000] 
[Epoch 9/20] [Batch 33/274] [Batch classify loss: 0.103006] 
[Epoch 9/20] [Batch 34/274] [Batch classify loss: 0.119993] 
[Epoch 9/20] [Batch 35/274] [Batch classify loss: 0.084155] 
[Epoch 9/20] [Batch 36/274] [Batch classify loss: 0.051289] 
[Epoch 9/20] [Batch 37/274] [Batch classify loss: 0.033734] 
[Epoch 9/20] [Batch 38/274] [Batch classify loss: 0.049430] 
[Epoch 9/20] [Batch 39/274] [Batch classify loss: 0.025105] 
[Epoch 9/20] [Batch 40/274] [Batch classify loss: 0.047351] 
[Epoch 9/20] [Batch 41/274] [Batch classify loss: 0.053520] 
[Epoch 9/20] [Batch 42/274] [Batch classify loss: 0.051438] 
[Epoch 9/20] [Batch 43/274] [Batch classify loss: 0.038567] 
[Epoch 9/20] [Batch 44/274] [Batch classify loss: 0.052104] 
[Epoch 9/20] [Batch 45/274] [Batch classify loss: 0.054731] 
[Epoch 9/20] [Batch 46/274] [Batch classify loss: 0.049646] 
[Epoch 9/20] [Batch 47/274] [Batch classify loss: 0.050559] 
[Epoch 9/20] [Batch 48/274] [Batch classify loss: 0.073365] 
[Epoch 9/20] [Batch 49/274] [Batch classify loss: 0.027244] 
[Epoch 9/20] [Batch 50/274] [Batch classify loss: 0.053121] 
[Epoch 9/20] [Batch 51/274] [Batch classify loss: 0.046390] 
[Epoch 9/20] [Batch 52/274] [Batch classify loss: 0.108603] 
[Epoch 9/20] [Batch 53/274] [Batch classify loss: 0.081338] 
[Epoch 9/20] [Batch 54/274] [Batch classify loss: 0.038447] 
[Epoch 9/20] [Batch 55/274] [Batch classify loss: 0.191865] 
[Epoch 9/20] [Batch 56/274] [Batch classify loss: 0.036325] 
[Epoch 9/20] [Batch 57/274] [Batch classify loss: 0.085437] 
[Epoch 9/20] [Batch 58/274] [Batch classify loss: 0.037459] 
[Epoch 9/20] [Batch 59/274] [Batch classify loss: 0.078640] 
[Epoch 9/20] [Batch 60/274] [Batch classify loss: 0.058940] 
[Epoch 9/20] [Batch 61/274] [Batch classify loss: 0.070493] 
[Epoch 9/20] [Batch 62/274] [Batch classify loss: 0.021268] 
[Epoch 9/20] [Batch 63/274] [Batch classify loss: 0.051697] 
[Epoch 9/20] [Batch 64/274] [Batch classify loss: 0.039149] 
[Epoch 9/20] [Batch 65/274] [Batch classify loss: 0.068278] 
[Epoch 9/20] [Batch 66/274] [Batch classify loss: 0.033893] 
[Epoch 9/20] [Batch 67/274] [Batch classify loss: 0.043098] 
[Epoch 9/20] [Batch 68/274] [Batch classify loss: 0.064741] 
[Epoch 9/20] [Batch 69/274] [Batch classify loss: 0.064242] 
[Epoch 9/20] [Batch 70/274] [Batch classify loss: 0.016089] 
[Epoch 9/20] [Batch 71/274] [Batch classify loss: 0.057686] 
[Epoch 9/20] [Batch 72/274] [Batch classify loss: 0.043439] 
[Epoch 9/20] [Batch 73/274] [Batch classify loss: 0.054076] 
[Epoch 9/20] [Batch 74/274] [Batch classify loss: 0.036600] 
[Epoch 9/20] [Batch 75/274] [Batch classify loss: 0.031001] 
[Epoch 9/20] [Batch 76/274] [Batch classify loss: 0.034955] 
[Epoch 9/20] [Batch 77/274] [Batch classify loss: 0.039352] 
[Epoch 9/20] [Batch 78/274] [Batch classify loss: 0.020096] 
[Epoch 9/20] [Batch 79/274] [Batch classify loss: 0.060642] 
[Epoch 9/20] [Batch 80/274] [Batch classify loss: 0.070076] 
[Epoch 9/20] [Batch 81/274] [Batch classify loss: 0.034276] 
[Epoch 9/20] [Batch 82/274] [Batch classify loss: 0.029992] 
[Epoch 9/20] [Batch 83/274] [Batch classify loss: 0.059229] 
[Epoch 9/20] [Batch 84/274] [Batch classify loss: 0.041030] 
[Epoch 9/20] [Batch 85/274] [Batch classify loss: 0.031712] 
[Epoch 9/20] [Batch 86/274] [Batch classify loss: 0.022356] 
[Epoch 9/20] [Batch 87/274] [Batch classify loss: 0.059329] 
[Epoch 9/20] [Batch 88/274] [Batch classify loss: 0.011294] 
[Epoch 9/20] [Batch 89/274] [Batch classify loss: 0.035421] 
[Epoch 9/20] [Batch 90/274] [Batch classify loss: 0.049981] 
[Epoch 9/20] [Batch 91/274] [Batch classify loss: 0.040934] 
[Epoch 9/20] [Batch 92/274] [Batch classify loss: 0.112719] 
[Epoch 9/20] [Batch 93/274] [Batch classify loss: 0.030957] 
[Epoch 9/20] [Batch 94/274] [Batch classify loss: 0.050348] 
[Epoch 9/20] [Batch 95/274] [Batch classify loss: 0.063680] 
[Epoch 9/20] [Batch 96/274] [Batch classify loss: 0.035166] 
[Epoch 9/20] [Batch 97/274] [Batch classify loss: 0.111611] 
[Epoch 9/20] [Batch 98/274] [Batch classify loss: 0.032820] 
[Epoch 9/20] [Batch 99/274] [Batch classify loss: 0.048593] 
[Epoch 9/20] [Batch 100/274] [Batch classify loss: 0.028950] 
[Epoch 9/20] [Batch 101/274] [Batch classify loss: 0.026224] 
[Epoch 9/20] [Batch 102/274] [Batch classify loss: 0.032491] 
[Epoch 9/20] [Batch 103/274] [Batch classify loss: 0.050037] 
[Epoch 9/20] [Batch 104/274] [Batch classify loss: 0.065759] 
[Epoch 9/20] [Batch 105/274] [Batch classify loss: 0.082789] 
[Epoch 9/20] [Batch 106/274] [Batch classify loss: 0.040181] 
[Epoch 9/20] [Batch 107/274] [Batch classify loss: 0.026490] 
[Epoch 9/20] [Batch 108/274] [Batch classify loss: 0.055288] 
[Epoch 9/20] [Batch 109/274] [Batch classify loss: 0.042174] 
[Epoch 9/20] [Batch 110/274] [Batch classify loss: 0.094434] 
[Epoch 9/20] [Batch 111/274] [Batch classify loss: 0.080152] 
[Epoch 9/20] [Batch 112/274] [Batch classify loss: 0.039121] 
[Epoch 9/20] [Batch 113/274] [Batch classify loss: 0.026970] 
[Epoch 9/20] [Batch 114/274] [Batch classify loss: 0.027523] 
[Epoch 9/20] [Batch 115/274] [Batch classify loss: 0.048063] 
[Epoch 9/20] [Batch 116/274] [Batch classify loss: 0.021814] 
[Epoch 9/20] [Batch 117/274] [Batch classify loss: 0.073928] 
[Epoch 9/20] [Batch 118/274] [Batch classify loss: 0.066466] 
[Epoch 9/20] [Batch 119/274] [Batch classify loss: 0.044561] 
[Epoch 9/20] [Batch 120/274] [Batch classify loss: 0.026277] 
[Epoch 9/20] [Batch 121/274] [Batch classify loss: 0.077631] 
[Epoch 9/20] [Batch 122/274] [Batch classify loss: 0.051764] 
[Epoch 9/20] [Batch 123/274] [Batch classify loss: 0.066609] 
[Epoch 9/20] [Batch 124/274] [Batch classify loss: 0.025100] 
[Epoch 9/20] [Batch 125/274] [Batch classify loss: 0.021324] 
[Epoch 9/20] [Batch 126/274] [Batch classify loss: 0.032418] 
[Epoch 9/20] [Batch 127/274] [Batch classify loss: 0.048665] 
[Epoch 9/20] [Batch 128/274] [Batch classify loss: 0.051309] 
[Epoch 9/20] [Batch 129/274] [Batch classify loss: 0.034280] 
[Epoch 9/20] [Batch 130/274] [Batch classify loss: 0.043297] 
[Epoch 9/20] [Batch 131/274] [Batch classify loss: 0.056724] 
[Epoch 9/20] [Batch 132/274] [Batch classify loss: 0.020003] 
[Epoch 9/20] [Batch 133/274] [Batch classify loss: 0.015886] 
[Epoch 9/20] [Batch 134/274] [Batch classify loss: 0.019914] 
[Epoch 9/20] [Batch 135/274] [Batch classify loss: 0.037053] 
[Epoch 9/20] [Batch 136/274] [Batch classify loss: 0.018052] 
[Epoch 9/20] [Batch 137/274] [Batch classify loss: 0.071821] 
[Epoch 9/20] [Batch 138/274] [Batch classify loss: 0.036219] 
[Epoch 9/20] [Batch 139/274] [Batch classify loss: 0.038566] 
[Epoch 9/20] [Batch 140/274] [Batch classify loss: 0.150617] 
[Epoch 9/20] [Batch 141/274] [Batch classify loss: 0.024144] 
[Epoch 9/20] [Batch 142/274] [Batch classify loss: 0.055335] 
[Epoch 9/20] [Batch 143/274] [Batch classify loss: 0.067558] 
[Epoch 9/20] [Batch 144/274] [Batch classify loss: 0.076597] 
[Epoch 9/20] [Batch 145/274] [Batch classify loss: 0.022144] 
[Epoch 9/20] [Batch 146/274] [Batch classify loss: 0.038872] 
[Epoch 9/20] [Batch 147/274] [Batch classify loss: 0.030879] 
[Epoch 9/20] [Batch 148/274] [Batch classify loss: 0.015717] 
[Epoch 9/20] [Batch 149/274] [Batch classify loss: 0.035387] 
[Epoch 9/20] [Batch 150/274] [Batch classify loss: 0.040338] 
[Epoch 9/20] [Batch 151/274] [Batch classify loss: 0.092709] 
[Epoch 9/20] [Batch 152/274] [Batch classify loss: 0.024459] 
[Epoch 9/20] [Batch 153/274] [Batch classify loss: 0.027765] 
[Epoch 9/20] [Batch 154/274] [Batch classify loss: 0.042368] 
[Epoch 9/20] [Batch 155/274] [Batch classify loss: 0.037792] 
[Epoch 9/20] [Batch 156/274] [Batch classify loss: 0.064575] 
[Epoch 9/20] [Batch 157/274] [Batch classify loss: 0.045390] 
[Epoch 9/20] [Batch 158/274] [Batch classify loss: 0.051419] 
[Epoch 9/20] [Batch 159/274] [Batch classify loss: 0.064459] 
[Epoch 9/20] [Batch 160/274] [Batch classify loss: 0.050897] 
[Epoch 9/20] [Batch 161/274] [Batch classify loss: 0.023115] 
[Epoch 9/20] [Batch 162/274] [Batch classify loss: 0.036655] 
[Epoch 9/20] [Batch 163/274] [Batch classify loss: 0.026565] 
[Epoch 9/20] [Batch 164/274] [Batch classify loss: 0.041762] 
[Epoch 9/20] [Batch 165/274] [Batch classify loss: 0.070728] 
[Epoch 9/20] [Batch 166/274] [Batch classify loss: 0.043574] 
[Epoch 9/20] [Batch 167/274] [Batch classify loss: 0.020698] 
[Epoch 9/20] [Batch 168/274] [Batch classify loss: 0.016201] 
[Epoch 9/20] [Batch 169/274] [Batch classify loss: 0.038808] 
[Epoch 9/20] [Batch 170/274] [Batch classify loss: 0.031837] 
[Epoch 9/20] [Batch 171/274] [Batch classify loss: 0.040577] 
[Epoch 9/20] [Batch 172/274] [Batch classify loss: 0.048461] 
[Epoch 9/20] [Batch 173/274] [Batch classify loss: 0.051864] 
[Epoch 9/20] [Batch 174/274] [Batch classify loss: 0.037446] 
[Epoch 9/20] [Batch 175/274] [Batch classify loss: 0.031036] 
[Epoch 9/20] [Batch 176/274] [Batch classify loss: 0.032265] 
[Epoch 9/20] [Batch 177/274] [Batch classify loss: 0.041787] 
[Epoch 9/20] [Batch 178/274] [Batch classify loss: 0.045711] 
[Epoch 9/20] [Batch 179/274] [Batch classify loss: 0.017335] 
[Epoch 9/20] [Batch 180/274] [Batch classify loss: 0.038264] 
[Epoch 9/20] [Batch 181/274] [Batch classify loss: 0.026724] 
[Epoch 9/20] [Batch 182/274] [Batch classify loss: 0.045952] 
[Epoch 9/20] [Batch 183/274] [Batch classify loss: 0.028317] 
[Epoch 9/20] [Batch 184/274] [Batch classify loss: 0.018976] 
[Epoch 9/20] [Batch 185/274] [Batch classify loss: 0.039403] 
[Epoch 9/20] [Batch 186/274] [Batch classify loss: 0.034860] 
[Epoch 9/20] [Batch 187/274] [Batch classify loss: 0.010747] 
[Epoch 9/20] [Batch 188/274] [Batch classify loss: 0.033741] 
[Epoch 9/20] [Batch 189/274] [Batch classify loss: 0.049163] 
[Epoch 9/20] [Batch 190/274] [Batch classify loss: 0.047541] 
[Epoch 9/20] [Batch 191/274] [Batch classify loss: 0.063380] 
[Epoch 9/20] [Batch 192/274] [Batch classify loss: 0.031524] 
[Epoch 9/20] [Batch 193/274] [Batch classify loss: 0.045610] 
[Epoch 9/20] [Batch 194/274] [Batch classify loss: 0.058156] 
[Epoch 9/20] [Batch 195/274] [Batch classify loss: 0.029670] 
[Epoch 9/20] [Batch 196/274] [Batch classify loss: 0.041923] 
[Epoch 9/20] [Batch 197/274] [Batch classify loss: 0.016493] 
[Epoch 9/20] [Batch 198/274] [Batch classify loss: 0.051375] 
[Epoch 9/20] [Batch 199/274] [Batch classify loss: 0.025046] 
[Epoch 9/20] [Batch 200/274] [Batch classify loss: 0.013124] 
[Epoch 9/20] [Batch 201/274] [Batch classify loss: 0.031664] 
[Epoch 9/20] [Batch 202/274] [Batch classify loss: 0.062556] 
[Epoch 9/20] [Batch 203/274] [Batch classify loss: 0.018582] 
[Epoch 9/20] [Batch 204/274] [Batch classify loss: 0.028889] 
[Epoch 9/20] [Batch 205/274] [Batch classify loss: 0.052057] 
[Epoch 9/20] [Batch 206/274] [Batch classify loss: 0.063703] 
[Epoch 9/20] [Batch 207/274] [Batch classify loss: 0.044982] 
[Epoch 9/20] [Batch 208/274] [Batch classify loss: 0.028618] 
[Epoch 9/20] [Batch 209/274] [Batch classify loss: 0.024566] 
[Epoch 9/20] [Batch 210/274] [Batch classify loss: 0.040743] 
[Epoch 9/20] [Batch 211/274] [Batch classify loss: 0.031758] 
[Epoch 9/20] [Batch 212/274] [Batch classify loss: 0.091146] 
[Epoch 9/20] [Batch 213/274] [Batch classify loss: 0.022427] 
[Epoch 9/20] [Batch 214/274] [Batch classify loss: 0.011716] 
[Epoch 9/20] [Batch 215/274] [Batch classify loss: 0.021588] 
[Epoch 9/20] [Batch 216/274] [Batch classify loss: 0.052498] 
[Epoch 9/20] [Batch 217/274] [Batch classify loss: 0.039728] 
[Epoch 9/20] [Batch 218/274] [Batch classify loss: 0.019925] 
[Epoch 9/20] [Batch 219/274] [Batch classify loss: 0.026915] 
[Epoch 9/20] [Batch 220/274] [Batch classify loss: 0.052647] 
[Epoch 9/20] [Batch 221/274] [Batch classify loss: 0.032692] 
[Epoch 9/20] [Batch 222/274] [Batch classify loss: 0.044041] 
[Epoch 9/20] [Batch 223/274] [Batch classify loss: 0.030884] 
[Epoch 9/20] [Batch 224/274] [Batch classify loss: 0.040204] 
[Epoch 9/20] [Batch 225/274] [Batch classify loss: 0.037598] 
[Epoch 9/20] [Batch 226/274] [Batch classify loss: 0.022668] 
[Epoch 9/20] [Batch 227/274] [Batch classify loss: 0.025244] 
[Epoch 9/20] [Batch 228/274] [Batch classify loss: 0.015743] 
[Epoch 9/20] [Batch 229/274] [Batch classify loss: 0.014255] 
[Epoch 9/20] [Batch 230/274] [Batch classify loss: 0.048138] 
[Epoch 9/20] [Batch 231/274] [Batch classify loss: 0.035041] 
[Epoch 9/20] [Batch 232/274] [Batch classify loss: 0.026690] 
[Epoch 9/20] [Batch 233/274] [Batch classify loss: 0.053749] 
[Epoch 9/20] [Batch 234/274] [Batch classify loss: 0.039742] 
[Epoch 9/20] [Batch 235/274] [Batch classify loss: 0.038594] 
[Epoch 9/20] [Batch 236/274] [Batch classify loss: 0.058019] 
[Epoch 9/20] [Batch 237/274] [Batch classify loss: 0.056308] 
[Epoch 9/20] [Batch 238/274] [Batch classify loss: 0.039948] 
[Epoch 9/20] [Batch 239/274] [Batch classify loss: 0.030887] 
[Epoch 9/20] [Batch 240/274] [Batch classify loss: 0.052068] 
[Epoch 9/20] [Batch 241/274] [Batch classify loss: 0.033486] 
[Epoch 9/20] [Batch 242/274] [Batch classify loss: 0.051266] 
[Epoch 9/20] [Batch 243/274] [Batch classify loss: 0.031310] 
[Epoch 9/20] [Batch 244/274] [Batch classify loss: 0.035661] 
[Epoch 9/20] [Batch 245/274] [Batch classify loss: 0.021884] 
[Epoch 9/20] [Batch 246/274] [Batch classify loss: 0.067843] 
[Epoch 9/20] [Batch 247/274] [Batch classify loss: 0.028616] 
[Epoch 9/20] [Batch 248/274] [Batch classify loss: 0.022965] 
[Epoch 9/20] [Batch 249/274] [Batch classify loss: 0.019026] 
[Epoch 9/20] [Batch 250/274] [Batch classify loss: 0.046979] 
[Epoch 9/20] [Batch 251/274] [Batch classify loss: 0.044896] 
[Epoch 9/20] [Batch 252/274] [Batch classify loss: 0.008882] 
[Epoch 9/20] [Batch 253/274] [Batch classify loss: 0.027195] 
[Epoch 9/20] [Batch 254/274] [Batch classify loss: 0.047736] 
[Epoch 9/20] [Batch 255/274] [Batch classify loss: 0.019471] 
[Epoch 9/20] [Batch 256/274] [Batch classify loss: 0.045417] 
[Epoch 9/20] [Batch 257/274] [Batch classify loss: 0.019061] 
[Epoch 9/20] [Batch 258/274] [Batch classify loss: 0.030048] 
[Epoch 9/20] [Batch 259/274] [Batch classify loss: 0.040070] 
[Epoch 9/20] [Batch 260/274] [Batch classify loss: 0.040720] 
[Epoch 9/20] [Batch 261/274] [Batch classify loss: 0.043246] 
[Epoch 9/20] [Batch 262/274] [Batch classify loss: 0.022368] 
[Epoch 9/20] [Batch 263/274] [Batch classify loss: 0.018339] 
[Epoch 9/20] [Batch 264/274] [Batch classify loss: 0.027247] 
[Epoch 9/20] [Batch 265/274] [Batch classify loss: 0.052969] 
[Epoch 9/20] [Batch 266/274] [Batch classify loss: 0.036066] 
[Epoch 9/20] [Batch 267/274] [Batch classify loss: 0.007570] 
[Epoch 9/20] [Batch 268/274] [Batch classify loss: 0.046673] 
[Epoch 9/20] [Batch 269/274] [Batch classify loss: 0.045791] 
[Epoch 9/20] [Batch 270/274] [Batch classify loss: 0.042703] 
[Epoch 9/20] [Batch 271/274] [Batch classify loss: 0.030619] 
[Epoch 9/20] [Batch 272/274] [Batch classify loss: 0.043358] 
[Epoch 9/20] [Batch 273/274] [Batch classify loss: 0.031752] 
[Epoch 9/20] [Batch 274/274] [Batch classify loss: 0.033047] 
0009 epoch mmat trained classifier accuary on the clean testing examples:94.6681%
0009 epoch mmat trained classifier loss on the clean testing examples:0.2210
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2620%
mmat trained classifier loss on adversarial testset:4.522788047790527
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
9epoch learning rate:0.01
[Epoch 10/20] [Batch 1/274] [Batch classify loss: 0.256333] 
[Epoch 10/20] [Batch 2/274] [Batch classify loss: 0.129528] 
[Epoch 10/20] [Batch 3/274] [Batch classify loss: 0.153176] 
[Epoch 10/20] [Batch 4/274] [Batch classify loss: 0.130224] 
[Epoch 10/20] [Batch 5/274] [Batch classify loss: 0.221033] 
[Epoch 10/20] [Batch 6/274] [Batch classify loss: 0.303895] 
[Epoch 10/20] [Batch 7/274] [Batch classify loss: 0.121533] 
[Epoch 10/20] [Batch 8/274] [Batch classify loss: 0.122405] 
[Epoch 10/20] [Batch 9/274] [Batch classify loss: 0.255864] 
[Epoch 10/20] [Batch 10/274] [Batch classify loss: 0.257371] 
[Epoch 10/20] [Batch 11/274] [Batch classify loss: 0.134398] 
[Epoch 10/20] [Batch 12/274] [Batch classify loss: 0.245399] 
[Epoch 10/20] [Batch 13/274] [Batch classify loss: 0.110787] 
[Epoch 10/20] [Batch 14/274] [Batch classify loss: 0.259276] 
[Epoch 10/20] [Batch 15/274] [Batch classify loss: 0.170290] 
[Epoch 10/20] [Batch 16/274] [Batch classify loss: 0.091213] 
[Epoch 10/20] [Batch 17/274] [Batch classify loss: 0.160517] 
[Epoch 10/20] [Batch 18/274] [Batch classify loss: 0.128639] 
[Epoch 10/20] [Batch 19/274] [Batch classify loss: 0.234933] 
[Epoch 10/20] [Batch 20/274] [Batch classify loss: 0.107124] 
[Epoch 10/20] [Batch 21/274] [Batch classify loss: 0.096267] 
[Epoch 10/20] [Batch 22/274] [Batch classify loss: 0.199281] 
[Epoch 10/20] [Batch 23/274] [Batch classify loss: 0.167342] 
[Epoch 10/20] [Batch 24/274] [Batch classify loss: 0.092777] 
[Epoch 10/20] [Batch 25/274] [Batch classify loss: 0.187139] 
[Epoch 10/20] [Batch 26/274] [Batch classify loss: 0.114154] 
[Epoch 10/20] [Batch 27/274] [Batch classify loss: 0.111292] 
[Epoch 10/20] [Batch 28/274] [Batch classify loss: 0.076668] 
[Epoch 10/20] [Batch 29/274] [Batch classify loss: 0.077383] 
[Epoch 10/20] [Batch 30/274] [Batch classify loss: 0.075893] 
[Epoch 10/20] [Batch 31/274] [Batch classify loss: 0.114877] 
[Epoch 10/20] [Batch 32/274] [Batch classify loss: 0.149551] 
[Epoch 10/20] [Batch 33/274] [Batch classify loss: 0.067320] 
[Epoch 10/20] [Batch 34/274] [Batch classify loss: 0.119734] 
[Epoch 10/20] [Batch 35/274] [Batch classify loss: 0.133648] 
[Epoch 10/20] [Batch 36/274] [Batch classify loss: 0.124596] 
[Epoch 10/20] [Batch 37/274] [Batch classify loss: 0.098858] 
[Epoch 10/20] [Batch 38/274] [Batch classify loss: 0.054928] 
[Epoch 10/20] [Batch 39/274] [Batch classify loss: 0.103375] 
[Epoch 10/20] [Batch 40/274] [Batch classify loss: 0.063610] 
[Epoch 10/20] [Batch 41/274] [Batch classify loss: 0.089601] 
[Epoch 10/20] [Batch 42/274] [Batch classify loss: 0.096436] 
[Epoch 10/20] [Batch 43/274] [Batch classify loss: 0.053494] 
[Epoch 10/20] [Batch 44/274] [Batch classify loss: 0.051925] 
[Epoch 10/20] [Batch 45/274] [Batch classify loss: 0.082287] 
[Epoch 10/20] [Batch 46/274] [Batch classify loss: 0.087732] 
[Epoch 10/20] [Batch 47/274] [Batch classify loss: 0.058971] 
[Epoch 10/20] [Batch 48/274] [Batch classify loss: 0.093408] 
[Epoch 10/20] [Batch 49/274] [Batch classify loss: 0.091207] 
[Epoch 10/20] [Batch 50/274] [Batch classify loss: 0.046716] 
[Epoch 10/20] [Batch 51/274] [Batch classify loss: 0.058683] 
[Epoch 10/20] [Batch 52/274] [Batch classify loss: 0.061696] 
[Epoch 10/20] [Batch 53/274] [Batch classify loss: 0.080249] 
[Epoch 10/20] [Batch 54/274] [Batch classify loss: 0.078253] 
[Epoch 10/20] [Batch 55/274] [Batch classify loss: 0.087509] 
[Epoch 10/20] [Batch 56/274] [Batch classify loss: 0.060198] 
[Epoch 10/20] [Batch 57/274] [Batch classify loss: 0.047038] 
[Epoch 10/20] [Batch 58/274] [Batch classify loss: 0.095273] 
[Epoch 10/20] [Batch 59/274] [Batch classify loss: 0.131266] 
[Epoch 10/20] [Batch 60/274] [Batch classify loss: 0.070378] 
[Epoch 10/20] [Batch 61/274] [Batch classify loss: 0.087139] 
[Epoch 10/20] [Batch 62/274] [Batch classify loss: 0.067145] 
[Epoch 10/20] [Batch 63/274] [Batch classify loss: 0.152623] 
[Epoch 10/20] [Batch 64/274] [Batch classify loss: 0.060717] 
[Epoch 10/20] [Batch 65/274] [Batch classify loss: 0.081468] 
[Epoch 10/20] [Batch 66/274] [Batch classify loss: 0.092022] 
[Epoch 10/20] [Batch 67/274] [Batch classify loss: 0.062106] 
[Epoch 10/20] [Batch 68/274] [Batch classify loss: 0.060056] 
[Epoch 10/20] [Batch 69/274] [Batch classify loss: 0.065181] 
[Epoch 10/20] [Batch 70/274] [Batch classify loss: 0.068267] 
[Epoch 10/20] [Batch 71/274] [Batch classify loss: 0.073272] 
[Epoch 10/20] [Batch 72/274] [Batch classify loss: 0.076786] 
[Epoch 10/20] [Batch 73/274] [Batch classify loss: 0.076607] 
[Epoch 10/20] [Batch 74/274] [Batch classify loss: 0.069331] 
[Epoch 10/20] [Batch 75/274] [Batch classify loss: 0.078070] 
[Epoch 10/20] [Batch 76/274] [Batch classify loss: 0.084828] 
[Epoch 10/20] [Batch 77/274] [Batch classify loss: 0.108407] 
[Epoch 10/20] [Batch 78/274] [Batch classify loss: 0.071144] 
[Epoch 10/20] [Batch 79/274] [Batch classify loss: 0.066343] 
[Epoch 10/20] [Batch 80/274] [Batch classify loss: 0.034498] 
[Epoch 10/20] [Batch 81/274] [Batch classify loss: 0.144960] 
[Epoch 10/20] [Batch 82/274] [Batch classify loss: 0.050242] 
[Epoch 10/20] [Batch 83/274] [Batch classify loss: 0.037730] 
[Epoch 10/20] [Batch 84/274] [Batch classify loss: 0.060973] 
[Epoch 10/20] [Batch 85/274] [Batch classify loss: 0.053361] 
[Epoch 10/20] [Batch 86/274] [Batch classify loss: 0.048145] 
[Epoch 10/20] [Batch 87/274] [Batch classify loss: 0.054293] 
[Epoch 10/20] [Batch 88/274] [Batch classify loss: 0.108495] 
[Epoch 10/20] [Batch 89/274] [Batch classify loss: 0.046971] 
[Epoch 10/20] [Batch 90/274] [Batch classify loss: 0.091239] 
[Epoch 10/20] [Batch 91/274] [Batch classify loss: 0.056454] 
[Epoch 10/20] [Batch 92/274] [Batch classify loss: 0.066831] 
[Epoch 10/20] [Batch 93/274] [Batch classify loss: 0.051608] 
[Epoch 10/20] [Batch 94/274] [Batch classify loss: 0.117699] 
[Epoch 10/20] [Batch 95/274] [Batch classify loss: 0.100124] 
[Epoch 10/20] [Batch 96/274] [Batch classify loss: 0.041409] 
[Epoch 10/20] [Batch 97/274] [Batch classify loss: 0.051263] 
[Epoch 10/20] [Batch 98/274] [Batch classify loss: 0.096095] 
[Epoch 10/20] [Batch 99/274] [Batch classify loss: 0.064034] 
[Epoch 10/20] [Batch 100/274] [Batch classify loss: 0.045192] 
[Epoch 10/20] [Batch 101/274] [Batch classify loss: 0.057907] 
[Epoch 10/20] [Batch 102/274] [Batch classify loss: 0.063622] 
[Epoch 10/20] [Batch 103/274] [Batch classify loss: 0.051351] 
[Epoch 10/20] [Batch 104/274] [Batch classify loss: 0.053813] 
[Epoch 10/20] [Batch 105/274] [Batch classify loss: 0.097340] 
[Epoch 10/20] [Batch 106/274] [Batch classify loss: 0.076637] 
[Epoch 10/20] [Batch 107/274] [Batch classify loss: 0.056003] 
[Epoch 10/20] [Batch 108/274] [Batch classify loss: 0.062271] 
[Epoch 10/20] [Batch 109/274] [Batch classify loss: 0.034075] 
[Epoch 10/20] [Batch 110/274] [Batch classify loss: 0.103247] 
[Epoch 10/20] [Batch 111/274] [Batch classify loss: 0.097945] 
[Epoch 10/20] [Batch 112/274] [Batch classify loss: 0.036560] 
[Epoch 10/20] [Batch 113/274] [Batch classify loss: 0.068929] 
[Epoch 10/20] [Batch 114/274] [Batch classify loss: 0.101687] 
[Epoch 10/20] [Batch 115/274] [Batch classify loss: 0.065139] 
[Epoch 10/20] [Batch 116/274] [Batch classify loss: 0.069886] 
[Epoch 10/20] [Batch 117/274] [Batch classify loss: 0.080785] 
[Epoch 10/20] [Batch 118/274] [Batch classify loss: 0.036896] 
[Epoch 10/20] [Batch 119/274] [Batch classify loss: 0.073232] 
[Epoch 10/20] [Batch 120/274] [Batch classify loss: 0.046922] 
[Epoch 10/20] [Batch 121/274] [Batch classify loss: 0.084388] 
[Epoch 10/20] [Batch 122/274] [Batch classify loss: 0.043953] 
[Epoch 10/20] [Batch 123/274] [Batch classify loss: 0.063472] 
[Epoch 10/20] [Batch 124/274] [Batch classify loss: 0.038787] 
[Epoch 10/20] [Batch 125/274] [Batch classify loss: 0.069331] 
[Epoch 10/20] [Batch 126/274] [Batch classify loss: 0.050971] 
[Epoch 10/20] [Batch 127/274] [Batch classify loss: 0.080113] 
[Epoch 10/20] [Batch 128/274] [Batch classify loss: 0.030641] 
[Epoch 10/20] [Batch 129/274] [Batch classify loss: 0.060930] 
[Epoch 10/20] [Batch 130/274] [Batch classify loss: 0.051541] 
[Epoch 10/20] [Batch 131/274] [Batch classify loss: 0.079948] 
[Epoch 10/20] [Batch 132/274] [Batch classify loss: 0.084076] 
[Epoch 10/20] [Batch 133/274] [Batch classify loss: 0.070740] 
[Epoch 10/20] [Batch 134/274] [Batch classify loss: 0.070684] 
[Epoch 10/20] [Batch 135/274] [Batch classify loss: 0.053260] 
[Epoch 10/20] [Batch 136/274] [Batch classify loss: 0.055489] 
[Epoch 10/20] [Batch 137/274] [Batch classify loss: 0.093693] 
[Epoch 10/20] [Batch 138/274] [Batch classify loss: 0.081277] 
[Epoch 10/20] [Batch 139/274] [Batch classify loss: 0.030377] 
[Epoch 10/20] [Batch 140/274] [Batch classify loss: 0.044139] 
[Epoch 10/20] [Batch 141/274] [Batch classify loss: 0.057574] 
[Epoch 10/20] [Batch 142/274] [Batch classify loss: 0.022475] 
[Epoch 10/20] [Batch 143/274] [Batch classify loss: 0.046612] 
[Epoch 10/20] [Batch 144/274] [Batch classify loss: 0.046803] 
[Epoch 10/20] [Batch 145/274] [Batch classify loss: 0.067312] 
[Epoch 10/20] [Batch 146/274] [Batch classify loss: 0.100360] 
[Epoch 10/20] [Batch 147/274] [Batch classify loss: 0.042541] 
[Epoch 10/20] [Batch 148/274] [Batch classify loss: 0.056401] 
[Epoch 10/20] [Batch 149/274] [Batch classify loss: 0.026133] 
[Epoch 10/20] [Batch 150/274] [Batch classify loss: 0.064814] 
[Epoch 10/20] [Batch 151/274] [Batch classify loss: 0.036882] 
[Epoch 10/20] [Batch 152/274] [Batch classify loss: 0.065341] 
[Epoch 10/20] [Batch 153/274] [Batch classify loss: 0.042864] 
[Epoch 10/20] [Batch 154/274] [Batch classify loss: 0.027288] 
[Epoch 10/20] [Batch 155/274] [Batch classify loss: 0.073486] 
[Epoch 10/20] [Batch 156/274] [Batch classify loss: 0.090983] 
[Epoch 10/20] [Batch 157/274] [Batch classify loss: 0.054626] 
[Epoch 10/20] [Batch 158/274] [Batch classify loss: 0.084902] 
[Epoch 10/20] [Batch 159/274] [Batch classify loss: 0.042969] 
[Epoch 10/20] [Batch 160/274] [Batch classify loss: 0.052761] 
[Epoch 10/20] [Batch 161/274] [Batch classify loss: 0.021953] 
[Epoch 10/20] [Batch 162/274] [Batch classify loss: 0.092494] 
[Epoch 10/20] [Batch 163/274] [Batch classify loss: 0.052584] 
[Epoch 10/20] [Batch 164/274] [Batch classify loss: 0.082140] 
[Epoch 10/20] [Batch 165/274] [Batch classify loss: 0.053007] 
[Epoch 10/20] [Batch 166/274] [Batch classify loss: 0.064350] 
[Epoch 10/20] [Batch 167/274] [Batch classify loss: 0.086555] 
[Epoch 10/20] [Batch 168/274] [Batch classify loss: 0.039210] 
[Epoch 10/20] [Batch 169/274] [Batch classify loss: 0.049170] 
[Epoch 10/20] [Batch 170/274] [Batch classify loss: 0.047108] 
[Epoch 10/20] [Batch 171/274] [Batch classify loss: 0.040057] 
[Epoch 10/20] [Batch 172/274] [Batch classify loss: 0.023614] 
[Epoch 10/20] [Batch 173/274] [Batch classify loss: 0.045191] 
[Epoch 10/20] [Batch 174/274] [Batch classify loss: 0.045762] 
[Epoch 10/20] [Batch 175/274] [Batch classify loss: 0.060800] 
[Epoch 10/20] [Batch 176/274] [Batch classify loss: 0.042360] 
[Epoch 10/20] [Batch 177/274] [Batch classify loss: 0.042646] 
[Epoch 10/20] [Batch 178/274] [Batch classify loss: 0.053987] 
[Epoch 10/20] [Batch 179/274] [Batch classify loss: 0.044741] 
[Epoch 10/20] [Batch 180/274] [Batch classify loss: 0.107535] 
[Epoch 10/20] [Batch 181/274] [Batch classify loss: 0.053073] 
[Epoch 10/20] [Batch 182/274] [Batch classify loss: 0.085239] 
[Epoch 10/20] [Batch 183/274] [Batch classify loss: 0.061558] 
[Epoch 10/20] [Batch 184/274] [Batch classify loss: 0.052641] 
[Epoch 10/20] [Batch 185/274] [Batch classify loss: 0.061870] 
[Epoch 10/20] [Batch 186/274] [Batch classify loss: 0.061095] 
[Epoch 10/20] [Batch 187/274] [Batch classify loss: 0.056921] 
[Epoch 10/20] [Batch 188/274] [Batch classify loss: 0.033776] 
[Epoch 10/20] [Batch 189/274] [Batch classify loss: 0.044551] 
[Epoch 10/20] [Batch 190/274] [Batch classify loss: 0.034557] 
[Epoch 10/20] [Batch 191/274] [Batch classify loss: 0.088968] 
[Epoch 10/20] [Batch 192/274] [Batch classify loss: 0.050423] 
[Epoch 10/20] [Batch 193/274] [Batch classify loss: 0.045682] 
[Epoch 10/20] [Batch 194/274] [Batch classify loss: 0.020879] 
[Epoch 10/20] [Batch 195/274] [Batch classify loss: 0.053928] 
[Epoch 10/20] [Batch 196/274] [Batch classify loss: 0.047913] 
[Epoch 10/20] [Batch 197/274] [Batch classify loss: 0.096088] 
[Epoch 10/20] [Batch 198/274] [Batch classify loss: 0.042635] 
[Epoch 10/20] [Batch 199/274] [Batch classify loss: 0.046411] 
[Epoch 10/20] [Batch 200/274] [Batch classify loss: 0.040554] 
[Epoch 10/20] [Batch 201/274] [Batch classify loss: 0.013138] 
[Epoch 10/20] [Batch 202/274] [Batch classify loss: 0.032229] 
[Epoch 10/20] [Batch 203/274] [Batch classify loss: 0.026197] 
[Epoch 10/20] [Batch 204/274] [Batch classify loss: 0.047292] 
[Epoch 10/20] [Batch 205/274] [Batch classify loss: 0.073336] 
[Epoch 10/20] [Batch 206/274] [Batch classify loss: 0.043877] 
[Epoch 10/20] [Batch 207/274] [Batch classify loss: 0.040328] 
[Epoch 10/20] [Batch 208/274] [Batch classify loss: 0.031327] 
[Epoch 10/20] [Batch 209/274] [Batch classify loss: 0.053335] 
[Epoch 10/20] [Batch 210/274] [Batch classify loss: 0.040876] 
[Epoch 10/20] [Batch 211/274] [Batch classify loss: 0.059644] 
[Epoch 10/20] [Batch 212/274] [Batch classify loss: 0.020042] 
[Epoch 10/20] [Batch 213/274] [Batch classify loss: 0.028413] 
[Epoch 10/20] [Batch 214/274] [Batch classify loss: 0.036733] 
[Epoch 10/20] [Batch 215/274] [Batch classify loss: 0.028227] 
[Epoch 10/20] [Batch 216/274] [Batch classify loss: 0.045211] 
[Epoch 10/20] [Batch 217/274] [Batch classify loss: 0.049202] 
[Epoch 10/20] [Batch 218/274] [Batch classify loss: 0.072424] 
[Epoch 10/20] [Batch 219/274] [Batch classify loss: 0.028285] 
[Epoch 10/20] [Batch 220/274] [Batch classify loss: 0.042440] 
[Epoch 10/20] [Batch 221/274] [Batch classify loss: 0.034092] 
[Epoch 10/20] [Batch 222/274] [Batch classify loss: 0.044644] 
[Epoch 10/20] [Batch 223/274] [Batch classify loss: 0.087555] 
[Epoch 10/20] [Batch 224/274] [Batch classify loss: 0.038995] 
[Epoch 10/20] [Batch 225/274] [Batch classify loss: 0.065150] 
[Epoch 10/20] [Batch 226/274] [Batch classify loss: 0.039307] 
[Epoch 10/20] [Batch 227/274] [Batch classify loss: 0.064745] 
[Epoch 10/20] [Batch 228/274] [Batch classify loss: 0.059337] 
[Epoch 10/20] [Batch 229/274] [Batch classify loss: 0.044043] 
[Epoch 10/20] [Batch 230/274] [Batch classify loss: 0.020833] 
[Epoch 10/20] [Batch 231/274] [Batch classify loss: 0.076333] 
[Epoch 10/20] [Batch 232/274] [Batch classify loss: 0.076000] 
[Epoch 10/20] [Batch 233/274] [Batch classify loss: 0.017882] 
[Epoch 10/20] [Batch 234/274] [Batch classify loss: 0.076869] 
[Epoch 10/20] [Batch 235/274] [Batch classify loss: 0.056752] 
[Epoch 10/20] [Batch 236/274] [Batch classify loss: 0.084451] 
[Epoch 10/20] [Batch 237/274] [Batch classify loss: 0.040988] 
[Epoch 10/20] [Batch 238/274] [Batch classify loss: 0.035681] 
[Epoch 10/20] [Batch 239/274] [Batch classify loss: 0.066283] 
[Epoch 10/20] [Batch 240/274] [Batch classify loss: 0.045760] 
[Epoch 10/20] [Batch 241/274] [Batch classify loss: 0.041290] 
[Epoch 10/20] [Batch 242/274] [Batch classify loss: 0.068696] 
[Epoch 10/20] [Batch 243/274] [Batch classify loss: 0.063170] 
[Epoch 10/20] [Batch 244/274] [Batch classify loss: 0.038533] 
[Epoch 10/20] [Batch 245/274] [Batch classify loss: 0.096022] 
[Epoch 10/20] [Batch 246/274] [Batch classify loss: 0.061130] 
[Epoch 10/20] [Batch 247/274] [Batch classify loss: 0.061970] 
[Epoch 10/20] [Batch 248/274] [Batch classify loss: 0.038342] 
[Epoch 10/20] [Batch 249/274] [Batch classify loss: 0.055241] 
[Epoch 10/20] [Batch 250/274] [Batch classify loss: 0.042166] 
[Epoch 10/20] [Batch 251/274] [Batch classify loss: 0.070616] 
[Epoch 10/20] [Batch 252/274] [Batch classify loss: 0.028915] 
[Epoch 10/20] [Batch 253/274] [Batch classify loss: 0.041810] 
[Epoch 10/20] [Batch 254/274] [Batch classify loss: 0.039312] 
[Epoch 10/20] [Batch 255/274] [Batch classify loss: 0.031608] 
[Epoch 10/20] [Batch 256/274] [Batch classify loss: 0.059163] 
[Epoch 10/20] [Batch 257/274] [Batch classify loss: 0.023189] 
[Epoch 10/20] [Batch 258/274] [Batch classify loss: 0.026056] 
[Epoch 10/20] [Batch 259/274] [Batch classify loss: 0.043062] 
[Epoch 10/20] [Batch 260/274] [Batch classify loss: 0.036190] 
[Epoch 10/20] [Batch 261/274] [Batch classify loss: 0.055246] 
[Epoch 10/20] [Batch 262/274] [Batch classify loss: 0.042831] 
[Epoch 10/20] [Batch 263/274] [Batch classify loss: 0.057346] 
[Epoch 10/20] [Batch 264/274] [Batch classify loss: 0.019278] 
[Epoch 10/20] [Batch 265/274] [Batch classify loss: 0.054880] 
[Epoch 10/20] [Batch 266/274] [Batch classify loss: 0.061056] 
[Epoch 10/20] [Batch 267/274] [Batch classify loss: 0.094289] 
[Epoch 10/20] [Batch 268/274] [Batch classify loss: 0.043807] 
[Epoch 10/20] [Batch 269/274] [Batch classify loss: 0.063389] 
[Epoch 10/20] [Batch 270/274] [Batch classify loss: 0.040270] 
[Epoch 10/20] [Batch 271/274] [Batch classify loss: 0.044289] 
[Epoch 10/20] [Batch 272/274] [Batch classify loss: 0.103328] 
[Epoch 10/20] [Batch 273/274] [Batch classify loss: 0.046376] 
[Epoch 10/20] [Batch 274/274] [Batch classify loss: 0.020747] 
0010 epoch mmat trained classifier accuary on the clean testing examples:94.7372%
0010 epoch mmat trained classifier loss on the clean testing examples:0.2244
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3657%
mmat trained classifier loss on adversarial testset:4.519038200378418
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
10epoch learning rate:0.001
[Epoch 11/20] [Batch 1/274] [Batch classify loss: 0.706600] 
[Epoch 11/20] [Batch 2/274] [Batch classify loss: 0.109880] 
[Epoch 11/20] [Batch 3/274] [Batch classify loss: 0.106038] 
[Epoch 11/20] [Batch 4/274] [Batch classify loss: 0.116389] 
[Epoch 11/20] [Batch 5/274] [Batch classify loss: 0.126136] 
[Epoch 11/20] [Batch 6/274] [Batch classify loss: 0.122886] 
[Epoch 11/20] [Batch 7/274] [Batch classify loss: 0.173923] 
[Epoch 11/20] [Batch 8/274] [Batch classify loss: 0.119812] 
[Epoch 11/20] [Batch 9/274] [Batch classify loss: 0.171168] 
[Epoch 11/20] [Batch 10/274] [Batch classify loss: 0.144100] 
[Epoch 11/20] [Batch 11/274] [Batch classify loss: 0.119031] 
[Epoch 11/20] [Batch 12/274] [Batch classify loss: 0.239361] 
[Epoch 11/20] [Batch 13/274] [Batch classify loss: 0.142860] 
[Epoch 11/20] [Batch 14/274] [Batch classify loss: 0.130676] 
[Epoch 11/20] [Batch 15/274] [Batch classify loss: 0.177196] 
[Epoch 11/20] [Batch 16/274] [Batch classify loss: 0.151998] 
[Epoch 11/20] [Batch 17/274] [Batch classify loss: 0.132120] 
[Epoch 11/20] [Batch 18/274] [Batch classify loss: 0.282885] 
[Epoch 11/20] [Batch 19/274] [Batch classify loss: 0.150044] 
[Epoch 11/20] [Batch 20/274] [Batch classify loss: 0.165889] 
[Epoch 11/20] [Batch 21/274] [Batch classify loss: 0.158840] 
[Epoch 11/20] [Batch 22/274] [Batch classify loss: 0.188289] 
[Epoch 11/20] [Batch 23/274] [Batch classify loss: 0.104681] 
[Epoch 11/20] [Batch 24/274] [Batch classify loss: 0.168658] 
[Epoch 11/20] [Batch 25/274] [Batch classify loss: 0.217415] 
[Epoch 11/20] [Batch 26/274] [Batch classify loss: 0.179228] 
[Epoch 11/20] [Batch 27/274] [Batch classify loss: 0.172687] 
[Epoch 11/20] [Batch 28/274] [Batch classify loss: 0.116781] 
[Epoch 11/20] [Batch 29/274] [Batch classify loss: 0.103561] 
[Epoch 11/20] [Batch 30/274] [Batch classify loss: 0.086387] 
[Epoch 11/20] [Batch 31/274] [Batch classify loss: 0.107529] 
[Epoch 11/20] [Batch 32/274] [Batch classify loss: 0.187078] 
[Epoch 11/20] [Batch 33/274] [Batch classify loss: 0.144122] 
[Epoch 11/20] [Batch 34/274] [Batch classify loss: 0.116401] 
[Epoch 11/20] [Batch 35/274] [Batch classify loss: 0.134433] 
[Epoch 11/20] [Batch 36/274] [Batch classify loss: 0.181701] 
[Epoch 11/20] [Batch 37/274] [Batch classify loss: 0.160137] 
[Epoch 11/20] [Batch 38/274] [Batch classify loss: 0.161944] 
[Epoch 11/20] [Batch 39/274] [Batch classify loss: 0.214973] 
[Epoch 11/20] [Batch 40/274] [Batch classify loss: 0.127453] 
[Epoch 11/20] [Batch 41/274] [Batch classify loss: 0.136962] 
[Epoch 11/20] [Batch 42/274] [Batch classify loss: 0.116875] 
[Epoch 11/20] [Batch 43/274] [Batch classify loss: 0.126713] 
[Epoch 11/20] [Batch 44/274] [Batch classify loss: 0.136404] 
[Epoch 11/20] [Batch 45/274] [Batch classify loss: 0.093251] 
[Epoch 11/20] [Batch 46/274] [Batch classify loss: 0.184105] 
[Epoch 11/20] [Batch 47/274] [Batch classify loss: 0.111032] 
[Epoch 11/20] [Batch 48/274] [Batch classify loss: 0.158255] 
[Epoch 11/20] [Batch 49/274] [Batch classify loss: 0.092162] 
[Epoch 11/20] [Batch 50/274] [Batch classify loss: 0.177022] 
[Epoch 11/20] [Batch 51/274] [Batch classify loss: 0.109668] 
[Epoch 11/20] [Batch 52/274] [Batch classify loss: 0.130279] 
[Epoch 11/20] [Batch 53/274] [Batch classify loss: 0.079936] 
[Epoch 11/20] [Batch 54/274] [Batch classify loss: 0.128004] 
[Epoch 11/20] [Batch 55/274] [Batch classify loss: 0.073607] 
[Epoch 11/20] [Batch 56/274] [Batch classify loss: 0.115870] 
[Epoch 11/20] [Batch 57/274] [Batch classify loss: 0.060900] 
[Epoch 11/20] [Batch 58/274] [Batch classify loss: 0.093720] 
[Epoch 11/20] [Batch 59/274] [Batch classify loss: 0.176440] 
[Epoch 11/20] [Batch 60/274] [Batch classify loss: 0.145958] 
[Epoch 11/20] [Batch 61/274] [Batch classify loss: 0.117950] 
[Epoch 11/20] [Batch 62/274] [Batch classify loss: 0.067968] 
[Epoch 11/20] [Batch 63/274] [Batch classify loss: 0.191631] 
[Epoch 11/20] [Batch 64/274] [Batch classify loss: 0.154497] 
[Epoch 11/20] [Batch 65/274] [Batch classify loss: 0.051964] 
[Epoch 11/20] [Batch 66/274] [Batch classify loss: 0.079604] 
[Epoch 11/20] [Batch 67/274] [Batch classify loss: 0.076033] 
[Epoch 11/20] [Batch 68/274] [Batch classify loss: 0.071632] 
[Epoch 11/20] [Batch 69/274] [Batch classify loss: 0.052235] 
[Epoch 11/20] [Batch 70/274] [Batch classify loss: 0.162508] 
[Epoch 11/20] [Batch 71/274] [Batch classify loss: 0.155998] 
[Epoch 11/20] [Batch 72/274] [Batch classify loss: 0.105460] 
[Epoch 11/20] [Batch 73/274] [Batch classify loss: 0.189256] 
[Epoch 11/20] [Batch 74/274] [Batch classify loss: 0.109847] 
[Epoch 11/20] [Batch 75/274] [Batch classify loss: 0.072052] 
[Epoch 11/20] [Batch 76/274] [Batch classify loss: 0.163980] 
[Epoch 11/20] [Batch 77/274] [Batch classify loss: 0.073109] 
[Epoch 11/20] [Batch 78/274] [Batch classify loss: 0.139649] 
[Epoch 11/20] [Batch 79/274] [Batch classify loss: 0.150187] 
[Epoch 11/20] [Batch 80/274] [Batch classify loss: 0.108761] 
[Epoch 11/20] [Batch 81/274] [Batch classify loss: 0.084238] 
[Epoch 11/20] [Batch 82/274] [Batch classify loss: 0.128309] 
[Epoch 11/20] [Batch 83/274] [Batch classify loss: 0.069595] 
[Epoch 11/20] [Batch 84/274] [Batch classify loss: 0.047151] 
[Epoch 11/20] [Batch 85/274] [Batch classify loss: 0.088555] 
[Epoch 11/20] [Batch 86/274] [Batch classify loss: 0.096148] 
[Epoch 11/20] [Batch 87/274] [Batch classify loss: 0.090003] 
[Epoch 11/20] [Batch 88/274] [Batch classify loss: 0.116070] 
[Epoch 11/20] [Batch 89/274] [Batch classify loss: 0.116304] 
[Epoch 11/20] [Batch 90/274] [Batch classify loss: 0.105870] 
[Epoch 11/20] [Batch 91/274] [Batch classify loss: 0.188151] 
[Epoch 11/20] [Batch 92/274] [Batch classify loss: 0.085917] 
[Epoch 11/20] [Batch 93/274] [Batch classify loss: 0.114848] 
[Epoch 11/20] [Batch 94/274] [Batch classify loss: 0.136433] 
[Epoch 11/20] [Batch 95/274] [Batch classify loss: 0.089507] 
[Epoch 11/20] [Batch 96/274] [Batch classify loss: 0.070684] 
[Epoch 11/20] [Batch 97/274] [Batch classify loss: 0.069356] 
[Epoch 11/20] [Batch 98/274] [Batch classify loss: 0.168732] 
[Epoch 11/20] [Batch 99/274] [Batch classify loss: 0.057156] 
[Epoch 11/20] [Batch 100/274] [Batch classify loss: 0.125517] 
[Epoch 11/20] [Batch 101/274] [Batch classify loss: 0.038642] 
[Epoch 11/20] [Batch 102/274] [Batch classify loss: 0.054433] 
[Epoch 11/20] [Batch 103/274] [Batch classify loss: 0.111316] 
[Epoch 11/20] [Batch 104/274] [Batch classify loss: 0.066158] 
[Epoch 11/20] [Batch 105/274] [Batch classify loss: 0.187900] 
[Epoch 11/20] [Batch 106/274] [Batch classify loss: 0.067058] 
[Epoch 11/20] [Batch 107/274] [Batch classify loss: 0.113036] 
[Epoch 11/20] [Batch 108/274] [Batch classify loss: 0.147060] 
[Epoch 11/20] [Batch 109/274] [Batch classify loss: 0.039957] 
[Epoch 11/20] [Batch 110/274] [Batch classify loss: 0.162300] 
[Epoch 11/20] [Batch 111/274] [Batch classify loss: 0.104167] 
[Epoch 11/20] [Batch 112/274] [Batch classify loss: 0.069520] 
[Epoch 11/20] [Batch 113/274] [Batch classify loss: 0.141605] 
[Epoch 11/20] [Batch 114/274] [Batch classify loss: 0.092087] 
[Epoch 11/20] [Batch 115/274] [Batch classify loss: 0.060893] 
[Epoch 11/20] [Batch 116/274] [Batch classify loss: 0.091446] 
[Epoch 11/20] [Batch 117/274] [Batch classify loss: 0.036986] 
[Epoch 11/20] [Batch 118/274] [Batch classify loss: 0.083261] 
[Epoch 11/20] [Batch 119/274] [Batch classify loss: 0.083968] 
[Epoch 11/20] [Batch 120/274] [Batch classify loss: 0.076156] 
[Epoch 11/20] [Batch 121/274] [Batch classify loss: 0.115144] 
[Epoch 11/20] [Batch 122/274] [Batch classify loss: 0.050486] 
[Epoch 11/20] [Batch 123/274] [Batch classify loss: 0.072677] 
[Epoch 11/20] [Batch 124/274] [Batch classify loss: 0.056558] 
[Epoch 11/20] [Batch 125/274] [Batch classify loss: 0.091122] 
[Epoch 11/20] [Batch 126/274] [Batch classify loss: 0.085537] 
[Epoch 11/20] [Batch 127/274] [Batch classify loss: 0.063613] 
[Epoch 11/20] [Batch 128/274] [Batch classify loss: 0.137168] 
[Epoch 11/20] [Batch 129/274] [Batch classify loss: 0.166140] 
[Epoch 11/20] [Batch 130/274] [Batch classify loss: 0.087809] 
[Epoch 11/20] [Batch 131/274] [Batch classify loss: 0.065051] 
[Epoch 11/20] [Batch 132/274] [Batch classify loss: 0.062663] 
[Epoch 11/20] [Batch 133/274] [Batch classify loss: 0.080834] 
[Epoch 11/20] [Batch 134/274] [Batch classify loss: 0.072775] 
[Epoch 11/20] [Batch 135/274] [Batch classify loss: 0.135415] 
[Epoch 11/20] [Batch 136/274] [Batch classify loss: 0.061570] 
[Epoch 11/20] [Batch 137/274] [Batch classify loss: 0.181562] 
[Epoch 11/20] [Batch 138/274] [Batch classify loss: 0.109042] 
[Epoch 11/20] [Batch 139/274] [Batch classify loss: 0.093679] 
[Epoch 11/20] [Batch 140/274] [Batch classify loss: 0.083432] 
[Epoch 11/20] [Batch 141/274] [Batch classify loss: 0.045339] 
[Epoch 11/20] [Batch 142/274] [Batch classify loss: 0.102007] 
[Epoch 11/20] [Batch 143/274] [Batch classify loss: 0.110308] 
[Epoch 11/20] [Batch 144/274] [Batch classify loss: 0.098754] 
[Epoch 11/20] [Batch 145/274] [Batch classify loss: 0.052838] 
[Epoch 11/20] [Batch 146/274] [Batch classify loss: 0.076933] 
[Epoch 11/20] [Batch 147/274] [Batch classify loss: 0.099811] 
[Epoch 11/20] [Batch 148/274] [Batch classify loss: 0.136999] 
[Epoch 11/20] [Batch 149/274] [Batch classify loss: 0.107164] 
[Epoch 11/20] [Batch 150/274] [Batch classify loss: 0.024933] 
[Epoch 11/20] [Batch 151/274] [Batch classify loss: 0.063990] 
[Epoch 11/20] [Batch 152/274] [Batch classify loss: 0.094246] 
[Epoch 11/20] [Batch 153/274] [Batch classify loss: 0.069702] 
[Epoch 11/20] [Batch 154/274] [Batch classify loss: 0.088644] 
[Epoch 11/20] [Batch 155/274] [Batch classify loss: 0.083616] 
[Epoch 11/20] [Batch 156/274] [Batch classify loss: 0.046212] 
[Epoch 11/20] [Batch 157/274] [Batch classify loss: 0.091753] 
[Epoch 11/20] [Batch 158/274] [Batch classify loss: 0.084665] 
[Epoch 11/20] [Batch 159/274] [Batch classify loss: 0.050491] 
[Epoch 11/20] [Batch 160/274] [Batch classify loss: 0.059501] 
[Epoch 11/20] [Batch 161/274] [Batch classify loss: 0.149460] 
[Epoch 11/20] [Batch 162/274] [Batch classify loss: 0.053972] 
[Epoch 11/20] [Batch 163/274] [Batch classify loss: 0.080332] 
[Epoch 11/20] [Batch 164/274] [Batch classify loss: 0.082830] 
[Epoch 11/20] [Batch 165/274] [Batch classify loss: 0.054655] 
[Epoch 11/20] [Batch 166/274] [Batch classify loss: 0.059605] 
[Epoch 11/20] [Batch 167/274] [Batch classify loss: 0.105754] 
[Epoch 11/20] [Batch 168/274] [Batch classify loss: 0.049611] 
[Epoch 11/20] [Batch 169/274] [Batch classify loss: 0.065999] 
[Epoch 11/20] [Batch 170/274] [Batch classify loss: 0.086864] 
[Epoch 11/20] [Batch 171/274] [Batch classify loss: 0.029535] 
[Epoch 11/20] [Batch 172/274] [Batch classify loss: 0.071771] 
[Epoch 11/20] [Batch 173/274] [Batch classify loss: 0.080893] 
[Epoch 11/20] [Batch 174/274] [Batch classify loss: 0.058170] 
[Epoch 11/20] [Batch 175/274] [Batch classify loss: 0.046223] 
[Epoch 11/20] [Batch 176/274] [Batch classify loss: 0.064294] 
[Epoch 11/20] [Batch 177/274] [Batch classify loss: 0.056068] 
[Epoch 11/20] [Batch 178/274] [Batch classify loss: 0.055815] 
[Epoch 11/20] [Batch 179/274] [Batch classify loss: 0.097403] 
[Epoch 11/20] [Batch 180/274] [Batch classify loss: 0.111108] 
[Epoch 11/20] [Batch 181/274] [Batch classify loss: 0.083522] 
[Epoch 11/20] [Batch 182/274] [Batch classify loss: 0.031166] 
[Epoch 11/20] [Batch 183/274] [Batch classify loss: 0.071427] 
[Epoch 11/20] [Batch 184/274] [Batch classify loss: 0.127803] 
[Epoch 11/20] [Batch 185/274] [Batch classify loss: 0.059784] 
[Epoch 11/20] [Batch 186/274] [Batch classify loss: 0.110218] 
[Epoch 11/20] [Batch 187/274] [Batch classify loss: 0.048606] 
[Epoch 11/20] [Batch 188/274] [Batch classify loss: 0.065526] 
[Epoch 11/20] [Batch 189/274] [Batch classify loss: 0.067512] 
[Epoch 11/20] [Batch 190/274] [Batch classify loss: 0.079861] 
[Epoch 11/20] [Batch 191/274] [Batch classify loss: 0.156689] 
[Epoch 11/20] [Batch 192/274] [Batch classify loss: 0.067475] 
[Epoch 11/20] [Batch 193/274] [Batch classify loss: 0.062428] 
[Epoch 11/20] [Batch 194/274] [Batch classify loss: 0.049895] 
[Epoch 11/20] [Batch 195/274] [Batch classify loss: 0.103857] 
[Epoch 11/20] [Batch 196/274] [Batch classify loss: 0.072333] 
[Epoch 11/20] [Batch 197/274] [Batch classify loss: 0.068046] 
[Epoch 11/20] [Batch 198/274] [Batch classify loss: 0.057334] 
[Epoch 11/20] [Batch 199/274] [Batch classify loss: 0.039380] 
[Epoch 11/20] [Batch 200/274] [Batch classify loss: 0.088268] 
[Epoch 11/20] [Batch 201/274] [Batch classify loss: 0.082504] 
[Epoch 11/20] [Batch 202/274] [Batch classify loss: 0.072361] 
[Epoch 11/20] [Batch 203/274] [Batch classify loss: 0.055145] 
[Epoch 11/20] [Batch 204/274] [Batch classify loss: 0.060304] 
[Epoch 11/20] [Batch 205/274] [Batch classify loss: 0.056978] 
[Epoch 11/20] [Batch 206/274] [Batch classify loss: 0.125026] 
[Epoch 11/20] [Batch 207/274] [Batch classify loss: 0.054304] 
[Epoch 11/20] [Batch 208/274] [Batch classify loss: 0.061741] 
[Epoch 11/20] [Batch 209/274] [Batch classify loss: 0.140510] 
[Epoch 11/20] [Batch 210/274] [Batch classify loss: 0.035870] 
[Epoch 11/20] [Batch 211/274] [Batch classify loss: 0.096850] 
[Epoch 11/20] [Batch 212/274] [Batch classify loss: 0.066564] 
[Epoch 11/20] [Batch 213/274] [Batch classify loss: 0.036511] 
[Epoch 11/20] [Batch 214/274] [Batch classify loss: 0.089269] 
[Epoch 11/20] [Batch 215/274] [Batch classify loss: 0.037563] 
[Epoch 11/20] [Batch 216/274] [Batch classify loss: 0.096831] 
[Epoch 11/20] [Batch 217/274] [Batch classify loss: 0.087475] 
[Epoch 11/20] [Batch 218/274] [Batch classify loss: 0.090435] 
[Epoch 11/20] [Batch 219/274] [Batch classify loss: 0.043710] 
[Epoch 11/20] [Batch 220/274] [Batch classify loss: 0.082003] 
[Epoch 11/20] [Batch 221/274] [Batch classify loss: 0.060418] 
[Epoch 11/20] [Batch 222/274] [Batch classify loss: 0.043304] 
[Epoch 11/20] [Batch 223/274] [Batch classify loss: 0.058464] 
[Epoch 11/20] [Batch 224/274] [Batch classify loss: 0.050892] 
[Epoch 11/20] [Batch 225/274] [Batch classify loss: 0.096112] 
[Epoch 11/20] [Batch 226/274] [Batch classify loss: 0.098096] 
[Epoch 11/20] [Batch 227/274] [Batch classify loss: 0.077410] 
[Epoch 11/20] [Batch 228/274] [Batch classify loss: 0.076505] 
[Epoch 11/20] [Batch 229/274] [Batch classify loss: 0.050808] 
[Epoch 11/20] [Batch 230/274] [Batch classify loss: 0.115657] 
[Epoch 11/20] [Batch 231/274] [Batch classify loss: 0.055963] 
[Epoch 11/20] [Batch 232/274] [Batch classify loss: 0.116752] 
[Epoch 11/20] [Batch 233/274] [Batch classify loss: 0.066973] 
[Epoch 11/20] [Batch 234/274] [Batch classify loss: 0.053538] 
[Epoch 11/20] [Batch 235/274] [Batch classify loss: 0.083474] 
[Epoch 11/20] [Batch 236/274] [Batch classify loss: 0.087990] 
[Epoch 11/20] [Batch 237/274] [Batch classify loss: 0.063018] 
[Epoch 11/20] [Batch 238/274] [Batch classify loss: 0.058666] 
[Epoch 11/20] [Batch 239/274] [Batch classify loss: 0.084760] 
[Epoch 11/20] [Batch 240/274] [Batch classify loss: 0.051302] 
[Epoch 11/20] [Batch 241/274] [Batch classify loss: 0.036677] 
[Epoch 11/20] [Batch 242/274] [Batch classify loss: 0.067328] 
[Epoch 11/20] [Batch 243/274] [Batch classify loss: 0.063674] 
[Epoch 11/20] [Batch 244/274] [Batch classify loss: 0.046075] 
[Epoch 11/20] [Batch 245/274] [Batch classify loss: 0.050266] 
[Epoch 11/20] [Batch 246/274] [Batch classify loss: 0.078632] 
[Epoch 11/20] [Batch 247/274] [Batch classify loss: 0.065676] 
[Epoch 11/20] [Batch 248/274] [Batch classify loss: 0.042749] 
[Epoch 11/20] [Batch 249/274] [Batch classify loss: 0.079197] 
[Epoch 11/20] [Batch 250/274] [Batch classify loss: 0.107576] 
[Epoch 11/20] [Batch 251/274] [Batch classify loss: 0.050902] 
[Epoch 11/20] [Batch 252/274] [Batch classify loss: 0.056242] 
[Epoch 11/20] [Batch 253/274] [Batch classify loss: 0.106907] 
[Epoch 11/20] [Batch 254/274] [Batch classify loss: 0.039944] 
[Epoch 11/20] [Batch 255/274] [Batch classify loss: 0.074642] 
[Epoch 11/20] [Batch 256/274] [Batch classify loss: 0.061095] 
[Epoch 11/20] [Batch 257/274] [Batch classify loss: 0.030846] 
[Epoch 11/20] [Batch 258/274] [Batch classify loss: 0.031414] 
[Epoch 11/20] [Batch 259/274] [Batch classify loss: 0.083803] 
[Epoch 11/20] [Batch 260/274] [Batch classify loss: 0.075975] 
[Epoch 11/20] [Batch 261/274] [Batch classify loss: 0.099461] 
[Epoch 11/20] [Batch 262/274] [Batch classify loss: 0.054737] 
[Epoch 11/20] [Batch 263/274] [Batch classify loss: 0.036761] 
[Epoch 11/20] [Batch 264/274] [Batch classify loss: 0.068572] 
[Epoch 11/20] [Batch 265/274] [Batch classify loss: 0.058711] 
[Epoch 11/20] [Batch 266/274] [Batch classify loss: 0.036598] 
[Epoch 11/20] [Batch 267/274] [Batch classify loss: 0.056163] 
[Epoch 11/20] [Batch 268/274] [Batch classify loss: 0.084882] 
[Epoch 11/20] [Batch 269/274] [Batch classify loss: 0.090138] 
[Epoch 11/20] [Batch 270/274] [Batch classify loss: 0.091821] 
[Epoch 11/20] [Batch 271/274] [Batch classify loss: 0.110259] 
[Epoch 11/20] [Batch 272/274] [Batch classify loss: 0.047590] 
[Epoch 11/20] [Batch 273/274] [Batch classify loss: 0.037306] 
[Epoch 11/20] [Batch 274/274] [Batch classify loss: 0.076994] 
0011 epoch mmat trained classifier accuary on the clean testing examples:94.6297%
0011 epoch mmat trained classifier loss on the clean testing examples:0.2276
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3388%
mmat trained classifier loss on adversarial testset:4.518428802490234
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
11epoch learning rate:0.001
[Epoch 12/20] [Batch 1/274] [Batch classify loss: 1.336840] 
[Epoch 12/20] [Batch 2/274] [Batch classify loss: 0.385062] 
[Epoch 12/20] [Batch 3/274] [Batch classify loss: 0.264265] 
[Epoch 12/20] [Batch 4/274] [Batch classify loss: 0.133783] 
[Epoch 12/20] [Batch 5/274] [Batch classify loss: 0.145226] 
[Epoch 12/20] [Batch 6/274] [Batch classify loss: 0.164839] 
[Epoch 12/20] [Batch 7/274] [Batch classify loss: 0.090578] 
[Epoch 12/20] [Batch 8/274] [Batch classify loss: 0.086746] 
[Epoch 12/20] [Batch 9/274] [Batch classify loss: 0.175765] 
[Epoch 12/20] [Batch 10/274] [Batch classify loss: 0.085428] 
[Epoch 12/20] [Batch 11/274] [Batch classify loss: 0.119484] 
[Epoch 12/20] [Batch 12/274] [Batch classify loss: 0.084862] 
[Epoch 12/20] [Batch 13/274] [Batch classify loss: 0.152501] 
[Epoch 12/20] [Batch 14/274] [Batch classify loss: 0.093342] 
[Epoch 12/20] [Batch 15/274] [Batch classify loss: 0.078165] 
[Epoch 12/20] [Batch 16/274] [Batch classify loss: 0.089889] 
[Epoch 12/20] [Batch 17/274] [Batch classify loss: 0.129218] 
[Epoch 12/20] [Batch 18/274] [Batch classify loss: 0.099021] 
[Epoch 12/20] [Batch 19/274] [Batch classify loss: 0.176465] 
[Epoch 12/20] [Batch 20/274] [Batch classify loss: 0.117433] 
[Epoch 12/20] [Batch 21/274] [Batch classify loss: 0.193730] 
[Epoch 12/20] [Batch 22/274] [Batch classify loss: 0.164271] 
[Epoch 12/20] [Batch 23/274] [Batch classify loss: 0.174964] 
[Epoch 12/20] [Batch 24/274] [Batch classify loss: 0.183728] 
[Epoch 12/20] [Batch 25/274] [Batch classify loss: 0.157553] 
[Epoch 12/20] [Batch 26/274] [Batch classify loss: 0.161961] 
[Epoch 12/20] [Batch 27/274] [Batch classify loss: 0.092741] 
[Epoch 12/20] [Batch 28/274] [Batch classify loss: 0.169058] 
[Epoch 12/20] [Batch 29/274] [Batch classify loss: 0.246306] 
[Epoch 12/20] [Batch 30/274] [Batch classify loss: 0.157018] 
[Epoch 12/20] [Batch 31/274] [Batch classify loss: 0.124829] 
[Epoch 12/20] [Batch 32/274] [Batch classify loss: 0.159351] 
[Epoch 12/20] [Batch 33/274] [Batch classify loss: 0.151598] 
[Epoch 12/20] [Batch 34/274] [Batch classify loss: 0.169257] 
[Epoch 12/20] [Batch 35/274] [Batch classify loss: 0.085406] 
[Epoch 12/20] [Batch 36/274] [Batch classify loss: 0.186165] 
[Epoch 12/20] [Batch 37/274] [Batch classify loss: 0.109971] 
[Epoch 12/20] [Batch 38/274] [Batch classify loss: 0.133370] 
[Epoch 12/20] [Batch 39/274] [Batch classify loss: 0.173403] 
[Epoch 12/20] [Batch 40/274] [Batch classify loss: 0.137966] 
[Epoch 12/20] [Batch 41/274] [Batch classify loss: 0.098747] 
[Epoch 12/20] [Batch 42/274] [Batch classify loss: 0.062801] 
[Epoch 12/20] [Batch 43/274] [Batch classify loss: 0.146555] 
[Epoch 12/20] [Batch 44/274] [Batch classify loss: 0.158151] 
[Epoch 12/20] [Batch 45/274] [Batch classify loss: 0.091117] 
[Epoch 12/20] [Batch 46/274] [Batch classify loss: 0.138697] 
[Epoch 12/20] [Batch 47/274] [Batch classify loss: 0.146683] 
[Epoch 12/20] [Batch 48/274] [Batch classify loss: 0.080503] 
[Epoch 12/20] [Batch 49/274] [Batch classify loss: 0.221897] 
[Epoch 12/20] [Batch 50/274] [Batch classify loss: 0.132427] 
[Epoch 12/20] [Batch 51/274] [Batch classify loss: 0.104389] 
[Epoch 12/20] [Batch 52/274] [Batch classify loss: 0.143875] 
[Epoch 12/20] [Batch 53/274] [Batch classify loss: 0.101917] 
[Epoch 12/20] [Batch 54/274] [Batch classify loss: 0.145678] 
[Epoch 12/20] [Batch 55/274] [Batch classify loss: 0.199692] 
[Epoch 12/20] [Batch 56/274] [Batch classify loss: 0.057963] 
[Epoch 12/20] [Batch 57/274] [Batch classify loss: 0.179954] 
[Epoch 12/20] [Batch 58/274] [Batch classify loss: 0.061016] 
[Epoch 12/20] [Batch 59/274] [Batch classify loss: 0.146955] 
[Epoch 12/20] [Batch 60/274] [Batch classify loss: 0.157349] 
[Epoch 12/20] [Batch 61/274] [Batch classify loss: 0.089497] 
[Epoch 12/20] [Batch 62/274] [Batch classify loss: 0.156182] 
[Epoch 12/20] [Batch 63/274] [Batch classify loss: 0.141929] 
[Epoch 12/20] [Batch 64/274] [Batch classify loss: 0.093282] 
[Epoch 12/20] [Batch 65/274] [Batch classify loss: 0.120817] 
[Epoch 12/20] [Batch 66/274] [Batch classify loss: 0.146934] 
[Epoch 12/20] [Batch 67/274] [Batch classify loss: 0.127789] 
[Epoch 12/20] [Batch 68/274] [Batch classify loss: 0.129368] 
[Epoch 12/20] [Batch 69/274] [Batch classify loss: 0.132478] 
[Epoch 12/20] [Batch 70/274] [Batch classify loss: 0.098813] 
[Epoch 12/20] [Batch 71/274] [Batch classify loss: 0.094041] 
[Epoch 12/20] [Batch 72/274] [Batch classify loss: 0.087096] 
[Epoch 12/20] [Batch 73/274] [Batch classify loss: 0.146158] 
[Epoch 12/20] [Batch 74/274] [Batch classify loss: 0.092752] 
[Epoch 12/20] [Batch 75/274] [Batch classify loss: 0.074451] 
[Epoch 12/20] [Batch 76/274] [Batch classify loss: 0.166484] 
[Epoch 12/20] [Batch 77/274] [Batch classify loss: 0.094904] 
[Epoch 12/20] [Batch 78/274] [Batch classify loss: 0.103683] 
[Epoch 12/20] [Batch 79/274] [Batch classify loss: 0.137866] 
[Epoch 12/20] [Batch 80/274] [Batch classify loss: 0.155998] 
[Epoch 12/20] [Batch 81/274] [Batch classify loss: 0.146311] 
[Epoch 12/20] [Batch 82/274] [Batch classify loss: 0.071687] 
[Epoch 12/20] [Batch 83/274] [Batch classify loss: 0.129638] 
[Epoch 12/20] [Batch 84/274] [Batch classify loss: 0.171672] 
[Epoch 12/20] [Batch 85/274] [Batch classify loss: 0.079011] 
[Epoch 12/20] [Batch 86/274] [Batch classify loss: 0.164659] 
[Epoch 12/20] [Batch 87/274] [Batch classify loss: 0.130387] 
[Epoch 12/20] [Batch 88/274] [Batch classify loss: 0.096195] 
[Epoch 12/20] [Batch 89/274] [Batch classify loss: 0.132990] 
[Epoch 12/20] [Batch 90/274] [Batch classify loss: 0.185739] 
[Epoch 12/20] [Batch 91/274] [Batch classify loss: 0.130811] 
[Epoch 12/20] [Batch 92/274] [Batch classify loss: 0.099696] 
[Epoch 12/20] [Batch 93/274] [Batch classify loss: 0.143577] 
[Epoch 12/20] [Batch 94/274] [Batch classify loss: 0.140265] 
[Epoch 12/20] [Batch 95/274] [Batch classify loss: 0.153824] 
[Epoch 12/20] [Batch 96/274] [Batch classify loss: 0.138842] 
[Epoch 12/20] [Batch 97/274] [Batch classify loss: 0.118045] 
[Epoch 12/20] [Batch 98/274] [Batch classify loss: 0.083174] 
[Epoch 12/20] [Batch 99/274] [Batch classify loss: 0.108048] 
[Epoch 12/20] [Batch 100/274] [Batch classify loss: 0.162365] 
[Epoch 12/20] [Batch 101/274] [Batch classify loss: 0.068983] 
[Epoch 12/20] [Batch 102/274] [Batch classify loss: 0.223542] 
[Epoch 12/20] [Batch 103/274] [Batch classify loss: 0.065905] 
[Epoch 12/20] [Batch 104/274] [Batch classify loss: 0.115863] 
[Epoch 12/20] [Batch 105/274] [Batch classify loss: 0.066850] 
[Epoch 12/20] [Batch 106/274] [Batch classify loss: 0.160365] 
[Epoch 12/20] [Batch 107/274] [Batch classify loss: 0.146079] 
[Epoch 12/20] [Batch 108/274] [Batch classify loss: 0.094868] 
[Epoch 12/20] [Batch 109/274] [Batch classify loss: 0.210281] 
[Epoch 12/20] [Batch 110/274] [Batch classify loss: 0.108557] 
[Epoch 12/20] [Batch 111/274] [Batch classify loss: 0.111273] 
[Epoch 12/20] [Batch 112/274] [Batch classify loss: 0.173962] 
[Epoch 12/20] [Batch 113/274] [Batch classify loss: 0.071878] 
[Epoch 12/20] [Batch 114/274] [Batch classify loss: 0.118860] 
[Epoch 12/20] [Batch 115/274] [Batch classify loss: 0.135218] 
[Epoch 12/20] [Batch 116/274] [Batch classify loss: 0.133372] 
[Epoch 12/20] [Batch 117/274] [Batch classify loss: 0.131401] 
[Epoch 12/20] [Batch 118/274] [Batch classify loss: 0.104795] 
[Epoch 12/20] [Batch 119/274] [Batch classify loss: 0.084374] 
[Epoch 12/20] [Batch 120/274] [Batch classify loss: 0.044159] 
[Epoch 12/20] [Batch 121/274] [Batch classify loss: 0.204253] 
[Epoch 12/20] [Batch 122/274] [Batch classify loss: 0.135478] 
[Epoch 12/20] [Batch 123/274] [Batch classify loss: 0.150697] 
[Epoch 12/20] [Batch 124/274] [Batch classify loss: 0.070873] 
[Epoch 12/20] [Batch 125/274] [Batch classify loss: 0.120801] 
[Epoch 12/20] [Batch 126/274] [Batch classify loss: 0.195305] 
[Epoch 12/20] [Batch 127/274] [Batch classify loss: 0.068652] 
[Epoch 12/20] [Batch 128/274] [Batch classify loss: 0.214460] 
[Epoch 12/20] [Batch 129/274] [Batch classify loss: 0.086840] 
[Epoch 12/20] [Batch 130/274] [Batch classify loss: 0.174706] 
[Epoch 12/20] [Batch 131/274] [Batch classify loss: 0.136299] 
[Epoch 12/20] [Batch 132/274] [Batch classify loss: 0.096177] 
[Epoch 12/20] [Batch 133/274] [Batch classify loss: 0.059525] 
[Epoch 12/20] [Batch 134/274] [Batch classify loss: 0.071549] 
[Epoch 12/20] [Batch 135/274] [Batch classify loss: 0.090894] 
[Epoch 12/20] [Batch 136/274] [Batch classify loss: 0.139051] 
[Epoch 12/20] [Batch 137/274] [Batch classify loss: 0.077798] 
[Epoch 12/20] [Batch 138/274] [Batch classify loss: 0.098667] 
[Epoch 12/20] [Batch 139/274] [Batch classify loss: 0.101711] 
[Epoch 12/20] [Batch 140/274] [Batch classify loss: 0.113141] 
[Epoch 12/20] [Batch 141/274] [Batch classify loss: 0.119450] 
[Epoch 12/20] [Batch 142/274] [Batch classify loss: 0.126547] 
[Epoch 12/20] [Batch 143/274] [Batch classify loss: 0.129068] 
[Epoch 12/20] [Batch 144/274] [Batch classify loss: 0.227495] 
[Epoch 12/20] [Batch 145/274] [Batch classify loss: 0.099918] 
[Epoch 12/20] [Batch 146/274] [Batch classify loss: 0.093298] 
[Epoch 12/20] [Batch 147/274] [Batch classify loss: 0.189804] 
[Epoch 12/20] [Batch 148/274] [Batch classify loss: 0.191572] 
[Epoch 12/20] [Batch 149/274] [Batch classify loss: 0.059576] 
[Epoch 12/20] [Batch 150/274] [Batch classify loss: 0.095548] 
[Epoch 12/20] [Batch 151/274] [Batch classify loss: 0.129207] 
[Epoch 12/20] [Batch 152/274] [Batch classify loss: 0.157350] 
[Epoch 12/20] [Batch 153/274] [Batch classify loss: 0.105631] 
[Epoch 12/20] [Batch 154/274] [Batch classify loss: 0.103656] 
[Epoch 12/20] [Batch 155/274] [Batch classify loss: 0.240286] 
[Epoch 12/20] [Batch 156/274] [Batch classify loss: 0.047995] 
[Epoch 12/20] [Batch 157/274] [Batch classify loss: 0.127559] 
[Epoch 12/20] [Batch 158/274] [Batch classify loss: 0.091024] 
[Epoch 12/20] [Batch 159/274] [Batch classify loss: 0.063087] 
[Epoch 12/20] [Batch 160/274] [Batch classify loss: 0.078402] 
[Epoch 12/20] [Batch 161/274] [Batch classify loss: 0.079104] 
[Epoch 12/20] [Batch 162/274] [Batch classify loss: 0.148419] 
[Epoch 12/20] [Batch 163/274] [Batch classify loss: 0.086593] 
[Epoch 12/20] [Batch 164/274] [Batch classify loss: 0.110281] 
[Epoch 12/20] [Batch 165/274] [Batch classify loss: 0.211618] 
[Epoch 12/20] [Batch 166/274] [Batch classify loss: 0.116880] 
[Epoch 12/20] [Batch 167/274] [Batch classify loss: 0.097276] 
[Epoch 12/20] [Batch 168/274] [Batch classify loss: 0.173911] 
[Epoch 12/20] [Batch 169/274] [Batch classify loss: 0.127954] 
[Epoch 12/20] [Batch 170/274] [Batch classify loss: 0.077552] 
[Epoch 12/20] [Batch 171/274] [Batch classify loss: 0.201770] 
[Epoch 12/20] [Batch 172/274] [Batch classify loss: 0.101074] 
[Epoch 12/20] [Batch 173/274] [Batch classify loss: 0.111973] 
[Epoch 12/20] [Batch 174/274] [Batch classify loss: 0.051014] 
[Epoch 12/20] [Batch 175/274] [Batch classify loss: 0.097966] 
[Epoch 12/20] [Batch 176/274] [Batch classify loss: 0.086428] 
[Epoch 12/20] [Batch 177/274] [Batch classify loss: 0.119077] 
[Epoch 12/20] [Batch 178/274] [Batch classify loss: 0.089309] 
[Epoch 12/20] [Batch 179/274] [Batch classify loss: 0.213438] 
[Epoch 12/20] [Batch 180/274] [Batch classify loss: 0.108644] 
[Epoch 12/20] [Batch 181/274] [Batch classify loss: 0.056058] 
[Epoch 12/20] [Batch 182/274] [Batch classify loss: 0.073656] 
[Epoch 12/20] [Batch 183/274] [Batch classify loss: 0.078469] 
[Epoch 12/20] [Batch 184/274] [Batch classify loss: 0.091635] 
[Epoch 12/20] [Batch 185/274] [Batch classify loss: 0.083047] 
[Epoch 12/20] [Batch 186/274] [Batch classify loss: 0.099787] 
[Epoch 12/20] [Batch 187/274] [Batch classify loss: 0.097410] 
[Epoch 12/20] [Batch 188/274] [Batch classify loss: 0.034701] 
[Epoch 12/20] [Batch 189/274] [Batch classify loss: 0.055103] 
[Epoch 12/20] [Batch 190/274] [Batch classify loss: 0.074586] 
[Epoch 12/20] [Batch 191/274] [Batch classify loss: 0.106466] 
[Epoch 12/20] [Batch 192/274] [Batch classify loss: 0.108284] 
[Epoch 12/20] [Batch 193/274] [Batch classify loss: 0.142055] 
[Epoch 12/20] [Batch 194/274] [Batch classify loss: 0.091721] 
[Epoch 12/20] [Batch 195/274] [Batch classify loss: 0.100826] 
[Epoch 12/20] [Batch 196/274] [Batch classify loss: 0.179260] 
[Epoch 12/20] [Batch 197/274] [Batch classify loss: 0.074580] 
[Epoch 12/20] [Batch 198/274] [Batch classify loss: 0.087854] 
[Epoch 12/20] [Batch 199/274] [Batch classify loss: 0.151595] 
[Epoch 12/20] [Batch 200/274] [Batch classify loss: 0.083419] 
[Epoch 12/20] [Batch 201/274] [Batch classify loss: 0.121869] 
[Epoch 12/20] [Batch 202/274] [Batch classify loss: 0.102808] 
[Epoch 12/20] [Batch 203/274] [Batch classify loss: 0.064746] 
[Epoch 12/20] [Batch 204/274] [Batch classify loss: 0.057788] 
[Epoch 12/20] [Batch 205/274] [Batch classify loss: 0.150433] 
[Epoch 12/20] [Batch 206/274] [Batch classify loss: 0.069329] 
[Epoch 12/20] [Batch 207/274] [Batch classify loss: 0.113157] 
[Epoch 12/20] [Batch 208/274] [Batch classify loss: 0.136681] 
[Epoch 12/20] [Batch 209/274] [Batch classify loss: 0.113521] 
[Epoch 12/20] [Batch 210/274] [Batch classify loss: 0.114693] 
[Epoch 12/20] [Batch 211/274] [Batch classify loss: 0.044295] 
[Epoch 12/20] [Batch 212/274] [Batch classify loss: 0.102751] 
[Epoch 12/20] [Batch 213/274] [Batch classify loss: 0.088592] 
[Epoch 12/20] [Batch 214/274] [Batch classify loss: 0.084106] 
[Epoch 12/20] [Batch 215/274] [Batch classify loss: 0.099381] 
[Epoch 12/20] [Batch 216/274] [Batch classify loss: 0.087164] 
[Epoch 12/20] [Batch 217/274] [Batch classify loss: 0.043559] 
[Epoch 12/20] [Batch 218/274] [Batch classify loss: 0.133351] 
[Epoch 12/20] [Batch 219/274] [Batch classify loss: 0.105480] 
[Epoch 12/20] [Batch 220/274] [Batch classify loss: 0.107730] 
[Epoch 12/20] [Batch 221/274] [Batch classify loss: 0.111178] 
[Epoch 12/20] [Batch 222/274] [Batch classify loss: 0.140639] 
[Epoch 12/20] [Batch 223/274] [Batch classify loss: 0.087423] 
[Epoch 12/20] [Batch 224/274] [Batch classify loss: 0.093757] 
[Epoch 12/20] [Batch 225/274] [Batch classify loss: 0.077311] 
[Epoch 12/20] [Batch 226/274] [Batch classify loss: 0.070941] 
[Epoch 12/20] [Batch 227/274] [Batch classify loss: 0.132805] 
[Epoch 12/20] [Batch 228/274] [Batch classify loss: 0.167485] 
[Epoch 12/20] [Batch 229/274] [Batch classify loss: 0.084518] 
[Epoch 12/20] [Batch 230/274] [Batch classify loss: 0.079420] 
[Epoch 12/20] [Batch 231/274] [Batch classify loss: 0.152722] 
[Epoch 12/20] [Batch 232/274] [Batch classify loss: 0.060566] 
[Epoch 12/20] [Batch 233/274] [Batch classify loss: 0.061093] 
[Epoch 12/20] [Batch 234/274] [Batch classify loss: 0.122190] 
[Epoch 12/20] [Batch 235/274] [Batch classify loss: 0.124447] 
[Epoch 12/20] [Batch 236/274] [Batch classify loss: 0.075922] 
[Epoch 12/20] [Batch 237/274] [Batch classify loss: 0.131968] 
[Epoch 12/20] [Batch 238/274] [Batch classify loss: 0.088377] 
[Epoch 12/20] [Batch 239/274] [Batch classify loss: 0.047263] 
[Epoch 12/20] [Batch 240/274] [Batch classify loss: 0.045538] 
[Epoch 12/20] [Batch 241/274] [Batch classify loss: 0.072162] 
[Epoch 12/20] [Batch 242/274] [Batch classify loss: 0.066410] 
[Epoch 12/20] [Batch 243/274] [Batch classify loss: 0.108607] 
[Epoch 12/20] [Batch 244/274] [Batch classify loss: 0.037481] 
[Epoch 12/20] [Batch 245/274] [Batch classify loss: 0.131069] 
[Epoch 12/20] [Batch 246/274] [Batch classify loss: 0.087629] 
[Epoch 12/20] [Batch 247/274] [Batch classify loss: 0.040509] 
[Epoch 12/20] [Batch 248/274] [Batch classify loss: 0.073187] 
[Epoch 12/20] [Batch 249/274] [Batch classify loss: 0.080144] 
[Epoch 12/20] [Batch 250/274] [Batch classify loss: 0.058325] 
[Epoch 12/20] [Batch 251/274] [Batch classify loss: 0.065950] 
[Epoch 12/20] [Batch 252/274] [Batch classify loss: 0.065628] 
[Epoch 12/20] [Batch 253/274] [Batch classify loss: 0.124144] 
[Epoch 12/20] [Batch 254/274] [Batch classify loss: 0.087497] 
[Epoch 12/20] [Batch 255/274] [Batch classify loss: 0.060662] 
[Epoch 12/20] [Batch 256/274] [Batch classify loss: 0.118770] 
[Epoch 12/20] [Batch 257/274] [Batch classify loss: 0.078802] 
[Epoch 12/20] [Batch 258/274] [Batch classify loss: 0.062959] 
[Epoch 12/20] [Batch 259/274] [Batch classify loss: 0.060411] 
[Epoch 12/20] [Batch 260/274] [Batch classify loss: 0.113242] 
[Epoch 12/20] [Batch 261/274] [Batch classify loss: 0.115175] 
[Epoch 12/20] [Batch 262/274] [Batch classify loss: 0.079038] 
[Epoch 12/20] [Batch 263/274] [Batch classify loss: 0.071443] 
[Epoch 12/20] [Batch 264/274] [Batch classify loss: 0.052466] 
[Epoch 12/20] [Batch 265/274] [Batch classify loss: 0.092365] 
[Epoch 12/20] [Batch 266/274] [Batch classify loss: 0.098851] 
[Epoch 12/20] [Batch 267/274] [Batch classify loss: 0.098560] 
[Epoch 12/20] [Batch 268/274] [Batch classify loss: 0.120840] 
[Epoch 12/20] [Batch 269/274] [Batch classify loss: 0.064256] 
[Epoch 12/20] [Batch 270/274] [Batch classify loss: 0.112674] 
[Epoch 12/20] [Batch 271/274] [Batch classify loss: 0.109278] 
[Epoch 12/20] [Batch 272/274] [Batch classify loss: 0.071856] 
[Epoch 12/20] [Batch 273/274] [Batch classify loss: 0.094867] 
[Epoch 12/20] [Batch 274/274] [Batch classify loss: 0.081284] 
0012 epoch mmat trained classifier accuary on the clean testing examples:94.7488%
0012 epoch mmat trained classifier loss on the clean testing examples:0.2237
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2389%
mmat trained classifier loss on adversarial testset:4.5273518562316895
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
12epoch learning rate:0.001
[Epoch 13/20] [Batch 1/274] [Batch classify loss: 2.117997] 
[Epoch 13/20] [Batch 2/274] [Batch classify loss: 1.102694] 
[Epoch 13/20] [Batch 3/274] [Batch classify loss: 0.483581] 
[Epoch 13/20] [Batch 4/274] [Batch classify loss: 0.471429] 
[Epoch 13/20] [Batch 5/274] [Batch classify loss: 0.336541] 
[Epoch 13/20] [Batch 6/274] [Batch classify loss: 0.224748] 
[Epoch 13/20] [Batch 7/274] [Batch classify loss: 0.206415] 
[Epoch 13/20] [Batch 8/274] [Batch classify loss: 0.209468] 
[Epoch 13/20] [Batch 9/274] [Batch classify loss: 0.155262] 
[Epoch 13/20] [Batch 10/274] [Batch classify loss: 0.125848] 
[Epoch 13/20] [Batch 11/274] [Batch classify loss: 0.135286] 
[Epoch 13/20] [Batch 12/274] [Batch classify loss: 0.193907] 
[Epoch 13/20] [Batch 13/274] [Batch classify loss: 0.094428] 
[Epoch 13/20] [Batch 14/274] [Batch classify loss: 0.086993] 
[Epoch 13/20] [Batch 15/274] [Batch classify loss: 0.092875] 
[Epoch 13/20] [Batch 16/274] [Batch classify loss: 0.085106] 
[Epoch 13/20] [Batch 17/274] [Batch classify loss: 0.107692] 
[Epoch 13/20] [Batch 18/274] [Batch classify loss: 0.125390] 
[Epoch 13/20] [Batch 19/274] [Batch classify loss: 0.180001] 
[Epoch 13/20] [Batch 20/274] [Batch classify loss: 0.069628] 
[Epoch 13/20] [Batch 21/274] [Batch classify loss: 0.111957] 
[Epoch 13/20] [Batch 22/274] [Batch classify loss: 0.059786] 
[Epoch 13/20] [Batch 23/274] [Batch classify loss: 0.052211] 
[Epoch 13/20] [Batch 24/274] [Batch classify loss: 0.120680] 
[Epoch 13/20] [Batch 25/274] [Batch classify loss: 0.108079] 
[Epoch 13/20] [Batch 26/274] [Batch classify loss: 0.075772] 
[Epoch 13/20] [Batch 27/274] [Batch classify loss: 0.139978] 
[Epoch 13/20] [Batch 28/274] [Batch classify loss: 0.068719] 
[Epoch 13/20] [Batch 29/274] [Batch classify loss: 0.100499] 
[Epoch 13/20] [Batch 30/274] [Batch classify loss: 0.087366] 
[Epoch 13/20] [Batch 31/274] [Batch classify loss: 0.160648] 
[Epoch 13/20] [Batch 32/274] [Batch classify loss: 0.101945] 
[Epoch 13/20] [Batch 33/274] [Batch classify loss: 0.102668] 
[Epoch 13/20] [Batch 34/274] [Batch classify loss: 0.108557] 
[Epoch 13/20] [Batch 35/274] [Batch classify loss: 0.108002] 
[Epoch 13/20] [Batch 36/274] [Batch classify loss: 0.108175] 
[Epoch 13/20] [Batch 37/274] [Batch classify loss: 0.092142] 
[Epoch 13/20] [Batch 38/274] [Batch classify loss: 0.154921] 
[Epoch 13/20] [Batch 39/274] [Batch classify loss: 0.163985] 
[Epoch 13/20] [Batch 40/274] [Batch classify loss: 0.078254] 
[Epoch 13/20] [Batch 41/274] [Batch classify loss: 0.096484] 
[Epoch 13/20] [Batch 42/274] [Batch classify loss: 0.084760] 
[Epoch 13/20] [Batch 43/274] [Batch classify loss: 0.114298] 
[Epoch 13/20] [Batch 44/274] [Batch classify loss: 0.077132] 
[Epoch 13/20] [Batch 45/274] [Batch classify loss: 0.137717] 
[Epoch 13/20] [Batch 46/274] [Batch classify loss: 0.158736] 
[Epoch 13/20] [Batch 47/274] [Batch classify loss: 0.118218] 
[Epoch 13/20] [Batch 48/274] [Batch classify loss: 0.082372] 
[Epoch 13/20] [Batch 49/274] [Batch classify loss: 0.106771] 
[Epoch 13/20] [Batch 50/274] [Batch classify loss: 0.076723] 
[Epoch 13/20] [Batch 51/274] [Batch classify loss: 0.135121] 
[Epoch 13/20] [Batch 52/274] [Batch classify loss: 0.088429] 
[Epoch 13/20] [Batch 53/274] [Batch classify loss: 0.085377] 
[Epoch 13/20] [Batch 54/274] [Batch classify loss: 0.115394] 
[Epoch 13/20] [Batch 55/274] [Batch classify loss: 0.083065] 
[Epoch 13/20] [Batch 56/274] [Batch classify loss: 0.162164] 
[Epoch 13/20] [Batch 57/274] [Batch classify loss: 0.067103] 
[Epoch 13/20] [Batch 58/274] [Batch classify loss: 0.128877] 
[Epoch 13/20] [Batch 59/274] [Batch classify loss: 0.072442] 
[Epoch 13/20] [Batch 60/274] [Batch classify loss: 0.117267] 
[Epoch 13/20] [Batch 61/274] [Batch classify loss: 0.111593] 
[Epoch 13/20] [Batch 62/274] [Batch classify loss: 0.075766] 
[Epoch 13/20] [Batch 63/274] [Batch classify loss: 0.136627] 
[Epoch 13/20] [Batch 64/274] [Batch classify loss: 0.132613] 
[Epoch 13/20] [Batch 65/274] [Batch classify loss: 0.134174] 
[Epoch 13/20] [Batch 66/274] [Batch classify loss: 0.115725] 
[Epoch 13/20] [Batch 67/274] [Batch classify loss: 0.082773] 
[Epoch 13/20] [Batch 68/274] [Batch classify loss: 0.086231] 
[Epoch 13/20] [Batch 69/274] [Batch classify loss: 0.119711] 
[Epoch 13/20] [Batch 70/274] [Batch classify loss: 0.097531] 
[Epoch 13/20] [Batch 71/274] [Batch classify loss: 0.120110] 
[Epoch 13/20] [Batch 72/274] [Batch classify loss: 0.120197] 
[Epoch 13/20] [Batch 73/274] [Batch classify loss: 0.115306] 
[Epoch 13/20] [Batch 74/274] [Batch classify loss: 0.129597] 
[Epoch 13/20] [Batch 75/274] [Batch classify loss: 0.069557] 
[Epoch 13/20] [Batch 76/274] [Batch classify loss: 0.176949] 
[Epoch 13/20] [Batch 77/274] [Batch classify loss: 0.105321] 
[Epoch 13/20] [Batch 78/274] [Batch classify loss: 0.165586] 
[Epoch 13/20] [Batch 79/274] [Batch classify loss: 0.182236] 
[Epoch 13/20] [Batch 80/274] [Batch classify loss: 0.162995] 
[Epoch 13/20] [Batch 81/274] [Batch classify loss: 0.109078] 
[Epoch 13/20] [Batch 82/274] [Batch classify loss: 0.123433] 
[Epoch 13/20] [Batch 83/274] [Batch classify loss: 0.160015] 
[Epoch 13/20] [Batch 84/274] [Batch classify loss: 0.111549] 
[Epoch 13/20] [Batch 85/274] [Batch classify loss: 0.160105] 
[Epoch 13/20] [Batch 86/274] [Batch classify loss: 0.078048] 
[Epoch 13/20] [Batch 87/274] [Batch classify loss: 0.174153] 
[Epoch 13/20] [Batch 88/274] [Batch classify loss: 0.190097] 
[Epoch 13/20] [Batch 89/274] [Batch classify loss: 0.082630] 
[Epoch 13/20] [Batch 90/274] [Batch classify loss: 0.097053] 
[Epoch 13/20] [Batch 91/274] [Batch classify loss: 0.124859] 
[Epoch 13/20] [Batch 92/274] [Batch classify loss: 0.103199] 
[Epoch 13/20] [Batch 93/274] [Batch classify loss: 0.254522] 
[Epoch 13/20] [Batch 94/274] [Batch classify loss: 0.068347] 
[Epoch 13/20] [Batch 95/274] [Batch classify loss: 0.122213] 
[Epoch 13/20] [Batch 96/274] [Batch classify loss: 0.115681] 
[Epoch 13/20] [Batch 97/274] [Batch classify loss: 0.059186] 
[Epoch 13/20] [Batch 98/274] [Batch classify loss: 0.116629] 
[Epoch 13/20] [Batch 99/274] [Batch classify loss: 0.053815] 
[Epoch 13/20] [Batch 100/274] [Batch classify loss: 0.141691] 
[Epoch 13/20] [Batch 101/274] [Batch classify loss: 0.153761] 
[Epoch 13/20] [Batch 102/274] [Batch classify loss: 0.115666] 
[Epoch 13/20] [Batch 103/274] [Batch classify loss: 0.066470] 
[Epoch 13/20] [Batch 104/274] [Batch classify loss: 0.143730] 
[Epoch 13/20] [Batch 105/274] [Batch classify loss: 0.058535] 
[Epoch 13/20] [Batch 106/274] [Batch classify loss: 0.096975] 
[Epoch 13/20] [Batch 107/274] [Batch classify loss: 0.167711] 
[Epoch 13/20] [Batch 108/274] [Batch classify loss: 0.132863] 
[Epoch 13/20] [Batch 109/274] [Batch classify loss: 0.083547] 
[Epoch 13/20] [Batch 110/274] [Batch classify loss: 0.166707] 
[Epoch 13/20] [Batch 111/274] [Batch classify loss: 0.140797] 
[Epoch 13/20] [Batch 112/274] [Batch classify loss: 0.088073] 
[Epoch 13/20] [Batch 113/274] [Batch classify loss: 0.123465] 
[Epoch 13/20] [Batch 114/274] [Batch classify loss: 0.077286] 
[Epoch 13/20] [Batch 115/274] [Batch classify loss: 0.077861] 
[Epoch 13/20] [Batch 116/274] [Batch classify loss: 0.078847] 
[Epoch 13/20] [Batch 117/274] [Batch classify loss: 0.090390] 
[Epoch 13/20] [Batch 118/274] [Batch classify loss: 0.060776] 
[Epoch 13/20] [Batch 119/274] [Batch classify loss: 0.108068] 
[Epoch 13/20] [Batch 120/274] [Batch classify loss: 0.066050] 
[Epoch 13/20] [Batch 121/274] [Batch classify loss: 0.105067] 
[Epoch 13/20] [Batch 122/274] [Batch classify loss: 0.087273] 
[Epoch 13/20] [Batch 123/274] [Batch classify loss: 0.056005] 
[Epoch 13/20] [Batch 124/274] [Batch classify loss: 0.168891] 
[Epoch 13/20] [Batch 125/274] [Batch classify loss: 0.109889] 
[Epoch 13/20] [Batch 126/274] [Batch classify loss: 0.204313] 
[Epoch 13/20] [Batch 127/274] [Batch classify loss: 0.097875] 
[Epoch 13/20] [Batch 128/274] [Batch classify loss: 0.105613] 
[Epoch 13/20] [Batch 129/274] [Batch classify loss: 0.097699] 
[Epoch 13/20] [Batch 130/274] [Batch classify loss: 0.098647] 
[Epoch 13/20] [Batch 131/274] [Batch classify loss: 0.149146] 
[Epoch 13/20] [Batch 132/274] [Batch classify loss: 0.119500] 
[Epoch 13/20] [Batch 133/274] [Batch classify loss: 0.083121] 
[Epoch 13/20] [Batch 134/274] [Batch classify loss: 0.183195] 
[Epoch 13/20] [Batch 135/274] [Batch classify loss: 0.072135] 
[Epoch 13/20] [Batch 136/274] [Batch classify loss: 0.085043] 
[Epoch 13/20] [Batch 137/274] [Batch classify loss: 0.101103] 
[Epoch 13/20] [Batch 138/274] [Batch classify loss: 0.110263] 
[Epoch 13/20] [Batch 139/274] [Batch classify loss: 0.150874] 
[Epoch 13/20] [Batch 140/274] [Batch classify loss: 0.142190] 
[Epoch 13/20] [Batch 141/274] [Batch classify loss: 0.095221] 
[Epoch 13/20] [Batch 142/274] [Batch classify loss: 0.195939] 
[Epoch 13/20] [Batch 143/274] [Batch classify loss: 0.067103] 
[Epoch 13/20] [Batch 144/274] [Batch classify loss: 0.093018] 
[Epoch 13/20] [Batch 145/274] [Batch classify loss: 0.083209] 
[Epoch 13/20] [Batch 146/274] [Batch classify loss: 0.115773] 
[Epoch 13/20] [Batch 147/274] [Batch classify loss: 0.095004] 
[Epoch 13/20] [Batch 148/274] [Batch classify loss: 0.238613] 
[Epoch 13/20] [Batch 149/274] [Batch classify loss: 0.097342] 
[Epoch 13/20] [Batch 150/274] [Batch classify loss: 0.104476] 
[Epoch 13/20] [Batch 151/274] [Batch classify loss: 0.084118] 
[Epoch 13/20] [Batch 152/274] [Batch classify loss: 0.153011] 
[Epoch 13/20] [Batch 153/274] [Batch classify loss: 0.131933] 
[Epoch 13/20] [Batch 154/274] [Batch classify loss: 0.172880] 
[Epoch 13/20] [Batch 155/274] [Batch classify loss: 0.117758] 
[Epoch 13/20] [Batch 156/274] [Batch classify loss: 0.143616] 
[Epoch 13/20] [Batch 157/274] [Batch classify loss: 0.094665] 
[Epoch 13/20] [Batch 158/274] [Batch classify loss: 0.106375] 
[Epoch 13/20] [Batch 159/274] [Batch classify loss: 0.181396] 
[Epoch 13/20] [Batch 160/274] [Batch classify loss: 0.117086] 
[Epoch 13/20] [Batch 161/274] [Batch classify loss: 0.117749] 
[Epoch 13/20] [Batch 162/274] [Batch classify loss: 0.098949] 
[Epoch 13/20] [Batch 163/274] [Batch classify loss: 0.180259] 
[Epoch 13/20] [Batch 164/274] [Batch classify loss: 0.105411] 
[Epoch 13/20] [Batch 165/274] [Batch classify loss: 0.098693] 
[Epoch 13/20] [Batch 166/274] [Batch classify loss: 0.091007] 
[Epoch 13/20] [Batch 167/274] [Batch classify loss: 0.091674] 
[Epoch 13/20] [Batch 168/274] [Batch classify loss: 0.188111] 
[Epoch 13/20] [Batch 169/274] [Batch classify loss: 0.181567] 
[Epoch 13/20] [Batch 170/274] [Batch classify loss: 0.155824] 
[Epoch 13/20] [Batch 171/274] [Batch classify loss: 0.094522] 
[Epoch 13/20] [Batch 172/274] [Batch classify loss: 0.098651] 
[Epoch 13/20] [Batch 173/274] [Batch classify loss: 0.082059] 
[Epoch 13/20] [Batch 174/274] [Batch classify loss: 0.067698] 
[Epoch 13/20] [Batch 175/274] [Batch classify loss: 0.052887] 
[Epoch 13/20] [Batch 176/274] [Batch classify loss: 0.142381] 
[Epoch 13/20] [Batch 177/274] [Batch classify loss: 0.058634] 
[Epoch 13/20] [Batch 178/274] [Batch classify loss: 0.101551] 
[Epoch 13/20] [Batch 179/274] [Batch classify loss: 0.160045] 
[Epoch 13/20] [Batch 180/274] [Batch classify loss: 0.122545] 
[Epoch 13/20] [Batch 181/274] [Batch classify loss: 0.070850] 
[Epoch 13/20] [Batch 182/274] [Batch classify loss: 0.113749] 
[Epoch 13/20] [Batch 183/274] [Batch classify loss: 0.078766] 
[Epoch 13/20] [Batch 184/274] [Batch classify loss: 0.139826] 
[Epoch 13/20] [Batch 185/274] [Batch classify loss: 0.090538] 
[Epoch 13/20] [Batch 186/274] [Batch classify loss: 0.107637] 
[Epoch 13/20] [Batch 187/274] [Batch classify loss: 0.142799] 
[Epoch 13/20] [Batch 188/274] [Batch classify loss: 0.086578] 
[Epoch 13/20] [Batch 189/274] [Batch classify loss: 0.070061] 
[Epoch 13/20] [Batch 190/274] [Batch classify loss: 0.163614] 
[Epoch 13/20] [Batch 191/274] [Batch classify loss: 0.158122] 
[Epoch 13/20] [Batch 192/274] [Batch classify loss: 0.073276] 
[Epoch 13/20] [Batch 193/274] [Batch classify loss: 0.064531] 
[Epoch 13/20] [Batch 194/274] [Batch classify loss: 0.118257] 
[Epoch 13/20] [Batch 195/274] [Batch classify loss: 0.129530] 
[Epoch 13/20] [Batch 196/274] [Batch classify loss: 0.105935] 
[Epoch 13/20] [Batch 197/274] [Batch classify loss: 0.124641] 
[Epoch 13/20] [Batch 198/274] [Batch classify loss: 0.136732] 
[Epoch 13/20] [Batch 199/274] [Batch classify loss: 0.132173] 
[Epoch 13/20] [Batch 200/274] [Batch classify loss: 0.111551] 
[Epoch 13/20] [Batch 201/274] [Batch classify loss: 0.044679] 
[Epoch 13/20] [Batch 202/274] [Batch classify loss: 0.071473] 
[Epoch 13/20] [Batch 203/274] [Batch classify loss: 0.112580] 
[Epoch 13/20] [Batch 204/274] [Batch classify loss: 0.103017] 
[Epoch 13/20] [Batch 205/274] [Batch classify loss: 0.139071] 
[Epoch 13/20] [Batch 206/274] [Batch classify loss: 0.163632] 
[Epoch 13/20] [Batch 207/274] [Batch classify loss: 0.130998] 
[Epoch 13/20] [Batch 208/274] [Batch classify loss: 0.067732] 
[Epoch 13/20] [Batch 209/274] [Batch classify loss: 0.145861] 
[Epoch 13/20] [Batch 210/274] [Batch classify loss: 0.107357] 
[Epoch 13/20] [Batch 211/274] [Batch classify loss: 0.066330] 
[Epoch 13/20] [Batch 212/274] [Batch classify loss: 0.154698] 
[Epoch 13/20] [Batch 213/274] [Batch classify loss: 0.066038] 
[Epoch 13/20] [Batch 214/274] [Batch classify loss: 0.165191] 
[Epoch 13/20] [Batch 215/274] [Batch classify loss: 0.120363] 
[Epoch 13/20] [Batch 216/274] [Batch classify loss: 0.075983] 
[Epoch 13/20] [Batch 217/274] [Batch classify loss: 0.136683] 
[Epoch 13/20] [Batch 218/274] [Batch classify loss: 0.070633] 
[Epoch 13/20] [Batch 219/274] [Batch classify loss: 0.149925] 
[Epoch 13/20] [Batch 220/274] [Batch classify loss: 0.117245] 
[Epoch 13/20] [Batch 221/274] [Batch classify loss: 0.205266] 
[Epoch 13/20] [Batch 222/274] [Batch classify loss: 0.075815] 
[Epoch 13/20] [Batch 223/274] [Batch classify loss: 0.142676] 
[Epoch 13/20] [Batch 224/274] [Batch classify loss: 0.077783] 
[Epoch 13/20] [Batch 225/274] [Batch classify loss: 0.122995] 
[Epoch 13/20] [Batch 226/274] [Batch classify loss: 0.177813] 
[Epoch 13/20] [Batch 227/274] [Batch classify loss: 0.147742] 
[Epoch 13/20] [Batch 228/274] [Batch classify loss: 0.106698] 
[Epoch 13/20] [Batch 229/274] [Batch classify loss: 0.114705] 
[Epoch 13/20] [Batch 230/274] [Batch classify loss: 0.057683] 
[Epoch 13/20] [Batch 231/274] [Batch classify loss: 0.114961] 
[Epoch 13/20] [Batch 232/274] [Batch classify loss: 0.131853] 
[Epoch 13/20] [Batch 233/274] [Batch classify loss: 0.123116] 
[Epoch 13/20] [Batch 234/274] [Batch classify loss: 0.108500] 
[Epoch 13/20] [Batch 235/274] [Batch classify loss: 0.079012] 
[Epoch 13/20] [Batch 236/274] [Batch classify loss: 0.093157] 
[Epoch 13/20] [Batch 237/274] [Batch classify loss: 0.146769] 
[Epoch 13/20] [Batch 238/274] [Batch classify loss: 0.047329] 
[Epoch 13/20] [Batch 239/274] [Batch classify loss: 0.061285] 
[Epoch 13/20] [Batch 240/274] [Batch classify loss: 0.082159] 
[Epoch 13/20] [Batch 241/274] [Batch classify loss: 0.252532] 
[Epoch 13/20] [Batch 242/274] [Batch classify loss: 0.052601] 
[Epoch 13/20] [Batch 243/274] [Batch classify loss: 0.082041] 
[Epoch 13/20] [Batch 244/274] [Batch classify loss: 0.042536] 
[Epoch 13/20] [Batch 245/274] [Batch classify loss: 0.140869] 
[Epoch 13/20] [Batch 246/274] [Batch classify loss: 0.064166] 
[Epoch 13/20] [Batch 247/274] [Batch classify loss: 0.081012] 
[Epoch 13/20] [Batch 248/274] [Batch classify loss: 0.091212] 
[Epoch 13/20] [Batch 249/274] [Batch classify loss: 0.166419] 
[Epoch 13/20] [Batch 250/274] [Batch classify loss: 0.129542] 
[Epoch 13/20] [Batch 251/274] [Batch classify loss: 0.207703] 
[Epoch 13/20] [Batch 252/274] [Batch classify loss: 0.111133] 
[Epoch 13/20] [Batch 253/274] [Batch classify loss: 0.138228] 
[Epoch 13/20] [Batch 254/274] [Batch classify loss: 0.080466] 
[Epoch 13/20] [Batch 255/274] [Batch classify loss: 0.098317] 
[Epoch 13/20] [Batch 256/274] [Batch classify loss: 0.153569] 
[Epoch 13/20] [Batch 257/274] [Batch classify loss: 0.073594] 
[Epoch 13/20] [Batch 258/274] [Batch classify loss: 0.097012] 
[Epoch 13/20] [Batch 259/274] [Batch classify loss: 0.125439] 
[Epoch 13/20] [Batch 260/274] [Batch classify loss: 0.203064] 
[Epoch 13/20] [Batch 261/274] [Batch classify loss: 0.114679] 
[Epoch 13/20] [Batch 262/274] [Batch classify loss: 0.162009] 
[Epoch 13/20] [Batch 263/274] [Batch classify loss: 0.086220] 
[Epoch 13/20] [Batch 264/274] [Batch classify loss: 0.122380] 
[Epoch 13/20] [Batch 265/274] [Batch classify loss: 0.122836] 
[Epoch 13/20] [Batch 266/274] [Batch classify loss: 0.072810] 
[Epoch 13/20] [Batch 267/274] [Batch classify loss: 0.139917] 
[Epoch 13/20] [Batch 268/274] [Batch classify loss: 0.110933] 
[Epoch 13/20] [Batch 269/274] [Batch classify loss: 0.135400] 
[Epoch 13/20] [Batch 270/274] [Batch classify loss: 0.078756] 
[Epoch 13/20] [Batch 271/274] [Batch classify loss: 0.087239] 
[Epoch 13/20] [Batch 272/274] [Batch classify loss: 0.150306] 
[Epoch 13/20] [Batch 273/274] [Batch classify loss: 0.118561] 
[Epoch 13/20] [Batch 274/274] [Batch classify loss: 0.089610] 
0013 epoch mmat trained classifier accuary on the clean testing examples:94.6604%
0013 epoch mmat trained classifier loss on the clean testing examples:0.2225
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2966%
mmat trained classifier loss on adversarial testset:4.540055751800537
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
13epoch learning rate:0.001
[Epoch 14/20] [Batch 1/274] [Batch classify loss: 2.748363] 
[Epoch 14/20] [Batch 2/274] [Batch classify loss: 1.962537] 
[Epoch 14/20] [Batch 3/274] [Batch classify loss: 1.212102] 
[Epoch 14/20] [Batch 4/274] [Batch classify loss: 1.175574] 
[Epoch 14/20] [Batch 5/274] [Batch classify loss: 0.824110] 
[Epoch 14/20] [Batch 6/274] [Batch classify loss: 0.668372] 
[Epoch 14/20] [Batch 7/274] [Batch classify loss: 0.527903] 
[Epoch 14/20] [Batch 8/274] [Batch classify loss: 0.611054] 
[Epoch 14/20] [Batch 9/274] [Batch classify loss: 0.471065] 
[Epoch 14/20] [Batch 10/274] [Batch classify loss: 0.377501] 
[Epoch 14/20] [Batch 11/274] [Batch classify loss: 0.384315] 
[Epoch 14/20] [Batch 12/274] [Batch classify loss: 0.261668] 
[Epoch 14/20] [Batch 13/274] [Batch classify loss: 0.155070] 
[Epoch 14/20] [Batch 14/274] [Batch classify loss: 0.211007] 
[Epoch 14/20] [Batch 15/274] [Batch classify loss: 0.217312] 
[Epoch 14/20] [Batch 16/274] [Batch classify loss: 0.259681] 
[Epoch 14/20] [Batch 17/274] [Batch classify loss: 0.175456] 
[Epoch 14/20] [Batch 18/274] [Batch classify loss: 0.156684] 
[Epoch 14/20] [Batch 19/274] [Batch classify loss: 0.139164] 
[Epoch 14/20] [Batch 20/274] [Batch classify loss: 0.138998] 
[Epoch 14/20] [Batch 21/274] [Batch classify loss: 0.177107] 
[Epoch 14/20] [Batch 22/274] [Batch classify loss: 0.143334] 
[Epoch 14/20] [Batch 23/274] [Batch classify loss: 0.204800] 
[Epoch 14/20] [Batch 24/274] [Batch classify loss: 0.168405] 
[Epoch 14/20] [Batch 25/274] [Batch classify loss: 0.074502] 
[Epoch 14/20] [Batch 26/274] [Batch classify loss: 0.106187] 
[Epoch 14/20] [Batch 27/274] [Batch classify loss: 0.088924] 
[Epoch 14/20] [Batch 28/274] [Batch classify loss: 0.113570] 
[Epoch 14/20] [Batch 29/274] [Batch classify loss: 0.172741] 
[Epoch 14/20] [Batch 30/274] [Batch classify loss: 0.109585] 
[Epoch 14/20] [Batch 31/274] [Batch classify loss: 0.220137] 
[Epoch 14/20] [Batch 32/274] [Batch classify loss: 0.185345] 
[Epoch 14/20] [Batch 33/274] [Batch classify loss: 0.075564] 
[Epoch 14/20] [Batch 34/274] [Batch classify loss: 0.191694] 
[Epoch 14/20] [Batch 35/274] [Batch classify loss: 0.172004] 
[Epoch 14/20] [Batch 36/274] [Batch classify loss: 0.136724] 
[Epoch 14/20] [Batch 37/274] [Batch classify loss: 0.075072] 
[Epoch 14/20] [Batch 38/274] [Batch classify loss: 0.122558] 
[Epoch 14/20] [Batch 39/274] [Batch classify loss: 0.212233] 
[Epoch 14/20] [Batch 40/274] [Batch classify loss: 0.087252] 
[Epoch 14/20] [Batch 41/274] [Batch classify loss: 0.072042] 
[Epoch 14/20] [Batch 42/274] [Batch classify loss: 0.088445] 
[Epoch 14/20] [Batch 43/274] [Batch classify loss: 0.154341] 
[Epoch 14/20] [Batch 44/274] [Batch classify loss: 0.139960] 
[Epoch 14/20] [Batch 45/274] [Batch classify loss: 0.091585] 
[Epoch 14/20] [Batch 46/274] [Batch classify loss: 0.136697] 
[Epoch 14/20] [Batch 47/274] [Batch classify loss: 0.138036] 
[Epoch 14/20] [Batch 48/274] [Batch classify loss: 0.097025] 
[Epoch 14/20] [Batch 49/274] [Batch classify loss: 0.071900] 
[Epoch 14/20] [Batch 50/274] [Batch classify loss: 0.152487] 
[Epoch 14/20] [Batch 51/274] [Batch classify loss: 0.110194] 
[Epoch 14/20] [Batch 52/274] [Batch classify loss: 0.113079] 
[Epoch 14/20] [Batch 53/274] [Batch classify loss: 0.091332] 
[Epoch 14/20] [Batch 54/274] [Batch classify loss: 0.142682] 
[Epoch 14/20] [Batch 55/274] [Batch classify loss: 0.136857] 
[Epoch 14/20] [Batch 56/274] [Batch classify loss: 0.129634] 
[Epoch 14/20] [Batch 57/274] [Batch classify loss: 0.141516] 
[Epoch 14/20] [Batch 58/274] [Batch classify loss: 0.081181] 
[Epoch 14/20] [Batch 59/274] [Batch classify loss: 0.091278] 
[Epoch 14/20] [Batch 60/274] [Batch classify loss: 0.095756] 
[Epoch 14/20] [Batch 61/274] [Batch classify loss: 0.071232] 
[Epoch 14/20] [Batch 62/274] [Batch classify loss: 0.097959] 
[Epoch 14/20] [Batch 63/274] [Batch classify loss: 0.145177] 
[Epoch 14/20] [Batch 64/274] [Batch classify loss: 0.127878] 
[Epoch 14/20] [Batch 65/274] [Batch classify loss: 0.118486] 
[Epoch 14/20] [Batch 66/274] [Batch classify loss: 0.096606] 
[Epoch 14/20] [Batch 67/274] [Batch classify loss: 0.064420] 
[Epoch 14/20] [Batch 68/274] [Batch classify loss: 0.124361] 
[Epoch 14/20] [Batch 69/274] [Batch classify loss: 0.154729] 
[Epoch 14/20] [Batch 70/274] [Batch classify loss: 0.095251] 
[Epoch 14/20] [Batch 71/274] [Batch classify loss: 0.061270] 
[Epoch 14/20] [Batch 72/274] [Batch classify loss: 0.104109] 
[Epoch 14/20] [Batch 73/274] [Batch classify loss: 0.134621] 
[Epoch 14/20] [Batch 74/274] [Batch classify loss: 0.078111] 
[Epoch 14/20] [Batch 75/274] [Batch classify loss: 0.083248] 
[Epoch 14/20] [Batch 76/274] [Batch classify loss: 0.122132] 
[Epoch 14/20] [Batch 77/274] [Batch classify loss: 0.161040] 
[Epoch 14/20] [Batch 78/274] [Batch classify loss: 0.160635] 
[Epoch 14/20] [Batch 79/274] [Batch classify loss: 0.151738] 
[Epoch 14/20] [Batch 80/274] [Batch classify loss: 0.122139] 
[Epoch 14/20] [Batch 81/274] [Batch classify loss: 0.093770] 
[Epoch 14/20] [Batch 82/274] [Batch classify loss: 0.129630] 
[Epoch 14/20] [Batch 83/274] [Batch classify loss: 0.047833] 
[Epoch 14/20] [Batch 84/274] [Batch classify loss: 0.090069] 
[Epoch 14/20] [Batch 85/274] [Batch classify loss: 0.085949] 
[Epoch 14/20] [Batch 86/274] [Batch classify loss: 0.098461] 
[Epoch 14/20] [Batch 87/274] [Batch classify loss: 0.084665] 
[Epoch 14/20] [Batch 88/274] [Batch classify loss: 0.098833] 
[Epoch 14/20] [Batch 89/274] [Batch classify loss: 0.090185] 
[Epoch 14/20] [Batch 90/274] [Batch classify loss: 0.092079] 
[Epoch 14/20] [Batch 91/274] [Batch classify loss: 0.080070] 
[Epoch 14/20] [Batch 92/274] [Batch classify loss: 0.102021] 
[Epoch 14/20] [Batch 93/274] [Batch classify loss: 0.111379] 
[Epoch 14/20] [Batch 94/274] [Batch classify loss: 0.116215] 
[Epoch 14/20] [Batch 95/274] [Batch classify loss: 0.126249] 
[Epoch 14/20] [Batch 96/274] [Batch classify loss: 0.081539] 
[Epoch 14/20] [Batch 97/274] [Batch classify loss: 0.180211] 
[Epoch 14/20] [Batch 98/274] [Batch classify loss: 0.111858] 
[Epoch 14/20] [Batch 99/274] [Batch classify loss: 0.081781] 
[Epoch 14/20] [Batch 100/274] [Batch classify loss: 0.054836] 
[Epoch 14/20] [Batch 101/274] [Batch classify loss: 0.123842] 
[Epoch 14/20] [Batch 102/274] [Batch classify loss: 0.104065] 
[Epoch 14/20] [Batch 103/274] [Batch classify loss: 0.060249] 
[Epoch 14/20] [Batch 104/274] [Batch classify loss: 0.062446] 
[Epoch 14/20] [Batch 105/274] [Batch classify loss: 0.083433] 
[Epoch 14/20] [Batch 106/274] [Batch classify loss: 0.134379] 
[Epoch 14/20] [Batch 107/274] [Batch classify loss: 0.068900] 
[Epoch 14/20] [Batch 108/274] [Batch classify loss: 0.157156] 
[Epoch 14/20] [Batch 109/274] [Batch classify loss: 0.188397] 
[Epoch 14/20] [Batch 110/274] [Batch classify loss: 0.062014] 
[Epoch 14/20] [Batch 111/274] [Batch classify loss: 0.115442] 
[Epoch 14/20] [Batch 112/274] [Batch classify loss: 0.155717] 
[Epoch 14/20] [Batch 113/274] [Batch classify loss: 0.110379] 
[Epoch 14/20] [Batch 114/274] [Batch classify loss: 0.124899] 
[Epoch 14/20] [Batch 115/274] [Batch classify loss: 0.077872] 
[Epoch 14/20] [Batch 116/274] [Batch classify loss: 0.067024] 
[Epoch 14/20] [Batch 117/274] [Batch classify loss: 0.091104] 
[Epoch 14/20] [Batch 118/274] [Batch classify loss: 0.074512] 
[Epoch 14/20] [Batch 119/274] [Batch classify loss: 0.103952] 
[Epoch 14/20] [Batch 120/274] [Batch classify loss: 0.088600] 
[Epoch 14/20] [Batch 121/274] [Batch classify loss: 0.047382] 
[Epoch 14/20] [Batch 122/274] [Batch classify loss: 0.140420] 
[Epoch 14/20] [Batch 123/274] [Batch classify loss: 0.199667] 
[Epoch 14/20] [Batch 124/274] [Batch classify loss: 0.130282] 
[Epoch 14/20] [Batch 125/274] [Batch classify loss: 0.072317] 
[Epoch 14/20] [Batch 126/274] [Batch classify loss: 0.114594] 
[Epoch 14/20] [Batch 127/274] [Batch classify loss: 0.076091] 
[Epoch 14/20] [Batch 128/274] [Batch classify loss: 0.145802] 
[Epoch 14/20] [Batch 129/274] [Batch classify loss: 0.081731] 
[Epoch 14/20] [Batch 130/274] [Batch classify loss: 0.102996] 
[Epoch 14/20] [Batch 131/274] [Batch classify loss: 0.102585] 
[Epoch 14/20] [Batch 132/274] [Batch classify loss: 0.067298] 
[Epoch 14/20] [Batch 133/274] [Batch classify loss: 0.170542] 
[Epoch 14/20] [Batch 134/274] [Batch classify loss: 0.086073] 
[Epoch 14/20] [Batch 135/274] [Batch classify loss: 0.120484] 
[Epoch 14/20] [Batch 136/274] [Batch classify loss: 0.120733] 
[Epoch 14/20] [Batch 137/274] [Batch classify loss: 0.078716] 
[Epoch 14/20] [Batch 138/274] [Batch classify loss: 0.187846] 
[Epoch 14/20] [Batch 139/274] [Batch classify loss: 0.095036] 
[Epoch 14/20] [Batch 140/274] [Batch classify loss: 0.093634] 
[Epoch 14/20] [Batch 141/274] [Batch classify loss: 0.097987] 
[Epoch 14/20] [Batch 142/274] [Batch classify loss: 0.057565] 
[Epoch 14/20] [Batch 143/274] [Batch classify loss: 0.159305] 
[Epoch 14/20] [Batch 144/274] [Batch classify loss: 0.089322] 
[Epoch 14/20] [Batch 145/274] [Batch classify loss: 0.124498] 
[Epoch 14/20] [Batch 146/274] [Batch classify loss: 0.092990] 
[Epoch 14/20] [Batch 147/274] [Batch classify loss: 0.084207] 
[Epoch 14/20] [Batch 148/274] [Batch classify loss: 0.126976] 
[Epoch 14/20] [Batch 149/274] [Batch classify loss: 0.068761] 
[Epoch 14/20] [Batch 150/274] [Batch classify loss: 0.113652] 
[Epoch 14/20] [Batch 151/274] [Batch classify loss: 0.070204] 
[Epoch 14/20] [Batch 152/274] [Batch classify loss: 0.143990] 
[Epoch 14/20] [Batch 153/274] [Batch classify loss: 0.145210] 
[Epoch 14/20] [Batch 154/274] [Batch classify loss: 0.081020] 
[Epoch 14/20] [Batch 155/274] [Batch classify loss: 0.076012] 
[Epoch 14/20] [Batch 156/274] [Batch classify loss: 0.045713] 
[Epoch 14/20] [Batch 157/274] [Batch classify loss: 0.109527] 
[Epoch 14/20] [Batch 158/274] [Batch classify loss: 0.128340] 
[Epoch 14/20] [Batch 159/274] [Batch classify loss: 0.072817] 
[Epoch 14/20] [Batch 160/274] [Batch classify loss: 0.126009] 
[Epoch 14/20] [Batch 161/274] [Batch classify loss: 0.054177] 
[Epoch 14/20] [Batch 162/274] [Batch classify loss: 0.075398] 
[Epoch 14/20] [Batch 163/274] [Batch classify loss: 0.100363] 
[Epoch 14/20] [Batch 164/274] [Batch classify loss: 0.098831] 
[Epoch 14/20] [Batch 165/274] [Batch classify loss: 0.064848] 
[Epoch 14/20] [Batch 166/274] [Batch classify loss: 0.123245] 
[Epoch 14/20] [Batch 167/274] [Batch classify loss: 0.068455] 
[Epoch 14/20] [Batch 168/274] [Batch classify loss: 0.072771] 
[Epoch 14/20] [Batch 169/274] [Batch classify loss: 0.105739] 
[Epoch 14/20] [Batch 170/274] [Batch classify loss: 0.157764] 
[Epoch 14/20] [Batch 171/274] [Batch classify loss: 0.119055] 
[Epoch 14/20] [Batch 172/274] [Batch classify loss: 0.123603] 
[Epoch 14/20] [Batch 173/274] [Batch classify loss: 0.131478] 
[Epoch 14/20] [Batch 174/274] [Batch classify loss: 0.113889] 
[Epoch 14/20] [Batch 175/274] [Batch classify loss: 0.101790] 
[Epoch 14/20] [Batch 176/274] [Batch classify loss: 0.147343] 
[Epoch 14/20] [Batch 177/274] [Batch classify loss: 0.080134] 
[Epoch 14/20] [Batch 178/274] [Batch classify loss: 0.051217] 
[Epoch 14/20] [Batch 179/274] [Batch classify loss: 0.100177] 
[Epoch 14/20] [Batch 180/274] [Batch classify loss: 0.119243] 
[Epoch 14/20] [Batch 181/274] [Batch classify loss: 0.153801] 
[Epoch 14/20] [Batch 182/274] [Batch classify loss: 0.096900] 
[Epoch 14/20] [Batch 183/274] [Batch classify loss: 0.075599] 
[Epoch 14/20] [Batch 184/274] [Batch classify loss: 0.052053] 
[Epoch 14/20] [Batch 185/274] [Batch classify loss: 0.098674] 
[Epoch 14/20] [Batch 186/274] [Batch classify loss: 0.198867] 
[Epoch 14/20] [Batch 187/274] [Batch classify loss: 0.099355] 
[Epoch 14/20] [Batch 188/274] [Batch classify loss: 0.100047] 
[Epoch 14/20] [Batch 189/274] [Batch classify loss: 0.119787] 
[Epoch 14/20] [Batch 190/274] [Batch classify loss: 0.116360] 
[Epoch 14/20] [Batch 191/274] [Batch classify loss: 0.116444] 
[Epoch 14/20] [Batch 192/274] [Batch classify loss: 0.056041] 
[Epoch 14/20] [Batch 193/274] [Batch classify loss: 0.124845] 
[Epoch 14/20] [Batch 194/274] [Batch classify loss: 0.072306] 
[Epoch 14/20] [Batch 195/274] [Batch classify loss: 0.123619] 
[Epoch 14/20] [Batch 196/274] [Batch classify loss: 0.050334] 
[Epoch 14/20] [Batch 197/274] [Batch classify loss: 0.082913] 
[Epoch 14/20] [Batch 198/274] [Batch classify loss: 0.120356] 
[Epoch 14/20] [Batch 199/274] [Batch classify loss: 0.072232] 
[Epoch 14/20] [Batch 200/274] [Batch classify loss: 0.052833] 
[Epoch 14/20] [Batch 201/274] [Batch classify loss: 0.176114] 
[Epoch 14/20] [Batch 202/274] [Batch classify loss: 0.091243] 
[Epoch 14/20] [Batch 203/274] [Batch classify loss: 0.132621] 
[Epoch 14/20] [Batch 204/274] [Batch classify loss: 0.119092] 
[Epoch 14/20] [Batch 205/274] [Batch classify loss: 0.122355] 
[Epoch 14/20] [Batch 206/274] [Batch classify loss: 0.108634] 
[Epoch 14/20] [Batch 207/274] [Batch classify loss: 0.076288] 
[Epoch 14/20] [Batch 208/274] [Batch classify loss: 0.079567] 
[Epoch 14/20] [Batch 209/274] [Batch classify loss: 0.062613] 
[Epoch 14/20] [Batch 210/274] [Batch classify loss: 0.122944] 
[Epoch 14/20] [Batch 211/274] [Batch classify loss: 0.129148] 
[Epoch 14/20] [Batch 212/274] [Batch classify loss: 0.090392] 
[Epoch 14/20] [Batch 213/274] [Batch classify loss: 0.064340] 
[Epoch 14/20] [Batch 214/274] [Batch classify loss: 0.086911] 
[Epoch 14/20] [Batch 215/274] [Batch classify loss: 0.126582] 
[Epoch 14/20] [Batch 216/274] [Batch classify loss: 0.100173] 
[Epoch 14/20] [Batch 217/274] [Batch classify loss: 0.087559] 
[Epoch 14/20] [Batch 218/274] [Batch classify loss: 0.077417] 
[Epoch 14/20] [Batch 219/274] [Batch classify loss: 0.151688] 
[Epoch 14/20] [Batch 220/274] [Batch classify loss: 0.103663] 
[Epoch 14/20] [Batch 221/274] [Batch classify loss: 0.052832] 
[Epoch 14/20] [Batch 222/274] [Batch classify loss: 0.245046] 
[Epoch 14/20] [Batch 223/274] [Batch classify loss: 0.128712] 
[Epoch 14/20] [Batch 224/274] [Batch classify loss: 0.105066] 
[Epoch 14/20] [Batch 225/274] [Batch classify loss: 0.105146] 
[Epoch 14/20] [Batch 226/274] [Batch classify loss: 0.075381] 
[Epoch 14/20] [Batch 227/274] [Batch classify loss: 0.132695] 
[Epoch 14/20] [Batch 228/274] [Batch classify loss: 0.079183] 
[Epoch 14/20] [Batch 229/274] [Batch classify loss: 0.092409] 
[Epoch 14/20] [Batch 230/274] [Batch classify loss: 0.101183] 
[Epoch 14/20] [Batch 231/274] [Batch classify loss: 0.087143] 
[Epoch 14/20] [Batch 232/274] [Batch classify loss: 0.100978] 
[Epoch 14/20] [Batch 233/274] [Batch classify loss: 0.103672] 
[Epoch 14/20] [Batch 234/274] [Batch classify loss: 0.084345] 
[Epoch 14/20] [Batch 235/274] [Batch classify loss: 0.067317] 
[Epoch 14/20] [Batch 236/274] [Batch classify loss: 0.101970] 
[Epoch 14/20] [Batch 237/274] [Batch classify loss: 0.112996] 
[Epoch 14/20] [Batch 238/274] [Batch classify loss: 0.151729] 
[Epoch 14/20] [Batch 239/274] [Batch classify loss: 0.082921] 
[Epoch 14/20] [Batch 240/274] [Batch classify loss: 0.060558] 
[Epoch 14/20] [Batch 241/274] [Batch classify loss: 0.081195] 
[Epoch 14/20] [Batch 242/274] [Batch classify loss: 0.092488] 
[Epoch 14/20] [Batch 243/274] [Batch classify loss: 0.112056] 
[Epoch 14/20] [Batch 244/274] [Batch classify loss: 0.132097] 
[Epoch 14/20] [Batch 245/274] [Batch classify loss: 0.131849] 
[Epoch 14/20] [Batch 246/274] [Batch classify loss: 0.078125] 
[Epoch 14/20] [Batch 247/274] [Batch classify loss: 0.076150] 
[Epoch 14/20] [Batch 248/274] [Batch classify loss: 0.149577] 
[Epoch 14/20] [Batch 249/274] [Batch classify loss: 0.149903] 
[Epoch 14/20] [Batch 250/274] [Batch classify loss: 0.093247] 
[Epoch 14/20] [Batch 251/274] [Batch classify loss: 0.090075] 
[Epoch 14/20] [Batch 252/274] [Batch classify loss: 0.092468] 
[Epoch 14/20] [Batch 253/274] [Batch classify loss: 0.060712] 
[Epoch 14/20] [Batch 254/274] [Batch classify loss: 0.098323] 
[Epoch 14/20] [Batch 255/274] [Batch classify loss: 0.084790] 
[Epoch 14/20] [Batch 256/274] [Batch classify loss: 0.104982] 
[Epoch 14/20] [Batch 257/274] [Batch classify loss: 0.120486] 
[Epoch 14/20] [Batch 258/274] [Batch classify loss: 0.127192] 
[Epoch 14/20] [Batch 259/274] [Batch classify loss: 0.086920] 
[Epoch 14/20] [Batch 260/274] [Batch classify loss: 0.092083] 
[Epoch 14/20] [Batch 261/274] [Batch classify loss: 0.056790] 
[Epoch 14/20] [Batch 262/274] [Batch classify loss: 0.063976] 
[Epoch 14/20] [Batch 263/274] [Batch classify loss: 0.112909] 
[Epoch 14/20] [Batch 264/274] [Batch classify loss: 0.134574] 
[Epoch 14/20] [Batch 265/274] [Batch classify loss: 0.072679] 
[Epoch 14/20] [Batch 266/274] [Batch classify loss: 0.112416] 
[Epoch 14/20] [Batch 267/274] [Batch classify loss: 0.112216] 
[Epoch 14/20] [Batch 268/274] [Batch classify loss: 0.138156] 
[Epoch 14/20] [Batch 269/274] [Batch classify loss: 0.160226] 
[Epoch 14/20] [Batch 270/274] [Batch classify loss: 0.160154] 
[Epoch 14/20] [Batch 271/274] [Batch classify loss: 0.069771] 
[Epoch 14/20] [Batch 272/274] [Batch classify loss: 0.084508] 
[Epoch 14/20] [Batch 273/274] [Batch classify loss: 0.148633] 
[Epoch 14/20] [Batch 274/274] [Batch classify loss: 0.117953] 
0014 epoch mmat trained classifier accuary on the clean testing examples:94.6950%
0014 epoch mmat trained classifier loss on the clean testing examples:0.2244
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2620%
mmat trained classifier loss on adversarial testset:4.518157958984375
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
14epoch learning rate:0.001
[Epoch 15/20] [Batch 1/274] [Batch classify loss: 3.149991] 
[Epoch 15/20] [Batch 2/274] [Batch classify loss: 2.499294] 
[Epoch 15/20] [Batch 3/274] [Batch classify loss: 1.800048] 
[Epoch 15/20] [Batch 4/274] [Batch classify loss: 1.163106] 
[Epoch 15/20] [Batch 5/274] [Batch classify loss: 1.455299] 
[Epoch 15/20] [Batch 6/274] [Batch classify loss: 1.045391] 
[Epoch 15/20] [Batch 7/274] [Batch classify loss: 0.875790] 
[Epoch 15/20] [Batch 8/274] [Batch classify loss: 1.201067] 
[Epoch 15/20] [Batch 9/274] [Batch classify loss: 1.431357] 
[Epoch 15/20] [Batch 10/274] [Batch classify loss: 0.696345] 
[Epoch 15/20] [Batch 11/274] [Batch classify loss: 0.769778] 
[Epoch 15/20] [Batch 12/274] [Batch classify loss: 0.749475] 
[Epoch 15/20] [Batch 13/274] [Batch classify loss: 0.620212] 
[Epoch 15/20] [Batch 14/274] [Batch classify loss: 0.969590] 
[Epoch 15/20] [Batch 15/274] [Batch classify loss: 0.558792] 
[Epoch 15/20] [Batch 16/274] [Batch classify loss: 0.970291] 
[Epoch 15/20] [Batch 17/274] [Batch classify loss: 0.683165] 
[Epoch 15/20] [Batch 18/274] [Batch classify loss: 0.427401] 
[Epoch 15/20] [Batch 19/274] [Batch classify loss: 0.469867] 
[Epoch 15/20] [Batch 20/274] [Batch classify loss: 0.442638] 
[Epoch 15/20] [Batch 21/274] [Batch classify loss: 0.389926] 
[Epoch 15/20] [Batch 22/274] [Batch classify loss: 0.450663] 
[Epoch 15/20] [Batch 23/274] [Batch classify loss: 0.288066] 
[Epoch 15/20] [Batch 24/274] [Batch classify loss: 0.335132] 
[Epoch 15/20] [Batch 25/274] [Batch classify loss: 0.286496] 
[Epoch 15/20] [Batch 26/274] [Batch classify loss: 0.334817] 
[Epoch 15/20] [Batch 27/274] [Batch classify loss: 0.206534] 
[Epoch 15/20] [Batch 28/274] [Batch classify loss: 0.312706] 
[Epoch 15/20] [Batch 29/274] [Batch classify loss: 0.212613] 
[Epoch 15/20] [Batch 30/274] [Batch classify loss: 0.149372] 
[Epoch 15/20] [Batch 31/274] [Batch classify loss: 0.194575] 
[Epoch 15/20] [Batch 32/274] [Batch classify loss: 0.261729] 
[Epoch 15/20] [Batch 33/274] [Batch classify loss: 0.237797] 
[Epoch 15/20] [Batch 34/274] [Batch classify loss: 0.273204] 
[Epoch 15/20] [Batch 35/274] [Batch classify loss: 0.180505] 
[Epoch 15/20] [Batch 36/274] [Batch classify loss: 0.185741] 
[Epoch 15/20] [Batch 37/274] [Batch classify loss: 0.202907] 
[Epoch 15/20] [Batch 38/274] [Batch classify loss: 0.262309] 
[Epoch 15/20] [Batch 39/274] [Batch classify loss: 0.177655] 
[Epoch 15/20] [Batch 40/274] [Batch classify loss: 0.144444] 
[Epoch 15/20] [Batch 41/274] [Batch classify loss: 0.262363] 
[Epoch 15/20] [Batch 42/274] [Batch classify loss: 0.224758] 
[Epoch 15/20] [Batch 43/274] [Batch classify loss: 0.215724] 
[Epoch 15/20] [Batch 44/274] [Batch classify loss: 0.087797] 
[Epoch 15/20] [Batch 45/274] [Batch classify loss: 0.197184] 
[Epoch 15/20] [Batch 46/274] [Batch classify loss: 0.195093] 
[Epoch 15/20] [Batch 47/274] [Batch classify loss: 0.192690] 
[Epoch 15/20] [Batch 48/274] [Batch classify loss: 0.187528] 
[Epoch 15/20] [Batch 49/274] [Batch classify loss: 0.240839] 
[Epoch 15/20] [Batch 50/274] [Batch classify loss: 0.153147] 
[Epoch 15/20] [Batch 51/274] [Batch classify loss: 0.189452] 
[Epoch 15/20] [Batch 52/274] [Batch classify loss: 0.078495] 
[Epoch 15/20] [Batch 53/274] [Batch classify loss: 0.144615] 
[Epoch 15/20] [Batch 54/274] [Batch classify loss: 0.169354] 
[Epoch 15/20] [Batch 55/274] [Batch classify loss: 0.130893] 
[Epoch 15/20] [Batch 56/274] [Batch classify loss: 0.199510] 
[Epoch 15/20] [Batch 57/274] [Batch classify loss: 0.234904] 
[Epoch 15/20] [Batch 58/274] [Batch classify loss: 0.189369] 
[Epoch 15/20] [Batch 59/274] [Batch classify loss: 0.259449] 
[Epoch 15/20] [Batch 60/274] [Batch classify loss: 0.164610] 
[Epoch 15/20] [Batch 61/274] [Batch classify loss: 0.081044] 
[Epoch 15/20] [Batch 62/274] [Batch classify loss: 0.185204] 
[Epoch 15/20] [Batch 63/274] [Batch classify loss: 0.174061] 
[Epoch 15/20] [Batch 64/274] [Batch classify loss: 0.202909] 
[Epoch 15/20] [Batch 65/274] [Batch classify loss: 0.130017] 
[Epoch 15/20] [Batch 66/274] [Batch classify loss: 0.095721] 
[Epoch 15/20] [Batch 67/274] [Batch classify loss: 0.135310] 
[Epoch 15/20] [Batch 68/274] [Batch classify loss: 0.206039] 
[Epoch 15/20] [Batch 69/274] [Batch classify loss: 0.170300] 
[Epoch 15/20] [Batch 70/274] [Batch classify loss: 0.162278] 
[Epoch 15/20] [Batch 71/274] [Batch classify loss: 0.164808] 
[Epoch 15/20] [Batch 72/274] [Batch classify loss: 0.116587] 
[Epoch 15/20] [Batch 73/274] [Batch classify loss: 0.131584] 
[Epoch 15/20] [Batch 74/274] [Batch classify loss: 0.244898] 
[Epoch 15/20] [Batch 75/274] [Batch classify loss: 0.200391] 
[Epoch 15/20] [Batch 76/274] [Batch classify loss: 0.139575] 
[Epoch 15/20] [Batch 77/274] [Batch classify loss: 0.082059] 
[Epoch 15/20] [Batch 78/274] [Batch classify loss: 0.081863] 
[Epoch 15/20] [Batch 79/274] [Batch classify loss: 0.164913] 
[Epoch 15/20] [Batch 80/274] [Batch classify loss: 0.123045] 
[Epoch 15/20] [Batch 81/274] [Batch classify loss: 0.239255] 
[Epoch 15/20] [Batch 82/274] [Batch classify loss: 0.086902] 
[Epoch 15/20] [Batch 83/274] [Batch classify loss: 0.106378] 
[Epoch 15/20] [Batch 84/274] [Batch classify loss: 0.118191] 
[Epoch 15/20] [Batch 85/274] [Batch classify loss: 0.129345] 
[Epoch 15/20] [Batch 86/274] [Batch classify loss: 0.110054] 
[Epoch 15/20] [Batch 87/274] [Batch classify loss: 0.116404] 
[Epoch 15/20] [Batch 88/274] [Batch classify loss: 0.105183] 
[Epoch 15/20] [Batch 89/274] [Batch classify loss: 0.088101] 
[Epoch 15/20] [Batch 90/274] [Batch classify loss: 0.152434] 
[Epoch 15/20] [Batch 91/274] [Batch classify loss: 0.163490] 
[Epoch 15/20] [Batch 92/274] [Batch classify loss: 0.134562] 
[Epoch 15/20] [Batch 93/274] [Batch classify loss: 0.177180] 
[Epoch 15/20] [Batch 94/274] [Batch classify loss: 0.138442] 
[Epoch 15/20] [Batch 95/274] [Batch classify loss: 0.091350] 
[Epoch 15/20] [Batch 96/274] [Batch classify loss: 0.123136] 
[Epoch 15/20] [Batch 97/274] [Batch classify loss: 0.115877] 
[Epoch 15/20] [Batch 98/274] [Batch classify loss: 0.105327] 
[Epoch 15/20] [Batch 99/274] [Batch classify loss: 0.103544] 
[Epoch 15/20] [Batch 100/274] [Batch classify loss: 0.116958] 
[Epoch 15/20] [Batch 101/274] [Batch classify loss: 0.169307] 
[Epoch 15/20] [Batch 102/274] [Batch classify loss: 0.073335] 
[Epoch 15/20] [Batch 103/274] [Batch classify loss: 0.098459] 
[Epoch 15/20] [Batch 104/274] [Batch classify loss: 0.188004] 
[Epoch 15/20] [Batch 105/274] [Batch classify loss: 0.125850] 
[Epoch 15/20] [Batch 106/274] [Batch classify loss: 0.106797] 
[Epoch 15/20] [Batch 107/274] [Batch classify loss: 0.128610] 
[Epoch 15/20] [Batch 108/274] [Batch classify loss: 0.074132] 
[Epoch 15/20] [Batch 109/274] [Batch classify loss: 0.088858] 
[Epoch 15/20] [Batch 110/274] [Batch classify loss: 0.076076] 
[Epoch 15/20] [Batch 111/274] [Batch classify loss: 0.194063] 
[Epoch 15/20] [Batch 112/274] [Batch classify loss: 0.064903] 
[Epoch 15/20] [Batch 113/274] [Batch classify loss: 0.130204] 
[Epoch 15/20] [Batch 114/274] [Batch classify loss: 0.101959] 
[Epoch 15/20] [Batch 115/274] [Batch classify loss: 0.128271] 
[Epoch 15/20] [Batch 116/274] [Batch classify loss: 0.077600] 
[Epoch 15/20] [Batch 117/274] [Batch classify loss: 0.118076] 
[Epoch 15/20] [Batch 118/274] [Batch classify loss: 0.115938] 
[Epoch 15/20] [Batch 119/274] [Batch classify loss: 0.136001] 
[Epoch 15/20] [Batch 120/274] [Batch classify loss: 0.119048] 
[Epoch 15/20] [Batch 121/274] [Batch classify loss: 0.115473] 
[Epoch 15/20] [Batch 122/274] [Batch classify loss: 0.156599] 
[Epoch 15/20] [Batch 123/274] [Batch classify loss: 0.114953] 
[Epoch 15/20] [Batch 124/274] [Batch classify loss: 0.132166] 
[Epoch 15/20] [Batch 125/274] [Batch classify loss: 0.067022] 
[Epoch 15/20] [Batch 126/274] [Batch classify loss: 0.105609] 
[Epoch 15/20] [Batch 127/274] [Batch classify loss: 0.124859] 
[Epoch 15/20] [Batch 128/274] [Batch classify loss: 0.063912] 
[Epoch 15/20] [Batch 129/274] [Batch classify loss: 0.137687] 
[Epoch 15/20] [Batch 130/274] [Batch classify loss: 0.134194] 
[Epoch 15/20] [Batch 131/274] [Batch classify loss: 0.150721] 
[Epoch 15/20] [Batch 132/274] [Batch classify loss: 0.131992] 
[Epoch 15/20] [Batch 133/274] [Batch classify loss: 0.132000] 
[Epoch 15/20] [Batch 134/274] [Batch classify loss: 0.110812] 
[Epoch 15/20] [Batch 135/274] [Batch classify loss: 0.077665] 
[Epoch 15/20] [Batch 136/274] [Batch classify loss: 0.066781] 
[Epoch 15/20] [Batch 137/274] [Batch classify loss: 0.150614] 
[Epoch 15/20] [Batch 138/274] [Batch classify loss: 0.190296] 
[Epoch 15/20] [Batch 139/274] [Batch classify loss: 0.063487] 
[Epoch 15/20] [Batch 140/274] [Batch classify loss: 0.104795] 
[Epoch 15/20] [Batch 141/274] [Batch classify loss: 0.097741] 
[Epoch 15/20] [Batch 142/274] [Batch classify loss: 0.102695] 
[Epoch 15/20] [Batch 143/274] [Batch classify loss: 0.104138] 
[Epoch 15/20] [Batch 144/274] [Batch classify loss: 0.094736] 
[Epoch 15/20] [Batch 145/274] [Batch classify loss: 0.082192] 
[Epoch 15/20] [Batch 146/274] [Batch classify loss: 0.084369] 
[Epoch 15/20] [Batch 147/274] [Batch classify loss: 0.137480] 
[Epoch 15/20] [Batch 148/274] [Batch classify loss: 0.087816] 
[Epoch 15/20] [Batch 149/274] [Batch classify loss: 0.096247] 
[Epoch 15/20] [Batch 150/274] [Batch classify loss: 0.106190] 
[Epoch 15/20] [Batch 151/274] [Batch classify loss: 0.191738] 
[Epoch 15/20] [Batch 152/274] [Batch classify loss: 0.105243] 
[Epoch 15/20] [Batch 153/274] [Batch classify loss: 0.103559] 
[Epoch 15/20] [Batch 154/274] [Batch classify loss: 0.116364] 
[Epoch 15/20] [Batch 155/274] [Batch classify loss: 0.133093] 
[Epoch 15/20] [Batch 156/274] [Batch classify loss: 0.110877] 
[Epoch 15/20] [Batch 157/274] [Batch classify loss: 0.108583] 
[Epoch 15/20] [Batch 158/274] [Batch classify loss: 0.086300] 
[Epoch 15/20] [Batch 159/274] [Batch classify loss: 0.099380] 
[Epoch 15/20] [Batch 160/274] [Batch classify loss: 0.137310] 
[Epoch 15/20] [Batch 161/274] [Batch classify loss: 0.088628] 
[Epoch 15/20] [Batch 162/274] [Batch classify loss: 0.079225] 
[Epoch 15/20] [Batch 163/274] [Batch classify loss: 0.090105] 
[Epoch 15/20] [Batch 164/274] [Batch classify loss: 0.048812] 
[Epoch 15/20] [Batch 165/274] [Batch classify loss: 0.079516] 
[Epoch 15/20] [Batch 166/274] [Batch classify loss: 0.078116] 
[Epoch 15/20] [Batch 167/274] [Batch classify loss: 0.115584] 
[Epoch 15/20] [Batch 168/274] [Batch classify loss: 0.138487] 
[Epoch 15/20] [Batch 169/274] [Batch classify loss: 0.072313] 
[Epoch 15/20] [Batch 170/274] [Batch classify loss: 0.099094] 
[Epoch 15/20] [Batch 171/274] [Batch classify loss: 0.103554] 
[Epoch 15/20] [Batch 172/274] [Batch classify loss: 0.085354] 
[Epoch 15/20] [Batch 173/274] [Batch classify loss: 0.116443] 
[Epoch 15/20] [Batch 174/274] [Batch classify loss: 0.091524] 
[Epoch 15/20] [Batch 175/274] [Batch classify loss: 0.108208] 
[Epoch 15/20] [Batch 176/274] [Batch classify loss: 0.154331] 
[Epoch 15/20] [Batch 177/274] [Batch classify loss: 0.124372] 
[Epoch 15/20] [Batch 178/274] [Batch classify loss: 0.131813] 
[Epoch 15/20] [Batch 179/274] [Batch classify loss: 0.083466] 
[Epoch 15/20] [Batch 180/274] [Batch classify loss: 0.061009] 
[Epoch 15/20] [Batch 181/274] [Batch classify loss: 0.055198] 
[Epoch 15/20] [Batch 182/274] [Batch classify loss: 0.116107] 
[Epoch 15/20] [Batch 183/274] [Batch classify loss: 0.130850] 
[Epoch 15/20] [Batch 184/274] [Batch classify loss: 0.099005] 
[Epoch 15/20] [Batch 185/274] [Batch classify loss: 0.154647] 
[Epoch 15/20] [Batch 186/274] [Batch classify loss: 0.049845] 
[Epoch 15/20] [Batch 187/274] [Batch classify loss: 0.122907] 
[Epoch 15/20] [Batch 188/274] [Batch classify loss: 0.048847] 
[Epoch 15/20] [Batch 189/274] [Batch classify loss: 0.102800] 
[Epoch 15/20] [Batch 190/274] [Batch classify loss: 0.049488] 
[Epoch 15/20] [Batch 191/274] [Batch classify loss: 0.089641] 
[Epoch 15/20] [Batch 192/274] [Batch classify loss: 0.079330] 
[Epoch 15/20] [Batch 193/274] [Batch classify loss: 0.132916] 
[Epoch 15/20] [Batch 194/274] [Batch classify loss: 0.076612] 
[Epoch 15/20] [Batch 195/274] [Batch classify loss: 0.093660] 
[Epoch 15/20] [Batch 196/274] [Batch classify loss: 0.061755] 
[Epoch 15/20] [Batch 197/274] [Batch classify loss: 0.106023] 
[Epoch 15/20] [Batch 198/274] [Batch classify loss: 0.120988] 
[Epoch 15/20] [Batch 199/274] [Batch classify loss: 0.119678] 
[Epoch 15/20] [Batch 200/274] [Batch classify loss: 0.083338] 
[Epoch 15/20] [Batch 201/274] [Batch classify loss: 0.045777] 
[Epoch 15/20] [Batch 202/274] [Batch classify loss: 0.062585] 
[Epoch 15/20] [Batch 203/274] [Batch classify loss: 0.159766] 
[Epoch 15/20] [Batch 204/274] [Batch classify loss: 0.121322] 
[Epoch 15/20] [Batch 205/274] [Batch classify loss: 0.065343] 
[Epoch 15/20] [Batch 206/274] [Batch classify loss: 0.136394] 
[Epoch 15/20] [Batch 207/274] [Batch classify loss: 0.071470] 
[Epoch 15/20] [Batch 208/274] [Batch classify loss: 0.088015] 
[Epoch 15/20] [Batch 209/274] [Batch classify loss: 0.095456] 
[Epoch 15/20] [Batch 210/274] [Batch classify loss: 0.060504] 
[Epoch 15/20] [Batch 211/274] [Batch classify loss: 0.107970] 
[Epoch 15/20] [Batch 212/274] [Batch classify loss: 0.097293] 
[Epoch 15/20] [Batch 213/274] [Batch classify loss: 0.127511] 
[Epoch 15/20] [Batch 214/274] [Batch classify loss: 0.083304] 
[Epoch 15/20] [Batch 215/274] [Batch classify loss: 0.120839] 
[Epoch 15/20] [Batch 216/274] [Batch classify loss: 0.111507] 
[Epoch 15/20] [Batch 217/274] [Batch classify loss: 0.189202] 
[Epoch 15/20] [Batch 218/274] [Batch classify loss: 0.090706] 
[Epoch 15/20] [Batch 219/274] [Batch classify loss: 0.074294] 
[Epoch 15/20] [Batch 220/274] [Batch classify loss: 0.106479] 
[Epoch 15/20] [Batch 221/274] [Batch classify loss: 0.129503] 
[Epoch 15/20] [Batch 222/274] [Batch classify loss: 0.101900] 
[Epoch 15/20] [Batch 223/274] [Batch classify loss: 0.110344] 
[Epoch 15/20] [Batch 224/274] [Batch classify loss: 0.119136] 
[Epoch 15/20] [Batch 225/274] [Batch classify loss: 0.162672] 
[Epoch 15/20] [Batch 226/274] [Batch classify loss: 0.152195] 
[Epoch 15/20] [Batch 227/274] [Batch classify loss: 0.109606] 
[Epoch 15/20] [Batch 228/274] [Batch classify loss: 0.064605] 
[Epoch 15/20] [Batch 229/274] [Batch classify loss: 0.089069] 
[Epoch 15/20] [Batch 230/274] [Batch classify loss: 0.138773] 
[Epoch 15/20] [Batch 231/274] [Batch classify loss: 0.104774] 
[Epoch 15/20] [Batch 232/274] [Batch classify loss: 0.201261] 
[Epoch 15/20] [Batch 233/274] [Batch classify loss: 0.092762] 
[Epoch 15/20] [Batch 234/274] [Batch classify loss: 0.080535] 
[Epoch 15/20] [Batch 235/274] [Batch classify loss: 0.119103] 
[Epoch 15/20] [Batch 236/274] [Batch classify loss: 0.114572] 
[Epoch 15/20] [Batch 237/274] [Batch classify loss: 0.138210] 
[Epoch 15/20] [Batch 238/274] [Batch classify loss: 0.105487] 
[Epoch 15/20] [Batch 239/274] [Batch classify loss: 0.086674] 
[Epoch 15/20] [Batch 240/274] [Batch classify loss: 0.172577] 
[Epoch 15/20] [Batch 241/274] [Batch classify loss: 0.071973] 
[Epoch 15/20] [Batch 242/274] [Batch classify loss: 0.111789] 
[Epoch 15/20] [Batch 243/274] [Batch classify loss: 0.102295] 
[Epoch 15/20] [Batch 244/274] [Batch classify loss: 0.124985] 
[Epoch 15/20] [Batch 245/274] [Batch classify loss: 0.063743] 
[Epoch 15/20] [Batch 246/274] [Batch classify loss: 0.100059] 
[Epoch 15/20] [Batch 247/274] [Batch classify loss: 0.065987] 
[Epoch 15/20] [Batch 248/274] [Batch classify loss: 0.137463] 
[Epoch 15/20] [Batch 249/274] [Batch classify loss: 0.094794] 
[Epoch 15/20] [Batch 250/274] [Batch classify loss: 0.146631] 
[Epoch 15/20] [Batch 251/274] [Batch classify loss: 0.067286] 
[Epoch 15/20] [Batch 252/274] [Batch classify loss: 0.098837] 
[Epoch 15/20] [Batch 253/274] [Batch classify loss: 0.072795] 
[Epoch 15/20] [Batch 254/274] [Batch classify loss: 0.113580] 
[Epoch 15/20] [Batch 255/274] [Batch classify loss: 0.070316] 
[Epoch 15/20] [Batch 256/274] [Batch classify loss: 0.075745] 
[Epoch 15/20] [Batch 257/274] [Batch classify loss: 0.075837] 
[Epoch 15/20] [Batch 258/274] [Batch classify loss: 0.101154] 
[Epoch 15/20] [Batch 259/274] [Batch classify loss: 0.098241] 
[Epoch 15/20] [Batch 260/274] [Batch classify loss: 0.098468] 
[Epoch 15/20] [Batch 261/274] [Batch classify loss: 0.126037] 
[Epoch 15/20] [Batch 262/274] [Batch classify loss: 0.075798] 
[Epoch 15/20] [Batch 263/274] [Batch classify loss: 0.123725] 
[Epoch 15/20] [Batch 264/274] [Batch classify loss: 0.068117] 
[Epoch 15/20] [Batch 265/274] [Batch classify loss: 0.089735] 
[Epoch 15/20] [Batch 266/274] [Batch classify loss: 0.074649] 
[Epoch 15/20] [Batch 267/274] [Batch classify loss: 0.138481] 
[Epoch 15/20] [Batch 268/274] [Batch classify loss: 0.050412] 
[Epoch 15/20] [Batch 269/274] [Batch classify loss: 0.143577] 
[Epoch 15/20] [Batch 270/274] [Batch classify loss: 0.104984] 
[Epoch 15/20] [Batch 271/274] [Batch classify loss: 0.128442] 
[Epoch 15/20] [Batch 272/274] [Batch classify loss: 0.148105] 
[Epoch 15/20] [Batch 273/274] [Batch classify loss: 0.062475] 
[Epoch 15/20] [Batch 274/274] [Batch classify loss: 0.125963] 
0015 epoch mmat trained classifier accuary on the clean testing examples:94.7219%
0015 epoch mmat trained classifier loss on the clean testing examples:0.2244
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3004%
mmat trained classifier loss on adversarial testset:4.516546726226807
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
15epoch learning rate:0.001
[Epoch 16/20] [Batch 1/274] [Batch classify loss: 3.135882] 
[Epoch 16/20] [Batch 2/274] [Batch classify loss: 3.214811] 
[Epoch 16/20] [Batch 3/274] [Batch classify loss: 2.745961] 
[Epoch 16/20] [Batch 4/274] [Batch classify loss: 1.509605] 
[Epoch 16/20] [Batch 5/274] [Batch classify loss: 1.778114] 
[Epoch 16/20] [Batch 6/274] [Batch classify loss: 1.642680] 
[Epoch 16/20] [Batch 7/274] [Batch classify loss: 1.957390] 
[Epoch 16/20] [Batch 8/274] [Batch classify loss: 1.519838] 
[Epoch 16/20] [Batch 9/274] [Batch classify loss: 1.307112] 
[Epoch 16/20] [Batch 10/274] [Batch classify loss: 1.398318] 
[Epoch 16/20] [Batch 11/274] [Batch classify loss: 1.209993] 
[Epoch 16/20] [Batch 12/274] [Batch classify loss: 1.218253] 
[Epoch 16/20] [Batch 13/274] [Batch classify loss: 1.105311] 
[Epoch 16/20] [Batch 14/274] [Batch classify loss: 1.164718] 
[Epoch 16/20] [Batch 15/274] [Batch classify loss: 1.172536] 
[Epoch 16/20] [Batch 16/274] [Batch classify loss: 1.292397] 
[Epoch 16/20] [Batch 17/274] [Batch classify loss: 0.845464] 
[Epoch 16/20] [Batch 18/274] [Batch classify loss: 1.398454] 
[Epoch 16/20] [Batch 19/274] [Batch classify loss: 0.875311] 
[Epoch 16/20] [Batch 20/274] [Batch classify loss: 0.694263] 
[Epoch 16/20] [Batch 21/274] [Batch classify loss: 0.843335] 
[Epoch 16/20] [Batch 22/274] [Batch classify loss: 1.067960] 
[Epoch 16/20] [Batch 23/274] [Batch classify loss: 0.824100] 
[Epoch 16/20] [Batch 24/274] [Batch classify loss: 0.731558] 
[Epoch 16/20] [Batch 25/274] [Batch classify loss: 0.841507] 
[Epoch 16/20] [Batch 26/274] [Batch classify loss: 0.772107] 
[Epoch 16/20] [Batch 27/274] [Batch classify loss: 0.862357] 
[Epoch 16/20] [Batch 28/274] [Batch classify loss: 0.721196] 
[Epoch 16/20] [Batch 29/274] [Batch classify loss: 0.605052] 
[Epoch 16/20] [Batch 30/274] [Batch classify loss: 0.732691] 
[Epoch 16/20] [Batch 31/274] [Batch classify loss: 0.646348] 
[Epoch 16/20] [Batch 32/274] [Batch classify loss: 0.637109] 
[Epoch 16/20] [Batch 33/274] [Batch classify loss: 0.375588] 
[Epoch 16/20] [Batch 34/274] [Batch classify loss: 0.551462] 
[Epoch 16/20] [Batch 35/274] [Batch classify loss: 0.555606] 
[Epoch 16/20] [Batch 36/274] [Batch classify loss: 0.721405] 
[Epoch 16/20] [Batch 37/274] [Batch classify loss: 0.516100] 
[Epoch 16/20] [Batch 38/274] [Batch classify loss: 0.486195] 
[Epoch 16/20] [Batch 39/274] [Batch classify loss: 0.802184] 
[Epoch 16/20] [Batch 40/274] [Batch classify loss: 0.363672] 
[Epoch 16/20] [Batch 41/274] [Batch classify loss: 0.460101] 
[Epoch 16/20] [Batch 42/274] [Batch classify loss: 0.493695] 
[Epoch 16/20] [Batch 43/274] [Batch classify loss: 0.307613] 
[Epoch 16/20] [Batch 44/274] [Batch classify loss: 0.369904] 
[Epoch 16/20] [Batch 45/274] [Batch classify loss: 0.421380] 
[Epoch 16/20] [Batch 46/274] [Batch classify loss: 0.437152] 
[Epoch 16/20] [Batch 47/274] [Batch classify loss: 0.694901] 
[Epoch 16/20] [Batch 48/274] [Batch classify loss: 0.511116] 
[Epoch 16/20] [Batch 49/274] [Batch classify loss: 0.331975] 
[Epoch 16/20] [Batch 50/274] [Batch classify loss: 0.404031] 
[Epoch 16/20] [Batch 51/274] [Batch classify loss: 0.537301] 
[Epoch 16/20] [Batch 52/274] [Batch classify loss: 0.433677] 
[Epoch 16/20] [Batch 53/274] [Batch classify loss: 0.416367] 
[Epoch 16/20] [Batch 54/274] [Batch classify loss: 0.326308] 
[Epoch 16/20] [Batch 55/274] [Batch classify loss: 0.516518] 
[Epoch 16/20] [Batch 56/274] [Batch classify loss: 0.286140] 
[Epoch 16/20] [Batch 57/274] [Batch classify loss: 0.402235] 
[Epoch 16/20] [Batch 58/274] [Batch classify loss: 0.374722] 
[Epoch 16/20] [Batch 59/274] [Batch classify loss: 0.443435] 
[Epoch 16/20] [Batch 60/274] [Batch classify loss: 0.270240] 
[Epoch 16/20] [Batch 61/274] [Batch classify loss: 0.499377] 
[Epoch 16/20] [Batch 62/274] [Batch classify loss: 0.391374] 
[Epoch 16/20] [Batch 63/274] [Batch classify loss: 0.367353] 
[Epoch 16/20] [Batch 64/274] [Batch classify loss: 0.238179] 
[Epoch 16/20] [Batch 65/274] [Batch classify loss: 0.476822] 
[Epoch 16/20] [Batch 66/274] [Batch classify loss: 0.362769] 
[Epoch 16/20] [Batch 67/274] [Batch classify loss: 0.353183] 
[Epoch 16/20] [Batch 68/274] [Batch classify loss: 0.221611] 
[Epoch 16/20] [Batch 69/274] [Batch classify loss: 0.316556] 
[Epoch 16/20] [Batch 70/274] [Batch classify loss: 0.333443] 
[Epoch 16/20] [Batch 71/274] [Batch classify loss: 0.328820] 
[Epoch 16/20] [Batch 72/274] [Batch classify loss: 0.338776] 
[Epoch 16/20] [Batch 73/274] [Batch classify loss: 0.279323] 
[Epoch 16/20] [Batch 74/274] [Batch classify loss: 0.224273] 
[Epoch 16/20] [Batch 75/274] [Batch classify loss: 0.272511] 
[Epoch 16/20] [Batch 76/274] [Batch classify loss: 0.265194] 
[Epoch 16/20] [Batch 77/274] [Batch classify loss: 0.329755] 
[Epoch 16/20] [Batch 78/274] [Batch classify loss: 0.343166] 
[Epoch 16/20] [Batch 79/274] [Batch classify loss: 0.223223] 
[Epoch 16/20] [Batch 80/274] [Batch classify loss: 0.227535] 
[Epoch 16/20] [Batch 81/274] [Batch classify loss: 0.200373] 
[Epoch 16/20] [Batch 82/274] [Batch classify loss: 0.235746] 
[Epoch 16/20] [Batch 83/274] [Batch classify loss: 0.198613] 
[Epoch 16/20] [Batch 84/274] [Batch classify loss: 0.274144] 
[Epoch 16/20] [Batch 85/274] [Batch classify loss: 0.259747] 
[Epoch 16/20] [Batch 86/274] [Batch classify loss: 0.173030] 
[Epoch 16/20] [Batch 87/274] [Batch classify loss: 0.281421] 
[Epoch 16/20] [Batch 88/274] [Batch classify loss: 0.170872] 
[Epoch 16/20] [Batch 89/274] [Batch classify loss: 0.309798] 
[Epoch 16/20] [Batch 90/274] [Batch classify loss: 0.310018] 
[Epoch 16/20] [Batch 91/274] [Batch classify loss: 0.292964] 
[Epoch 16/20] [Batch 92/274] [Batch classify loss: 0.251049] 
[Epoch 16/20] [Batch 93/274] [Batch classify loss: 0.186297] 
[Epoch 16/20] [Batch 94/274] [Batch classify loss: 0.280182] 
[Epoch 16/20] [Batch 95/274] [Batch classify loss: 0.138682] 
[Epoch 16/20] [Batch 96/274] [Batch classify loss: 0.224940] 
[Epoch 16/20] [Batch 97/274] [Batch classify loss: 0.137499] 
[Epoch 16/20] [Batch 98/274] [Batch classify loss: 0.314284] 
[Epoch 16/20] [Batch 99/274] [Batch classify loss: 0.182600] 
[Epoch 16/20] [Batch 100/274] [Batch classify loss: 0.178795] 
[Epoch 16/20] [Batch 101/274] [Batch classify loss: 0.212882] 
[Epoch 16/20] [Batch 102/274] [Batch classify loss: 0.313695] 
[Epoch 16/20] [Batch 103/274] [Batch classify loss: 0.154686] 
[Epoch 16/20] [Batch 104/274] [Batch classify loss: 0.177414] 
[Epoch 16/20] [Batch 105/274] [Batch classify loss: 0.169656] 
[Epoch 16/20] [Batch 106/274] [Batch classify loss: 0.206706] 
[Epoch 16/20] [Batch 107/274] [Batch classify loss: 0.257729] 
[Epoch 16/20] [Batch 108/274] [Batch classify loss: 0.380916] 
[Epoch 16/20] [Batch 109/274] [Batch classify loss: 0.123128] 
[Epoch 16/20] [Batch 110/274] [Batch classify loss: 0.206613] 
[Epoch 16/20] [Batch 111/274] [Batch classify loss: 0.171972] 
[Epoch 16/20] [Batch 112/274] [Batch classify loss: 0.104879] 
[Epoch 16/20] [Batch 113/274] [Batch classify loss: 0.158462] 
[Epoch 16/20] [Batch 114/274] [Batch classify loss: 0.206164] 
[Epoch 16/20] [Batch 115/274] [Batch classify loss: 0.334994] 
[Epoch 16/20] [Batch 116/274] [Batch classify loss: 0.210083] 
[Epoch 16/20] [Batch 117/274] [Batch classify loss: 0.308484] 
[Epoch 16/20] [Batch 118/274] [Batch classify loss: 0.199760] 
[Epoch 16/20] [Batch 119/274] [Batch classify loss: 0.244726] 
[Epoch 16/20] [Batch 120/274] [Batch classify loss: 0.183435] 
[Epoch 16/20] [Batch 121/274] [Batch classify loss: 0.204102] 
[Epoch 16/20] [Batch 122/274] [Batch classify loss: 0.220641] 
[Epoch 16/20] [Batch 123/274] [Batch classify loss: 0.146616] 
[Epoch 16/20] [Batch 124/274] [Batch classify loss: 0.144459] 
[Epoch 16/20] [Batch 125/274] [Batch classify loss: 0.255633] 
[Epoch 16/20] [Batch 126/274] [Batch classify loss: 0.107166] 
[Epoch 16/20] [Batch 127/274] [Batch classify loss: 0.217839] 
[Epoch 16/20] [Batch 128/274] [Batch classify loss: 0.107566] 
[Epoch 16/20] [Batch 129/274] [Batch classify loss: 0.161169] 
[Epoch 16/20] [Batch 130/274] [Batch classify loss: 0.202825] 
[Epoch 16/20] [Batch 131/274] [Batch classify loss: 0.215925] 
[Epoch 16/20] [Batch 132/274] [Batch classify loss: 0.130060] 
[Epoch 16/20] [Batch 133/274] [Batch classify loss: 0.127746] 
[Epoch 16/20] [Batch 134/274] [Batch classify loss: 0.205576] 
[Epoch 16/20] [Batch 135/274] [Batch classify loss: 0.171757] 
[Epoch 16/20] [Batch 136/274] [Batch classify loss: 0.108219] 
[Epoch 16/20] [Batch 137/274] [Batch classify loss: 0.167574] 
[Epoch 16/20] [Batch 138/274] [Batch classify loss: 0.287469] 
[Epoch 16/20] [Batch 139/274] [Batch classify loss: 0.185360] 
[Epoch 16/20] [Batch 140/274] [Batch classify loss: 0.199669] 
[Epoch 16/20] [Batch 141/274] [Batch classify loss: 0.166762] 
[Epoch 16/20] [Batch 142/274] [Batch classify loss: 0.221811] 
[Epoch 16/20] [Batch 143/274] [Batch classify loss: 0.108879] 
[Epoch 16/20] [Batch 144/274] [Batch classify loss: 0.136523] 
[Epoch 16/20] [Batch 145/274] [Batch classify loss: 0.129008] 
[Epoch 16/20] [Batch 146/274] [Batch classify loss: 0.153393] 
[Epoch 16/20] [Batch 147/274] [Batch classify loss: 0.170230] 
[Epoch 16/20] [Batch 148/274] [Batch classify loss: 0.192343] 
[Epoch 16/20] [Batch 149/274] [Batch classify loss: 0.155408] 
[Epoch 16/20] [Batch 150/274] [Batch classify loss: 0.239982] 
[Epoch 16/20] [Batch 151/274] [Batch classify loss: 0.139701] 
[Epoch 16/20] [Batch 152/274] [Batch classify loss: 0.177017] 
[Epoch 16/20] [Batch 153/274] [Batch classify loss: 0.094496] 
[Epoch 16/20] [Batch 154/274] [Batch classify loss: 0.129000] 
[Epoch 16/20] [Batch 155/274] [Batch classify loss: 0.145671] 
[Epoch 16/20] [Batch 156/274] [Batch classify loss: 0.101152] 
[Epoch 16/20] [Batch 157/274] [Batch classify loss: 0.177256] 
[Epoch 16/20] [Batch 158/274] [Batch classify loss: 0.102184] 
[Epoch 16/20] [Batch 159/274] [Batch classify loss: 0.198332] 
[Epoch 16/20] [Batch 160/274] [Batch classify loss: 0.113841] 
[Epoch 16/20] [Batch 161/274] [Batch classify loss: 0.205767] 
[Epoch 16/20] [Batch 162/274] [Batch classify loss: 0.171372] 
[Epoch 16/20] [Batch 163/274] [Batch classify loss: 0.117346] 
[Epoch 16/20] [Batch 164/274] [Batch classify loss: 0.089289] 
[Epoch 16/20] [Batch 165/274] [Batch classify loss: 0.152693] 
[Epoch 16/20] [Batch 166/274] [Batch classify loss: 0.117001] 
[Epoch 16/20] [Batch 167/274] [Batch classify loss: 0.138105] 
[Epoch 16/20] [Batch 168/274] [Batch classify loss: 0.123374] 
[Epoch 16/20] [Batch 169/274] [Batch classify loss: 0.101796] 
[Epoch 16/20] [Batch 170/274] [Batch classify loss: 0.159956] 
[Epoch 16/20] [Batch 171/274] [Batch classify loss: 0.113631] 
[Epoch 16/20] [Batch 172/274] [Batch classify loss: 0.104379] 
[Epoch 16/20] [Batch 173/274] [Batch classify loss: 0.245574] 
[Epoch 16/20] [Batch 174/274] [Batch classify loss: 0.116779] 
[Epoch 16/20] [Batch 175/274] [Batch classify loss: 0.194804] 
[Epoch 16/20] [Batch 176/274] [Batch classify loss: 0.132489] 
[Epoch 16/20] [Batch 177/274] [Batch classify loss: 0.251358] 
[Epoch 16/20] [Batch 178/274] [Batch classify loss: 0.172035] 
[Epoch 16/20] [Batch 179/274] [Batch classify loss: 0.194192] 
[Epoch 16/20] [Batch 180/274] [Batch classify loss: 0.069806] 
[Epoch 16/20] [Batch 181/274] [Batch classify loss: 0.141636] 
[Epoch 16/20] [Batch 182/274] [Batch classify loss: 0.175016] 
[Epoch 16/20] [Batch 183/274] [Batch classify loss: 0.130427] 
[Epoch 16/20] [Batch 184/274] [Batch classify loss: 0.252402] 
[Epoch 16/20] [Batch 185/274] [Batch classify loss: 0.104919] 
[Epoch 16/20] [Batch 186/274] [Batch classify loss: 0.152724] 
[Epoch 16/20] [Batch 187/274] [Batch classify loss: 0.133430] 
[Epoch 16/20] [Batch 188/274] [Batch classify loss: 0.141902] 
[Epoch 16/20] [Batch 189/274] [Batch classify loss: 0.082416] 
[Epoch 16/20] [Batch 190/274] [Batch classify loss: 0.111050] 
[Epoch 16/20] [Batch 191/274] [Batch classify loss: 0.118976] 
[Epoch 16/20] [Batch 192/274] [Batch classify loss: 0.119025] 
[Epoch 16/20] [Batch 193/274] [Batch classify loss: 0.210662] 
[Epoch 16/20] [Batch 194/274] [Batch classify loss: 0.152732] 
[Epoch 16/20] [Batch 195/274] [Batch classify loss: 0.183159] 
[Epoch 16/20] [Batch 196/274] [Batch classify loss: 0.128730] 
[Epoch 16/20] [Batch 197/274] [Batch classify loss: 0.228777] 
[Epoch 16/20] [Batch 198/274] [Batch classify loss: 0.088116] 
[Epoch 16/20] [Batch 199/274] [Batch classify loss: 0.196240] 
[Epoch 16/20] [Batch 200/274] [Batch classify loss: 0.159320] 
[Epoch 16/20] [Batch 201/274] [Batch classify loss: 0.133841] 
[Epoch 16/20] [Batch 202/274] [Batch classify loss: 0.138393] 
[Epoch 16/20] [Batch 203/274] [Batch classify loss: 0.130143] 
[Epoch 16/20] [Batch 204/274] [Batch classify loss: 0.185004] 
[Epoch 16/20] [Batch 205/274] [Batch classify loss: 0.123494] 
[Epoch 16/20] [Batch 206/274] [Batch classify loss: 0.324151] 
[Epoch 16/20] [Batch 207/274] [Batch classify loss: 0.152566] 
[Epoch 16/20] [Batch 208/274] [Batch classify loss: 0.109977] 
[Epoch 16/20] [Batch 209/274] [Batch classify loss: 0.171780] 
[Epoch 16/20] [Batch 210/274] [Batch classify loss: 0.099068] 
[Epoch 16/20] [Batch 211/274] [Batch classify loss: 0.166240] 
[Epoch 16/20] [Batch 212/274] [Batch classify loss: 0.198238] 
[Epoch 16/20] [Batch 213/274] [Batch classify loss: 0.117534] 
[Epoch 16/20] [Batch 214/274] [Batch classify loss: 0.137353] 
[Epoch 16/20] [Batch 215/274] [Batch classify loss: 0.119938] 
[Epoch 16/20] [Batch 216/274] [Batch classify loss: 0.080260] 
[Epoch 16/20] [Batch 217/274] [Batch classify loss: 0.135647] 
[Epoch 16/20] [Batch 218/274] [Batch classify loss: 0.150032] 
[Epoch 16/20] [Batch 219/274] [Batch classify loss: 0.153886] 
[Epoch 16/20] [Batch 220/274] [Batch classify loss: 0.108472] 
[Epoch 16/20] [Batch 221/274] [Batch classify loss: 0.155525] 
[Epoch 16/20] [Batch 222/274] [Batch classify loss: 0.127481] 
[Epoch 16/20] [Batch 223/274] [Batch classify loss: 0.091439] 
[Epoch 16/20] [Batch 224/274] [Batch classify loss: 0.101193] 
[Epoch 16/20] [Batch 225/274] [Batch classify loss: 0.085793] 
[Epoch 16/20] [Batch 226/274] [Batch classify loss: 0.137544] 
[Epoch 16/20] [Batch 227/274] [Batch classify loss: 0.067590] 
[Epoch 16/20] [Batch 228/274] [Batch classify loss: 0.116905] 
[Epoch 16/20] [Batch 229/274] [Batch classify loss: 0.237886] 
[Epoch 16/20] [Batch 230/274] [Batch classify loss: 0.102410] 
[Epoch 16/20] [Batch 231/274] [Batch classify loss: 0.095438] 
[Epoch 16/20] [Batch 232/274] [Batch classify loss: 0.127222] 
[Epoch 16/20] [Batch 233/274] [Batch classify loss: 0.127314] 
[Epoch 16/20] [Batch 234/274] [Batch classify loss: 0.193444] 
[Epoch 16/20] [Batch 235/274] [Batch classify loss: 0.194132] 
[Epoch 16/20] [Batch 236/274] [Batch classify loss: 0.217948] 
[Epoch 16/20] [Batch 237/274] [Batch classify loss: 0.109901] 
[Epoch 16/20] [Batch 238/274] [Batch classify loss: 0.146111] 
[Epoch 16/20] [Batch 239/274] [Batch classify loss: 0.116126] 
[Epoch 16/20] [Batch 240/274] [Batch classify loss: 0.117748] 
[Epoch 16/20] [Batch 241/274] [Batch classify loss: 0.070590] 
[Epoch 16/20] [Batch 242/274] [Batch classify loss: 0.092006] 
[Epoch 16/20] [Batch 243/274] [Batch classify loss: 0.121789] 
[Epoch 16/20] [Batch 244/274] [Batch classify loss: 0.129938] 
[Epoch 16/20] [Batch 245/274] [Batch classify loss: 0.157961] 
[Epoch 16/20] [Batch 246/274] [Batch classify loss: 0.075943] 
[Epoch 16/20] [Batch 247/274] [Batch classify loss: 0.137702] 
[Epoch 16/20] [Batch 248/274] [Batch classify loss: 0.092922] 
[Epoch 16/20] [Batch 249/274] [Batch classify loss: 0.100240] 
[Epoch 16/20] [Batch 250/274] [Batch classify loss: 0.102713] 
[Epoch 16/20] [Batch 251/274] [Batch classify loss: 0.093753] 
[Epoch 16/20] [Batch 252/274] [Batch classify loss: 0.118816] 
[Epoch 16/20] [Batch 253/274] [Batch classify loss: 0.181803] 
[Epoch 16/20] [Batch 254/274] [Batch classify loss: 0.054217] 
[Epoch 16/20] [Batch 255/274] [Batch classify loss: 0.100962] 
[Epoch 16/20] [Batch 256/274] [Batch classify loss: 0.097149] 
[Epoch 16/20] [Batch 257/274] [Batch classify loss: 0.086612] 
[Epoch 16/20] [Batch 258/274] [Batch classify loss: 0.171782] 
[Epoch 16/20] [Batch 259/274] [Batch classify loss: 0.177710] 
[Epoch 16/20] [Batch 260/274] [Batch classify loss: 0.153423] 
[Epoch 16/20] [Batch 261/274] [Batch classify loss: 0.094386] 
[Epoch 16/20] [Batch 262/274] [Batch classify loss: 0.095890] 
[Epoch 16/20] [Batch 263/274] [Batch classify loss: 0.144474] 
[Epoch 16/20] [Batch 264/274] [Batch classify loss: 0.084989] 
[Epoch 16/20] [Batch 265/274] [Batch classify loss: 0.091420] 
[Epoch 16/20] [Batch 266/274] [Batch classify loss: 0.144780] 
[Epoch 16/20] [Batch 267/274] [Batch classify loss: 0.125294] 
[Epoch 16/20] [Batch 268/274] [Batch classify loss: 0.124764] 
[Epoch 16/20] [Batch 269/274] [Batch classify loss: 0.152808] 
[Epoch 16/20] [Batch 270/274] [Batch classify loss: 0.138928] 
[Epoch 16/20] [Batch 271/274] [Batch classify loss: 0.140003] 
[Epoch 16/20] [Batch 272/274] [Batch classify loss: 0.161278] 
[Epoch 16/20] [Batch 273/274] [Batch classify loss: 0.224287] 
[Epoch 16/20] [Batch 274/274] [Batch classify loss: 0.182941] 
0016 epoch mmat trained classifier accuary on the clean testing examples:94.8448%
0016 epoch mmat trained classifier loss on the clean testing examples:0.2209
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2044%
mmat trained classifier loss on adversarial testset:4.5177321434021
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
16epoch learning rate:0.001
[Epoch 17/20] [Batch 1/274] [Batch classify loss: 3.146684] 
[Epoch 17/20] [Batch 2/274] [Batch classify loss: 3.232353] 
[Epoch 17/20] [Batch 3/274] [Batch classify loss: 3.170748] 
[Epoch 17/20] [Batch 4/274] [Batch classify loss: 2.885060] 
[Epoch 17/20] [Batch 5/274] [Batch classify loss: 1.961294] 
[Epoch 17/20] [Batch 6/274] [Batch classify loss: 2.419071] 
[Epoch 17/20] [Batch 7/274] [Batch classify loss: 2.473801] 
[Epoch 17/20] [Batch 8/274] [Batch classify loss: 1.967233] 
[Epoch 17/20] [Batch 9/274] [Batch classify loss: 1.991651] 
[Epoch 17/20] [Batch 10/274] [Batch classify loss: 2.199787] 
[Epoch 17/20] [Batch 11/274] [Batch classify loss: 1.732255] 
[Epoch 17/20] [Batch 12/274] [Batch classify loss: 1.619646] 
[Epoch 17/20] [Batch 13/274] [Batch classify loss: 1.764935] 
[Epoch 17/20] [Batch 14/274] [Batch classify loss: 1.553216] 
[Epoch 17/20] [Batch 15/274] [Batch classify loss: 1.747084] 
[Epoch 17/20] [Batch 16/274] [Batch classify loss: 1.516939] 
[Epoch 17/20] [Batch 17/274] [Batch classify loss: 1.799946] 
[Epoch 17/20] [Batch 18/274] [Batch classify loss: 1.806358] 
[Epoch 17/20] [Batch 19/274] [Batch classify loss: 1.232477] 
[Epoch 17/20] [Batch 20/274] [Batch classify loss: 1.215778] 
[Epoch 17/20] [Batch 21/274] [Batch classify loss: 0.948678] 
[Epoch 17/20] [Batch 22/274] [Batch classify loss: 1.374958] 
[Epoch 17/20] [Batch 23/274] [Batch classify loss: 1.385330] 
[Epoch 17/20] [Batch 24/274] [Batch classify loss: 1.289716] 
[Epoch 17/20] [Batch 25/274] [Batch classify loss: 2.168116] 
[Epoch 17/20] [Batch 26/274] [Batch classify loss: 1.045259] 
[Epoch 17/20] [Batch 27/274] [Batch classify loss: 1.207503] 
[Epoch 17/20] [Batch 28/274] [Batch classify loss: 1.190255] 
[Epoch 17/20] [Batch 29/274] [Batch classify loss: 1.153313] 
[Epoch 17/20] [Batch 30/274] [Batch classify loss: 1.185347] 
[Epoch 17/20] [Batch 31/274] [Batch classify loss: 0.895446] 
[Epoch 17/20] [Batch 32/274] [Batch classify loss: 1.063489] 
[Epoch 17/20] [Batch 33/274] [Batch classify loss: 1.192222] 
[Epoch 17/20] [Batch 34/274] [Batch classify loss: 1.071860] 
[Epoch 17/20] [Batch 35/274] [Batch classify loss: 1.091601] 
[Epoch 17/20] [Batch 36/274] [Batch classify loss: 1.118802] 
[Epoch 17/20] [Batch 37/274] [Batch classify loss: 0.960489] 
[Epoch 17/20] [Batch 38/274] [Batch classify loss: 1.339544] 
[Epoch 17/20] [Batch 39/274] [Batch classify loss: 0.977488] 
[Epoch 17/20] [Batch 40/274] [Batch classify loss: 0.950899] 
[Epoch 17/20] [Batch 41/274] [Batch classify loss: 0.935125] 
[Epoch 17/20] [Batch 42/274] [Batch classify loss: 0.758928] 
[Epoch 17/20] [Batch 43/274] [Batch classify loss: 1.122771] 
[Epoch 17/20] [Batch 44/274] [Batch classify loss: 0.904057] 
[Epoch 17/20] [Batch 45/274] [Batch classify loss: 0.635574] 
[Epoch 17/20] [Batch 46/274] [Batch classify loss: 0.862267] 
[Epoch 17/20] [Batch 47/274] [Batch classify loss: 0.894139] 
[Epoch 17/20] [Batch 48/274] [Batch classify loss: 0.770552] 
[Epoch 17/20] [Batch 49/274] [Batch classify loss: 0.847775] 
[Epoch 17/20] [Batch 50/274] [Batch classify loss: 0.509414] 
[Epoch 17/20] [Batch 51/274] [Batch classify loss: 1.080542] 
[Epoch 17/20] [Batch 52/274] [Batch classify loss: 0.559840] 
[Epoch 17/20] [Batch 53/274] [Batch classify loss: 0.770507] 
[Epoch 17/20] [Batch 54/274] [Batch classify loss: 0.992184] 
[Epoch 17/20] [Batch 55/274] [Batch classify loss: 0.864078] 
[Epoch 17/20] [Batch 56/274] [Batch classify loss: 0.730277] 
[Epoch 17/20] [Batch 57/274] [Batch classify loss: 0.444782] 
[Epoch 17/20] [Batch 58/274] [Batch classify loss: 0.494710] 
[Epoch 17/20] [Batch 59/274] [Batch classify loss: 0.837282] 
[Epoch 17/20] [Batch 60/274] [Batch classify loss: 0.812342] 
[Epoch 17/20] [Batch 61/274] [Batch classify loss: 0.537759] 
[Epoch 17/20] [Batch 62/274] [Batch classify loss: 0.463547] 
[Epoch 17/20] [Batch 63/274] [Batch classify loss: 0.606844] 
[Epoch 17/20] [Batch 64/274] [Batch classify loss: 0.827778] 
[Epoch 17/20] [Batch 65/274] [Batch classify loss: 0.616908] 
[Epoch 17/20] [Batch 66/274] [Batch classify loss: 0.713383] 
[Epoch 17/20] [Batch 67/274] [Batch classify loss: 0.820031] 
[Epoch 17/20] [Batch 68/274] [Batch classify loss: 0.424037] 
[Epoch 17/20] [Batch 69/274] [Batch classify loss: 0.637960] 
[Epoch 17/20] [Batch 70/274] [Batch classify loss: 0.623891] 
[Epoch 17/20] [Batch 71/274] [Batch classify loss: 0.652208] 
[Epoch 17/20] [Batch 72/274] [Batch classify loss: 0.624785] 
[Epoch 17/20] [Batch 73/274] [Batch classify loss: 0.999475] 
[Epoch 17/20] [Batch 74/274] [Batch classify loss: 0.837356] 
[Epoch 17/20] [Batch 75/274] [Batch classify loss: 0.787448] 
[Epoch 17/20] [Batch 76/274] [Batch classify loss: 0.681858] 
[Epoch 17/20] [Batch 77/274] [Batch classify loss: 0.633643] 
[Epoch 17/20] [Batch 78/274] [Batch classify loss: 0.585762] 
[Epoch 17/20] [Batch 79/274] [Batch classify loss: 0.448548] 
[Epoch 17/20] [Batch 80/274] [Batch classify loss: 0.839698] 
[Epoch 17/20] [Batch 81/274] [Batch classify loss: 0.448846] 
[Epoch 17/20] [Batch 82/274] [Batch classify loss: 0.639502] 
[Epoch 17/20] [Batch 83/274] [Batch classify loss: 0.506151] 
[Epoch 17/20] [Batch 84/274] [Batch classify loss: 0.507007] 
[Epoch 17/20] [Batch 85/274] [Batch classify loss: 0.629620] 
[Epoch 17/20] [Batch 86/274] [Batch classify loss: 0.644908] 
[Epoch 17/20] [Batch 87/274] [Batch classify loss: 0.473611] 
[Epoch 17/20] [Batch 88/274] [Batch classify loss: 0.566526] 
[Epoch 17/20] [Batch 89/274] [Batch classify loss: 0.462556] 
[Epoch 17/20] [Batch 90/274] [Batch classify loss: 0.531551] 
[Epoch 17/20] [Batch 91/274] [Batch classify loss: 0.480608] 
[Epoch 17/20] [Batch 92/274] [Batch classify loss: 0.409934] 
[Epoch 17/20] [Batch 93/274] [Batch classify loss: 0.411716] 
[Epoch 17/20] [Batch 94/274] [Batch classify loss: 0.473810] 
[Epoch 17/20] [Batch 95/274] [Batch classify loss: 0.522997] 
[Epoch 17/20] [Batch 96/274] [Batch classify loss: 0.426935] 
[Epoch 17/20] [Batch 97/274] [Batch classify loss: 0.429600] 
[Epoch 17/20] [Batch 98/274] [Batch classify loss: 0.433427] 
[Epoch 17/20] [Batch 99/274] [Batch classify loss: 0.494220] 
[Epoch 17/20] [Batch 100/274] [Batch classify loss: 0.556084] 
[Epoch 17/20] [Batch 101/274] [Batch classify loss: 0.665861] 
[Epoch 17/20] [Batch 102/274] [Batch classify loss: 0.462632] 
[Epoch 17/20] [Batch 103/274] [Batch classify loss: 0.439312] 
[Epoch 17/20] [Batch 104/274] [Batch classify loss: 0.372479] 
[Epoch 17/20] [Batch 105/274] [Batch classify loss: 0.551973] 
[Epoch 17/20] [Batch 106/274] [Batch classify loss: 0.497288] 
[Epoch 17/20] [Batch 107/274] [Batch classify loss: 0.591308] 
[Epoch 17/20] [Batch 108/274] [Batch classify loss: 0.476782] 
[Epoch 17/20] [Batch 109/274] [Batch classify loss: 0.594647] 
[Epoch 17/20] [Batch 110/274] [Batch classify loss: 0.377128] 
[Epoch 17/20] [Batch 111/274] [Batch classify loss: 0.532126] 
[Epoch 17/20] [Batch 112/274] [Batch classify loss: 0.550465] 
[Epoch 17/20] [Batch 113/274] [Batch classify loss: 0.573448] 
[Epoch 17/20] [Batch 114/274] [Batch classify loss: 0.259348] 
[Epoch 17/20] [Batch 115/274] [Batch classify loss: 0.353709] 
[Epoch 17/20] [Batch 116/274] [Batch classify loss: 0.428437] 
[Epoch 17/20] [Batch 117/274] [Batch classify loss: 0.281959] 
[Epoch 17/20] [Batch 118/274] [Batch classify loss: 0.320839] 
[Epoch 17/20] [Batch 119/274] [Batch classify loss: 0.437847] 
[Epoch 17/20] [Batch 120/274] [Batch classify loss: 0.500144] 
[Epoch 17/20] [Batch 121/274] [Batch classify loss: 0.540703] 
[Epoch 17/20] [Batch 122/274] [Batch classify loss: 0.658297] 
[Epoch 17/20] [Batch 123/274] [Batch classify loss: 0.539075] 
[Epoch 17/20] [Batch 124/274] [Batch classify loss: 0.641605] 
[Epoch 17/20] [Batch 125/274] [Batch classify loss: 0.494672] 
[Epoch 17/20] [Batch 126/274] [Batch classify loss: 0.479006] 
[Epoch 17/20] [Batch 127/274] [Batch classify loss: 0.266802] 
[Epoch 17/20] [Batch 128/274] [Batch classify loss: 0.757312] 
[Epoch 17/20] [Batch 129/274] [Batch classify loss: 0.679469] 
[Epoch 17/20] [Batch 130/274] [Batch classify loss: 0.312573] 
[Epoch 17/20] [Batch 131/274] [Batch classify loss: 0.333234] 
[Epoch 17/20] [Batch 132/274] [Batch classify loss: 0.302073] 
[Epoch 17/20] [Batch 133/274] [Batch classify loss: 0.380328] 
[Epoch 17/20] [Batch 134/274] [Batch classify loss: 0.417790] 
[Epoch 17/20] [Batch 135/274] [Batch classify loss: 0.310891] 
[Epoch 17/20] [Batch 136/274] [Batch classify loss: 0.455798] 
[Epoch 17/20] [Batch 137/274] [Batch classify loss: 0.457758] 
[Epoch 17/20] [Batch 138/274] [Batch classify loss: 0.624200] 
[Epoch 17/20] [Batch 139/274] [Batch classify loss: 0.263247] 
[Epoch 17/20] [Batch 140/274] [Batch classify loss: 0.328496] 
[Epoch 17/20] [Batch 141/274] [Batch classify loss: 0.261360] 
[Epoch 17/20] [Batch 142/274] [Batch classify loss: 0.393232] 
[Epoch 17/20] [Batch 143/274] [Batch classify loss: 0.354924] 
[Epoch 17/20] [Batch 144/274] [Batch classify loss: 0.446692] 
[Epoch 17/20] [Batch 145/274] [Batch classify loss: 0.293471] 
[Epoch 17/20] [Batch 146/274] [Batch classify loss: 0.222178] 
[Epoch 17/20] [Batch 147/274] [Batch classify loss: 0.269506] 
[Epoch 17/20] [Batch 148/274] [Batch classify loss: 0.611926] 
[Epoch 17/20] [Batch 149/274] [Batch classify loss: 0.472113] 
[Epoch 17/20] [Batch 150/274] [Batch classify loss: 0.414357] 
[Epoch 17/20] [Batch 151/274] [Batch classify loss: 0.321317] 
[Epoch 17/20] [Batch 152/274] [Batch classify loss: 0.178249] 
[Epoch 17/20] [Batch 153/274] [Batch classify loss: 0.266572] 
[Epoch 17/20] [Batch 154/274] [Batch classify loss: 0.319446] 
[Epoch 17/20] [Batch 155/274] [Batch classify loss: 0.235700] 
[Epoch 17/20] [Batch 156/274] [Batch classify loss: 0.274237] 
[Epoch 17/20] [Batch 157/274] [Batch classify loss: 0.413957] 
[Epoch 17/20] [Batch 158/274] [Batch classify loss: 0.238945] 
[Epoch 17/20] [Batch 159/274] [Batch classify loss: 0.235788] 
[Epoch 17/20] [Batch 160/274] [Batch classify loss: 0.271182] 
[Epoch 17/20] [Batch 161/274] [Batch classify loss: 0.201385] 
[Epoch 17/20] [Batch 162/274] [Batch classify loss: 0.251656] 
[Epoch 17/20] [Batch 163/274] [Batch classify loss: 0.274550] 
[Epoch 17/20] [Batch 164/274] [Batch classify loss: 0.323951] 
[Epoch 17/20] [Batch 165/274] [Batch classify loss: 0.267266] 
[Epoch 17/20] [Batch 166/274] [Batch classify loss: 0.378634] 
[Epoch 17/20] [Batch 167/274] [Batch classify loss: 0.364048] 
[Epoch 17/20] [Batch 168/274] [Batch classify loss: 0.373765] 
[Epoch 17/20] [Batch 169/274] [Batch classify loss: 0.310403] 
[Epoch 17/20] [Batch 170/274] [Batch classify loss: 0.295232] 
[Epoch 17/20] [Batch 171/274] [Batch classify loss: 0.264805] 
[Epoch 17/20] [Batch 172/274] [Batch classify loss: 0.187342] 
[Epoch 17/20] [Batch 173/274] [Batch classify loss: 0.189459] 
[Epoch 17/20] [Batch 174/274] [Batch classify loss: 0.354543] 
[Epoch 17/20] [Batch 175/274] [Batch classify loss: 0.434477] 
[Epoch 17/20] [Batch 176/274] [Batch classify loss: 0.287888] 
[Epoch 17/20] [Batch 177/274] [Batch classify loss: 0.293952] 
[Epoch 17/20] [Batch 178/274] [Batch classify loss: 0.226079] 
[Epoch 17/20] [Batch 179/274] [Batch classify loss: 0.319407] 
[Epoch 17/20] [Batch 180/274] [Batch classify loss: 0.261129] 
[Epoch 17/20] [Batch 181/274] [Batch classify loss: 0.191166] 
[Epoch 17/20] [Batch 182/274] [Batch classify loss: 0.285612] 
[Epoch 17/20] [Batch 183/274] [Batch classify loss: 0.211587] 
[Epoch 17/20] [Batch 184/274] [Batch classify loss: 0.305088] 
[Epoch 17/20] [Batch 185/274] [Batch classify loss: 0.289080] 
[Epoch 17/20] [Batch 186/274] [Batch classify loss: 0.439859] 
[Epoch 17/20] [Batch 187/274] [Batch classify loss: 0.404288] 
[Epoch 17/20] [Batch 188/274] [Batch classify loss: 0.258556] 
[Epoch 17/20] [Batch 189/274] [Batch classify loss: 0.277842] 
[Epoch 17/20] [Batch 190/274] [Batch classify loss: 0.224639] 
[Epoch 17/20] [Batch 191/274] [Batch classify loss: 0.261160] 
[Epoch 17/20] [Batch 192/274] [Batch classify loss: 0.168289] 
[Epoch 17/20] [Batch 193/274] [Batch classify loss: 0.258279] 
[Epoch 17/20] [Batch 194/274] [Batch classify loss: 0.304403] 
[Epoch 17/20] [Batch 195/274] [Batch classify loss: 0.232426] 
[Epoch 17/20] [Batch 196/274] [Batch classify loss: 0.249363] 
[Epoch 17/20] [Batch 197/274] [Batch classify loss: 0.196704] 
[Epoch 17/20] [Batch 198/274] [Batch classify loss: 0.240500] 
[Epoch 17/20] [Batch 199/274] [Batch classify loss: 0.304184] 
[Epoch 17/20] [Batch 200/274] [Batch classify loss: 0.270831] 
[Epoch 17/20] [Batch 201/274] [Batch classify loss: 0.169262] 
[Epoch 17/20] [Batch 202/274] [Batch classify loss: 0.274789] 
[Epoch 17/20] [Batch 203/274] [Batch classify loss: 0.352385] 
[Epoch 17/20] [Batch 204/274] [Batch classify loss: 0.371494] 
[Epoch 17/20] [Batch 205/274] [Batch classify loss: 0.258809] 
[Epoch 17/20] [Batch 206/274] [Batch classify loss: 0.324462] 
[Epoch 17/20] [Batch 207/274] [Batch classify loss: 0.256830] 
[Epoch 17/20] [Batch 208/274] [Batch classify loss: 0.192312] 
[Epoch 17/20] [Batch 209/274] [Batch classify loss: 0.344074] 
[Epoch 17/20] [Batch 210/274] [Batch classify loss: 0.231081] 
[Epoch 17/20] [Batch 211/274] [Batch classify loss: 0.257474] 
[Epoch 17/20] [Batch 212/274] [Batch classify loss: 0.336935] 
[Epoch 17/20] [Batch 213/274] [Batch classify loss: 0.173404] 
[Epoch 17/20] [Batch 214/274] [Batch classify loss: 0.182223] 
[Epoch 17/20] [Batch 215/274] [Batch classify loss: 0.223555] 
[Epoch 17/20] [Batch 216/274] [Batch classify loss: 0.268376] 
[Epoch 17/20] [Batch 217/274] [Batch classify loss: 0.177610] 
[Epoch 17/20] [Batch 218/274] [Batch classify loss: 0.326953] 
[Epoch 17/20] [Batch 219/274] [Batch classify loss: 0.141214] 
[Epoch 17/20] [Batch 220/274] [Batch classify loss: 0.119699] 
[Epoch 17/20] [Batch 221/274] [Batch classify loss: 0.260172] 
[Epoch 17/20] [Batch 222/274] [Batch classify loss: 0.183194] 
[Epoch 17/20] [Batch 223/274] [Batch classify loss: 0.183745] 
[Epoch 17/20] [Batch 224/274] [Batch classify loss: 0.206421] 
[Epoch 17/20] [Batch 225/274] [Batch classify loss: 0.209861] 
[Epoch 17/20] [Batch 226/274] [Batch classify loss: 0.219051] 
[Epoch 17/20] [Batch 227/274] [Batch classify loss: 0.230198] 
[Epoch 17/20] [Batch 228/274] [Batch classify loss: 0.270566] 
[Epoch 17/20] [Batch 229/274] [Batch classify loss: 0.232922] 
[Epoch 17/20] [Batch 230/274] [Batch classify loss: 0.183180] 
[Epoch 17/20] [Batch 231/274] [Batch classify loss: 0.237144] 
[Epoch 17/20] [Batch 232/274] [Batch classify loss: 0.271145] 
[Epoch 17/20] [Batch 233/274] [Batch classify loss: 0.168877] 
[Epoch 17/20] [Batch 234/274] [Batch classify loss: 0.330713] 
[Epoch 17/20] [Batch 235/274] [Batch classify loss: 0.225007] 
[Epoch 17/20] [Batch 236/274] [Batch classify loss: 0.204466] 
[Epoch 17/20] [Batch 237/274] [Batch classify loss: 0.226932] 
[Epoch 17/20] [Batch 238/274] [Batch classify loss: 0.175304] 
[Epoch 17/20] [Batch 239/274] [Batch classify loss: 0.168220] 
[Epoch 17/20] [Batch 240/274] [Batch classify loss: 0.133932] 
[Epoch 17/20] [Batch 241/274] [Batch classify loss: 0.187479] 
[Epoch 17/20] [Batch 242/274] [Batch classify loss: 0.160236] 
[Epoch 17/20] [Batch 243/274] [Batch classify loss: 0.140024] 
[Epoch 17/20] [Batch 244/274] [Batch classify loss: 0.140828] 
[Epoch 17/20] [Batch 245/274] [Batch classify loss: 0.238824] 
[Epoch 17/20] [Batch 246/274] [Batch classify loss: 0.235898] 
[Epoch 17/20] [Batch 247/274] [Batch classify loss: 0.183737] 
[Epoch 17/20] [Batch 248/274] [Batch classify loss: 0.210070] 
[Epoch 17/20] [Batch 249/274] [Batch classify loss: 0.327065] 
[Epoch 17/20] [Batch 250/274] [Batch classify loss: 0.119224] 
[Epoch 17/20] [Batch 251/274] [Batch classify loss: 0.118222] 
[Epoch 17/20] [Batch 252/274] [Batch classify loss: 0.230059] 
[Epoch 17/20] [Batch 253/274] [Batch classify loss: 0.182679] 
[Epoch 17/20] [Batch 254/274] [Batch classify loss: 0.270126] 
[Epoch 17/20] [Batch 255/274] [Batch classify loss: 0.278667] 
[Epoch 17/20] [Batch 256/274] [Batch classify loss: 0.261557] 
[Epoch 17/20] [Batch 257/274] [Batch classify loss: 0.377389] 
[Epoch 17/20] [Batch 258/274] [Batch classify loss: 0.270466] 
[Epoch 17/20] [Batch 259/274] [Batch classify loss: 0.179158] 
[Epoch 17/20] [Batch 260/274] [Batch classify loss: 0.173177] 
[Epoch 17/20] [Batch 261/274] [Batch classify loss: 0.113754] 
[Epoch 17/20] [Batch 262/274] [Batch classify loss: 0.243381] 
[Epoch 17/20] [Batch 263/274] [Batch classify loss: 0.206356] 
[Epoch 17/20] [Batch 264/274] [Batch classify loss: 0.385005] 
[Epoch 17/20] [Batch 265/274] [Batch classify loss: 0.228347] 
[Epoch 17/20] [Batch 266/274] [Batch classify loss: 0.276929] 
[Epoch 17/20] [Batch 267/274] [Batch classify loss: 0.305366] 
[Epoch 17/20] [Batch 268/274] [Batch classify loss: 0.173216] 
[Epoch 17/20] [Batch 269/274] [Batch classify loss: 0.289571] 
[Epoch 17/20] [Batch 270/274] [Batch classify loss: 0.191437] 
[Epoch 17/20] [Batch 271/274] [Batch classify loss: 0.176956] 
[Epoch 17/20] [Batch 272/274] [Batch classify loss: 0.384853] 
[Epoch 17/20] [Batch 273/274] [Batch classify loss: 0.246635] 
[Epoch 17/20] [Batch 274/274] [Batch classify loss: 0.195861] 
0017 epoch mmat trained classifier accuary on the clean testing examples:94.6566%
0017 epoch mmat trained classifier loss on the clean testing examples:0.2230
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3004%
mmat trained classifier loss on adversarial testset:4.505453109741211
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
17epoch learning rate:0.001
[Epoch 18/20] [Batch 1/274] [Batch classify loss: 3.076781] 
[Epoch 18/20] [Batch 2/274] [Batch classify loss: 3.221546] 
[Epoch 18/20] [Batch 3/274] [Batch classify loss: 3.448241] 
[Epoch 18/20] [Batch 4/274] [Batch classify loss: 3.193876] 
[Epoch 18/20] [Batch 5/274] [Batch classify loss: 3.239620] 
[Epoch 18/20] [Batch 6/274] [Batch classify loss: 2.740239] 
[Epoch 18/20] [Batch 7/274] [Batch classify loss: 2.807666] 
[Epoch 18/20] [Batch 8/274] [Batch classify loss: 2.119697] 
[Epoch 18/20] [Batch 9/274] [Batch classify loss: 2.417991] 
[Epoch 18/20] [Batch 10/274] [Batch classify loss: 2.086066] 
[Epoch 18/20] [Batch 11/274] [Batch classify loss: 1.922239] 
[Epoch 18/20] [Batch 12/274] [Batch classify loss: 2.902846] 
[Epoch 18/20] [Batch 13/274] [Batch classify loss: 1.831496] 
[Epoch 18/20] [Batch 14/274] [Batch classify loss: 2.200221] 
[Epoch 18/20] [Batch 15/274] [Batch classify loss: 2.086617] 
[Epoch 18/20] [Batch 16/274] [Batch classify loss: 2.065588] 
[Epoch 18/20] [Batch 17/274] [Batch classify loss: 2.155479] 
[Epoch 18/20] [Batch 18/274] [Batch classify loss: 1.829118] 
[Epoch 18/20] [Batch 19/274] [Batch classify loss: 1.688342] 
[Epoch 18/20] [Batch 20/274] [Batch classify loss: 2.067337] 
[Epoch 18/20] [Batch 21/274] [Batch classify loss: 2.119409] 
[Epoch 18/20] [Batch 22/274] [Batch classify loss: 1.891898] 
[Epoch 18/20] [Batch 23/274] [Batch classify loss: 1.696758] 
[Epoch 18/20] [Batch 24/274] [Batch classify loss: 1.705855] 
[Epoch 18/20] [Batch 25/274] [Batch classify loss: 2.079290] 
[Epoch 18/20] [Batch 26/274] [Batch classify loss: 1.886941] 
[Epoch 18/20] [Batch 27/274] [Batch classify loss: 1.348797] 
[Epoch 18/20] [Batch 28/274] [Batch classify loss: 1.301473] 
[Epoch 18/20] [Batch 29/274] [Batch classify loss: 1.735632] 
[Epoch 18/20] [Batch 30/274] [Batch classify loss: 1.869755] 
[Epoch 18/20] [Batch 31/274] [Batch classify loss: 1.602270] 
[Epoch 18/20] [Batch 32/274] [Batch classify loss: 1.851711] 
[Epoch 18/20] [Batch 33/274] [Batch classify loss: 1.421444] 
[Epoch 18/20] [Batch 34/274] [Batch classify loss: 1.267781] 
[Epoch 18/20] [Batch 35/274] [Batch classify loss: 1.773745] 
[Epoch 18/20] [Batch 36/274] [Batch classify loss: 1.747399] 
[Epoch 18/20] [Batch 37/274] [Batch classify loss: 1.576149] 
[Epoch 18/20] [Batch 38/274] [Batch classify loss: 1.461458] 
[Epoch 18/20] [Batch 39/274] [Batch classify loss: 1.222379] 
[Epoch 18/20] [Batch 40/274] [Batch classify loss: 1.450444] 
[Epoch 18/20] [Batch 41/274] [Batch classify loss: 1.435498] 
[Epoch 18/20] [Batch 42/274] [Batch classify loss: 1.144558] 
[Epoch 18/20] [Batch 43/274] [Batch classify loss: 1.365706] 
[Epoch 18/20] [Batch 44/274] [Batch classify loss: 1.297377] 
[Epoch 18/20] [Batch 45/274] [Batch classify loss: 1.333671] 
[Epoch 18/20] [Batch 46/274] [Batch classify loss: 1.435601] 
[Epoch 18/20] [Batch 47/274] [Batch classify loss: 1.309205] 
[Epoch 18/20] [Batch 48/274] [Batch classify loss: 1.217885] 
[Epoch 18/20] [Batch 49/274] [Batch classify loss: 1.070409] 
[Epoch 18/20] [Batch 50/274] [Batch classify loss: 1.230802] 
[Epoch 18/20] [Batch 51/274] [Batch classify loss: 1.467787] 
[Epoch 18/20] [Batch 52/274] [Batch classify loss: 1.404366] 
[Epoch 18/20] [Batch 53/274] [Batch classify loss: 1.143792] 
[Epoch 18/20] [Batch 54/274] [Batch classify loss: 0.977758] 
[Epoch 18/20] [Batch 55/274] [Batch classify loss: 1.164000] 
[Epoch 18/20] [Batch 56/274] [Batch classify loss: 1.088598] 
[Epoch 18/20] [Batch 57/274] [Batch classify loss: 1.065974] 
[Epoch 18/20] [Batch 58/274] [Batch classify loss: 1.216106] 
[Epoch 18/20] [Batch 59/274] [Batch classify loss: 1.082685] 
[Epoch 18/20] [Batch 60/274] [Batch classify loss: 0.989485] 
[Epoch 18/20] [Batch 61/274] [Batch classify loss: 1.344947] 
[Epoch 18/20] [Batch 62/274] [Batch classify loss: 1.074667] 
[Epoch 18/20] [Batch 63/274] [Batch classify loss: 0.998073] 
[Epoch 18/20] [Batch 64/274] [Batch classify loss: 1.709905] 
[Epoch 18/20] [Batch 65/274] [Batch classify loss: 1.165647] 
[Epoch 18/20] [Batch 66/274] [Batch classify loss: 0.834052] 
[Epoch 18/20] [Batch 67/274] [Batch classify loss: 1.581616] 
[Epoch 18/20] [Batch 68/274] [Batch classify loss: 0.923288] 
[Epoch 18/20] [Batch 69/274] [Batch classify loss: 1.005975] 
[Epoch 18/20] [Batch 70/274] [Batch classify loss: 0.950927] 
[Epoch 18/20] [Batch 71/274] [Batch classify loss: 1.125896] 
[Epoch 18/20] [Batch 72/274] [Batch classify loss: 0.837737] 
[Epoch 18/20] [Batch 73/274] [Batch classify loss: 0.821367] 
[Epoch 18/20] [Batch 74/274] [Batch classify loss: 0.740324] 
[Epoch 18/20] [Batch 75/274] [Batch classify loss: 0.898827] 
[Epoch 18/20] [Batch 76/274] [Batch classify loss: 1.078197] 
[Epoch 18/20] [Batch 77/274] [Batch classify loss: 0.964359] 
[Epoch 18/20] [Batch 78/274] [Batch classify loss: 1.007385] 
[Epoch 18/20] [Batch 79/274] [Batch classify loss: 1.101989] 
[Epoch 18/20] [Batch 80/274] [Batch classify loss: 0.907176] 
[Epoch 18/20] [Batch 81/274] [Batch classify loss: 0.857633] 
[Epoch 18/20] [Batch 82/274] [Batch classify loss: 1.092489] 
[Epoch 18/20] [Batch 83/274] [Batch classify loss: 1.132033] 
[Epoch 18/20] [Batch 84/274] [Batch classify loss: 0.784191] 
[Epoch 18/20] [Batch 85/274] [Batch classify loss: 0.822398] 
[Epoch 18/20] [Batch 86/274] [Batch classify loss: 1.019773] 
[Epoch 18/20] [Batch 87/274] [Batch classify loss: 0.857371] 
[Epoch 18/20] [Batch 88/274] [Batch classify loss: 0.828860] 
[Epoch 18/20] [Batch 89/274] [Batch classify loss: 0.970427] 
[Epoch 18/20] [Batch 90/274] [Batch classify loss: 0.914983] 
[Epoch 18/20] [Batch 91/274] [Batch classify loss: 0.833754] 
[Epoch 18/20] [Batch 92/274] [Batch classify loss: 1.032764] 
[Epoch 18/20] [Batch 93/274] [Batch classify loss: 0.775017] 
[Epoch 18/20] [Batch 94/274] [Batch classify loss: 0.997318] 
[Epoch 18/20] [Batch 95/274] [Batch classify loss: 0.785264] 
[Epoch 18/20] [Batch 96/274] [Batch classify loss: 1.220074] 
[Epoch 18/20] [Batch 97/274] [Batch classify loss: 1.058035] 
[Epoch 18/20] [Batch 98/274] [Batch classify loss: 0.900035] 
[Epoch 18/20] [Batch 99/274] [Batch classify loss: 1.023919] 
[Epoch 18/20] [Batch 100/274] [Batch classify loss: 0.691877] 
[Epoch 18/20] [Batch 101/274] [Batch classify loss: 0.712271] 
[Epoch 18/20] [Batch 102/274] [Batch classify loss: 0.667103] 
[Epoch 18/20] [Batch 103/274] [Batch classify loss: 0.719566] 
[Epoch 18/20] [Batch 104/274] [Batch classify loss: 0.900596] 
[Epoch 18/20] [Batch 105/274] [Batch classify loss: 1.003046] 
[Epoch 18/20] [Batch 106/274] [Batch classify loss: 0.770689] 
[Epoch 18/20] [Batch 107/274] [Batch classify loss: 0.892994] 
[Epoch 18/20] [Batch 108/274] [Batch classify loss: 0.683925] 
[Epoch 18/20] [Batch 109/274] [Batch classify loss: 1.089684] 
[Epoch 18/20] [Batch 110/274] [Batch classify loss: 0.782169] 
[Epoch 18/20] [Batch 111/274] [Batch classify loss: 0.762525] 
[Epoch 18/20] [Batch 112/274] [Batch classify loss: 0.853019] 
[Epoch 18/20] [Batch 113/274] [Batch classify loss: 0.903321] 
[Epoch 18/20] [Batch 114/274] [Batch classify loss: 0.624077] 
[Epoch 18/20] [Batch 115/274] [Batch classify loss: 0.802667] 
[Epoch 18/20] [Batch 116/274] [Batch classify loss: 0.763472] 
[Epoch 18/20] [Batch 117/274] [Batch classify loss: 0.779689] 
[Epoch 18/20] [Batch 118/274] [Batch classify loss: 0.993490] 
[Epoch 18/20] [Batch 119/274] [Batch classify loss: 0.954916] 
[Epoch 18/20] [Batch 120/274] [Batch classify loss: 0.811631] 
[Epoch 18/20] [Batch 121/274] [Batch classify loss: 0.551337] 
[Epoch 18/20] [Batch 122/274] [Batch classify loss: 0.842871] 
[Epoch 18/20] [Batch 123/274] [Batch classify loss: 0.763558] 
[Epoch 18/20] [Batch 124/274] [Batch classify loss: 0.690585] 
[Epoch 18/20] [Batch 125/274] [Batch classify loss: 0.716385] 
[Epoch 18/20] [Batch 126/274] [Batch classify loss: 0.822747] 
[Epoch 18/20] [Batch 127/274] [Batch classify loss: 0.877702] 
[Epoch 18/20] [Batch 128/274] [Batch classify loss: 0.838315] 
[Epoch 18/20] [Batch 129/274] [Batch classify loss: 0.732287] 
[Epoch 18/20] [Batch 130/274] [Batch classify loss: 0.724733] 
[Epoch 18/20] [Batch 131/274] [Batch classify loss: 0.774052] 
[Epoch 18/20] [Batch 132/274] [Batch classify loss: 0.630751] 
[Epoch 18/20] [Batch 133/274] [Batch classify loss: 0.867025] 
[Epoch 18/20] [Batch 134/274] [Batch classify loss: 0.551950] 
[Epoch 18/20] [Batch 135/274] [Batch classify loss: 0.709351] 
[Epoch 18/20] [Batch 136/274] [Batch classify loss: 0.834168] 
[Epoch 18/20] [Batch 137/274] [Batch classify loss: 0.590527] 
[Epoch 18/20] [Batch 138/274] [Batch classify loss: 0.665695] 
[Epoch 18/20] [Batch 139/274] [Batch classify loss: 0.759394] 
[Epoch 18/20] [Batch 140/274] [Batch classify loss: 0.623784] 
[Epoch 18/20] [Batch 141/274] [Batch classify loss: 0.812315] 
[Epoch 18/20] [Batch 142/274] [Batch classify loss: 0.648433] 
[Epoch 18/20] [Batch 143/274] [Batch classify loss: 0.809863] 
[Epoch 18/20] [Batch 144/274] [Batch classify loss: 0.826701] 
[Epoch 18/20] [Batch 145/274] [Batch classify loss: 0.704336] 
[Epoch 18/20] [Batch 146/274] [Batch classify loss: 0.455547] 
[Epoch 18/20] [Batch 147/274] [Batch classify loss: 0.684408] 
[Epoch 18/20] [Batch 148/274] [Batch classify loss: 0.672011] 
[Epoch 18/20] [Batch 149/274] [Batch classify loss: 0.941031] 
[Epoch 18/20] [Batch 150/274] [Batch classify loss: 0.550950] 
[Epoch 18/20] [Batch 151/274] [Batch classify loss: 0.521402] 
[Epoch 18/20] [Batch 152/274] [Batch classify loss: 0.571324] 
[Epoch 18/20] [Batch 153/274] [Batch classify loss: 0.609753] 
[Epoch 18/20] [Batch 154/274] [Batch classify loss: 0.412380] 
[Epoch 18/20] [Batch 155/274] [Batch classify loss: 0.522201] 
[Epoch 18/20] [Batch 156/274] [Batch classify loss: 0.803877] 
[Epoch 18/20] [Batch 157/274] [Batch classify loss: 0.646592] 
[Epoch 18/20] [Batch 158/274] [Batch classify loss: 0.587584] 
[Epoch 18/20] [Batch 159/274] [Batch classify loss: 0.855030] 
[Epoch 18/20] [Batch 160/274] [Batch classify loss: 0.574947] 
[Epoch 18/20] [Batch 161/274] [Batch classify loss: 0.528399] 
[Epoch 18/20] [Batch 162/274] [Batch classify loss: 0.534776] 
[Epoch 18/20] [Batch 163/274] [Batch classify loss: 0.531676] 
[Epoch 18/20] [Batch 164/274] [Batch classify loss: 0.678334] 
[Epoch 18/20] [Batch 165/274] [Batch classify loss: 0.514278] 
[Epoch 18/20] [Batch 166/274] [Batch classify loss: 0.578639] 
[Epoch 18/20] [Batch 167/274] [Batch classify loss: 0.430122] 
[Epoch 18/20] [Batch 168/274] [Batch classify loss: 0.535165] 
[Epoch 18/20] [Batch 169/274] [Batch classify loss: 0.638185] 
[Epoch 18/20] [Batch 170/274] [Batch classify loss: 0.569339] 
[Epoch 18/20] [Batch 171/274] [Batch classify loss: 0.544883] 
[Epoch 18/20] [Batch 172/274] [Batch classify loss: 0.786710] 
[Epoch 18/20] [Batch 173/274] [Batch classify loss: 0.646728] 
[Epoch 18/20] [Batch 174/274] [Batch classify loss: 0.581815] 
[Epoch 18/20] [Batch 175/274] [Batch classify loss: 0.733414] 
[Epoch 18/20] [Batch 176/274] [Batch classify loss: 0.584653] 
[Epoch 18/20] [Batch 177/274] [Batch classify loss: 0.707568] 
[Epoch 18/20] [Batch 178/274] [Batch classify loss: 0.524710] 
[Epoch 18/20] [Batch 179/274] [Batch classify loss: 0.817034] 
[Epoch 18/20] [Batch 180/274] [Batch classify loss: 0.391342] 
[Epoch 18/20] [Batch 181/274] [Batch classify loss: 0.461025] 
[Epoch 18/20] [Batch 182/274] [Batch classify loss: 0.637274] 
[Epoch 18/20] [Batch 183/274] [Batch classify loss: 0.511137] 
[Epoch 18/20] [Batch 184/274] [Batch classify loss: 0.594200] 
[Epoch 18/20] [Batch 185/274] [Batch classify loss: 0.590413] 
[Epoch 18/20] [Batch 186/274] [Batch classify loss: 0.567286] 
[Epoch 18/20] [Batch 187/274] [Batch classify loss: 0.604011] 
[Epoch 18/20] [Batch 188/274] [Batch classify loss: 0.466402] 
[Epoch 18/20] [Batch 189/274] [Batch classify loss: 0.413858] 
[Epoch 18/20] [Batch 190/274] [Batch classify loss: 0.530872] 
[Epoch 18/20] [Batch 191/274] [Batch classify loss: 0.506341] 
[Epoch 18/20] [Batch 192/274] [Batch classify loss: 0.458451] 
[Epoch 18/20] [Batch 193/274] [Batch classify loss: 0.678759] 
[Epoch 18/20] [Batch 194/274] [Batch classify loss: 0.539738] 
[Epoch 18/20] [Batch 195/274] [Batch classify loss: 0.360716] 
[Epoch 18/20] [Batch 196/274] [Batch classify loss: 0.517109] 
[Epoch 18/20] [Batch 197/274] [Batch classify loss: 0.480995] 
[Epoch 18/20] [Batch 198/274] [Batch classify loss: 0.529644] 
[Epoch 18/20] [Batch 199/274] [Batch classify loss: 0.608773] 
[Epoch 18/20] [Batch 200/274] [Batch classify loss: 0.607042] 
[Epoch 18/20] [Batch 201/274] [Batch classify loss: 0.504322] 
[Epoch 18/20] [Batch 202/274] [Batch classify loss: 0.551600] 
[Epoch 18/20] [Batch 203/274] [Batch classify loss: 0.662657] 
[Epoch 18/20] [Batch 204/274] [Batch classify loss: 0.361844] 
[Epoch 18/20] [Batch 205/274] [Batch classify loss: 0.542675] 
[Epoch 18/20] [Batch 206/274] [Batch classify loss: 0.369505] 
[Epoch 18/20] [Batch 207/274] [Batch classify loss: 0.550180] 
[Epoch 18/20] [Batch 208/274] [Batch classify loss: 0.467575] 
[Epoch 18/20] [Batch 209/274] [Batch classify loss: 0.444483] 
[Epoch 18/20] [Batch 210/274] [Batch classify loss: 0.525034] 
[Epoch 18/20] [Batch 211/274] [Batch classify loss: 0.695661] 
[Epoch 18/20] [Batch 212/274] [Batch classify loss: 0.621825] 
[Epoch 18/20] [Batch 213/274] [Batch classify loss: 0.407814] 
[Epoch 18/20] [Batch 214/274] [Batch classify loss: 0.607206] 
[Epoch 18/20] [Batch 215/274] [Batch classify loss: 0.701051] 
[Epoch 18/20] [Batch 216/274] [Batch classify loss: 0.476695] 
[Epoch 18/20] [Batch 217/274] [Batch classify loss: 0.583164] 
[Epoch 18/20] [Batch 218/274] [Batch classify loss: 0.574832] 
[Epoch 18/20] [Batch 219/274] [Batch classify loss: 0.461727] 
[Epoch 18/20] [Batch 220/274] [Batch classify loss: 0.464573] 
[Epoch 18/20] [Batch 221/274] [Batch classify loss: 0.626986] 
[Epoch 18/20] [Batch 222/274] [Batch classify loss: 0.527862] 
[Epoch 18/20] [Batch 223/274] [Batch classify loss: 0.388979] 
[Epoch 18/20] [Batch 224/274] [Batch classify loss: 0.506118] 
[Epoch 18/20] [Batch 225/274] [Batch classify loss: 0.421087] 
[Epoch 18/20] [Batch 226/274] [Batch classify loss: 0.367680] 
[Epoch 18/20] [Batch 227/274] [Batch classify loss: 0.486799] 
[Epoch 18/20] [Batch 228/274] [Batch classify loss: 0.409858] 
[Epoch 18/20] [Batch 229/274] [Batch classify loss: 0.686071] 
[Epoch 18/20] [Batch 230/274] [Batch classify loss: 0.623779] 
[Epoch 18/20] [Batch 231/274] [Batch classify loss: 0.470912] 
[Epoch 18/20] [Batch 232/274] [Batch classify loss: 0.457723] 
[Epoch 18/20] [Batch 233/274] [Batch classify loss: 0.344280] 
[Epoch 18/20] [Batch 234/274] [Batch classify loss: 0.497922] 
[Epoch 18/20] [Batch 235/274] [Batch classify loss: 0.500808] 
[Epoch 18/20] [Batch 236/274] [Batch classify loss: 0.421850] 
[Epoch 18/20] [Batch 237/274] [Batch classify loss: 0.636115] 
[Epoch 18/20] [Batch 238/274] [Batch classify loss: 0.464967] 
[Epoch 18/20] [Batch 239/274] [Batch classify loss: 0.480944] 
[Epoch 18/20] [Batch 240/274] [Batch classify loss: 0.728492] 
[Epoch 18/20] [Batch 241/274] [Batch classify loss: 0.456104] 
[Epoch 18/20] [Batch 242/274] [Batch classify loss: 0.336841] 
[Epoch 18/20] [Batch 243/274] [Batch classify loss: 0.495011] 
[Epoch 18/20] [Batch 244/274] [Batch classify loss: 0.502968] 
[Epoch 18/20] [Batch 245/274] [Batch classify loss: 0.361552] 
[Epoch 18/20] [Batch 246/274] [Batch classify loss: 0.438467] 
[Epoch 18/20] [Batch 247/274] [Batch classify loss: 0.395350] 
[Epoch 18/20] [Batch 248/274] [Batch classify loss: 0.563500] 
[Epoch 18/20] [Batch 249/274] [Batch classify loss: 0.537753] 
[Epoch 18/20] [Batch 250/274] [Batch classify loss: 0.605698] 
[Epoch 18/20] [Batch 251/274] [Batch classify loss: 0.499646] 
[Epoch 18/20] [Batch 252/274] [Batch classify loss: 0.616557] 
[Epoch 18/20] [Batch 253/274] [Batch classify loss: 0.373542] 
[Epoch 18/20] [Batch 254/274] [Batch classify loss: 0.338077] 
[Epoch 18/20] [Batch 255/274] [Batch classify loss: 0.447708] 
[Epoch 18/20] [Batch 256/274] [Batch classify loss: 0.604308] 
[Epoch 18/20] [Batch 257/274] [Batch classify loss: 0.399422] 
[Epoch 18/20] [Batch 258/274] [Batch classify loss: 0.280194] 
[Epoch 18/20] [Batch 259/274] [Batch classify loss: 0.273990] 
[Epoch 18/20] [Batch 260/274] [Batch classify loss: 0.423583] 
[Epoch 18/20] [Batch 261/274] [Batch classify loss: 0.540686] 
[Epoch 18/20] [Batch 262/274] [Batch classify loss: 0.418188] 
[Epoch 18/20] [Batch 263/274] [Batch classify loss: 0.579587] 
[Epoch 18/20] [Batch 264/274] [Batch classify loss: 0.515378] 
[Epoch 18/20] [Batch 265/274] [Batch classify loss: 0.376970] 
[Epoch 18/20] [Batch 266/274] [Batch classify loss: 0.526308] 
[Epoch 18/20] [Batch 267/274] [Batch classify loss: 0.458887] 
[Epoch 18/20] [Batch 268/274] [Batch classify loss: 0.412786] 
[Epoch 18/20] [Batch 269/274] [Batch classify loss: 0.286656] 
[Epoch 18/20] [Batch 270/274] [Batch classify loss: 0.472487] 
[Epoch 18/20] [Batch 271/274] [Batch classify loss: 0.299968] 
[Epoch 18/20] [Batch 272/274] [Batch classify loss: 0.567316] 
[Epoch 18/20] [Batch 273/274] [Batch classify loss: 0.413461] 
[Epoch 18/20] [Batch 274/274] [Batch classify loss: 0.430084] 
0018 epoch mmat trained classifier accuary on the clean testing examples:94.6873%
0018 epoch mmat trained classifier loss on the clean testing examples:0.2229
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.1006%
mmat trained classifier loss on adversarial testset:4.532024383544922
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
18epoch learning rate:0.001
[Epoch 19/20] [Batch 1/274] [Batch classify loss: 3.260761] 
[Epoch 19/20] [Batch 2/274] [Batch classify loss: 3.153888] 
[Epoch 19/20] [Batch 3/274] [Batch classify loss: 3.206803] 
[Epoch 19/20] [Batch 4/274] [Batch classify loss: 3.218824] 
[Epoch 19/20] [Batch 5/274] [Batch classify loss: 3.217529] 
[Epoch 19/20] [Batch 6/274] [Batch classify loss: 3.083430] 
[Epoch 19/20] [Batch 7/274] [Batch classify loss: 3.253397] 
[Epoch 19/20] [Batch 8/274] [Batch classify loss: 3.107887] 
[Epoch 19/20] [Batch 9/274] [Batch classify loss: 2.543569] 
[Epoch 19/20] [Batch 10/274] [Batch classify loss: 2.925558] 
[Epoch 19/20] [Batch 11/274] [Batch classify loss: 2.588663] 
[Epoch 19/20] [Batch 12/274] [Batch classify loss: 2.920821] 
[Epoch 19/20] [Batch 13/274] [Batch classify loss: 2.863221] 
[Epoch 19/20] [Batch 14/274] [Batch classify loss: 2.311481] 
[Epoch 19/20] [Batch 15/274] [Batch classify loss: 2.196662] 
[Epoch 19/20] [Batch 16/274] [Batch classify loss: 2.644243] 
[Epoch 19/20] [Batch 17/274] [Batch classify loss: 2.033256] 
[Epoch 19/20] [Batch 18/274] [Batch classify loss: 2.205939] 
[Epoch 19/20] [Batch 19/274] [Batch classify loss: 2.282731] 
[Epoch 19/20] [Batch 20/274] [Batch classify loss: 2.160943] 
[Epoch 19/20] [Batch 21/274] [Batch classify loss: 1.902290] 
[Epoch 19/20] [Batch 22/274] [Batch classify loss: 2.313100] 
[Epoch 19/20] [Batch 23/274] [Batch classify loss: 1.871979] 
[Epoch 19/20] [Batch 24/274] [Batch classify loss: 2.295424] 
[Epoch 19/20] [Batch 25/274] [Batch classify loss: 2.313454] 
[Epoch 19/20] [Batch 26/274] [Batch classify loss: 2.389273] 
[Epoch 19/20] [Batch 27/274] [Batch classify loss: 2.184462] 
[Epoch 19/20] [Batch 28/274] [Batch classify loss: 2.131325] 
[Epoch 19/20] [Batch 29/274] [Batch classify loss: 2.057570] 
[Epoch 19/20] [Batch 30/274] [Batch classify loss: 2.063120] 
[Epoch 19/20] [Batch 31/274] [Batch classify loss: 2.296302] 
[Epoch 19/20] [Batch 32/274] [Batch classify loss: 2.031817] 
[Epoch 19/20] [Batch 33/274] [Batch classify loss: 2.065762] 
[Epoch 19/20] [Batch 34/274] [Batch classify loss: 2.202603] 
[Epoch 19/20] [Batch 35/274] [Batch classify loss: 2.110797] 
[Epoch 19/20] [Batch 36/274] [Batch classify loss: 1.638081] 
[Epoch 19/20] [Batch 37/274] [Batch classify loss: 1.545938] 
[Epoch 19/20] [Batch 38/274] [Batch classify loss: 1.581695] 
[Epoch 19/20] [Batch 39/274] [Batch classify loss: 1.924206] 
[Epoch 19/20] [Batch 40/274] [Batch classify loss: 1.638736] 
[Epoch 19/20] [Batch 41/274] [Batch classify loss: 1.956549] 
[Epoch 19/20] [Batch 42/274] [Batch classify loss: 2.049490] 
[Epoch 19/20] [Batch 43/274] [Batch classify loss: 1.864512] 
[Epoch 19/20] [Batch 44/274] [Batch classify loss: 2.110952] 
[Epoch 19/20] [Batch 45/274] [Batch classify loss: 1.680831] 
[Epoch 19/20] [Batch 46/274] [Batch classify loss: 1.903419] 
[Epoch 19/20] [Batch 47/274] [Batch classify loss: 1.456519] 
[Epoch 19/20] [Batch 48/274] [Batch classify loss: 1.466360] 
[Epoch 19/20] [Batch 49/274] [Batch classify loss: 1.842882] 
[Epoch 19/20] [Batch 50/274] [Batch classify loss: 1.967691] 
[Epoch 19/20] [Batch 51/274] [Batch classify loss: 2.024573] 
[Epoch 19/20] [Batch 52/274] [Batch classify loss: 1.524988] 
[Epoch 19/20] [Batch 53/274] [Batch classify loss: 1.620837] 
[Epoch 19/20] [Batch 54/274] [Batch classify loss: 1.658355] 
[Epoch 19/20] [Batch 55/274] [Batch classify loss: 1.656079] 
[Epoch 19/20] [Batch 56/274] [Batch classify loss: 1.755666] 
[Epoch 19/20] [Batch 57/274] [Batch classify loss: 1.351428] 
[Epoch 19/20] [Batch 58/274] [Batch classify loss: 1.677033] 
[Epoch 19/20] [Batch 59/274] [Batch classify loss: 1.837841] 
[Epoch 19/20] [Batch 60/274] [Batch classify loss: 1.584753] 
[Epoch 19/20] [Batch 61/274] [Batch classify loss: 1.449878] 
[Epoch 19/20] [Batch 62/274] [Batch classify loss: 1.381739] 
[Epoch 19/20] [Batch 63/274] [Batch classify loss: 2.034856] 
[Epoch 19/20] [Batch 64/274] [Batch classify loss: 1.536238] 
[Epoch 19/20] [Batch 65/274] [Batch classify loss: 1.360085] 
[Epoch 19/20] [Batch 66/274] [Batch classify loss: 1.375915] 
[Epoch 19/20] [Batch 67/274] [Batch classify loss: 1.711373] 
[Epoch 19/20] [Batch 68/274] [Batch classify loss: 1.571813] 
[Epoch 19/20] [Batch 69/274] [Batch classify loss: 1.639395] 
[Epoch 19/20] [Batch 70/274] [Batch classify loss: 1.968075] 
[Epoch 19/20] [Batch 71/274] [Batch classify loss: 1.393238] 
[Epoch 19/20] [Batch 72/274] [Batch classify loss: 1.471766] 
[Epoch 19/20] [Batch 73/274] [Batch classify loss: 1.602205] 
[Epoch 19/20] [Batch 74/274] [Batch classify loss: 1.646359] 
[Epoch 19/20] [Batch 75/274] [Batch classify loss: 1.310417] 
[Epoch 19/20] [Batch 76/274] [Batch classify loss: 1.289295] 
[Epoch 19/20] [Batch 77/274] [Batch classify loss: 1.653043] 
[Epoch 19/20] [Batch 78/274] [Batch classify loss: 1.422826] 
[Epoch 19/20] [Batch 79/274] [Batch classify loss: 1.555236] 
[Epoch 19/20] [Batch 80/274] [Batch classify loss: 1.269802] 
[Epoch 19/20] [Batch 81/274] [Batch classify loss: 1.336565] 
[Epoch 19/20] [Batch 82/274] [Batch classify loss: 1.400331] 
[Epoch 19/20] [Batch 83/274] [Batch classify loss: 1.905475] 
[Epoch 19/20] [Batch 84/274] [Batch classify loss: 1.425830] 
[Epoch 19/20] [Batch 85/274] [Batch classify loss: 1.351956] 
[Epoch 19/20] [Batch 86/274] [Batch classify loss: 1.271577] 
[Epoch 19/20] [Batch 87/274] [Batch classify loss: 1.301720] 
[Epoch 19/20] [Batch 88/274] [Batch classify loss: 1.391761] 
[Epoch 19/20] [Batch 89/274] [Batch classify loss: 1.443165] 
[Epoch 19/20] [Batch 90/274] [Batch classify loss: 1.487090] 
[Epoch 19/20] [Batch 91/274] [Batch classify loss: 1.376992] 
[Epoch 19/20] [Batch 92/274] [Batch classify loss: 1.587315] 
[Epoch 19/20] [Batch 93/274] [Batch classify loss: 1.391055] 
[Epoch 19/20] [Batch 94/274] [Batch classify loss: 1.113189] 
[Epoch 19/20] [Batch 95/274] [Batch classify loss: 1.137443] 
[Epoch 19/20] [Batch 96/274] [Batch classify loss: 1.787771] 
[Epoch 19/20] [Batch 97/274] [Batch classify loss: 1.167501] 
[Epoch 19/20] [Batch 98/274] [Batch classify loss: 1.373936] 
[Epoch 19/20] [Batch 99/274] [Batch classify loss: 1.647000] 
[Epoch 19/20] [Batch 100/274] [Batch classify loss: 1.294879] 
[Epoch 19/20] [Batch 101/274] [Batch classify loss: 1.435826] 
[Epoch 19/20] [Batch 102/274] [Batch classify loss: 1.514328] 
[Epoch 19/20] [Batch 103/274] [Batch classify loss: 1.234637] 
[Epoch 19/20] [Batch 104/274] [Batch classify loss: 1.197261] 
[Epoch 19/20] [Batch 105/274] [Batch classify loss: 1.217136] 
[Epoch 19/20] [Batch 106/274] [Batch classify loss: 1.393157] 
[Epoch 19/20] [Batch 107/274] [Batch classify loss: 1.193388] 
[Epoch 19/20] [Batch 108/274] [Batch classify loss: 1.277294] 
[Epoch 19/20] [Batch 109/274] [Batch classify loss: 1.311322] 
[Epoch 19/20] [Batch 110/274] [Batch classify loss: 1.315437] 
[Epoch 19/20] [Batch 111/274] [Batch classify loss: 1.278109] 
[Epoch 19/20] [Batch 112/274] [Batch classify loss: 1.324228] 
[Epoch 19/20] [Batch 113/274] [Batch classify loss: 1.340340] 
[Epoch 19/20] [Batch 114/274] [Batch classify loss: 1.118598] 
[Epoch 19/20] [Batch 115/274] [Batch classify loss: 0.861055] 
[Epoch 19/20] [Batch 116/274] [Batch classify loss: 1.215737] 
[Epoch 19/20] [Batch 117/274] [Batch classify loss: 0.986647] 
[Epoch 19/20] [Batch 118/274] [Batch classify loss: 1.161785] 
[Epoch 19/20] [Batch 119/274] [Batch classify loss: 1.373080] 
[Epoch 19/20] [Batch 120/274] [Batch classify loss: 1.317228] 
[Epoch 19/20] [Batch 121/274] [Batch classify loss: 1.243327] 
[Epoch 19/20] [Batch 122/274] [Batch classify loss: 1.035660] 
[Epoch 19/20] [Batch 123/274] [Batch classify loss: 1.566959] 
[Epoch 19/20] [Batch 124/274] [Batch classify loss: 1.338043] 
[Epoch 19/20] [Batch 125/274] [Batch classify loss: 1.463372] 
[Epoch 19/20] [Batch 126/274] [Batch classify loss: 1.028777] 
[Epoch 19/20] [Batch 127/274] [Batch classify loss: 0.946820] 
[Epoch 19/20] [Batch 128/274] [Batch classify loss: 1.336688] 
[Epoch 19/20] [Batch 129/274] [Batch classify loss: 1.514884] 
[Epoch 19/20] [Batch 130/274] [Batch classify loss: 1.120631] 
[Epoch 19/20] [Batch 131/274] [Batch classify loss: 1.159309] 
[Epoch 19/20] [Batch 132/274] [Batch classify loss: 1.249302] 
[Epoch 19/20] [Batch 133/274] [Batch classify loss: 1.228170] 
[Epoch 19/20] [Batch 134/274] [Batch classify loss: 1.064661] 
[Epoch 19/20] [Batch 135/274] [Batch classify loss: 0.939019] 
[Epoch 19/20] [Batch 136/274] [Batch classify loss: 1.476631] 
[Epoch 19/20] [Batch 137/274] [Batch classify loss: 1.008979] 
[Epoch 19/20] [Batch 138/274] [Batch classify loss: 1.158933] 
[Epoch 19/20] [Batch 139/274] [Batch classify loss: 1.109802] 
[Epoch 19/20] [Batch 140/274] [Batch classify loss: 1.042638] 
[Epoch 19/20] [Batch 141/274] [Batch classify loss: 0.771362] 
[Epoch 19/20] [Batch 142/274] [Batch classify loss: 1.002279] 
[Epoch 19/20] [Batch 143/274] [Batch classify loss: 1.020720] 
[Epoch 19/20] [Batch 144/274] [Batch classify loss: 1.090523] 
[Epoch 19/20] [Batch 145/274] [Batch classify loss: 1.019820] 
[Epoch 19/20] [Batch 146/274] [Batch classify loss: 0.939023] 
[Epoch 19/20] [Batch 147/274] [Batch classify loss: 0.989263] 
[Epoch 19/20] [Batch 148/274] [Batch classify loss: 1.077826] 
[Epoch 19/20] [Batch 149/274] [Batch classify loss: 0.946757] 
[Epoch 19/20] [Batch 150/274] [Batch classify loss: 0.935938] 
[Epoch 19/20] [Batch 151/274] [Batch classify loss: 0.787989] 
[Epoch 19/20] [Batch 152/274] [Batch classify loss: 0.988136] 
[Epoch 19/20] [Batch 153/274] [Batch classify loss: 1.079549] 
[Epoch 19/20] [Batch 154/274] [Batch classify loss: 1.203695] 
[Epoch 19/20] [Batch 155/274] [Batch classify loss: 0.882483] 
[Epoch 19/20] [Batch 156/274] [Batch classify loss: 1.038074] 
[Epoch 19/20] [Batch 157/274] [Batch classify loss: 0.981933] 
[Epoch 19/20] [Batch 158/274] [Batch classify loss: 1.328193] 
[Epoch 19/20] [Batch 159/274] [Batch classify loss: 1.156250] 
[Epoch 19/20] [Batch 160/274] [Batch classify loss: 1.264302] 
[Epoch 19/20] [Batch 161/274] [Batch classify loss: 1.021778] 
[Epoch 19/20] [Batch 162/274] [Batch classify loss: 0.952015] 
[Epoch 19/20] [Batch 163/274] [Batch classify loss: 1.230405] 
[Epoch 19/20] [Batch 164/274] [Batch classify loss: 0.954801] 
[Epoch 19/20] [Batch 165/274] [Batch classify loss: 0.813628] 
[Epoch 19/20] [Batch 166/274] [Batch classify loss: 1.365461] 
[Epoch 19/20] [Batch 167/274] [Batch classify loss: 1.077391] 
[Epoch 19/20] [Batch 168/274] [Batch classify loss: 0.603374] 
[Epoch 19/20] [Batch 169/274] [Batch classify loss: 1.043438] 
[Epoch 19/20] [Batch 170/274] [Batch classify loss: 0.857760] 
[Epoch 19/20] [Batch 171/274] [Batch classify loss: 1.082840] 
[Epoch 19/20] [Batch 172/274] [Batch classify loss: 0.949597] 
[Epoch 19/20] [Batch 173/274] [Batch classify loss: 0.812560] 
[Epoch 19/20] [Batch 174/274] [Batch classify loss: 0.804054] 
[Epoch 19/20] [Batch 175/274] [Batch classify loss: 1.079387] 
[Epoch 19/20] [Batch 176/274] [Batch classify loss: 0.878333] 
[Epoch 19/20] [Batch 177/274] [Batch classify loss: 1.088481] 
[Epoch 19/20] [Batch 178/274] [Batch classify loss: 0.952840] 
[Epoch 19/20] [Batch 179/274] [Batch classify loss: 1.448528] 
[Epoch 19/20] [Batch 180/274] [Batch classify loss: 1.279782] 
[Epoch 19/20] [Batch 181/274] [Batch classify loss: 0.867772] 
[Epoch 19/20] [Batch 182/274] [Batch classify loss: 0.888081] 
[Epoch 19/20] [Batch 183/274] [Batch classify loss: 0.819591] 
[Epoch 19/20] [Batch 184/274] [Batch classify loss: 0.870221] 
[Epoch 19/20] [Batch 185/274] [Batch classify loss: 0.983249] 
[Epoch 19/20] [Batch 186/274] [Batch classify loss: 0.900395] 
[Epoch 19/20] [Batch 187/274] [Batch classify loss: 0.791661] 
[Epoch 19/20] [Batch 188/274] [Batch classify loss: 0.859712] 
[Epoch 19/20] [Batch 189/274] [Batch classify loss: 0.887948] 
[Epoch 19/20] [Batch 190/274] [Batch classify loss: 0.785158] 
[Epoch 19/20] [Batch 191/274] [Batch classify loss: 0.907912] 
[Epoch 19/20] [Batch 192/274] [Batch classify loss: 0.852270] 
[Epoch 19/20] [Batch 193/274] [Batch classify loss: 0.964161] 
[Epoch 19/20] [Batch 194/274] [Batch classify loss: 0.754978] 
[Epoch 19/20] [Batch 195/274] [Batch classify loss: 0.816049] 
[Epoch 19/20] [Batch 196/274] [Batch classify loss: 0.930110] 
[Epoch 19/20] [Batch 197/274] [Batch classify loss: 0.836638] 
[Epoch 19/20] [Batch 198/274] [Batch classify loss: 0.814969] 
[Epoch 19/20] [Batch 199/274] [Batch classify loss: 0.948253] 
[Epoch 19/20] [Batch 200/274] [Batch classify loss: 1.000435] 
[Epoch 19/20] [Batch 201/274] [Batch classify loss: 1.056748] 
[Epoch 19/20] [Batch 202/274] [Batch classify loss: 0.982570] 
[Epoch 19/20] [Batch 203/274] [Batch classify loss: 0.785381] 
[Epoch 19/20] [Batch 204/274] [Batch classify loss: 1.051485] 
[Epoch 19/20] [Batch 205/274] [Batch classify loss: 0.978817] 
[Epoch 19/20] [Batch 206/274] [Batch classify loss: 1.057089] 
[Epoch 19/20] [Batch 207/274] [Batch classify loss: 0.661347] 
[Epoch 19/20] [Batch 208/274] [Batch classify loss: 0.767263] 
[Epoch 19/20] [Batch 209/274] [Batch classify loss: 1.128152] 
[Epoch 19/20] [Batch 210/274] [Batch classify loss: 0.725192] 
[Epoch 19/20] [Batch 211/274] [Batch classify loss: 0.736073] 
[Epoch 19/20] [Batch 212/274] [Batch classify loss: 1.740367] 
[Epoch 19/20] [Batch 213/274] [Batch classify loss: 0.740113] 
[Epoch 19/20] [Batch 214/274] [Batch classify loss: 0.831889] 
[Epoch 19/20] [Batch 215/274] [Batch classify loss: 0.678285] 
[Epoch 19/20] [Batch 216/274] [Batch classify loss: 0.889976] 
[Epoch 19/20] [Batch 217/274] [Batch classify loss: 0.958923] 
[Epoch 19/20] [Batch 218/274] [Batch classify loss: 0.617218] 
[Epoch 19/20] [Batch 219/274] [Batch classify loss: 0.776903] 
[Epoch 19/20] [Batch 220/274] [Batch classify loss: 0.955458] 
[Epoch 19/20] [Batch 221/274] [Batch classify loss: 0.660146] 
[Epoch 19/20] [Batch 222/274] [Batch classify loss: 0.914790] 
[Epoch 19/20] [Batch 223/274] [Batch classify loss: 0.864237] 
[Epoch 19/20] [Batch 224/274] [Batch classify loss: 0.941182] 
[Epoch 19/20] [Batch 225/274] [Batch classify loss: 0.700364] 
[Epoch 19/20] [Batch 226/274] [Batch classify loss: 0.999968] 
[Epoch 19/20] [Batch 227/274] [Batch classify loss: 1.179762] 
[Epoch 19/20] [Batch 228/274] [Batch classify loss: 1.212911] 
[Epoch 19/20] [Batch 229/274] [Batch classify loss: 0.882960] 
[Epoch 19/20] [Batch 230/274] [Batch classify loss: 0.797822] 
[Epoch 19/20] [Batch 231/274] [Batch classify loss: 0.647505] 
[Epoch 19/20] [Batch 232/274] [Batch classify loss: 0.738025] 
[Epoch 19/20] [Batch 233/274] [Batch classify loss: 0.717494] 
[Epoch 19/20] [Batch 234/274] [Batch classify loss: 1.164046] 
[Epoch 19/20] [Batch 235/274] [Batch classify loss: 0.908622] 
[Epoch 19/20] [Batch 236/274] [Batch classify loss: 0.824377] 
[Epoch 19/20] [Batch 237/274] [Batch classify loss: 0.732244] 
[Epoch 19/20] [Batch 238/274] [Batch classify loss: 0.976182] 
[Epoch 19/20] [Batch 239/274] [Batch classify loss: 0.837889] 
[Epoch 19/20] [Batch 240/274] [Batch classify loss: 0.842969] 
[Epoch 19/20] [Batch 241/274] [Batch classify loss: 1.031246] 
[Epoch 19/20] [Batch 242/274] [Batch classify loss: 0.818580] 
[Epoch 19/20] [Batch 243/274] [Batch classify loss: 0.700338] 
[Epoch 19/20] [Batch 244/274] [Batch classify loss: 0.692386] 
[Epoch 19/20] [Batch 245/274] [Batch classify loss: 0.744700] 
[Epoch 19/20] [Batch 246/274] [Batch classify loss: 0.996015] 
[Epoch 19/20] [Batch 247/274] [Batch classify loss: 0.836595] 
[Epoch 19/20] [Batch 248/274] [Batch classify loss: 0.780938] 
[Epoch 19/20] [Batch 249/274] [Batch classify loss: 0.837587] 
[Epoch 19/20] [Batch 250/274] [Batch classify loss: 0.887218] 
[Epoch 19/20] [Batch 251/274] [Batch classify loss: 0.722648] 
[Epoch 19/20] [Batch 252/274] [Batch classify loss: 0.687039] 
[Epoch 19/20] [Batch 253/274] [Batch classify loss: 0.933883] 
[Epoch 19/20] [Batch 254/274] [Batch classify loss: 0.866269] 
[Epoch 19/20] [Batch 255/274] [Batch classify loss: 0.823911] 
[Epoch 19/20] [Batch 256/274] [Batch classify loss: 0.794816] 
[Epoch 19/20] [Batch 257/274] [Batch classify loss: 0.740767] 
[Epoch 19/20] [Batch 258/274] [Batch classify loss: 1.042650] 
[Epoch 19/20] [Batch 259/274] [Batch classify loss: 0.888836] 
[Epoch 19/20] [Batch 260/274] [Batch classify loss: 0.578078] 
[Epoch 19/20] [Batch 261/274] [Batch classify loss: 0.569795] 
[Epoch 19/20] [Batch 262/274] [Batch classify loss: 0.859058] 
[Epoch 19/20] [Batch 263/274] [Batch classify loss: 0.845413] 
[Epoch 19/20] [Batch 264/274] [Batch classify loss: 0.725240] 
[Epoch 19/20] [Batch 265/274] [Batch classify loss: 0.788120] 
[Epoch 19/20] [Batch 266/274] [Batch classify loss: 0.616620] 
[Epoch 19/20] [Batch 267/274] [Batch classify loss: 0.795600] 
[Epoch 19/20] [Batch 268/274] [Batch classify loss: 0.653710] 
[Epoch 19/20] [Batch 269/274] [Batch classify loss: 0.700255] 
[Epoch 19/20] [Batch 270/274] [Batch classify loss: 0.554161] 
[Epoch 19/20] [Batch 271/274] [Batch classify loss: 0.664365] 
[Epoch 19/20] [Batch 272/274] [Batch classify loss: 0.649030] 
[Epoch 19/20] [Batch 273/274] [Batch classify loss: 1.029392] 
[Epoch 19/20] [Batch 274/274] [Batch classify loss: 1.234658] 
0019 epoch mmat trained classifier accuary on the clean testing examples:94.6335%
0019 epoch mmat trained classifier loss on the clean testing examples:0.2258
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3503%
mmat trained classifier loss on adversarial testset:4.529442310333252
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
19epoch learning rate:0.001
[Epoch 20/20] [Batch 1/274] [Batch classify loss: 3.205583] 
[Epoch 20/20] [Batch 2/274] [Batch classify loss: 3.307028] 
[Epoch 20/20] [Batch 3/274] [Batch classify loss: 3.151091] 
[Epoch 20/20] [Batch 4/274] [Batch classify loss: 3.139071] 
[Epoch 20/20] [Batch 5/274] [Batch classify loss: 3.145550] 
[Epoch 20/20] [Batch 6/274] [Batch classify loss: 3.098522] 
[Epoch 20/20] [Batch 7/274] [Batch classify loss: 3.144773] 
[Epoch 20/20] [Batch 8/274] [Batch classify loss: 3.269460] 
[Epoch 20/20] [Batch 9/274] [Batch classify loss: 3.238480] 
[Epoch 20/20] [Batch 10/274] [Batch classify loss: 3.139876] 
[Epoch 20/20] [Batch 11/274] [Batch classify loss: 3.047105] 
[Epoch 20/20] [Batch 12/274] [Batch classify loss: 2.964579] 
[Epoch 20/20] [Batch 13/274] [Batch classify loss: 2.889060] 
[Epoch 20/20] [Batch 14/274] [Batch classify loss: 3.239751] 
[Epoch 20/20] [Batch 15/274] [Batch classify loss: 2.686849] 
[Epoch 20/20] [Batch 16/274] [Batch classify loss: 2.492757] 
[Epoch 20/20] [Batch 17/274] [Batch classify loss: 2.920674] 
[Epoch 20/20] [Batch 18/274] [Batch classify loss: 3.070715] 
[Epoch 20/20] [Batch 19/274] [Batch classify loss: 2.646870] 
[Epoch 20/20] [Batch 20/274] [Batch classify loss: 2.724015] 
[Epoch 20/20] [Batch 21/274] [Batch classify loss: 2.481200] 
[Epoch 20/20] [Batch 22/274] [Batch classify loss: 2.554476] 
[Epoch 20/20] [Batch 23/274] [Batch classify loss: 2.090549] 
[Epoch 20/20] [Batch 24/274] [Batch classify loss: 2.331908] 
[Epoch 20/20] [Batch 25/274] [Batch classify loss: 2.690637] 
[Epoch 20/20] [Batch 26/274] [Batch classify loss: 1.995812] 
[Epoch 20/20] [Batch 27/274] [Batch classify loss: 3.135236] 
[Epoch 20/20] [Batch 28/274] [Batch classify loss: 2.556817] 
[Epoch 20/20] [Batch 29/274] [Batch classify loss: 2.635779] 
[Epoch 20/20] [Batch 30/274] [Batch classify loss: 2.027245] 
[Epoch 20/20] [Batch 31/274] [Batch classify loss: 2.126554] 
[Epoch 20/20] [Batch 32/274] [Batch classify loss: 2.543351] 
[Epoch 20/20] [Batch 33/274] [Batch classify loss: 2.293353] 
[Epoch 20/20] [Batch 34/274] [Batch classify loss: 2.278899] 
[Epoch 20/20] [Batch 35/274] [Batch classify loss: 2.206529] 
[Epoch 20/20] [Batch 36/274] [Batch classify loss: 2.438924] 
[Epoch 20/20] [Batch 37/274] [Batch classify loss: 1.948860] 
[Epoch 20/20] [Batch 38/274] [Batch classify loss: 2.456023] 
[Epoch 20/20] [Batch 39/274] [Batch classify loss: 2.098478] 
[Epoch 20/20] [Batch 40/274] [Batch classify loss: 2.363882] 
[Epoch 20/20] [Batch 41/274] [Batch classify loss: 2.796321] 
[Epoch 20/20] [Batch 42/274] [Batch classify loss: 2.592532] 
[Epoch 20/20] [Batch 43/274] [Batch classify loss: 2.831938] 
[Epoch 20/20] [Batch 44/274] [Batch classify loss: 2.171004] 
[Epoch 20/20] [Batch 45/274] [Batch classify loss: 2.264347] 
[Epoch 20/20] [Batch 46/274] [Batch classify loss: 2.129692] 
[Epoch 20/20] [Batch 47/274] [Batch classify loss: 1.898196] 
[Epoch 20/20] [Batch 48/274] [Batch classify loss: 2.510285] 
[Epoch 20/20] [Batch 49/274] [Batch classify loss: 2.249469] 
[Epoch 20/20] [Batch 50/274] [Batch classify loss: 2.116035] 
[Epoch 20/20] [Batch 51/274] [Batch classify loss: 1.912594] 
[Epoch 20/20] [Batch 52/274] [Batch classify loss: 2.308235] 
[Epoch 20/20] [Batch 53/274] [Batch classify loss: 2.290616] 
[Epoch 20/20] [Batch 54/274] [Batch classify loss: 2.367283] 
[Epoch 20/20] [Batch 55/274] [Batch classify loss: 2.440804] 
[Epoch 20/20] [Batch 56/274] [Batch classify loss: 2.335984] 
[Epoch 20/20] [Batch 57/274] [Batch classify loss: 2.195715] 
[Epoch 20/20] [Batch 58/274] [Batch classify loss: 2.771320] 
[Epoch 20/20] [Batch 59/274] [Batch classify loss: 2.046559] 
[Epoch 20/20] [Batch 60/274] [Batch classify loss: 1.856252] 
[Epoch 20/20] [Batch 61/274] [Batch classify loss: 2.043905] 
[Epoch 20/20] [Batch 62/274] [Batch classify loss: 2.345065] 
[Epoch 20/20] [Batch 63/274] [Batch classify loss: 2.096938] 
[Epoch 20/20] [Batch 64/274] [Batch classify loss: 1.801251] 
[Epoch 20/20] [Batch 65/274] [Batch classify loss: 1.642679] 
[Epoch 20/20] [Batch 66/274] [Batch classify loss: 2.069129] 
[Epoch 20/20] [Batch 67/274] [Batch classify loss: 2.020320] 
[Epoch 20/20] [Batch 68/274] [Batch classify loss: 2.619779] 
[Epoch 20/20] [Batch 69/274] [Batch classify loss: 2.064458] 
[Epoch 20/20] [Batch 70/274] [Batch classify loss: 2.210102] 
[Epoch 20/20] [Batch 71/274] [Batch classify loss: 2.157749] 
[Epoch 20/20] [Batch 72/274] [Batch classify loss: 1.587292] 
[Epoch 20/20] [Batch 73/274] [Batch classify loss: 2.136439] 
[Epoch 20/20] [Batch 74/274] [Batch classify loss: 2.149148] 
[Epoch 20/20] [Batch 75/274] [Batch classify loss: 1.909534] 
[Epoch 20/20] [Batch 76/274] [Batch classify loss: 1.540459] 
[Epoch 20/20] [Batch 77/274] [Batch classify loss: 2.058664] 
[Epoch 20/20] [Batch 78/274] [Batch classify loss: 1.945431] 
[Epoch 20/20] [Batch 79/274] [Batch classify loss: 1.893589] 
[Epoch 20/20] [Batch 80/274] [Batch classify loss: 2.175880] 
[Epoch 20/20] [Batch 81/274] [Batch classify loss: 1.513796] 
[Epoch 20/20] [Batch 82/274] [Batch classify loss: 1.888198] 
[Epoch 20/20] [Batch 83/274] [Batch classify loss: 1.956296] 
[Epoch 20/20] [Batch 84/274] [Batch classify loss: 1.510101] 
[Epoch 20/20] [Batch 85/274] [Batch classify loss: 2.011933] 
[Epoch 20/20] [Batch 86/274] [Batch classify loss: 2.088062] 
[Epoch 20/20] [Batch 87/274] [Batch classify loss: 2.543953] 
[Epoch 20/20] [Batch 88/274] [Batch classify loss: 2.109428] 
[Epoch 20/20] [Batch 89/274] [Batch classify loss: 1.375029] 
[Epoch 20/20] [Batch 90/274] [Batch classify loss: 1.735235] 
[Epoch 20/20] [Batch 91/274] [Batch classify loss: 1.514536] 
[Epoch 20/20] [Batch 92/274] [Batch classify loss: 1.620709] 
[Epoch 20/20] [Batch 93/274] [Batch classify loss: 2.107263] 
[Epoch 20/20] [Batch 94/274] [Batch classify loss: 1.908569] 
[Epoch 20/20] [Batch 95/274] [Batch classify loss: 1.964692] 
[Epoch 20/20] [Batch 96/274] [Batch classify loss: 1.822659] 
[Epoch 20/20] [Batch 97/274] [Batch classify loss: 1.814424] 
[Epoch 20/20] [Batch 98/274] [Batch classify loss: 1.571397] 
[Epoch 20/20] [Batch 99/274] [Batch classify loss: 2.005893] 
[Epoch 20/20] [Batch 100/274] [Batch classify loss: 1.408017] 
[Epoch 20/20] [Batch 101/274] [Batch classify loss: 1.685030] 
[Epoch 20/20] [Batch 102/274] [Batch classify loss: 1.355564] 
[Epoch 20/20] [Batch 103/274] [Batch classify loss: 1.566622] 
[Epoch 20/20] [Batch 104/274] [Batch classify loss: 1.991369] 
[Epoch 20/20] [Batch 105/274] [Batch classify loss: 2.051461] 
[Epoch 20/20] [Batch 106/274] [Batch classify loss: 1.218328] 
[Epoch 20/20] [Batch 107/274] [Batch classify loss: 2.041735] 
[Epoch 20/20] [Batch 108/274] [Batch classify loss: 1.477466] 
[Epoch 20/20] [Batch 109/274] [Batch classify loss: 1.558582] 
[Epoch 20/20] [Batch 110/274] [Batch classify loss: 2.162516] 
[Epoch 20/20] [Batch 111/274] [Batch classify loss: 1.412890] 
[Epoch 20/20] [Batch 112/274] [Batch classify loss: 1.948746] 
[Epoch 20/20] [Batch 113/274] [Batch classify loss: 1.773700] 
[Epoch 20/20] [Batch 114/274] [Batch classify loss: 1.564788] 
[Epoch 20/20] [Batch 115/274] [Batch classify loss: 1.258000] 
[Epoch 20/20] [Batch 116/274] [Batch classify loss: 1.667368] 
[Epoch 20/20] [Batch 117/274] [Batch classify loss: 1.644741] 
[Epoch 20/20] [Batch 118/274] [Batch classify loss: 2.103619] 
[Epoch 20/20] [Batch 119/274] [Batch classify loss: 1.461377] 
[Epoch 20/20] [Batch 120/274] [Batch classify loss: 1.631441] 
[Epoch 20/20] [Batch 121/274] [Batch classify loss: 1.543031] 
[Epoch 20/20] [Batch 122/274] [Batch classify loss: 1.906887] 
[Epoch 20/20] [Batch 123/274] [Batch classify loss: 1.427464] 
[Epoch 20/20] [Batch 124/274] [Batch classify loss: 1.495592] 
[Epoch 20/20] [Batch 125/274] [Batch classify loss: 1.724118] 
[Epoch 20/20] [Batch 126/274] [Batch classify loss: 1.943652] 
[Epoch 20/20] [Batch 127/274] [Batch classify loss: 1.826648] 
[Epoch 20/20] [Batch 128/274] [Batch classify loss: 1.928961] 
[Epoch 20/20] [Batch 129/274] [Batch classify loss: 1.805545] 
[Epoch 20/20] [Batch 130/274] [Batch classify loss: 1.545014] 
[Epoch 20/20] [Batch 131/274] [Batch classify loss: 1.389520] 
[Epoch 20/20] [Batch 132/274] [Batch classify loss: 1.420850] 
[Epoch 20/20] [Batch 133/274] [Batch classify loss: 1.354929] 
[Epoch 20/20] [Batch 134/274] [Batch classify loss: 1.621268] 
[Epoch 20/20] [Batch 135/274] [Batch classify loss: 1.416930] 
[Epoch 20/20] [Batch 136/274] [Batch classify loss: 2.140632] 
[Epoch 20/20] [Batch 137/274] [Batch classify loss: 1.161972] 
[Epoch 20/20] [Batch 138/274] [Batch classify loss: 1.694386] 
[Epoch 20/20] [Batch 139/274] [Batch classify loss: 1.727907] 
[Epoch 20/20] [Batch 140/274] [Batch classify loss: 1.663786] 
[Epoch 20/20] [Batch 141/274] [Batch classify loss: 1.428129] 
[Epoch 20/20] [Batch 142/274] [Batch classify loss: 1.665790] 
[Epoch 20/20] [Batch 143/274] [Batch classify loss: 1.501168] 
[Epoch 20/20] [Batch 144/274] [Batch classify loss: 1.958130] 
[Epoch 20/20] [Batch 145/274] [Batch classify loss: 1.197940] 
[Epoch 20/20] [Batch 146/274] [Batch classify loss: 1.553586] 
[Epoch 20/20] [Batch 147/274] [Batch classify loss: 1.551945] 
[Epoch 20/20] [Batch 148/274] [Batch classify loss: 2.058617] 
[Epoch 20/20] [Batch 149/274] [Batch classify loss: 1.414401] 
[Epoch 20/20] [Batch 150/274] [Batch classify loss: 1.102623] 
[Epoch 20/20] [Batch 151/274] [Batch classify loss: 1.298244] 
[Epoch 20/20] [Batch 152/274] [Batch classify loss: 1.132912] 
[Epoch 20/20] [Batch 153/274] [Batch classify loss: 1.451030] 
[Epoch 20/20] [Batch 154/274] [Batch classify loss: 1.496215] 
[Epoch 20/20] [Batch 155/274] [Batch classify loss: 1.760033] 
[Epoch 20/20] [Batch 156/274] [Batch classify loss: 1.359635] 
[Epoch 20/20] [Batch 157/274] [Batch classify loss: 1.505270] 
[Epoch 20/20] [Batch 158/274] [Batch classify loss: 1.583059] 
[Epoch 20/20] [Batch 159/274] [Batch classify loss: 1.527245] 
[Epoch 20/20] [Batch 160/274] [Batch classify loss: 1.306090] 
[Epoch 20/20] [Batch 161/274] [Batch classify loss: 1.558406] 
[Epoch 20/20] [Batch 162/274] [Batch classify loss: 1.489039] 
[Epoch 20/20] [Batch 163/274] [Batch classify loss: 1.353415] 
[Epoch 20/20] [Batch 164/274] [Batch classify loss: 1.216813] 
[Epoch 20/20] [Batch 165/274] [Batch classify loss: 1.528477] 
[Epoch 20/20] [Batch 166/274] [Batch classify loss: 1.428427] 
[Epoch 20/20] [Batch 167/274] [Batch classify loss: 1.155200] 
[Epoch 20/20] [Batch 168/274] [Batch classify loss: 1.611347] 
[Epoch 20/20] [Batch 169/274] [Batch classify loss: 1.692103] 
[Epoch 20/20] [Batch 170/274] [Batch classify loss: 1.314071] 
[Epoch 20/20] [Batch 171/274] [Batch classify loss: 1.331866] 
[Epoch 20/20] [Batch 172/274] [Batch classify loss: 1.185608] 
[Epoch 20/20] [Batch 173/274] [Batch classify loss: 2.183907] 
[Epoch 20/20] [Batch 174/274] [Batch classify loss: 1.409776] 
[Epoch 20/20] [Batch 175/274] [Batch classify loss: 1.172597] 
[Epoch 20/20] [Batch 176/274] [Batch classify loss: 1.551243] 
[Epoch 20/20] [Batch 177/274] [Batch classify loss: 1.126337] 
[Epoch 20/20] [Batch 178/274] [Batch classify loss: 1.204636] 
[Epoch 20/20] [Batch 179/274] [Batch classify loss: 1.898568] 
[Epoch 20/20] [Batch 180/274] [Batch classify loss: 1.629863] 
[Epoch 20/20] [Batch 181/274] [Batch classify loss: 1.438260] 
[Epoch 20/20] [Batch 182/274] [Batch classify loss: 1.273953] 
[Epoch 20/20] [Batch 183/274] [Batch classify loss: 1.308462] 
[Epoch 20/20] [Batch 184/274] [Batch classify loss: 1.146400] 
[Epoch 20/20] [Batch 185/274] [Batch classify loss: 1.538706] 
[Epoch 20/20] [Batch 186/274] [Batch classify loss: 1.274131] 
[Epoch 20/20] [Batch 187/274] [Batch classify loss: 1.891931] 
[Epoch 20/20] [Batch 188/274] [Batch classify loss: 1.687938] 
[Epoch 20/20] [Batch 189/274] [Batch classify loss: 1.442049] 
[Epoch 20/20] [Batch 190/274] [Batch classify loss: 1.374177] 
[Epoch 20/20] [Batch 191/274] [Batch classify loss: 1.428917] 
[Epoch 20/20] [Batch 192/274] [Batch classify loss: 1.545846] 
[Epoch 20/20] [Batch 193/274] [Batch classify loss: 0.973537] 
[Epoch 20/20] [Batch 194/274] [Batch classify loss: 1.610262] 
[Epoch 20/20] [Batch 195/274] [Batch classify loss: 1.125597] 
[Epoch 20/20] [Batch 196/274] [Batch classify loss: 1.464898] 
[Epoch 20/20] [Batch 197/274] [Batch classify loss: 1.362926] 
[Epoch 20/20] [Batch 198/274] [Batch classify loss: 1.326308] 
[Epoch 20/20] [Batch 199/274] [Batch classify loss: 1.327235] 
[Epoch 20/20] [Batch 200/274] [Batch classify loss: 1.277352] 
[Epoch 20/20] [Batch 201/274] [Batch classify loss: 1.431650] 
[Epoch 20/20] [Batch 202/274] [Batch classify loss: 1.002393] 
[Epoch 20/20] [Batch 203/274] [Batch classify loss: 1.610209] 
[Epoch 20/20] [Batch 204/274] [Batch classify loss: 1.126629] 
[Epoch 20/20] [Batch 205/274] [Batch classify loss: 1.502007] 
[Epoch 20/20] [Batch 206/274] [Batch classify loss: 1.523001] 
[Epoch 20/20] [Batch 207/274] [Batch classify loss: 1.599677] 
[Epoch 20/20] [Batch 208/274] [Batch classify loss: 1.504299] 
[Epoch 20/20] [Batch 209/274] [Batch classify loss: 1.418271] 
[Epoch 20/20] [Batch 210/274] [Batch classify loss: 1.167895] 
[Epoch 20/20] [Batch 211/274] [Batch classify loss: 1.556234] 
[Epoch 20/20] [Batch 212/274] [Batch classify loss: 1.174456] 
[Epoch 20/20] [Batch 213/274] [Batch classify loss: 1.435858] 
[Epoch 20/20] [Batch 214/274] [Batch classify loss: 1.426370] 
[Epoch 20/20] [Batch 215/274] [Batch classify loss: 1.062374] 
[Epoch 20/20] [Batch 216/274] [Batch classify loss: 1.177385] 
[Epoch 20/20] [Batch 217/274] [Batch classify loss: 1.074783] 
[Epoch 20/20] [Batch 218/274] [Batch classify loss: 1.082897] 
[Epoch 20/20] [Batch 219/274] [Batch classify loss: 1.133501] 
[Epoch 20/20] [Batch 220/274] [Batch classify loss: 1.049253] 
[Epoch 20/20] [Batch 221/274] [Batch classify loss: 1.203965] 
[Epoch 20/20] [Batch 222/274] [Batch classify loss: 1.262296] 
[Epoch 20/20] [Batch 223/274] [Batch classify loss: 1.361982] 
[Epoch 20/20] [Batch 224/274] [Batch classify loss: 1.495642] 
[Epoch 20/20] [Batch 225/274] [Batch classify loss: 1.229939] 
[Epoch 20/20] [Batch 226/274] [Batch classify loss: 1.225213] 
[Epoch 20/20] [Batch 227/274] [Batch classify loss: 1.267596] 
[Epoch 20/20] [Batch 228/274] [Batch classify loss: 1.327882] 
[Epoch 20/20] [Batch 229/274] [Batch classify loss: 1.257450] 
[Epoch 20/20] [Batch 230/274] [Batch classify loss: 1.236656] 
[Epoch 20/20] [Batch 231/274] [Batch classify loss: 1.077116] 
[Epoch 20/20] [Batch 232/274] [Batch classify loss: 0.999411] 
[Epoch 20/20] [Batch 233/274] [Batch classify loss: 1.111623] 
[Epoch 20/20] [Batch 234/274] [Batch classify loss: 1.490021] 
[Epoch 20/20] [Batch 235/274] [Batch classify loss: 1.186467] 
[Epoch 20/20] [Batch 236/274] [Batch classify loss: 1.180229] 
[Epoch 20/20] [Batch 237/274] [Batch classify loss: 1.276522] 
[Epoch 20/20] [Batch 238/274] [Batch classify loss: 1.196138] 
[Epoch 20/20] [Batch 239/274] [Batch classify loss: 1.375926] 
[Epoch 20/20] [Batch 240/274] [Batch classify loss: 1.296154] 
[Epoch 20/20] [Batch 241/274] [Batch classify loss: 1.054203] 
[Epoch 20/20] [Batch 242/274] [Batch classify loss: 1.038456] 
[Epoch 20/20] [Batch 243/274] [Batch classify loss: 1.202018] 
[Epoch 20/20] [Batch 244/274] [Batch classify loss: 1.242073] 
[Epoch 20/20] [Batch 245/274] [Batch classify loss: 1.210333] 
[Epoch 20/20] [Batch 246/274] [Batch classify loss: 1.129865] 
[Epoch 20/20] [Batch 247/274] [Batch classify loss: 1.171089] 
[Epoch 20/20] [Batch 248/274] [Batch classify loss: 1.462382] 
[Epoch 20/20] [Batch 249/274] [Batch classify loss: 1.264800] 
[Epoch 20/20] [Batch 250/274] [Batch classify loss: 1.369136] 
[Epoch 20/20] [Batch 251/274] [Batch classify loss: 1.027969] 
[Epoch 20/20] [Batch 252/274] [Batch classify loss: 1.229196] 
[Epoch 20/20] [Batch 253/274] [Batch classify loss: 0.875726] 
[Epoch 20/20] [Batch 254/274] [Batch classify loss: 1.260823] 
[Epoch 20/20] [Batch 255/274] [Batch classify loss: 1.149656] 
[Epoch 20/20] [Batch 256/274] [Batch classify loss: 1.613824] 
[Epoch 20/20] [Batch 257/274] [Batch classify loss: 1.201542] 
[Epoch 20/20] [Batch 258/274] [Batch classify loss: 1.181114] 
[Epoch 20/20] [Batch 259/274] [Batch classify loss: 1.379458] 
[Epoch 20/20] [Batch 260/274] [Batch classify loss: 0.851875] 
[Epoch 20/20] [Batch 261/274] [Batch classify loss: 1.172405] 
[Epoch 20/20] [Batch 262/274] [Batch classify loss: 1.142663] 
[Epoch 20/20] [Batch 263/274] [Batch classify loss: 1.112115] 
[Epoch 20/20] [Batch 264/274] [Batch classify loss: 1.206305] 
[Epoch 20/20] [Batch 265/274] [Batch classify loss: 1.731856] 
[Epoch 20/20] [Batch 266/274] [Batch classify loss: 1.047113] 
[Epoch 20/20] [Batch 267/274] [Batch classify loss: 1.262450] 
[Epoch 20/20] [Batch 268/274] [Batch classify loss: 1.231156] 
[Epoch 20/20] [Batch 269/274] [Batch classify loss: 1.194965] 
[Epoch 20/20] [Batch 270/274] [Batch classify loss: 1.025071] 
[Epoch 20/20] [Batch 271/274] [Batch classify loss: 1.210695] 
[Epoch 20/20] [Batch 272/274] [Batch classify loss: 1.048994] 
[Epoch 20/20] [Batch 273/274] [Batch classify loss: 1.148852] 
[Epoch 20/20] [Batch 274/274] [Batch classify loss: 1.228202] 
0020 epoch mmat trained classifier accuary on the clean testing examples:94.5913%
0020 epoch mmat trained classifier loss on the clean testing examples:0.2257
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3657%
mmat trained classifier loss on adversarial testset:4.512153148651123
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00002/mmat-svhn-dataset/tensorboard-log-run-acc-cle
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.0392%
mmat trained classifier loss on adversarial testset:4.547910690307617
mmat trained classifier accuary on clean testset:94.6950%
mmat trained classifier loss on clean testset:0.22094060480594635
---------------------------------------




---------------------------------------
Torch cuda is available
args.subcommand=run, run the command line
date: 20210919
Experiment result save dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003
initilize the dataset loading parameters
Using downloaded and verified file: /home/data/maggie/svhn/train_32x32.mat
Loading *svhn* train dataloader finished !
Loading *svhn* test dataloader finished !
initlize classifier
learned calssify model != None
standard trained classifier *accuary* on adversarial testset:40.2428%
standard trained classifier *accuary* on clean testset:94.7680%
gen_network_pkl:  abc test
load mixed sampels from /home/maggie/mmat/result/interpolate/2mixup/basemixup/uniformsampler/stylegan2ada-svhn/20210917/00000/generate-svhn-trainset
共使用 70000 个混合样本
*only using mixed samples*
aug_x_train.shape: (70000, 3, 32, 32)
aug_y_train.shape: (70000, 10)
use 0/70000 clean sampels，70000/70000 mixed samples
/home/maggie/mmat/clamodels/classifier.py:900: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._adv_test_tensorset_x = torch.tensor(x_test_adv)
/home/maggie/mmat/clamodels/classifier.py:901: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._adv_test_tensorset_y = torch.tensor(y_test_adv)
/home/maggie/mmat/clamodels/classifier.py:903: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._cle_test_tensorset_x = torch.tensor(cle_x_test)
/home/maggie/mmat/clamodels/classifier.py:904: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._cle_test_tensorset_y = torch.tensor(cle_y_test)
self._train_tensorset_x.shape: torch.Size([70000, 3, 32, 32])
self._train_tensorset_y.shape: torch.Size([70000, 10])
self._adv_test_tensorset_x.shape: torch.Size([26032, 3, 32, 32])
self._adv_test_tensorset_y.shape: torch.Size([26032])
self._cle_test_tensorset_x.shape: torch.Size([26032, 3, 32, 32])
self._cle_test_tensorset_y.shape: torch.Size([26032])
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
before mmat trained classifier accuary on adversarial testset:40.3388%
before mmat trained classifier loss on adversarial testset:4.503713607788086
0epoch learning rate:0.01
[Epoch 1/10] [Batch 1/274] [Batch classify loss: 4.113704] 
[Epoch 1/10] [Batch 2/274] [Batch classify loss: 4.762085] 
[Epoch 1/10] [Batch 3/274] [Batch classify loss: 4.892362] 
[Epoch 1/10] [Batch 4/274] [Batch classify loss: 4.799680] 
[Epoch 1/10] [Batch 5/274] [Batch classify loss: 4.426888] 
[Epoch 1/10] [Batch 6/274] [Batch classify loss: 4.651165] 
[Epoch 1/10] [Batch 7/274] [Batch classify loss: 4.557883] 
[Epoch 1/10] [Batch 8/274] [Batch classify loss: 4.456572] 
[Epoch 1/10] [Batch 9/274] [Batch classify loss: 4.482109] 
[Epoch 1/10] [Batch 10/274] [Batch classify loss: 5.098693] 
[Epoch 1/10] [Batch 11/274] [Batch classify loss: 4.629975] 
[Epoch 1/10] [Batch 12/274] [Batch classify loss: 4.438836] 
[Epoch 1/10] [Batch 13/274] [Batch classify loss: 4.386532] 
[Epoch 1/10] [Batch 14/274] [Batch classify loss: 4.495479] 
[Epoch 1/10] [Batch 15/274] [Batch classify loss: 4.774907] 
[Epoch 1/10] [Batch 16/274] [Batch classify loss: 4.502342] 
[Epoch 1/10] [Batch 17/274] [Batch classify loss: 4.436411] 
[Epoch 1/10] [Batch 18/274] [Batch classify loss: 4.646335] 
[Epoch 1/10] [Batch 19/274] [Batch classify loss: 4.679999] 
[Epoch 1/10] [Batch 20/274] [Batch classify loss: 5.041615] 
[Epoch 1/10] [Batch 21/274] [Batch classify loss: 4.789869] 
[Epoch 1/10] [Batch 22/274] [Batch classify loss: 4.547832] 
[Epoch 1/10] [Batch 23/274] [Batch classify loss: 4.427624] 
[Epoch 1/10] [Batch 24/274] [Batch classify loss: 4.857860] 
[Epoch 1/10] [Batch 25/274] [Batch classify loss: 4.674476] 
[Epoch 1/10] [Batch 26/274] [Batch classify loss: 4.337509] 
[Epoch 1/10] [Batch 27/274] [Batch classify loss: 4.632949] 
[Epoch 1/10] [Batch 28/274] [Batch classify loss: 5.613912] 
[Epoch 1/10] [Batch 29/274] [Batch classify loss: 4.325914] 
[Epoch 1/10] [Batch 30/274] [Batch classify loss: 4.365630] 
[Epoch 1/10] [Batch 31/274] [Batch classify loss: 4.859488] 
[Epoch 1/10] [Batch 32/274] [Batch classify loss: 4.307254] 
[Epoch 1/10] [Batch 33/274] [Batch classify loss: 4.471034] 
[Epoch 1/10] [Batch 34/274] [Batch classify loss: 4.749724] 
[Epoch 1/10] [Batch 35/274] [Batch classify loss: 4.354803] 
[Epoch 1/10] [Batch 36/274] [Batch classify loss: 4.452426] 
[Epoch 1/10] [Batch 37/274] [Batch classify loss: 4.614628] 
[Epoch 1/10] [Batch 38/274] [Batch classify loss: 4.064366] 
[Epoch 1/10] [Batch 39/274] [Batch classify loss: 3.941991] 
[Epoch 1/10] [Batch 40/274] [Batch classify loss: 4.132197] 
[Epoch 1/10] [Batch 41/274] [Batch classify loss: 4.589975] 
[Epoch 1/10] [Batch 42/274] [Batch classify loss: 4.222359] 
[Epoch 1/10] [Batch 43/274] [Batch classify loss: 4.097888] 
[Epoch 1/10] [Batch 44/274] [Batch classify loss: 4.283453] 
[Epoch 1/10] [Batch 45/274] [Batch classify loss: 4.289299] 
[Epoch 1/10] [Batch 46/274] [Batch classify loss: 4.044702] 
[Epoch 1/10] [Batch 47/274] [Batch classify loss: 3.987211] 
[Epoch 1/10] [Batch 48/274] [Batch classify loss: 4.176278] 
[Epoch 1/10] [Batch 49/274] [Batch classify loss: 4.581204] 
[Epoch 1/10] [Batch 50/274] [Batch classify loss: 4.307640] 
[Epoch 1/10] [Batch 51/274] [Batch classify loss: 4.684436] 
[Epoch 1/10] [Batch 52/274] [Batch classify loss: 4.469035] 
[Epoch 1/10] [Batch 53/274] [Batch classify loss: 4.340258] 
[Epoch 1/10] [Batch 54/274] [Batch classify loss: 4.054614] 
[Epoch 1/10] [Batch 55/274] [Batch classify loss: 4.287469] 
[Epoch 1/10] [Batch 56/274] [Batch classify loss: 4.156672] 
[Epoch 1/10] [Batch 57/274] [Batch classify loss: 4.009271] 
[Epoch 1/10] [Batch 58/274] [Batch classify loss: 4.591765] 
[Epoch 1/10] [Batch 59/274] [Batch classify loss: 4.244154] 
[Epoch 1/10] [Batch 60/274] [Batch classify loss: 3.828138] 
[Epoch 1/10] [Batch 61/274] [Batch classify loss: 4.613585] 
[Epoch 1/10] [Batch 62/274] [Batch classify loss: 4.144888] 
[Epoch 1/10] [Batch 63/274] [Batch classify loss: 4.217005] 
[Epoch 1/10] [Batch 64/274] [Batch classify loss: 4.497869] 
[Epoch 1/10] [Batch 65/274] [Batch classify loss: 4.055396] 
[Epoch 1/10] [Batch 66/274] [Batch classify loss: 4.157195] 
[Epoch 1/10] [Batch 67/274] [Batch classify loss: 3.695532] 
[Epoch 1/10] [Batch 68/274] [Batch classify loss: 4.436130] 
[Epoch 1/10] [Batch 69/274] [Batch classify loss: 3.848982] 
[Epoch 1/10] [Batch 70/274] [Batch classify loss: 4.262346] 
[Epoch 1/10] [Batch 71/274] [Batch classify loss: 4.452664] 
[Epoch 1/10] [Batch 72/274] [Batch classify loss: 4.195872] 
[Epoch 1/10] [Batch 73/274] [Batch classify loss: 3.906045] 
[Epoch 1/10] [Batch 74/274] [Batch classify loss: 3.997530] 
[Epoch 1/10] [Batch 75/274] [Batch classify loss: 4.212832] 
[Epoch 1/10] [Batch 76/274] [Batch classify loss: 3.980268] 
[Epoch 1/10] [Batch 77/274] [Batch classify loss: 4.473658] 
[Epoch 1/10] [Batch 78/274] [Batch classify loss: 4.101443] 
[Epoch 1/10] [Batch 79/274] [Batch classify loss: 4.331854] 
[Epoch 1/10] [Batch 80/274] [Batch classify loss: 3.988196] 
[Epoch 1/10] [Batch 81/274] [Batch classify loss: 4.206409] 
[Epoch 1/10] [Batch 82/274] [Batch classify loss: 4.070832] 
[Epoch 1/10] [Batch 83/274] [Batch classify loss: 3.615724] 
[Epoch 1/10] [Batch 84/274] [Batch classify loss: 4.085890] 
[Epoch 1/10] [Batch 85/274] [Batch classify loss: 4.014735] 
[Epoch 1/10] [Batch 86/274] [Batch classify loss: 3.934979] 
[Epoch 1/10] [Batch 87/274] [Batch classify loss: 4.042114] 
[Epoch 1/10] [Batch 88/274] [Batch classify loss: 4.162923] 
[Epoch 1/10] [Batch 89/274] [Batch classify loss: 4.461062] 
[Epoch 1/10] [Batch 90/274] [Batch classify loss: 3.720803] 
[Epoch 1/10] [Batch 91/274] [Batch classify loss: 3.735385] 
[Epoch 1/10] [Batch 92/274] [Batch classify loss: 4.351231] 
[Epoch 1/10] [Batch 93/274] [Batch classify loss: 3.866797] 
[Epoch 1/10] [Batch 94/274] [Batch classify loss: 4.187663] 
[Epoch 1/10] [Batch 95/274] [Batch classify loss: 3.680973] 
[Epoch 1/10] [Batch 96/274] [Batch classify loss: 3.924305] 
[Epoch 1/10] [Batch 97/274] [Batch classify loss: 3.943187] 
[Epoch 1/10] [Batch 98/274] [Batch classify loss: 4.044360] 
[Epoch 1/10] [Batch 99/274] [Batch classify loss: 3.576984] 
[Epoch 1/10] [Batch 100/274] [Batch classify loss: 4.217474] 
[Epoch 1/10] [Batch 101/274] [Batch classify loss: 3.944322] 
[Epoch 1/10] [Batch 102/274] [Batch classify loss: 4.573620] 
[Epoch 1/10] [Batch 103/274] [Batch classify loss: 4.059822] 
[Epoch 1/10] [Batch 104/274] [Batch classify loss: 3.845167] 
[Epoch 1/10] [Batch 105/274] [Batch classify loss: 3.860788] 
[Epoch 1/10] [Batch 106/274] [Batch classify loss: 3.595849] 
[Epoch 1/10] [Batch 107/274] [Batch classify loss: 3.643419] 
[Epoch 1/10] [Batch 108/274] [Batch classify loss: 3.882351] 
[Epoch 1/10] [Batch 109/274] [Batch classify loss: 3.796298] 
[Epoch 1/10] [Batch 110/274] [Batch classify loss: 4.314030] 
[Epoch 1/10] [Batch 111/274] [Batch classify loss: 4.307847] 
[Epoch 1/10] [Batch 112/274] [Batch classify loss: 3.534084] 
[Epoch 1/10] [Batch 113/274] [Batch classify loss: 4.085749] 
[Epoch 1/10] [Batch 114/274] [Batch classify loss: 3.869798] 
[Epoch 1/10] [Batch 115/274] [Batch classify loss: 4.077112] 
[Epoch 1/10] [Batch 116/274] [Batch classify loss: 3.737844] 
[Epoch 1/10] [Batch 117/274] [Batch classify loss: 4.367875] 
[Epoch 1/10] [Batch 118/274] [Batch classify loss: 4.117600] 
[Epoch 1/10] [Batch 119/274] [Batch classify loss: 4.415018] 
[Epoch 1/10] [Batch 120/274] [Batch classify loss: 4.264539] 
[Epoch 1/10] [Batch 121/274] [Batch classify loss: 4.242644] 
[Epoch 1/10] [Batch 122/274] [Batch classify loss: 3.805570] 
[Epoch 1/10] [Batch 123/274] [Batch classify loss: 4.191827] 
[Epoch 1/10] [Batch 124/274] [Batch classify loss: 4.545041] 
[Epoch 1/10] [Batch 125/274] [Batch classify loss: 3.877807] 
[Epoch 1/10] [Batch 126/274] [Batch classify loss: 3.863866] 
[Epoch 1/10] [Batch 127/274] [Batch classify loss: 3.751762] 
[Epoch 1/10] [Batch 128/274] [Batch classify loss: 3.785551] 
[Epoch 1/10] [Batch 129/274] [Batch classify loss: 4.062776] 
[Epoch 1/10] [Batch 130/274] [Batch classify loss: 3.848153] 
[Epoch 1/10] [Batch 131/274] [Batch classify loss: 4.085358] 
[Epoch 1/10] [Batch 132/274] [Batch classify loss: 4.258095] 
[Epoch 1/10] [Batch 133/274] [Batch classify loss: 3.911751] 
[Epoch 1/10] [Batch 134/274] [Batch classify loss: 4.460044] 
[Epoch 1/10] [Batch 135/274] [Batch classify loss: 3.744700] 
[Epoch 1/10] [Batch 136/274] [Batch classify loss: 3.668655] 
[Epoch 1/10] [Batch 137/274] [Batch classify loss: 4.247434] 
[Epoch 1/10] [Batch 138/274] [Batch classify loss: 4.389935] 
[Epoch 1/10] [Batch 139/274] [Batch classify loss: 4.238763] 
[Epoch 1/10] [Batch 140/274] [Batch classify loss: 4.225589] 
[Epoch 1/10] [Batch 141/274] [Batch classify loss: 4.147147] 
[Epoch 1/10] [Batch 142/274] [Batch classify loss: 4.003828] 
[Epoch 1/10] [Batch 143/274] [Batch classify loss: 4.508633] 
[Epoch 1/10] [Batch 144/274] [Batch classify loss: 4.034999] 
[Epoch 1/10] [Batch 145/274] [Batch classify loss: 4.196761] 
[Epoch 1/10] [Batch 146/274] [Batch classify loss: 4.451286] 
[Epoch 1/10] [Batch 147/274] [Batch classify loss: 3.738453] 
[Epoch 1/10] [Batch 148/274] [Batch classify loss: 4.489289] 
[Epoch 1/10] [Batch 149/274] [Batch classify loss: 4.133964] 
[Epoch 1/10] [Batch 150/274] [Batch classify loss: 3.698041] 
[Epoch 1/10] [Batch 151/274] [Batch classify loss: 4.327437] 
[Epoch 1/10] [Batch 152/274] [Batch classify loss: 3.969955] 
[Epoch 1/10] [Batch 153/274] [Batch classify loss: 3.861026] 
[Epoch 1/10] [Batch 154/274] [Batch classify loss: 4.269143] 
[Epoch 1/10] [Batch 155/274] [Batch classify loss: 3.827741] 
[Epoch 1/10] [Batch 156/274] [Batch classify loss: 4.351888] 
[Epoch 1/10] [Batch 157/274] [Batch classify loss: 4.049285] 
[Epoch 1/10] [Batch 158/274] [Batch classify loss: 4.132459] 
[Epoch 1/10] [Batch 159/274] [Batch classify loss: 3.985995] 
[Epoch 1/10] [Batch 160/274] [Batch classify loss: 4.137161] 
[Epoch 1/10] [Batch 161/274] [Batch classify loss: 4.159370] 
[Epoch 1/10] [Batch 162/274] [Batch classify loss: 4.191315] 
[Epoch 1/10] [Batch 163/274] [Batch classify loss: 4.124067] 
[Epoch 1/10] [Batch 164/274] [Batch classify loss: 3.888434] 
[Epoch 1/10] [Batch 165/274] [Batch classify loss: 3.640990] 
[Epoch 1/10] [Batch 166/274] [Batch classify loss: 3.630966] 
[Epoch 1/10] [Batch 167/274] [Batch classify loss: 4.230421] 
[Epoch 1/10] [Batch 168/274] [Batch classify loss: 4.486294] 
[Epoch 1/10] [Batch 169/274] [Batch classify loss: 4.221800] 
[Epoch 1/10] [Batch 170/274] [Batch classify loss: 3.889673] 
[Epoch 1/10] [Batch 171/274] [Batch classify loss: 3.851327] 
[Epoch 1/10] [Batch 172/274] [Batch classify loss: 4.420455] 
[Epoch 1/10] [Batch 173/274] [Batch classify loss: 3.771334] 
[Epoch 1/10] [Batch 174/274] [Batch classify loss: 3.795575] 
[Epoch 1/10] [Batch 175/274] [Batch classify loss: 3.631671] 
[Epoch 1/10] [Batch 176/274] [Batch classify loss: 4.200414] 
[Epoch 1/10] [Batch 177/274] [Batch classify loss: 3.993239] 
[Epoch 1/10] [Batch 178/274] [Batch classify loss: 4.219574] 
[Epoch 1/10] [Batch 179/274] [Batch classify loss: 3.861048] 
[Epoch 1/10] [Batch 180/274] [Batch classify loss: 4.010358] 
[Epoch 1/10] [Batch 181/274] [Batch classify loss: 4.304464] 
[Epoch 1/10] [Batch 182/274] [Batch classify loss: 3.807767] 
[Epoch 1/10] [Batch 183/274] [Batch classify loss: 4.670943] 
[Epoch 1/10] [Batch 184/274] [Batch classify loss: 3.877765] 
[Epoch 1/10] [Batch 185/274] [Batch classify loss: 4.231086] 
[Epoch 1/10] [Batch 186/274] [Batch classify loss: 4.345967] 
[Epoch 1/10] [Batch 187/274] [Batch classify loss: 4.043236] 
[Epoch 1/10] [Batch 188/274] [Batch classify loss: 4.477017] 
[Epoch 1/10] [Batch 189/274] [Batch classify loss: 4.586357] 
[Epoch 1/10] [Batch 190/274] [Batch classify loss: 4.128162] 
[Epoch 1/10] [Batch 191/274] [Batch classify loss: 4.276173] 
[Epoch 1/10] [Batch 192/274] [Batch classify loss: 4.683352] 
[Epoch 1/10] [Batch 193/274] [Batch classify loss: 3.731687] 
[Epoch 1/10] [Batch 194/274] [Batch classify loss: 4.590768] 
[Epoch 1/10] [Batch 195/274] [Batch classify loss: 3.946529] 
[Epoch 1/10] [Batch 196/274] [Batch classify loss: 4.570473] 
[Epoch 1/10] [Batch 197/274] [Batch classify loss: 4.122324] 
[Epoch 1/10] [Batch 198/274] [Batch classify loss: 4.107326] 
[Epoch 1/10] [Batch 199/274] [Batch classify loss: 4.168958] 
[Epoch 1/10] [Batch 200/274] [Batch classify loss: 4.171927] 
[Epoch 1/10] [Batch 201/274] [Batch classify loss: 4.071341] 
[Epoch 1/10] [Batch 202/274] [Batch classify loss: 3.892107] 
[Epoch 1/10] [Batch 203/274] [Batch classify loss: 4.651814] 
[Epoch 1/10] [Batch 204/274] [Batch classify loss: 4.384422] 
[Epoch 1/10] [Batch 205/274] [Batch classify loss: 4.178370] 
[Epoch 1/10] [Batch 206/274] [Batch classify loss: 4.397244] 
[Epoch 1/10] [Batch 207/274] [Batch classify loss: 4.164971] 
[Epoch 1/10] [Batch 208/274] [Batch classify loss: 4.234293] 
[Epoch 1/10] [Batch 209/274] [Batch classify loss: 4.238864] 
[Epoch 1/10] [Batch 210/274] [Batch classify loss: 4.501888] 
[Epoch 1/10] [Batch 211/274] [Batch classify loss: 3.892585] 
[Epoch 1/10] [Batch 212/274] [Batch classify loss: 4.250875] 
[Epoch 1/10] [Batch 213/274] [Batch classify loss: 4.178701] 
[Epoch 1/10] [Batch 214/274] [Batch classify loss: 4.407809] 
[Epoch 1/10] [Batch 215/274] [Batch classify loss: 4.003863] 
[Epoch 1/10] [Batch 216/274] [Batch classify loss: 4.450125] 
[Epoch 1/10] [Batch 217/274] [Batch classify loss: 4.556733] 
[Epoch 1/10] [Batch 218/274] [Batch classify loss: 4.813519] 
[Epoch 1/10] [Batch 219/274] [Batch classify loss: 4.258995] 
[Epoch 1/10] [Batch 220/274] [Batch classify loss: 4.299322] 
[Epoch 1/10] [Batch 221/274] [Batch classify loss: 4.028655] 
[Epoch 1/10] [Batch 222/274] [Batch classify loss: 4.032353] 
[Epoch 1/10] [Batch 223/274] [Batch classify loss: 4.593629] 
[Epoch 1/10] [Batch 224/274] [Batch classify loss: 4.475935] 
[Epoch 1/10] [Batch 225/274] [Batch classify loss: 4.282491] 
[Epoch 1/10] [Batch 226/274] [Batch classify loss: 3.831089] 
[Epoch 1/10] [Batch 227/274] [Batch classify loss: 4.373216] 
[Epoch 1/10] [Batch 228/274] [Batch classify loss: 4.730584] 
[Epoch 1/10] [Batch 229/274] [Batch classify loss: 4.531054] 
[Epoch 1/10] [Batch 230/274] [Batch classify loss: 4.210596] 
[Epoch 1/10] [Batch 231/274] [Batch classify loss: 4.317948] 
[Epoch 1/10] [Batch 232/274] [Batch classify loss: 4.069812] 
[Epoch 1/10] [Batch 233/274] [Batch classify loss: 4.249223] 
[Epoch 1/10] [Batch 234/274] [Batch classify loss: 4.356605] 
[Epoch 1/10] [Batch 235/274] [Batch classify loss: 3.763925] 
[Epoch 1/10] [Batch 236/274] [Batch classify loss: 4.070307] 
[Epoch 1/10] [Batch 237/274] [Batch classify loss: 4.302732] 
[Epoch 1/10] [Batch 238/274] [Batch classify loss: 3.882481] 
[Epoch 1/10] [Batch 239/274] [Batch classify loss: 4.245883] 
[Epoch 1/10] [Batch 240/274] [Batch classify loss: 4.358339] 
[Epoch 1/10] [Batch 241/274] [Batch classify loss: 4.279376] 
[Epoch 1/10] [Batch 242/274] [Batch classify loss: 4.228262] 
[Epoch 1/10] [Batch 243/274] [Batch classify loss: 3.903109] 
[Epoch 1/10] [Batch 244/274] [Batch classify loss: 4.193637] 
[Epoch 1/10] [Batch 245/274] [Batch classify loss: 4.207111] 
[Epoch 1/10] [Batch 246/274] [Batch classify loss: 4.258330] 
[Epoch 1/10] [Batch 247/274] [Batch classify loss: 3.786957] 
[Epoch 1/10] [Batch 248/274] [Batch classify loss: 4.230779] 
[Epoch 1/10] [Batch 249/274] [Batch classify loss: 4.202089] 
[Epoch 1/10] [Batch 250/274] [Batch classify loss: 3.743406] 
[Epoch 1/10] [Batch 251/274] [Batch classify loss: 3.846805] 
[Epoch 1/10] [Batch 252/274] [Batch classify loss: 4.309339] 
[Epoch 1/10] [Batch 253/274] [Batch classify loss: 4.291378] 
[Epoch 1/10] [Batch 254/274] [Batch classify loss: 4.188613] 
[Epoch 1/10] [Batch 255/274] [Batch classify loss: 4.015042] 
[Epoch 1/10] [Batch 256/274] [Batch classify loss: 4.334337] 
[Epoch 1/10] [Batch 257/274] [Batch classify loss: 4.806184] 
[Epoch 1/10] [Batch 258/274] [Batch classify loss: 4.024037] 
[Epoch 1/10] [Batch 259/274] [Batch classify loss: 4.023932] 
[Epoch 1/10] [Batch 260/274] [Batch classify loss: 3.759464] 
[Epoch 1/10] [Batch 261/274] [Batch classify loss: 4.186871] 
[Epoch 1/10] [Batch 262/274] [Batch classify loss: 4.393028] 
[Epoch 1/10] [Batch 263/274] [Batch classify loss: 3.682581] 
[Epoch 1/10] [Batch 264/274] [Batch classify loss: 3.855988] 
[Epoch 1/10] [Batch 265/274] [Batch classify loss: 4.692144] 
[Epoch 1/10] [Batch 266/274] [Batch classify loss: 4.153049] 
[Epoch 1/10] [Batch 267/274] [Batch classify loss: 4.161721] 
[Epoch 1/10] [Batch 268/274] [Batch classify loss: 4.125912] 
[Epoch 1/10] [Batch 269/274] [Batch classify loss: 4.617937] 
[Epoch 1/10] [Batch 270/274] [Batch classify loss: 4.450364] 
[Epoch 1/10] [Batch 271/274] [Batch classify loss: 4.110693] 
[Epoch 1/10] [Batch 272/274] [Batch classify loss: 4.112268] 
[Epoch 1/10] [Batch 273/274] [Batch classify loss: 4.109980] 
[Epoch 1/10] [Batch 274/274] [Batch classify loss: 4.297050] 
0001 epoch mmat trained classifier accuary on the clean testing examples:94.7526%
0001 epoch mmat trained classifier loss on the clean testing examples:0.2251
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.4502%
mmat trained classifier loss on adversarial testset:4.5120463371276855
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-cle
1epoch learning rate:0.01
[Epoch 2/10] [Batch 1/274] [Batch classify loss: 3.622852] 
[Epoch 2/10] [Batch 2/274] [Batch classify loss: 4.318879] 
[Epoch 2/10] [Batch 3/274] [Batch classify loss: 4.006584] 
[Epoch 2/10] [Batch 4/274] [Batch classify loss: 4.249521] 
[Epoch 2/10] [Batch 5/274] [Batch classify loss: 4.773613] 
[Epoch 2/10] [Batch 6/274] [Batch classify loss: 4.941597] 
[Epoch 2/10] [Batch 7/274] [Batch classify loss: 4.552260] 
[Epoch 2/10] [Batch 8/274] [Batch classify loss: 4.528087] 
[Epoch 2/10] [Batch 9/274] [Batch classify loss: 4.706735] 
[Epoch 2/10] [Batch 10/274] [Batch classify loss: 4.024866] 
[Epoch 2/10] [Batch 11/274] [Batch classify loss: 4.644767] 
[Epoch 2/10] [Batch 12/274] [Batch classify loss: 4.548058] 
[Epoch 2/10] [Batch 13/274] [Batch classify loss: 4.401099] 
[Epoch 2/10] [Batch 14/274] [Batch classify loss: 4.676025] 
[Epoch 2/10] [Batch 15/274] [Batch classify loss: 4.494645] 
[Epoch 2/10] [Batch 16/274] [Batch classify loss: 4.627639] 
[Epoch 2/10] [Batch 17/274] [Batch classify loss: 4.408472] 
[Epoch 2/10] [Batch 18/274] [Batch classify loss: 4.299331] 
[Epoch 2/10] [Batch 19/274] [Batch classify loss: 4.354119] 
[Epoch 2/10] [Batch 20/274] [Batch classify loss: 4.623393] 
[Epoch 2/10] [Batch 21/274] [Batch classify loss: 4.329176] 
[Epoch 2/10] [Batch 22/274] [Batch classify loss: 4.497644] 
[Epoch 2/10] [Batch 23/274] [Batch classify loss: 4.533517] 
[Epoch 2/10] [Batch 24/274] [Batch classify loss: 4.505050] 
[Epoch 2/10] [Batch 25/274] [Batch classify loss: 4.491587] 
[Epoch 2/10] [Batch 26/274] [Batch classify loss: 4.440319] 
[Epoch 2/10] [Batch 27/274] [Batch classify loss: 4.604818] 
[Epoch 2/10] [Batch 28/274] [Batch classify loss: 4.869805] 
[Epoch 2/10] [Batch 29/274] [Batch classify loss: 4.366290] 
[Epoch 2/10] [Batch 30/274] [Batch classify loss: 4.883224] 
[Epoch 2/10] [Batch 31/274] [Batch classify loss: 4.277807] 
[Epoch 2/10] [Batch 32/274] [Batch classify loss: 4.795485] 
[Epoch 2/10] [Batch 33/274] [Batch classify loss: 4.421052] 
[Epoch 2/10] [Batch 34/274] [Batch classify loss: 4.549046] 
[Epoch 2/10] [Batch 35/274] [Batch classify loss: 4.201241] 
[Epoch 2/10] [Batch 36/274] [Batch classify loss: 4.885491] 
[Epoch 2/10] [Batch 37/274] [Batch classify loss: 4.735049] 
[Epoch 2/10] [Batch 38/274] [Batch classify loss: 4.870075] 
[Epoch 2/10] [Batch 39/274] [Batch classify loss: 4.270069] 
[Epoch 2/10] [Batch 40/274] [Batch classify loss: 4.181559] 
[Epoch 2/10] [Batch 41/274] [Batch classify loss: 4.419131] 
[Epoch 2/10] [Batch 42/274] [Batch classify loss: 4.292052] 
[Epoch 2/10] [Batch 43/274] [Batch classify loss: 4.292447] 
[Epoch 2/10] [Batch 44/274] [Batch classify loss: 4.720780] 
[Epoch 2/10] [Batch 45/274] [Batch classify loss: 4.868346] 
[Epoch 2/10] [Batch 46/274] [Batch classify loss: 4.980577] 
[Epoch 2/10] [Batch 47/274] [Batch classify loss: 4.280014] 
[Epoch 2/10] [Batch 48/274] [Batch classify loss: 4.622867] 
[Epoch 2/10] [Batch 49/274] [Batch classify loss: 4.770049] 
[Epoch 2/10] [Batch 50/274] [Batch classify loss: 3.907410] 
[Epoch 2/10] [Batch 51/274] [Batch classify loss: 4.227797] 
[Epoch 2/10] [Batch 52/274] [Batch classify loss: 4.274730] 
[Epoch 2/10] [Batch 53/274] [Batch classify loss: 4.077251] 
[Epoch 2/10] [Batch 54/274] [Batch classify loss: 4.357667] 
[Epoch 2/10] [Batch 55/274] [Batch classify loss: 4.263915] 
[Epoch 2/10] [Batch 56/274] [Batch classify loss: 4.770747] 
[Epoch 2/10] [Batch 57/274] [Batch classify loss: 4.095708] 
[Epoch 2/10] [Batch 58/274] [Batch classify loss: 4.598720] 
[Epoch 2/10] [Batch 59/274] [Batch classify loss: 4.426478] 
[Epoch 2/10] [Batch 60/274] [Batch classify loss: 4.677512] 
[Epoch 2/10] [Batch 61/274] [Batch classify loss: 4.292221] 
[Epoch 2/10] [Batch 62/274] [Batch classify loss: 4.362837] 
[Epoch 2/10] [Batch 63/274] [Batch classify loss: 4.935358] 
[Epoch 2/10] [Batch 64/274] [Batch classify loss: 3.958189] 
[Epoch 2/10] [Batch 65/274] [Batch classify loss: 4.563599] 
[Epoch 2/10] [Batch 66/274] [Batch classify loss: 4.750935] 
[Epoch 2/10] [Batch 67/274] [Batch classify loss: 4.426791] 
[Epoch 2/10] [Batch 68/274] [Batch classify loss: 4.143714] 
[Epoch 2/10] [Batch 69/274] [Batch classify loss: 4.011250] 
[Epoch 2/10] [Batch 70/274] [Batch classify loss: 4.337089] 
[Epoch 2/10] [Batch 71/274] [Batch classify loss: 4.908987] 
[Epoch 2/10] [Batch 72/274] [Batch classify loss: 4.792081] 
[Epoch 2/10] [Batch 73/274] [Batch classify loss: 4.228988] 
[Epoch 2/10] [Batch 74/274] [Batch classify loss: 4.209594] 
[Epoch 2/10] [Batch 75/274] [Batch classify loss: 3.906150] 
[Epoch 2/10] [Batch 76/274] [Batch classify loss: 4.363659] 
[Epoch 2/10] [Batch 77/274] [Batch classify loss: 4.400464] 
[Epoch 2/10] [Batch 78/274] [Batch classify loss: 4.446015] 
[Epoch 2/10] [Batch 79/274] [Batch classify loss: 4.326681] 
[Epoch 2/10] [Batch 80/274] [Batch classify loss: 3.917229] 
[Epoch 2/10] [Batch 81/274] [Batch classify loss: 3.963667] 
[Epoch 2/10] [Batch 82/274] [Batch classify loss: 4.764426] 
[Epoch 2/10] [Batch 83/274] [Batch classify loss: 4.500540] 
[Epoch 2/10] [Batch 84/274] [Batch classify loss: 4.099612] 
[Epoch 2/10] [Batch 85/274] [Batch classify loss: 4.301310] 
[Epoch 2/10] [Batch 86/274] [Batch classify loss: 3.991615] 
[Epoch 2/10] [Batch 87/274] [Batch classify loss: 4.366865] 
[Epoch 2/10] [Batch 88/274] [Batch classify loss: 4.658321] 
[Epoch 2/10] [Batch 89/274] [Batch classify loss: 4.000750] 
[Epoch 2/10] [Batch 90/274] [Batch classify loss: 4.075856] 
[Epoch 2/10] [Batch 91/274] [Batch classify loss: 4.532305] 
[Epoch 2/10] [Batch 92/274] [Batch classify loss: 3.937538] 
[Epoch 2/10] [Batch 93/274] [Batch classify loss: 4.775742] 
[Epoch 2/10] [Batch 94/274] [Batch classify loss: 4.621293] 
[Epoch 2/10] [Batch 95/274] [Batch classify loss: 4.859431] 
[Epoch 2/10] [Batch 96/274] [Batch classify loss: 4.458159] 
[Epoch 2/10] [Batch 97/274] [Batch classify loss: 4.259046] 
[Epoch 2/10] [Batch 98/274] [Batch classify loss: 4.487945] 
[Epoch 2/10] [Batch 99/274] [Batch classify loss: 4.454584] 
[Epoch 2/10] [Batch 100/274] [Batch classify loss: 4.082504] 
[Epoch 2/10] [Batch 101/274] [Batch classify loss: 3.754967] 
[Epoch 2/10] [Batch 102/274] [Batch classify loss: 4.066880] 
[Epoch 2/10] [Batch 103/274] [Batch classify loss: 4.159220] 
[Epoch 2/10] [Batch 104/274] [Batch classify loss: 4.109798] 
[Epoch 2/10] [Batch 105/274] [Batch classify loss: 4.349154] 
[Epoch 2/10] [Batch 106/274] [Batch classify loss: 3.849179] 
[Epoch 2/10] [Batch 107/274] [Batch classify loss: 4.166553] 
[Epoch 2/10] [Batch 108/274] [Batch classify loss: 4.350433] 
[Epoch 2/10] [Batch 109/274] [Batch classify loss: 4.386315] 
[Epoch 2/10] [Batch 110/274] [Batch classify loss: 4.827244] 
[Epoch 2/10] [Batch 111/274] [Batch classify loss: 4.018685] 
[Epoch 2/10] [Batch 112/274] [Batch classify loss: 3.945002] 
[Epoch 2/10] [Batch 113/274] [Batch classify loss: 4.226637] 
[Epoch 2/10] [Batch 114/274] [Batch classify loss: 4.507517] 
[Epoch 2/10] [Batch 115/274] [Batch classify loss: 4.299757] 
[Epoch 2/10] [Batch 116/274] [Batch classify loss: 3.768877] 
[Epoch 2/10] [Batch 117/274] [Batch classify loss: 4.235525] 
[Epoch 2/10] [Batch 118/274] [Batch classify loss: 4.703424] 
[Epoch 2/10] [Batch 119/274] [Batch classify loss: 4.187594] 
[Epoch 2/10] [Batch 120/274] [Batch classify loss: 4.369686] 
[Epoch 2/10] [Batch 121/274] [Batch classify loss: 4.250940] 
[Epoch 2/10] [Batch 122/274] [Batch classify loss: 4.887501] 
[Epoch 2/10] [Batch 123/274] [Batch classify loss: 4.066011] 
[Epoch 2/10] [Batch 124/274] [Batch classify loss: 3.843583] 
[Epoch 2/10] [Batch 125/274] [Batch classify loss: 4.124056] 
[Epoch 2/10] [Batch 126/274] [Batch classify loss: 3.883785] 
[Epoch 2/10] [Batch 127/274] [Batch classify loss: 4.454731] 
[Epoch 2/10] [Batch 128/274] [Batch classify loss: 4.250574] 
[Epoch 2/10] [Batch 129/274] [Batch classify loss: 4.099189] 
[Epoch 2/10] [Batch 130/274] [Batch classify loss: 4.048512] 
[Epoch 2/10] [Batch 131/274] [Batch classify loss: 3.806735] 
[Epoch 2/10] [Batch 132/274] [Batch classify loss: 4.240284] 
[Epoch 2/10] [Batch 133/274] [Batch classify loss: 4.775185] 
[Epoch 2/10] [Batch 134/274] [Batch classify loss: 3.915479] 
[Epoch 2/10] [Batch 135/274] [Batch classify loss: 4.328721] 
[Epoch 2/10] [Batch 136/274] [Batch classify loss: 4.193032] 
[Epoch 2/10] [Batch 137/274] [Batch classify loss: 4.245903] 
[Epoch 2/10] [Batch 138/274] [Batch classify loss: 4.211472] 
[Epoch 2/10] [Batch 139/274] [Batch classify loss: 4.350359] 
[Epoch 2/10] [Batch 140/274] [Batch classify loss: 3.786771] 
[Epoch 2/10] [Batch 141/274] [Batch classify loss: 4.159075] 
[Epoch 2/10] [Batch 142/274] [Batch classify loss: 4.036879] 
[Epoch 2/10] [Batch 143/274] [Batch classify loss: 4.429373] 
[Epoch 2/10] [Batch 144/274] [Batch classify loss: 4.391617] 
[Epoch 2/10] [Batch 145/274] [Batch classify loss: 4.004675] 
[Epoch 2/10] [Batch 146/274] [Batch classify loss: 4.036803] 
[Epoch 2/10] [Batch 147/274] [Batch classify loss: 4.708117] 
[Epoch 2/10] [Batch 148/274] [Batch classify loss: 4.453538] 
[Epoch 2/10] [Batch 149/274] [Batch classify loss: 4.353885] 
[Epoch 2/10] [Batch 150/274] [Batch classify loss: 4.393805] 
[Epoch 2/10] [Batch 151/274] [Batch classify loss: 4.489576] 
[Epoch 2/10] [Batch 152/274] [Batch classify loss: 4.223939] 
[Epoch 2/10] [Batch 153/274] [Batch classify loss: 3.989818] 
[Epoch 2/10] [Batch 154/274] [Batch classify loss: 4.220680] 
[Epoch 2/10] [Batch 155/274] [Batch classify loss: 4.054806] 
[Epoch 2/10] [Batch 156/274] [Batch classify loss: 4.402298] 
[Epoch 2/10] [Batch 157/274] [Batch classify loss: 4.312764] 
[Epoch 2/10] [Batch 158/274] [Batch classify loss: 4.298020] 
[Epoch 2/10] [Batch 159/274] [Batch classify loss: 3.969375] 
[Epoch 2/10] [Batch 160/274] [Batch classify loss: 4.286895] 
[Epoch 2/10] [Batch 161/274] [Batch classify loss: 4.624101] 
[Epoch 2/10] [Batch 162/274] [Batch classify loss: 4.233993] 
[Epoch 2/10] [Batch 163/274] [Batch classify loss: 4.639119] 
[Epoch 2/10] [Batch 164/274] [Batch classify loss: 4.208731] 
[Epoch 2/10] [Batch 165/274] [Batch classify loss: 4.109145] 
[Epoch 2/10] [Batch 166/274] [Batch classify loss: 3.925643] 
[Epoch 2/10] [Batch 167/274] [Batch classify loss: 4.503120] 
[Epoch 2/10] [Batch 168/274] [Batch classify loss: 4.037698] 
[Epoch 2/10] [Batch 169/274] [Batch classify loss: 4.109032] 
[Epoch 2/10] [Batch 170/274] [Batch classify loss: 4.190855] 
[Epoch 2/10] [Batch 171/274] [Batch classify loss: 4.111894] 
[Epoch 2/10] [Batch 172/274] [Batch classify loss: 4.244462] 
[Epoch 2/10] [Batch 173/274] [Batch classify loss: 3.924415] 
[Epoch 2/10] [Batch 174/274] [Batch classify loss: 4.185989] 
[Epoch 2/10] [Batch 175/274] [Batch classify loss: 4.009761] 
[Epoch 2/10] [Batch 176/274] [Batch classify loss: 4.231602] 
[Epoch 2/10] [Batch 177/274] [Batch classify loss: 3.665477] 
[Epoch 2/10] [Batch 178/274] [Batch classify loss: 4.490671] 
[Epoch 2/10] [Batch 179/274] [Batch classify loss: 3.948478] 
[Epoch 2/10] [Batch 180/274] [Batch classify loss: 3.993442] 
[Epoch 2/10] [Batch 181/274] [Batch classify loss: 4.483998] 
[Epoch 2/10] [Batch 182/274] [Batch classify loss: 4.903399] 
[Epoch 2/10] [Batch 183/274] [Batch classify loss: 4.232021] 
[Epoch 2/10] [Batch 184/274] [Batch classify loss: 4.348176] 
[Epoch 2/10] [Batch 185/274] [Batch classify loss: 3.740318] 
[Epoch 2/10] [Batch 186/274] [Batch classify loss: 3.864470] 
[Epoch 2/10] [Batch 187/274] [Batch classify loss: 4.486509] 
[Epoch 2/10] [Batch 188/274] [Batch classify loss: 4.208103] 
[Epoch 2/10] [Batch 189/274] [Batch classify loss: 3.532475] 
[Epoch 2/10] [Batch 190/274] [Batch classify loss: 4.263425] 
[Epoch 2/10] [Batch 191/274] [Batch classify loss: 4.545496] 
[Epoch 2/10] [Batch 192/274] [Batch classify loss: 4.151235] 
[Epoch 2/10] [Batch 193/274] [Batch classify loss: 4.322691] 
[Epoch 2/10] [Batch 194/274] [Batch classify loss: 3.695138] 
[Epoch 2/10] [Batch 195/274] [Batch classify loss: 4.133383] 
[Epoch 2/10] [Batch 196/274] [Batch classify loss: 4.586131] 
[Epoch 2/10] [Batch 197/274] [Batch classify loss: 3.915946] 
[Epoch 2/10] [Batch 198/274] [Batch classify loss: 4.158400] 
[Epoch 2/10] [Batch 199/274] [Batch classify loss: 3.700086] 
[Epoch 2/10] [Batch 200/274] [Batch classify loss: 4.521343] 
[Epoch 2/10] [Batch 201/274] [Batch classify loss: 4.223077] 
[Epoch 2/10] [Batch 202/274] [Batch classify loss: 4.446162] 
[Epoch 2/10] [Batch 203/274] [Batch classify loss: 4.325878] 
[Epoch 2/10] [Batch 204/274] [Batch classify loss: 4.380897] 
[Epoch 2/10] [Batch 205/274] [Batch classify loss: 3.942698] 
[Epoch 2/10] [Batch 206/274] [Batch classify loss: 3.888101] 
[Epoch 2/10] [Batch 207/274] [Batch classify loss: 4.123053] 
[Epoch 2/10] [Batch 208/274] [Batch classify loss: 3.603158] 
[Epoch 2/10] [Batch 209/274] [Batch classify loss: 3.793097] 
[Epoch 2/10] [Batch 210/274] [Batch classify loss: 3.988383] 
[Epoch 2/10] [Batch 211/274] [Batch classify loss: 3.846172] 
[Epoch 2/10] [Batch 212/274] [Batch classify loss: 4.263326] 
[Epoch 2/10] [Batch 213/274] [Batch classify loss: 3.902408] 
[Epoch 2/10] [Batch 214/274] [Batch classify loss: 4.077132] 
[Epoch 2/10] [Batch 215/274] [Batch classify loss: 3.905798] 
[Epoch 2/10] [Batch 216/274] [Batch classify loss: 3.811355] 
[Epoch 2/10] [Batch 217/274] [Batch classify loss: 4.809879] 
[Epoch 2/10] [Batch 218/274] [Batch classify loss: 4.131378] 
[Epoch 2/10] [Batch 219/274] [Batch classify loss: 3.610575] 
[Epoch 2/10] [Batch 220/274] [Batch classify loss: 4.028467] 
[Epoch 2/10] [Batch 221/274] [Batch classify loss: 4.144134] 
[Epoch 2/10] [Batch 222/274] [Batch classify loss: 4.223877] 
[Epoch 2/10] [Batch 223/274] [Batch classify loss: 4.556870] 
[Epoch 2/10] [Batch 224/274] [Batch classify loss: 4.640910] 
[Epoch 2/10] [Batch 225/274] [Batch classify loss: 4.295904] 
[Epoch 2/10] [Batch 226/274] [Batch classify loss: 3.753961] 
[Epoch 2/10] [Batch 227/274] [Batch classify loss: 4.079535] 
[Epoch 2/10] [Batch 228/274] [Batch classify loss: 4.183208] 
[Epoch 2/10] [Batch 229/274] [Batch classify loss: 4.198018] 
[Epoch 2/10] [Batch 230/274] [Batch classify loss: 4.021750] 
[Epoch 2/10] [Batch 231/274] [Batch classify loss: 4.268474] 
[Epoch 2/10] [Batch 232/274] [Batch classify loss: 4.076774] 
[Epoch 2/10] [Batch 233/274] [Batch classify loss: 4.409310] 
[Epoch 2/10] [Batch 234/274] [Batch classify loss: 4.159058] 
[Epoch 2/10] [Batch 235/274] [Batch classify loss: 4.085966] 
[Epoch 2/10] [Batch 236/274] [Batch classify loss: 4.299120] 
[Epoch 2/10] [Batch 237/274] [Batch classify loss: 3.682305] 
[Epoch 2/10] [Batch 238/274] [Batch classify loss: 4.332737] 
[Epoch 2/10] [Batch 239/274] [Batch classify loss: 4.489727] 
[Epoch 2/10] [Batch 240/274] [Batch classify loss: 3.945379] 
[Epoch 2/10] [Batch 241/274] [Batch classify loss: 4.077477] 
[Epoch 2/10] [Batch 242/274] [Batch classify loss: 4.029535] 
[Epoch 2/10] [Batch 243/274] [Batch classify loss: 4.452704] 
[Epoch 2/10] [Batch 244/274] [Batch classify loss: 3.901511] 
[Epoch 2/10] [Batch 245/274] [Batch classify loss: 3.999665] 
[Epoch 2/10] [Batch 246/274] [Batch classify loss: 4.242338] 
[Epoch 2/10] [Batch 247/274] [Batch classify loss: 4.464677] 
[Epoch 2/10] [Batch 248/274] [Batch classify loss: 3.584885] 
[Epoch 2/10] [Batch 249/274] [Batch classify loss: 4.073802] 
[Epoch 2/10] [Batch 250/274] [Batch classify loss: 3.883352] 
[Epoch 2/10] [Batch 251/274] [Batch classify loss: 3.498403] 
[Epoch 2/10] [Batch 252/274] [Batch classify loss: 4.120903] 
[Epoch 2/10] [Batch 253/274] [Batch classify loss: 4.297024] 
[Epoch 2/10] [Batch 254/274] [Batch classify loss: 3.967565] 
[Epoch 2/10] [Batch 255/274] [Batch classify loss: 4.053310] 
[Epoch 2/10] [Batch 256/274] [Batch classify loss: 4.015432] 
[Epoch 2/10] [Batch 257/274] [Batch classify loss: 4.317899] 
[Epoch 2/10] [Batch 258/274] [Batch classify loss: 4.035374] 
[Epoch 2/10] [Batch 259/274] [Batch classify loss: 4.399786] 
[Epoch 2/10] [Batch 260/274] [Batch classify loss: 3.886749] 
[Epoch 2/10] [Batch 261/274] [Batch classify loss: 3.783781] 
[Epoch 2/10] [Batch 262/274] [Batch classify loss: 4.434299] 
[Epoch 2/10] [Batch 263/274] [Batch classify loss: 4.264322] 
[Epoch 2/10] [Batch 264/274] [Batch classify loss: 3.476541] 
[Epoch 2/10] [Batch 265/274] [Batch classify loss: 3.934746] 
[Epoch 2/10] [Batch 266/274] [Batch classify loss: 4.416836] 
[Epoch 2/10] [Batch 267/274] [Batch classify loss: 4.177416] 
[Epoch 2/10] [Batch 268/274] [Batch classify loss: 4.333860] 
[Epoch 2/10] [Batch 269/274] [Batch classify loss: 4.170625] 
[Epoch 2/10] [Batch 270/274] [Batch classify loss: 4.330739] 
[Epoch 2/10] [Batch 271/274] [Batch classify loss: 4.067987] 
[Epoch 2/10] [Batch 272/274] [Batch classify loss: 4.001591] 
[Epoch 2/10] [Batch 273/274] [Batch classify loss: 3.778916] 
[Epoch 2/10] [Batch 274/274] [Batch classify loss: 3.637727] 
0002 epoch mmat trained classifier accuary on the clean testing examples:94.7488%
0002 epoch mmat trained classifier loss on the clean testing examples:0.2192
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2274%
mmat trained classifier loss on adversarial testset:4.535315990447998
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-cle
2epoch learning rate:0.01
[Epoch 3/10] [Batch 1/274] [Batch classify loss: 3.069309] 
[Epoch 3/10] [Batch 2/274] [Batch classify loss: 3.869327] 
[Epoch 3/10] [Batch 3/274] [Batch classify loss: 4.325845] 
[Epoch 3/10] [Batch 4/274] [Batch classify loss: 3.797811] 
[Epoch 3/10] [Batch 5/274] [Batch classify loss: 3.838253] 
[Epoch 3/10] [Batch 6/274] [Batch classify loss: 4.114857] 
[Epoch 3/10] [Batch 7/274] [Batch classify loss: 4.339511] 
[Epoch 3/10] [Batch 8/274] [Batch classify loss: 4.232800] 
[Epoch 3/10] [Batch 9/274] [Batch classify loss: 4.825217] 
[Epoch 3/10] [Batch 10/274] [Batch classify loss: 4.410627] 
[Epoch 3/10] [Batch 11/274] [Batch classify loss: 4.153201] 
[Epoch 3/10] [Batch 12/274] [Batch classify loss: 4.223725] 
[Epoch 3/10] [Batch 13/274] [Batch classify loss: 4.534290] 
[Epoch 3/10] [Batch 14/274] [Batch classify loss: 4.485971] 
[Epoch 3/10] [Batch 15/274] [Batch classify loss: 4.362108] 
[Epoch 3/10] [Batch 16/274] [Batch classify loss: 4.486841] 
[Epoch 3/10] [Batch 17/274] [Batch classify loss: 3.987246] 
[Epoch 3/10] [Batch 18/274] [Batch classify loss: 4.639375] 
[Epoch 3/10] [Batch 19/274] [Batch classify loss: 3.952459] 
[Epoch 3/10] [Batch 20/274] [Batch classify loss: 3.938236] 
[Epoch 3/10] [Batch 21/274] [Batch classify loss: 4.543299] 
[Epoch 3/10] [Batch 22/274] [Batch classify loss: 4.071007] 
[Epoch 3/10] [Batch 23/274] [Batch classify loss: 4.865120] 
[Epoch 3/10] [Batch 24/274] [Batch classify loss: 4.324265] 
[Epoch 3/10] [Batch 25/274] [Batch classify loss: 4.105574] 
[Epoch 3/10] [Batch 26/274] [Batch classify loss: 3.933748] 
[Epoch 3/10] [Batch 27/274] [Batch classify loss: 4.456702] 
[Epoch 3/10] [Batch 28/274] [Batch classify loss: 4.439260] 
[Epoch 3/10] [Batch 29/274] [Batch classify loss: 4.748530] 
[Epoch 3/10] [Batch 30/274] [Batch classify loss: 4.777955] 
[Epoch 3/10] [Batch 31/274] [Batch classify loss: 4.672577] 
[Epoch 3/10] [Batch 32/274] [Batch classify loss: 4.530426] 
[Epoch 3/10] [Batch 33/274] [Batch classify loss: 4.317235] 
[Epoch 3/10] [Batch 34/274] [Batch classify loss: 4.353280] 
[Epoch 3/10] [Batch 35/274] [Batch classify loss: 4.450073] 
[Epoch 3/10] [Batch 36/274] [Batch classify loss: 4.686597] 
[Epoch 3/10] [Batch 37/274] [Batch classify loss: 4.608803] 
[Epoch 3/10] [Batch 38/274] [Batch classify loss: 4.716457] 
[Epoch 3/10] [Batch 39/274] [Batch classify loss: 4.400989] 
[Epoch 3/10] [Batch 40/274] [Batch classify loss: 4.521049] 
[Epoch 3/10] [Batch 41/274] [Batch classify loss: 4.039681] 
[Epoch 3/10] [Batch 42/274] [Batch classify loss: 4.636875] 
[Epoch 3/10] [Batch 43/274] [Batch classify loss: 4.384929] 
[Epoch 3/10] [Batch 44/274] [Batch classify loss: 4.653750] 
[Epoch 3/10] [Batch 45/274] [Batch classify loss: 4.471020] 
[Epoch 3/10] [Batch 46/274] [Batch classify loss: 3.735401] 
[Epoch 3/10] [Batch 47/274] [Batch classify loss: 4.302888] 
[Epoch 3/10] [Batch 48/274] [Batch classify loss: 4.425862] 
[Epoch 3/10] [Batch 49/274] [Batch classify loss: 4.315666] 
[Epoch 3/10] [Batch 50/274] [Batch classify loss: 4.353831] 
[Epoch 3/10] [Batch 51/274] [Batch classify loss: 4.965050] 
[Epoch 3/10] [Batch 52/274] [Batch classify loss: 4.482980] 
[Epoch 3/10] [Batch 53/274] [Batch classify loss: 4.652249] 
[Epoch 3/10] [Batch 54/274] [Batch classify loss: 4.241515] 
[Epoch 3/10] [Batch 55/274] [Batch classify loss: 4.210305] 
[Epoch 3/10] [Batch 56/274] [Batch classify loss: 4.675964] 
[Epoch 3/10] [Batch 57/274] [Batch classify loss: 4.455084] 
[Epoch 3/10] [Batch 58/274] [Batch classify loss: 4.467148] 
[Epoch 3/10] [Batch 59/274] [Batch classify loss: 4.632194] 
[Epoch 3/10] [Batch 60/274] [Batch classify loss: 4.411654] 
[Epoch 3/10] [Batch 61/274] [Batch classify loss: 4.484189] 
[Epoch 3/10] [Batch 62/274] [Batch classify loss: 4.755596] 
[Epoch 3/10] [Batch 63/274] [Batch classify loss: 4.608572] 
[Epoch 3/10] [Batch 64/274] [Batch classify loss: 4.610207] 
[Epoch 3/10] [Batch 65/274] [Batch classify loss: 4.540236] 
[Epoch 3/10] [Batch 66/274] [Batch classify loss: 4.577281] 
[Epoch 3/10] [Batch 67/274] [Batch classify loss: 4.887200] 
[Epoch 3/10] [Batch 68/274] [Batch classify loss: 4.296930] 
[Epoch 3/10] [Batch 69/274] [Batch classify loss: 4.350664] 
[Epoch 3/10] [Batch 70/274] [Batch classify loss: 4.255223] 
[Epoch 3/10] [Batch 71/274] [Batch classify loss: 4.731628] 
[Epoch 3/10] [Batch 72/274] [Batch classify loss: 4.506412] 
[Epoch 3/10] [Batch 73/274] [Batch classify loss: 4.016033] 
[Epoch 3/10] [Batch 74/274] [Batch classify loss: 4.318063] 
[Epoch 3/10] [Batch 75/274] [Batch classify loss: 4.612535] 
[Epoch 3/10] [Batch 76/274] [Batch classify loss: 4.635114] 
[Epoch 3/10] [Batch 77/274] [Batch classify loss: 4.100127] 
[Epoch 3/10] [Batch 78/274] [Batch classify loss: 4.312107] 
[Epoch 3/10] [Batch 79/274] [Batch classify loss: 4.562180] 
[Epoch 3/10] [Batch 80/274] [Batch classify loss: 4.318677] 
[Epoch 3/10] [Batch 81/274] [Batch classify loss: 4.341343] 
[Epoch 3/10] [Batch 82/274] [Batch classify loss: 4.578330] 
[Epoch 3/10] [Batch 83/274] [Batch classify loss: 4.908457] 
[Epoch 3/10] [Batch 84/274] [Batch classify loss: 4.523818] 
[Epoch 3/10] [Batch 85/274] [Batch classify loss: 4.371650] 
[Epoch 3/10] [Batch 86/274] [Batch classify loss: 4.727324] 
[Epoch 3/10] [Batch 87/274] [Batch classify loss: 4.527292] 
[Epoch 3/10] [Batch 88/274] [Batch classify loss: 4.304860] 
[Epoch 3/10] [Batch 89/274] [Batch classify loss: 4.558059] 
[Epoch 3/10] [Batch 90/274] [Batch classify loss: 4.108398] 
[Epoch 3/10] [Batch 91/274] [Batch classify loss: 4.619741] 
[Epoch 3/10] [Batch 92/274] [Batch classify loss: 4.331292] 
[Epoch 3/10] [Batch 93/274] [Batch classify loss: 4.601165] 
[Epoch 3/10] [Batch 94/274] [Batch classify loss: 3.988236] 
[Epoch 3/10] [Batch 95/274] [Batch classify loss: 4.568100] 
[Epoch 3/10] [Batch 96/274] [Batch classify loss: 4.772117] 
[Epoch 3/10] [Batch 97/274] [Batch classify loss: 3.879539] 
[Epoch 3/10] [Batch 98/274] [Batch classify loss: 4.127922] 
[Epoch 3/10] [Batch 99/274] [Batch classify loss: 4.738706] 
[Epoch 3/10] [Batch 100/274] [Batch classify loss: 4.375872] 
[Epoch 3/10] [Batch 101/274] [Batch classify loss: 4.003573] 
[Epoch 3/10] [Batch 102/274] [Batch classify loss: 4.470830] 
[Epoch 3/10] [Batch 103/274] [Batch classify loss: 4.355680] 
[Epoch 3/10] [Batch 104/274] [Batch classify loss: 4.330828] 
[Epoch 3/10] [Batch 105/274] [Batch classify loss: 4.542710] 
[Epoch 3/10] [Batch 106/274] [Batch classify loss: 4.602905] 
[Epoch 3/10] [Batch 107/274] [Batch classify loss: 4.080951] 
[Epoch 3/10] [Batch 108/274] [Batch classify loss: 4.819600] 
[Epoch 3/10] [Batch 109/274] [Batch classify loss: 4.833415] 
[Epoch 3/10] [Batch 110/274] [Batch classify loss: 4.727262] 
[Epoch 3/10] [Batch 111/274] [Batch classify loss: 4.164617] 
[Epoch 3/10] [Batch 112/274] [Batch classify loss: 4.903646] 
[Epoch 3/10] [Batch 113/274] [Batch classify loss: 4.403038] 
[Epoch 3/10] [Batch 114/274] [Batch classify loss: 4.259029] 
[Epoch 3/10] [Batch 115/274] [Batch classify loss: 4.232314] 
[Epoch 3/10] [Batch 116/274] [Batch classify loss: 3.919669] 
[Epoch 3/10] [Batch 117/274] [Batch classify loss: 4.509925] 
[Epoch 3/10] [Batch 118/274] [Batch classify loss: 4.393339] 
[Epoch 3/10] [Batch 119/274] [Batch classify loss: 4.381058] 
[Epoch 3/10] [Batch 120/274] [Batch classify loss: 4.703372] 
[Epoch 3/10] [Batch 121/274] [Batch classify loss: 4.204336] 
[Epoch 3/10] [Batch 122/274] [Batch classify loss: 4.342422] 
[Epoch 3/10] [Batch 123/274] [Batch classify loss: 4.646041] 
[Epoch 3/10] [Batch 124/274] [Batch classify loss: 4.224135] 
[Epoch 3/10] [Batch 125/274] [Batch classify loss: 4.253489] 
[Epoch 3/10] [Batch 126/274] [Batch classify loss: 4.888740] 
[Epoch 3/10] [Batch 127/274] [Batch classify loss: 3.743240] 
[Epoch 3/10] [Batch 128/274] [Batch classify loss: 4.358622] 
[Epoch 3/10] [Batch 129/274] [Batch classify loss: 3.924524] 
[Epoch 3/10] [Batch 130/274] [Batch classify loss: 4.486695] 
[Epoch 3/10] [Batch 131/274] [Batch classify loss: 4.298927] 
[Epoch 3/10] [Batch 132/274] [Batch classify loss: 4.513970] 
[Epoch 3/10] [Batch 133/274] [Batch classify loss: 4.111072] 
[Epoch 3/10] [Batch 134/274] [Batch classify loss: 4.423299] 
[Epoch 3/10] [Batch 135/274] [Batch classify loss: 4.368741] 
[Epoch 3/10] [Batch 136/274] [Batch classify loss: 4.621452] 
[Epoch 3/10] [Batch 137/274] [Batch classify loss: 4.501900] 
[Epoch 3/10] [Batch 138/274] [Batch classify loss: 4.797249] 
[Epoch 3/10] [Batch 139/274] [Batch classify loss: 4.027538] 
[Epoch 3/10] [Batch 140/274] [Batch classify loss: 4.635895] 
[Epoch 3/10] [Batch 141/274] [Batch classify loss: 4.591369] 
[Epoch 3/10] [Batch 142/274] [Batch classify loss: 4.287239] 
[Epoch 3/10] [Batch 143/274] [Batch classify loss: 4.052571] 
[Epoch 3/10] [Batch 144/274] [Batch classify loss: 4.435041] 
[Epoch 3/10] [Batch 145/274] [Batch classify loss: 3.750734] 
[Epoch 3/10] [Batch 146/274] [Batch classify loss: 3.930345] 
[Epoch 3/10] [Batch 147/274] [Batch classify loss: 4.183616] 
[Epoch 3/10] [Batch 148/274] [Batch classify loss: 4.608855] 
[Epoch 3/10] [Batch 149/274] [Batch classify loss: 3.940625] 
[Epoch 3/10] [Batch 150/274] [Batch classify loss: 3.744395] 
[Epoch 3/10] [Batch 151/274] [Batch classify loss: 4.107215] 
[Epoch 3/10] [Batch 152/274] [Batch classify loss: 4.399809] 
[Epoch 3/10] [Batch 153/274] [Batch classify loss: 4.188899] 
[Epoch 3/10] [Batch 154/274] [Batch classify loss: 4.084352] 
[Epoch 3/10] [Batch 155/274] [Batch classify loss: 4.728046] 
[Epoch 3/10] [Batch 156/274] [Batch classify loss: 3.940956] 
[Epoch 3/10] [Batch 157/274] [Batch classify loss: 4.356586] 
[Epoch 3/10] [Batch 158/274] [Batch classify loss: 4.116921] 
[Epoch 3/10] [Batch 159/274] [Batch classify loss: 4.474846] 
[Epoch 3/10] [Batch 160/274] [Batch classify loss: 4.293739] 
[Epoch 3/10] [Batch 161/274] [Batch classify loss: 4.499293] 
[Epoch 3/10] [Batch 162/274] [Batch classify loss: 4.517623] 
[Epoch 3/10] [Batch 163/274] [Batch classify loss: 4.377789] 
[Epoch 3/10] [Batch 164/274] [Batch classify loss: 3.851194] 
[Epoch 3/10] [Batch 165/274] [Batch classify loss: 4.446334] 
[Epoch 3/10] [Batch 166/274] [Batch classify loss: 4.326821] 
[Epoch 3/10] [Batch 167/274] [Batch classify loss: 3.915386] 
[Epoch 3/10] [Batch 168/274] [Batch classify loss: 4.351174] 
[Epoch 3/10] [Batch 169/274] [Batch classify loss: 4.638668] 
[Epoch 3/10] [Batch 170/274] [Batch classify loss: 4.405963] 
[Epoch 3/10] [Batch 171/274] [Batch classify loss: 4.231196] 
[Epoch 3/10] [Batch 172/274] [Batch classify loss: 4.438759] 
[Epoch 3/10] [Batch 173/274] [Batch classify loss: 4.462263] 
[Epoch 3/10] [Batch 174/274] [Batch classify loss: 4.180805] 
[Epoch 3/10] [Batch 175/274] [Batch classify loss: 4.243343] 
[Epoch 3/10] [Batch 176/274] [Batch classify loss: 4.384350] 
[Epoch 3/10] [Batch 177/274] [Batch classify loss: 4.143531] 
[Epoch 3/10] [Batch 178/274] [Batch classify loss: 4.368542] 
[Epoch 3/10] [Batch 179/274] [Batch classify loss: 4.319726] 
[Epoch 3/10] [Batch 180/274] [Batch classify loss: 4.586508] 
[Epoch 3/10] [Batch 181/274] [Batch classify loss: 4.228260] 
[Epoch 3/10] [Batch 182/274] [Batch classify loss: 3.957598] 
[Epoch 3/10] [Batch 183/274] [Batch classify loss: 4.277227] 
[Epoch 3/10] [Batch 184/274] [Batch classify loss: 4.339352] 
[Epoch 3/10] [Batch 185/274] [Batch classify loss: 4.285526] 
[Epoch 3/10] [Batch 186/274] [Batch classify loss: 3.843676] 
[Epoch 3/10] [Batch 187/274] [Batch classify loss: 4.541052] 
[Epoch 3/10] [Batch 188/274] [Batch classify loss: 4.089722] 
[Epoch 3/10] [Batch 189/274] [Batch classify loss: 4.285779] 
[Epoch 3/10] [Batch 190/274] [Batch classify loss: 4.407841] 
[Epoch 3/10] [Batch 191/274] [Batch classify loss: 4.348776] 
[Epoch 3/10] [Batch 192/274] [Batch classify loss: 4.672723] 
[Epoch 3/10] [Batch 193/274] [Batch classify loss: 4.313641] 
[Epoch 3/10] [Batch 194/274] [Batch classify loss: 3.772364] 
[Epoch 3/10] [Batch 195/274] [Batch classify loss: 4.192177] 
[Epoch 3/10] [Batch 196/274] [Batch classify loss: 3.713663] 
[Epoch 3/10] [Batch 197/274] [Batch classify loss: 4.080726] 
[Epoch 3/10] [Batch 198/274] [Batch classify loss: 4.615574] 
[Epoch 3/10] [Batch 199/274] [Batch classify loss: 4.491353] 
[Epoch 3/10] [Batch 200/274] [Batch classify loss: 4.353003] 
[Epoch 3/10] [Batch 201/274] [Batch classify loss: 3.904306] 
[Epoch 3/10] [Batch 202/274] [Batch classify loss: 4.035948] 
[Epoch 3/10] [Batch 203/274] [Batch classify loss: 4.640919] 
[Epoch 3/10] [Batch 204/274] [Batch classify loss: 4.194093] 
[Epoch 3/10] [Batch 205/274] [Batch classify loss: 4.286526] 
[Epoch 3/10] [Batch 206/274] [Batch classify loss: 4.157015] 
[Epoch 3/10] [Batch 207/274] [Batch classify loss: 4.401645] 
[Epoch 3/10] [Batch 208/274] [Batch classify loss: 4.334771] 
[Epoch 3/10] [Batch 209/274] [Batch classify loss: 4.083294] 
[Epoch 3/10] [Batch 210/274] [Batch classify loss: 4.619521] 
[Epoch 3/10] [Batch 211/274] [Batch classify loss: 3.826558] 
[Epoch 3/10] [Batch 212/274] [Batch classify loss: 4.086543] 
[Epoch 3/10] [Batch 213/274] [Batch classify loss: 4.395141] 
[Epoch 3/10] [Batch 214/274] [Batch classify loss: 4.690918] 
[Epoch 3/10] [Batch 215/274] [Batch classify loss: 4.421483] 
[Epoch 3/10] [Batch 216/274] [Batch classify loss: 4.205765] 
[Epoch 3/10] [Batch 217/274] [Batch classify loss: 3.905153] 
[Epoch 3/10] [Batch 218/274] [Batch classify loss: 3.951465] 
[Epoch 3/10] [Batch 219/274] [Batch classify loss: 4.255674] 
[Epoch 3/10] [Batch 220/274] [Batch classify loss: 4.563621] 
[Epoch 3/10] [Batch 221/274] [Batch classify loss: 4.437479] 
[Epoch 3/10] [Batch 222/274] [Batch classify loss: 4.384027] 
[Epoch 3/10] [Batch 223/274] [Batch classify loss: 4.567458] 
[Epoch 3/10] [Batch 224/274] [Batch classify loss: 4.241288] 
[Epoch 3/10] [Batch 225/274] [Batch classify loss: 4.178437] 
[Epoch 3/10] [Batch 226/274] [Batch classify loss: 4.029861] 
[Epoch 3/10] [Batch 227/274] [Batch classify loss: 4.220355] 
[Epoch 3/10] [Batch 228/274] [Batch classify loss: 4.340053] 
[Epoch 3/10] [Batch 229/274] [Batch classify loss: 4.435960] 
[Epoch 3/10] [Batch 230/274] [Batch classify loss: 4.047821] 
[Epoch 3/10] [Batch 231/274] [Batch classify loss: 4.206672] 
[Epoch 3/10] [Batch 232/274] [Batch classify loss: 3.854359] 
[Epoch 3/10] [Batch 233/274] [Batch classify loss: 4.170563] 
[Epoch 3/10] [Batch 234/274] [Batch classify loss: 3.977532] 
[Epoch 3/10] [Batch 235/274] [Batch classify loss: 3.821564] 
[Epoch 3/10] [Batch 236/274] [Batch classify loss: 4.556619] 
[Epoch 3/10] [Batch 237/274] [Batch classify loss: 3.972068] 
[Epoch 3/10] [Batch 238/274] [Batch classify loss: 4.168633] 
[Epoch 3/10] [Batch 239/274] [Batch classify loss: 4.308354] 
[Epoch 3/10] [Batch 240/274] [Batch classify loss: 4.039869] 
[Epoch 3/10] [Batch 241/274] [Batch classify loss: 4.490517] 
[Epoch 3/10] [Batch 242/274] [Batch classify loss: 4.365683] 
[Epoch 3/10] [Batch 243/274] [Batch classify loss: 3.897907] 
[Epoch 3/10] [Batch 244/274] [Batch classify loss: 4.320493] 
[Epoch 3/10] [Batch 245/274] [Batch classify loss: 4.252645] 
[Epoch 3/10] [Batch 246/274] [Batch classify loss: 4.890581] 
[Epoch 3/10] [Batch 247/274] [Batch classify loss: 4.316243] 
[Epoch 3/10] [Batch 248/274] [Batch classify loss: 4.379491] 
[Epoch 3/10] [Batch 249/274] [Batch classify loss: 3.774632] 
[Epoch 3/10] [Batch 250/274] [Batch classify loss: 4.383881] 
[Epoch 3/10] [Batch 251/274] [Batch classify loss: 3.861834] 
[Epoch 3/10] [Batch 252/274] [Batch classify loss: 4.104756] 
[Epoch 3/10] [Batch 253/274] [Batch classify loss: 4.233306] 
[Epoch 3/10] [Batch 254/274] [Batch classify loss: 3.929663] 
[Epoch 3/10] [Batch 255/274] [Batch classify loss: 4.436311] 
[Epoch 3/10] [Batch 256/274] [Batch classify loss: 3.847361] 
[Epoch 3/10] [Batch 257/274] [Batch classify loss: 4.267278] 
[Epoch 3/10] [Batch 258/274] [Batch classify loss: 4.317250] 
[Epoch 3/10] [Batch 259/274] [Batch classify loss: 4.476268] 
[Epoch 3/10] [Batch 260/274] [Batch classify loss: 4.066519] 
[Epoch 3/10] [Batch 261/274] [Batch classify loss: 4.523817] 
[Epoch 3/10] [Batch 262/274] [Batch classify loss: 4.321052] 
[Epoch 3/10] [Batch 263/274] [Batch classify loss: 4.592896] 
[Epoch 3/10] [Batch 264/274] [Batch classify loss: 3.732394] 
[Epoch 3/10] [Batch 265/274] [Batch classify loss: 3.711397] 
[Epoch 3/10] [Batch 266/274] [Batch classify loss: 4.268438] 
[Epoch 3/10] [Batch 267/274] [Batch classify loss: 3.943105] 
[Epoch 3/10] [Batch 268/274] [Batch classify loss: 4.371362] 
[Epoch 3/10] [Batch 269/274] [Batch classify loss: 4.232112] 
[Epoch 3/10] [Batch 270/274] [Batch classify loss: 4.409159] 
[Epoch 3/10] [Batch 271/274] [Batch classify loss: 4.236297] 
[Epoch 3/10] [Batch 272/274] [Batch classify loss: 4.082588] 
[Epoch 3/10] [Batch 273/274] [Batch classify loss: 4.209741] 
[Epoch 3/10] [Batch 274/274] [Batch classify loss: 4.058440] 
0003 epoch mmat trained classifier accuary on the clean testing examples:94.8871%
0003 epoch mmat trained classifier loss on the clean testing examples:0.2238
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2966%
mmat trained classifier loss on adversarial testset:4.523214817047119
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-cle
3epoch learning rate:0.01
[Epoch 4/10] [Batch 1/274] [Batch classify loss: 2.338950] 
[Epoch 4/10] [Batch 2/274] [Batch classify loss: 3.106853] 
[Epoch 4/10] [Batch 3/274] [Batch classify loss: 3.745623] 
[Epoch 4/10] [Batch 4/274] [Batch classify loss: 3.842189] 
[Epoch 4/10] [Batch 5/274] [Batch classify loss: 3.600712] 
[Epoch 4/10] [Batch 6/274] [Batch classify loss: 3.946604] 
[Epoch 4/10] [Batch 7/274] [Batch classify loss: 3.929340] 
[Epoch 4/10] [Batch 8/274] [Batch classify loss: 3.806235] 
[Epoch 4/10] [Batch 9/274] [Batch classify loss: 4.121325] 
[Epoch 4/10] [Batch 10/274] [Batch classify loss: 4.139914] 
[Epoch 4/10] [Batch 11/274] [Batch classify loss: 3.753614] 
[Epoch 4/10] [Batch 12/274] [Batch classify loss: 3.912519] 
[Epoch 4/10] [Batch 13/274] [Batch classify loss: 4.298256] 
[Epoch 4/10] [Batch 14/274] [Batch classify loss: 3.885829] 
[Epoch 4/10] [Batch 15/274] [Batch classify loss: 4.436101] 
[Epoch 4/10] [Batch 16/274] [Batch classify loss: 3.771403] 
[Epoch 4/10] [Batch 17/274] [Batch classify loss: 4.017323] 
[Epoch 4/10] [Batch 18/274] [Batch classify loss: 4.021485] 
[Epoch 4/10] [Batch 19/274] [Batch classify loss: 3.934871] 
[Epoch 4/10] [Batch 20/274] [Batch classify loss: 4.368823] 
[Epoch 4/10] [Batch 21/274] [Batch classify loss: 4.707150] 
[Epoch 4/10] [Batch 22/274] [Batch classify loss: 4.054725] 
[Epoch 4/10] [Batch 23/274] [Batch classify loss: 4.018553] 
[Epoch 4/10] [Batch 24/274] [Batch classify loss: 4.255577] 
[Epoch 4/10] [Batch 25/274] [Batch classify loss: 4.377033] 
[Epoch 4/10] [Batch 26/274] [Batch classify loss: 3.901695] 
[Epoch 4/10] [Batch 27/274] [Batch classify loss: 4.272797] 
[Epoch 4/10] [Batch 28/274] [Batch classify loss: 4.189315] 
[Epoch 4/10] [Batch 29/274] [Batch classify loss: 4.146943] 
[Epoch 4/10] [Batch 30/274] [Batch classify loss: 4.427810] 
[Epoch 4/10] [Batch 31/274] [Batch classify loss: 3.964363] 
[Epoch 4/10] [Batch 32/274] [Batch classify loss: 3.689429] 
[Epoch 4/10] [Batch 33/274] [Batch classify loss: 4.175313] 
[Epoch 4/10] [Batch 34/274] [Batch classify loss: 4.086400] 
[Epoch 4/10] [Batch 35/274] [Batch classify loss: 4.376875] 
[Epoch 4/10] [Batch 36/274] [Batch classify loss: 4.301709] 
[Epoch 4/10] [Batch 37/274] [Batch classify loss: 4.515586] 
[Epoch 4/10] [Batch 38/274] [Batch classify loss: 4.069084] 
[Epoch 4/10] [Batch 39/274] [Batch classify loss: 3.818018] 
[Epoch 4/10] [Batch 40/274] [Batch classify loss: 4.328219] 
[Epoch 4/10] [Batch 41/274] [Batch classify loss: 4.333114] 
[Epoch 4/10] [Batch 42/274] [Batch classify loss: 4.073946] 
[Epoch 4/10] [Batch 43/274] [Batch classify loss: 4.498221] 
[Epoch 4/10] [Batch 44/274] [Batch classify loss: 4.436059] 
[Epoch 4/10] [Batch 45/274] [Batch classify loss: 4.166917] 
[Epoch 4/10] [Batch 46/274] [Batch classify loss: 4.469141] 
[Epoch 4/10] [Batch 47/274] [Batch classify loss: 4.900784] 
[Epoch 4/10] [Batch 48/274] [Batch classify loss: 5.027573] 
[Epoch 4/10] [Batch 49/274] [Batch classify loss: 4.069169] 
[Epoch 4/10] [Batch 50/274] [Batch classify loss: 4.608985] 
[Epoch 4/10] [Batch 51/274] [Batch classify loss: 3.978380] 
[Epoch 4/10] [Batch 52/274] [Batch classify loss: 4.382147] 
[Epoch 4/10] [Batch 53/274] [Batch classify loss: 4.516957] 
[Epoch 4/10] [Batch 54/274] [Batch classify loss: 4.213257] 
[Epoch 4/10] [Batch 55/274] [Batch classify loss: 4.343452] 
[Epoch 4/10] [Batch 56/274] [Batch classify loss: 4.352921] 
[Epoch 4/10] [Batch 57/274] [Batch classify loss: 4.293301] 
[Epoch 4/10] [Batch 58/274] [Batch classify loss: 4.336655] 
[Epoch 4/10] [Batch 59/274] [Batch classify loss: 4.612542] 
[Epoch 4/10] [Batch 60/274] [Batch classify loss: 4.235176] 
[Epoch 4/10] [Batch 61/274] [Batch classify loss: 4.214967] 
[Epoch 4/10] [Batch 62/274] [Batch classify loss: 4.321317] 
[Epoch 4/10] [Batch 63/274] [Batch classify loss: 4.181486] 
[Epoch 4/10] [Batch 64/274] [Batch classify loss: 4.283438] 
[Epoch 4/10] [Batch 65/274] [Batch classify loss: 4.346400] 
[Epoch 4/10] [Batch 66/274] [Batch classify loss: 4.697254] 
[Epoch 4/10] [Batch 67/274] [Batch classify loss: 4.036397] 
[Epoch 4/10] [Batch 68/274] [Batch classify loss: 4.598853] 
[Epoch 4/10] [Batch 69/274] [Batch classify loss: 4.475063] 
[Epoch 4/10] [Batch 70/274] [Batch classify loss: 4.500802] 
[Epoch 4/10] [Batch 71/274] [Batch classify loss: 4.210911] 
[Epoch 4/10] [Batch 72/274] [Batch classify loss: 4.434147] 
[Epoch 4/10] [Batch 73/274] [Batch classify loss: 4.450492] 
[Epoch 4/10] [Batch 74/274] [Batch classify loss: 4.540072] 
[Epoch 4/10] [Batch 75/274] [Batch classify loss: 4.634488] 
[Epoch 4/10] [Batch 76/274] [Batch classify loss: 4.696207] 
[Epoch 4/10] [Batch 77/274] [Batch classify loss: 4.619108] 
[Epoch 4/10] [Batch 78/274] [Batch classify loss: 4.374724] 
[Epoch 4/10] [Batch 79/274] [Batch classify loss: 4.064240] 
[Epoch 4/10] [Batch 80/274] [Batch classify loss: 4.183874] 
[Epoch 4/10] [Batch 81/274] [Batch classify loss: 4.225796] 
[Epoch 4/10] [Batch 82/274] [Batch classify loss: 4.679579] 
[Epoch 4/10] [Batch 83/274] [Batch classify loss: 4.224182] 
[Epoch 4/10] [Batch 84/274] [Batch classify loss: 4.428343] 
[Epoch 4/10] [Batch 85/274] [Batch classify loss: 4.504555] 
[Epoch 4/10] [Batch 86/274] [Batch classify loss: 4.355887] 
[Epoch 4/10] [Batch 87/274] [Batch classify loss: 4.561194] 
[Epoch 4/10] [Batch 88/274] [Batch classify loss: 4.259187] 
[Epoch 4/10] [Batch 89/274] [Batch classify loss: 4.565733] 
[Epoch 4/10] [Batch 90/274] [Batch classify loss: 4.272367] 
[Epoch 4/10] [Batch 91/274] [Batch classify loss: 4.473279] 
[Epoch 4/10] [Batch 92/274] [Batch classify loss: 4.288547] 
[Epoch 4/10] [Batch 93/274] [Batch classify loss: 4.581602] 
[Epoch 4/10] [Batch 94/274] [Batch classify loss: 4.654652] 
[Epoch 4/10] [Batch 95/274] [Batch classify loss: 3.823185] 
[Epoch 4/10] [Batch 96/274] [Batch classify loss: 4.838070] 
[Epoch 4/10] [Batch 97/274] [Batch classify loss: 4.832837] 
[Epoch 4/10] [Batch 98/274] [Batch classify loss: 4.306213] 
[Epoch 4/10] [Batch 99/274] [Batch classify loss: 4.247846] 
[Epoch 4/10] [Batch 100/274] [Batch classify loss: 4.424042] 
[Epoch 4/10] [Batch 101/274] [Batch classify loss: 4.190035] 
[Epoch 4/10] [Batch 102/274] [Batch classify loss: 4.503471] 
[Epoch 4/10] [Batch 103/274] [Batch classify loss: 4.103711] 
[Epoch 4/10] [Batch 104/274] [Batch classify loss: 4.459319] 
[Epoch 4/10] [Batch 105/274] [Batch classify loss: 4.109305] 
[Epoch 4/10] [Batch 106/274] [Batch classify loss: 3.908047] 
[Epoch 4/10] [Batch 107/274] [Batch classify loss: 4.662186] 
[Epoch 4/10] [Batch 108/274] [Batch classify loss: 4.593808] 
[Epoch 4/10] [Batch 109/274] [Batch classify loss: 4.411667] 
[Epoch 4/10] [Batch 110/274] [Batch classify loss: 4.433025] 
[Epoch 4/10] [Batch 111/274] [Batch classify loss: 3.886956] 
[Epoch 4/10] [Batch 112/274] [Batch classify loss: 4.501883] 
[Epoch 4/10] [Batch 113/274] [Batch classify loss: 4.228437] 
[Epoch 4/10] [Batch 114/274] [Batch classify loss: 4.435642] 
[Epoch 4/10] [Batch 115/274] [Batch classify loss: 4.571317] 
[Epoch 4/10] [Batch 116/274] [Batch classify loss: 4.755098] 
[Epoch 4/10] [Batch 117/274] [Batch classify loss: 4.782603] 
[Epoch 4/10] [Batch 118/274] [Batch classify loss: 4.314291] 
[Epoch 4/10] [Batch 119/274] [Batch classify loss: 4.532557] 
[Epoch 4/10] [Batch 120/274] [Batch classify loss: 4.276319] 
[Epoch 4/10] [Batch 121/274] [Batch classify loss: 4.464134] 
[Epoch 4/10] [Batch 122/274] [Batch classify loss: 4.832592] 
[Epoch 4/10] [Batch 123/274] [Batch classify loss: 4.216791] 
[Epoch 4/10] [Batch 124/274] [Batch classify loss: 4.259667] 
[Epoch 4/10] [Batch 125/274] [Batch classify loss: 4.258060] 
[Epoch 4/10] [Batch 126/274] [Batch classify loss: 4.314483] 
[Epoch 4/10] [Batch 127/274] [Batch classify loss: 4.386477] 
[Epoch 4/10] [Batch 128/274] [Batch classify loss: 4.114810] 
[Epoch 4/10] [Batch 129/274] [Batch classify loss: 4.614763] 
[Epoch 4/10] [Batch 130/274] [Batch classify loss: 4.347081] 
[Epoch 4/10] [Batch 131/274] [Batch classify loss: 4.125578] 
[Epoch 4/10] [Batch 132/274] [Batch classify loss: 4.731667] 
[Epoch 4/10] [Batch 133/274] [Batch classify loss: 4.815865] 
[Epoch 4/10] [Batch 134/274] [Batch classify loss: 4.055543] 
[Epoch 4/10] [Batch 135/274] [Batch classify loss: 4.291335] 
[Epoch 4/10] [Batch 136/274] [Batch classify loss: 4.524098] 
[Epoch 4/10] [Batch 137/274] [Batch classify loss: 4.525589] 
[Epoch 4/10] [Batch 138/274] [Batch classify loss: 4.547643] 
[Epoch 4/10] [Batch 139/274] [Batch classify loss: 4.190762] 
[Epoch 4/10] [Batch 140/274] [Batch classify loss: 4.443992] 
[Epoch 4/10] [Batch 141/274] [Batch classify loss: 4.088984] 
[Epoch 4/10] [Batch 142/274] [Batch classify loss: 4.347996] 
[Epoch 4/10] [Batch 143/274] [Batch classify loss: 4.221549] 
[Epoch 4/10] [Batch 144/274] [Batch classify loss: 4.886148] 
[Epoch 4/10] [Batch 145/274] [Batch classify loss: 4.959760] 
[Epoch 4/10] [Batch 146/274] [Batch classify loss: 4.406650] 
[Epoch 4/10] [Batch 147/274] [Batch classify loss: 4.239389] 
[Epoch 4/10] [Batch 148/274] [Batch classify loss: 4.714482] 
[Epoch 4/10] [Batch 149/274] [Batch classify loss: 4.267066] 
[Epoch 4/10] [Batch 150/274] [Batch classify loss: 4.200102] 
[Epoch 4/10] [Batch 151/274] [Batch classify loss: 4.268718] 
[Epoch 4/10] [Batch 152/274] [Batch classify loss: 4.112524] 
[Epoch 4/10] [Batch 153/274] [Batch classify loss: 5.005841] 
[Epoch 4/10] [Batch 154/274] [Batch classify loss: 4.197894] 
[Epoch 4/10] [Batch 155/274] [Batch classify loss: 4.234999] 
[Epoch 4/10] [Batch 156/274] [Batch classify loss: 3.831435] 
[Epoch 4/10] [Batch 157/274] [Batch classify loss: 4.801727] 
[Epoch 4/10] [Batch 158/274] [Batch classify loss: 4.347555] 
[Epoch 4/10] [Batch 159/274] [Batch classify loss: 4.074030] 
[Epoch 4/10] [Batch 160/274] [Batch classify loss: 3.967395] 
[Epoch 4/10] [Batch 161/274] [Batch classify loss: 4.198072] 
[Epoch 4/10] [Batch 162/274] [Batch classify loss: 4.770517] 
[Epoch 4/10] [Batch 163/274] [Batch classify loss: 4.624908] 
[Epoch 4/10] [Batch 164/274] [Batch classify loss: 4.319920] 
[Epoch 4/10] [Batch 165/274] [Batch classify loss: 4.416970] 
[Epoch 4/10] [Batch 166/274] [Batch classify loss: 4.067950] 
[Epoch 4/10] [Batch 167/274] [Batch classify loss: 4.357388] 
[Epoch 4/10] [Batch 168/274] [Batch classify loss: 4.872766] 
[Epoch 4/10] [Batch 169/274] [Batch classify loss: 4.013218] 
[Epoch 4/10] [Batch 170/274] [Batch classify loss: 3.654322] 
[Epoch 4/10] [Batch 171/274] [Batch classify loss: 5.238876] 
[Epoch 4/10] [Batch 172/274] [Batch classify loss: 4.300150] 
[Epoch 4/10] [Batch 173/274] [Batch classify loss: 4.352151] 
[Epoch 4/10] [Batch 174/274] [Batch classify loss: 4.690420] 
[Epoch 4/10] [Batch 175/274] [Batch classify loss: 3.987714] 
[Epoch 4/10] [Batch 176/274] [Batch classify loss: 4.153344] 
[Epoch 4/10] [Batch 177/274] [Batch classify loss: 4.148013] 
[Epoch 4/10] [Batch 178/274] [Batch classify loss: 4.211323] 
[Epoch 4/10] [Batch 179/274] [Batch classify loss: 4.359941] 
[Epoch 4/10] [Batch 180/274] [Batch classify loss: 4.493896] 
[Epoch 4/10] [Batch 181/274] [Batch classify loss: 4.478683] 
[Epoch 4/10] [Batch 182/274] [Batch classify loss: 3.961715] 
[Epoch 4/10] [Batch 183/274] [Batch classify loss: 4.650883] 
[Epoch 4/10] [Batch 184/274] [Batch classify loss: 4.317144] 
[Epoch 4/10] [Batch 185/274] [Batch classify loss: 4.094673] 
[Epoch 4/10] [Batch 186/274] [Batch classify loss: 4.617009] 
[Epoch 4/10] [Batch 187/274] [Batch classify loss: 4.203366] 
[Epoch 4/10] [Batch 188/274] [Batch classify loss: 3.862535] 
[Epoch 4/10] [Batch 189/274] [Batch classify loss: 4.288953] 
[Epoch 4/10] [Batch 190/274] [Batch classify loss: 4.446433] 
[Epoch 4/10] [Batch 191/274] [Batch classify loss: 4.182730] 
[Epoch 4/10] [Batch 192/274] [Batch classify loss: 4.581374] 
[Epoch 4/10] [Batch 193/274] [Batch classify loss: 4.092335] 
[Epoch 4/10] [Batch 194/274] [Batch classify loss: 4.363064] 
[Epoch 4/10] [Batch 195/274] [Batch classify loss: 4.602126] 
[Epoch 4/10] [Batch 196/274] [Batch classify loss: 4.332976] 
[Epoch 4/10] [Batch 197/274] [Batch classify loss: 4.024158] 
[Epoch 4/10] [Batch 198/274] [Batch classify loss: 4.247444] 
[Epoch 4/10] [Batch 199/274] [Batch classify loss: 3.894339] 
[Epoch 4/10] [Batch 200/274] [Batch classify loss: 4.633038] 
[Epoch 4/10] [Batch 201/274] [Batch classify loss: 4.104423] 
[Epoch 4/10] [Batch 202/274] [Batch classify loss: 4.615750] 
[Epoch 4/10] [Batch 203/274] [Batch classify loss: 4.458067] 
[Epoch 4/10] [Batch 204/274] [Batch classify loss: 4.478130] 
[Epoch 4/10] [Batch 205/274] [Batch classify loss: 4.694129] 
[Epoch 4/10] [Batch 206/274] [Batch classify loss: 3.824923] 
[Epoch 4/10] [Batch 207/274] [Batch classify loss: 4.470842] 
[Epoch 4/10] [Batch 208/274] [Batch classify loss: 4.591847] 
[Epoch 4/10] [Batch 209/274] [Batch classify loss: 4.180882] 
[Epoch 4/10] [Batch 210/274] [Batch classify loss: 4.748697] 
[Epoch 4/10] [Batch 211/274] [Batch classify loss: 4.536413] 
[Epoch 4/10] [Batch 212/274] [Batch classify loss: 4.777207] 
[Epoch 4/10] [Batch 213/274] [Batch classify loss: 4.208132] 
[Epoch 4/10] [Batch 214/274] [Batch classify loss: 3.841475] 
[Epoch 4/10] [Batch 215/274] [Batch classify loss: 4.247637] 
[Epoch 4/10] [Batch 216/274] [Batch classify loss: 4.651809] 
[Epoch 4/10] [Batch 217/274] [Batch classify loss: 4.472383] 
[Epoch 4/10] [Batch 218/274] [Batch classify loss: 4.523129] 
[Epoch 4/10] [Batch 219/274] [Batch classify loss: 4.071616] 
[Epoch 4/10] [Batch 220/274] [Batch classify loss: 4.614583] 
[Epoch 4/10] [Batch 221/274] [Batch classify loss: 4.051597] 
[Epoch 4/10] [Batch 222/274] [Batch classify loss: 4.165409] 
[Epoch 4/10] [Batch 223/274] [Batch classify loss: 3.986892] 
[Epoch 4/10] [Batch 224/274] [Batch classify loss: 4.765231] 
[Epoch 4/10] [Batch 225/274] [Batch classify loss: 4.926432] 
[Epoch 4/10] [Batch 226/274] [Batch classify loss: 4.112794] 
[Epoch 4/10] [Batch 227/274] [Batch classify loss: 4.047235] 
[Epoch 4/10] [Batch 228/274] [Batch classify loss: 4.341995] 
[Epoch 4/10] [Batch 229/274] [Batch classify loss: 4.386985] 
[Epoch 4/10] [Batch 230/274] [Batch classify loss: 4.406484] 
[Epoch 4/10] [Batch 231/274] [Batch classify loss: 3.955800] 
[Epoch 4/10] [Batch 232/274] [Batch classify loss: 4.349050] 
[Epoch 4/10] [Batch 233/274] [Batch classify loss: 4.723480] 
[Epoch 4/10] [Batch 234/274] [Batch classify loss: 4.524716] 
[Epoch 4/10] [Batch 235/274] [Batch classify loss: 4.224703] 
[Epoch 4/10] [Batch 236/274] [Batch classify loss: 4.688694] 
[Epoch 4/10] [Batch 237/274] [Batch classify loss: 4.371973] 
[Epoch 4/10] [Batch 238/274] [Batch classify loss: 4.603124] 
[Epoch 4/10] [Batch 239/274] [Batch classify loss: 4.339308] 
[Epoch 4/10] [Batch 240/274] [Batch classify loss: 4.580426] 
[Epoch 4/10] [Batch 241/274] [Batch classify loss: 4.510320] 
[Epoch 4/10] [Batch 242/274] [Batch classify loss: 4.553679] 
[Epoch 4/10] [Batch 243/274] [Batch classify loss: 4.572817] 
[Epoch 4/10] [Batch 244/274] [Batch classify loss: 3.965866] 
[Epoch 4/10] [Batch 245/274] [Batch classify loss: 4.758465] 
[Epoch 4/10] [Batch 246/274] [Batch classify loss: 4.398374] 
[Epoch 4/10] [Batch 247/274] [Batch classify loss: 4.711672] 
[Epoch 4/10] [Batch 248/274] [Batch classify loss: 4.319754] 
[Epoch 4/10] [Batch 249/274] [Batch classify loss: 3.686162] 
[Epoch 4/10] [Batch 250/274] [Batch classify loss: 4.698983] 
[Epoch 4/10] [Batch 251/274] [Batch classify loss: 3.776520] 
[Epoch 4/10] [Batch 252/274] [Batch classify loss: 4.162885] 
[Epoch 4/10] [Batch 253/274] [Batch classify loss: 4.169422] 
[Epoch 4/10] [Batch 254/274] [Batch classify loss: 4.097846] 
[Epoch 4/10] [Batch 255/274] [Batch classify loss: 4.263583] 
[Epoch 4/10] [Batch 256/274] [Batch classify loss: 4.307790] 
[Epoch 4/10] [Batch 257/274] [Batch classify loss: 3.877990] 
[Epoch 4/10] [Batch 258/274] [Batch classify loss: 4.240344] 
[Epoch 4/10] [Batch 259/274] [Batch classify loss: 4.607973] 
[Epoch 4/10] [Batch 260/274] [Batch classify loss: 3.911637] 
[Epoch 4/10] [Batch 261/274] [Batch classify loss: 4.399191] 
[Epoch 4/10] [Batch 262/274] [Batch classify loss: 4.574187] 
[Epoch 4/10] [Batch 263/274] [Batch classify loss: 4.168097] 
[Epoch 4/10] [Batch 264/274] [Batch classify loss: 4.195486] 
[Epoch 4/10] [Batch 265/274] [Batch classify loss: 4.222070] 
[Epoch 4/10] [Batch 266/274] [Batch classify loss: 4.108479] 
[Epoch 4/10] [Batch 267/274] [Batch classify loss: 4.663768] 
[Epoch 4/10] [Batch 268/274] [Batch classify loss: 4.706244] 
[Epoch 4/10] [Batch 269/274] [Batch classify loss: 4.573728] 
[Epoch 4/10] [Batch 270/274] [Batch classify loss: 4.509958] 
[Epoch 4/10] [Batch 271/274] [Batch classify loss: 4.727326] 
[Epoch 4/10] [Batch 272/274] [Batch classify loss: 4.244604] 
[Epoch 4/10] [Batch 273/274] [Batch classify loss: 4.560072] 
[Epoch 4/10] [Batch 274/274] [Batch classify loss: 5.440813] 
0004 epoch mmat trained classifier accuary on the clean testing examples:94.7526%
0004 epoch mmat trained classifier loss on the clean testing examples:0.2221
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.1314%
mmat trained classifier loss on adversarial testset:4.535048007965088
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-cle
4epoch learning rate:0.01
[Epoch 5/10] [Batch 1/274] [Batch classify loss: 2.044724] 
[Epoch 5/10] [Batch 2/274] [Batch classify loss: 2.738273] 
[Epoch 5/10] [Batch 3/274] [Batch classify loss: 3.074848] 
[Epoch 5/10] [Batch 4/274] [Batch classify loss: 2.978286] 
[Epoch 5/10] [Batch 5/274] [Batch classify loss: 2.874812] 
[Epoch 5/10] [Batch 6/274] [Batch classify loss: 3.402918] 
[Epoch 5/10] [Batch 7/274] [Batch classify loss: 3.586588] 
[Epoch 5/10] [Batch 8/274] [Batch classify loss: 3.309311] 
[Epoch 5/10] [Batch 9/274] [Batch classify loss: 3.654794] 
[Epoch 5/10] [Batch 10/274] [Batch classify loss: 3.314885] 
[Epoch 5/10] [Batch 11/274] [Batch classify loss: 3.879811] 
[Epoch 5/10] [Batch 12/274] [Batch classify loss: 3.762026] 
[Epoch 5/10] [Batch 13/274] [Batch classify loss: 3.890090] 
[Epoch 5/10] [Batch 14/274] [Batch classify loss: 3.787670] 
[Epoch 5/10] [Batch 15/274] [Batch classify loss: 3.761657] 
[Epoch 5/10] [Batch 16/274] [Batch classify loss: 3.415892] 
[Epoch 5/10] [Batch 17/274] [Batch classify loss: 3.367553] 
[Epoch 5/10] [Batch 18/274] [Batch classify loss: 3.827331] 
[Epoch 5/10] [Batch 19/274] [Batch classify loss: 3.969797] 
[Epoch 5/10] [Batch 20/274] [Batch classify loss: 4.158064] 
[Epoch 5/10] [Batch 21/274] [Batch classify loss: 3.663801] 
[Epoch 5/10] [Batch 22/274] [Batch classify loss: 3.994044] 
[Epoch 5/10] [Batch 23/274] [Batch classify loss: 3.743707] 
[Epoch 5/10] [Batch 24/274] [Batch classify loss: 3.916421] 
[Epoch 5/10] [Batch 25/274] [Batch classify loss: 4.018260] 
[Epoch 5/10] [Batch 26/274] [Batch classify loss: 3.974912] 
[Epoch 5/10] [Batch 27/274] [Batch classify loss: 3.938445] 
[Epoch 5/10] [Batch 28/274] [Batch classify loss: 4.401080] 
[Epoch 5/10] [Batch 29/274] [Batch classify loss: 3.953160] 
[Epoch 5/10] [Batch 30/274] [Batch classify loss: 3.947685] 
[Epoch 5/10] [Batch 31/274] [Batch classify loss: 3.877445] 
[Epoch 5/10] [Batch 32/274] [Batch classify loss: 3.909313] 
[Epoch 5/10] [Batch 33/274] [Batch classify loss: 3.950277] 
[Epoch 5/10] [Batch 34/274] [Batch classify loss: 4.536766] 
[Epoch 5/10] [Batch 35/274] [Batch classify loss: 3.885039] 
[Epoch 5/10] [Batch 36/274] [Batch classify loss: 3.768381] 
[Epoch 5/10] [Batch 37/274] [Batch classify loss: 4.084445] 
[Epoch 5/10] [Batch 38/274] [Batch classify loss: 4.528620] 
[Epoch 5/10] [Batch 39/274] [Batch classify loss: 3.889378] 
[Epoch 5/10] [Batch 40/274] [Batch classify loss: 3.914321] 
[Epoch 5/10] [Batch 41/274] [Batch classify loss: 3.501350] 
[Epoch 5/10] [Batch 42/274] [Batch classify loss: 4.108529] 
[Epoch 5/10] [Batch 43/274] [Batch classify loss: 4.120468] 
[Epoch 5/10] [Batch 44/274] [Batch classify loss: 3.974620] 
[Epoch 5/10] [Batch 45/274] [Batch classify loss: 3.817518] 
[Epoch 5/10] [Batch 46/274] [Batch classify loss: 3.857905] 
[Epoch 5/10] [Batch 47/274] [Batch classify loss: 4.512997] 
[Epoch 5/10] [Batch 48/274] [Batch classify loss: 4.281187] 
[Epoch 5/10] [Batch 49/274] [Batch classify loss: 4.162210] 
[Epoch 5/10] [Batch 50/274] [Batch classify loss: 3.663347] 
[Epoch 5/10] [Batch 51/274] [Batch classify loss: 3.937222] 
[Epoch 5/10] [Batch 52/274] [Batch classify loss: 4.441760] 
[Epoch 5/10] [Batch 53/274] [Batch classify loss: 3.832771] 
[Epoch 5/10] [Batch 54/274] [Batch classify loss: 4.553258] 
[Epoch 5/10] [Batch 55/274] [Batch classify loss: 4.169533] 
[Epoch 5/10] [Batch 56/274] [Batch classify loss: 4.295665] 
[Epoch 5/10] [Batch 57/274] [Batch classify loss: 4.281987] 
[Epoch 5/10] [Batch 58/274] [Batch classify loss: 3.941714] 
[Epoch 5/10] [Batch 59/274] [Batch classify loss: 3.800840] 
[Epoch 5/10] [Batch 60/274] [Batch classify loss: 4.173228] 
[Epoch 5/10] [Batch 61/274] [Batch classify loss: 3.738129] 
[Epoch 5/10] [Batch 62/274] [Batch classify loss: 4.092164] 
[Epoch 5/10] [Batch 63/274] [Batch classify loss: 3.992278] 
[Epoch 5/10] [Batch 64/274] [Batch classify loss: 3.955578] 
[Epoch 5/10] [Batch 65/274] [Batch classify loss: 4.781655] 
[Epoch 5/10] [Batch 66/274] [Batch classify loss: 3.996832] 
[Epoch 5/10] [Batch 67/274] [Batch classify loss: 4.111786] 
[Epoch 5/10] [Batch 68/274] [Batch classify loss: 3.974879] 
[Epoch 5/10] [Batch 69/274] [Batch classify loss: 4.081582] 
[Epoch 5/10] [Batch 70/274] [Batch classify loss: 4.217166] 
[Epoch 5/10] [Batch 71/274] [Batch classify loss: 3.850711] 
[Epoch 5/10] [Batch 72/274] [Batch classify loss: 4.463436] 
[Epoch 5/10] [Batch 73/274] [Batch classify loss: 4.507834] 
[Epoch 5/10] [Batch 74/274] [Batch classify loss: 4.238927] 
[Epoch 5/10] [Batch 75/274] [Batch classify loss: 4.079388] 
[Epoch 5/10] [Batch 76/274] [Batch classify loss: 4.205622] 
[Epoch 5/10] [Batch 77/274] [Batch classify loss: 4.410774] 
[Epoch 5/10] [Batch 78/274] [Batch classify loss: 4.246594] 
[Epoch 5/10] [Batch 79/274] [Batch classify loss: 4.122083] 
[Epoch 5/10] [Batch 80/274] [Batch classify loss: 4.362511] 
[Epoch 5/10] [Batch 81/274] [Batch classify loss: 4.027681] 
[Epoch 5/10] [Batch 82/274] [Batch classify loss: 4.116423] 
[Epoch 5/10] [Batch 83/274] [Batch classify loss: 4.107086] 
[Epoch 5/10] [Batch 84/274] [Batch classify loss: 4.579178] 
[Epoch 5/10] [Batch 85/274] [Batch classify loss: 4.131782] 
[Epoch 5/10] [Batch 86/274] [Batch classify loss: 4.323151] 
[Epoch 5/10] [Batch 87/274] [Batch classify loss: 4.411494] 
[Epoch 5/10] [Batch 88/274] [Batch classify loss: 4.251771] 
[Epoch 5/10] [Batch 89/274] [Batch classify loss: 3.871926] 
[Epoch 5/10] [Batch 90/274] [Batch classify loss: 4.055856] 
[Epoch 5/10] [Batch 91/274] [Batch classify loss: 4.686567] 
[Epoch 5/10] [Batch 92/274] [Batch classify loss: 4.138487] 
[Epoch 5/10] [Batch 93/274] [Batch classify loss: 4.499750] 
[Epoch 5/10] [Batch 94/274] [Batch classify loss: 4.149105] 
[Epoch 5/10] [Batch 95/274] [Batch classify loss: 4.509810] 
[Epoch 5/10] [Batch 96/274] [Batch classify loss: 3.626679] 
[Epoch 5/10] [Batch 97/274] [Batch classify loss: 4.023344] 
[Epoch 5/10] [Batch 98/274] [Batch classify loss: 4.477591] 
[Epoch 5/10] [Batch 99/274] [Batch classify loss: 4.344848] 
[Epoch 5/10] [Batch 100/274] [Batch classify loss: 4.189771] 
[Epoch 5/10] [Batch 101/274] [Batch classify loss: 4.262235] 
[Epoch 5/10] [Batch 102/274] [Batch classify loss: 4.507924] 
[Epoch 5/10] [Batch 103/274] [Batch classify loss: 3.867556] 
[Epoch 5/10] [Batch 104/274] [Batch classify loss: 4.264106] 
[Epoch 5/10] [Batch 105/274] [Batch classify loss: 4.465427] 
[Epoch 5/10] [Batch 106/274] [Batch classify loss: 4.350243] 
[Epoch 5/10] [Batch 107/274] [Batch classify loss: 3.962553] 
[Epoch 5/10] [Batch 108/274] [Batch classify loss: 4.551004] 
[Epoch 5/10] [Batch 109/274] [Batch classify loss: 4.550298] 
[Epoch 5/10] [Batch 110/274] [Batch classify loss: 4.379055] 
[Epoch 5/10] [Batch 111/274] [Batch classify loss: 4.258952] 
[Epoch 5/10] [Batch 112/274] [Batch classify loss: 4.434981] 
[Epoch 5/10] [Batch 113/274] [Batch classify loss: 4.469650] 
[Epoch 5/10] [Batch 114/274] [Batch classify loss: 4.738572] 
[Epoch 5/10] [Batch 115/274] [Batch classify loss: 4.523345] 
[Epoch 5/10] [Batch 116/274] [Batch classify loss: 4.528639] 
[Epoch 5/10] [Batch 117/274] [Batch classify loss: 4.228770] 
[Epoch 5/10] [Batch 118/274] [Batch classify loss: 4.054248] 
[Epoch 5/10] [Batch 119/274] [Batch classify loss: 3.802782] 
[Epoch 5/10] [Batch 120/274] [Batch classify loss: 3.883280] 
[Epoch 5/10] [Batch 121/274] [Batch classify loss: 4.463233] 
[Epoch 5/10] [Batch 122/274] [Batch classify loss: 4.203786] 
[Epoch 5/10] [Batch 123/274] [Batch classify loss: 4.619630] 
[Epoch 5/10] [Batch 124/274] [Batch classify loss: 4.013685] 
[Epoch 5/10] [Batch 125/274] [Batch classify loss: 4.078039] 
[Epoch 5/10] [Batch 126/274] [Batch classify loss: 4.324712] 
[Epoch 5/10] [Batch 127/274] [Batch classify loss: 4.599679] 
[Epoch 5/10] [Batch 128/274] [Batch classify loss: 4.328817] 
[Epoch 5/10] [Batch 129/274] [Batch classify loss: 4.323348] 
[Epoch 5/10] [Batch 130/274] [Batch classify loss: 4.097927] 
[Epoch 5/10] [Batch 131/274] [Batch classify loss: 4.334585] 
[Epoch 5/10] [Batch 132/274] [Batch classify loss: 4.263153] 
[Epoch 5/10] [Batch 133/274] [Batch classify loss: 4.604166] 
[Epoch 5/10] [Batch 134/274] [Batch classify loss: 4.446533] 
[Epoch 5/10] [Batch 135/274] [Batch classify loss: 4.040016] 
[Epoch 5/10] [Batch 136/274] [Batch classify loss: 4.173302] 
[Epoch 5/10] [Batch 137/274] [Batch classify loss: 4.086010] 
[Epoch 5/10] [Batch 138/274] [Batch classify loss: 3.810816] 
[Epoch 5/10] [Batch 139/274] [Batch classify loss: 4.227818] 
[Epoch 5/10] [Batch 140/274] [Batch classify loss: 4.433105] 
[Epoch 5/10] [Batch 141/274] [Batch classify loss: 4.646561] 
[Epoch 5/10] [Batch 142/274] [Batch classify loss: 4.140173] 
[Epoch 5/10] [Batch 143/274] [Batch classify loss: 4.431794] 
[Epoch 5/10] [Batch 144/274] [Batch classify loss: 4.027322] 
[Epoch 5/10] [Batch 145/274] [Batch classify loss: 4.035615] 
[Epoch 5/10] [Batch 146/274] [Batch classify loss: 4.252616] 
[Epoch 5/10] [Batch 147/274] [Batch classify loss: 4.346128] 
[Epoch 5/10] [Batch 148/274] [Batch classify loss: 4.379219] 
[Epoch 5/10] [Batch 149/274] [Batch classify loss: 4.088818] 
[Epoch 5/10] [Batch 150/274] [Batch classify loss: 4.477673] 
[Epoch 5/10] [Batch 151/274] [Batch classify loss: 4.658772] 
[Epoch 5/10] [Batch 152/274] [Batch classify loss: 4.119672] 
[Epoch 5/10] [Batch 153/274] [Batch classify loss: 4.283437] 
[Epoch 5/10] [Batch 154/274] [Batch classify loss: 4.395569] 
[Epoch 5/10] [Batch 155/274] [Batch classify loss: 4.457369] 
[Epoch 5/10] [Batch 156/274] [Batch classify loss: 3.838413] 
[Epoch 5/10] [Batch 157/274] [Batch classify loss: 3.859272] 
[Epoch 5/10] [Batch 158/274] [Batch classify loss: 3.977345] 
[Epoch 5/10] [Batch 159/274] [Batch classify loss: 4.921408] 
[Epoch 5/10] [Batch 160/274] [Batch classify loss: 4.169315] 
[Epoch 5/10] [Batch 161/274] [Batch classify loss: 4.608390] 
[Epoch 5/10] [Batch 162/274] [Batch classify loss: 4.297218] 
[Epoch 5/10] [Batch 163/274] [Batch classify loss: 4.057617] 
[Epoch 5/10] [Batch 164/274] [Batch classify loss: 4.329171] 
[Epoch 5/10] [Batch 165/274] [Batch classify loss: 4.194551] 
[Epoch 5/10] [Batch 166/274] [Batch classify loss: 4.905768] 
[Epoch 5/10] [Batch 167/274] [Batch classify loss: 4.035210] 
[Epoch 5/10] [Batch 168/274] [Batch classify loss: 3.835496] 
[Epoch 5/10] [Batch 169/274] [Batch classify loss: 3.778928] 
[Epoch 5/10] [Batch 170/274] [Batch classify loss: 4.884746] 
[Epoch 5/10] [Batch 171/274] [Batch classify loss: 4.160115] 
[Epoch 5/10] [Batch 172/274] [Batch classify loss: 4.441086] 
[Epoch 5/10] [Batch 173/274] [Batch classify loss: 4.849349] 
[Epoch 5/10] [Batch 174/274] [Batch classify loss: 4.060025] 
[Epoch 5/10] [Batch 175/274] [Batch classify loss: 4.052794] 
[Epoch 5/10] [Batch 176/274] [Batch classify loss: 4.050663] 
[Epoch 5/10] [Batch 177/274] [Batch classify loss: 4.329917] 
[Epoch 5/10] [Batch 178/274] [Batch classify loss: 4.207260] 
[Epoch 5/10] [Batch 179/274] [Batch classify loss: 4.119218] 
[Epoch 5/10] [Batch 180/274] [Batch classify loss: 4.056088] 
[Epoch 5/10] [Batch 181/274] [Batch classify loss: 4.271338] 
[Epoch 5/10] [Batch 182/274] [Batch classify loss: 4.492274] 
[Epoch 5/10] [Batch 183/274] [Batch classify loss: 4.544474] 
[Epoch 5/10] [Batch 184/274] [Batch classify loss: 4.325087] 
[Epoch 5/10] [Batch 185/274] [Batch classify loss: 4.284072] 
[Epoch 5/10] [Batch 186/274] [Batch classify loss: 4.027136] 
[Epoch 5/10] [Batch 187/274] [Batch classify loss: 4.431532] 
[Epoch 5/10] [Batch 188/274] [Batch classify loss: 4.227266] 
[Epoch 5/10] [Batch 189/274] [Batch classify loss: 4.294210] 
[Epoch 5/10] [Batch 190/274] [Batch classify loss: 4.525892] 
[Epoch 5/10] [Batch 191/274] [Batch classify loss: 4.614480] 
[Epoch 5/10] [Batch 192/274] [Batch classify loss: 4.132704] 
[Epoch 5/10] [Batch 193/274] [Batch classify loss: 4.063111] 
[Epoch 5/10] [Batch 194/274] [Batch classify loss: 4.391942] 
[Epoch 5/10] [Batch 195/274] [Batch classify loss: 4.351206] 
[Epoch 5/10] [Batch 196/274] [Batch classify loss: 4.513056] 
[Epoch 5/10] [Batch 197/274] [Batch classify loss: 3.842026] 
[Epoch 5/10] [Batch 198/274] [Batch classify loss: 4.386186] 
[Epoch 5/10] [Batch 199/274] [Batch classify loss: 4.124270] 
[Epoch 5/10] [Batch 200/274] [Batch classify loss: 4.243720] 
[Epoch 5/10] [Batch 201/274] [Batch classify loss: 3.602952] 
[Epoch 5/10] [Batch 202/274] [Batch classify loss: 4.398091] 
[Epoch 5/10] [Batch 203/274] [Batch classify loss: 4.107669] 
[Epoch 5/10] [Batch 204/274] [Batch classify loss: 4.409829] 
[Epoch 5/10] [Batch 205/274] [Batch classify loss: 4.657168] 
[Epoch 5/10] [Batch 206/274] [Batch classify loss: 4.279544] 
[Epoch 5/10] [Batch 207/274] [Batch classify loss: 4.281837] 
[Epoch 5/10] [Batch 208/274] [Batch classify loss: 4.071900] 
[Epoch 5/10] [Batch 209/274] [Batch classify loss: 4.484631] 
[Epoch 5/10] [Batch 210/274] [Batch classify loss: 4.657464] 
[Epoch 5/10] [Batch 211/274] [Batch classify loss: 4.329630] 
[Epoch 5/10] [Batch 212/274] [Batch classify loss: 4.023261] 
[Epoch 5/10] [Batch 213/274] [Batch classify loss: 4.239528] 
[Epoch 5/10] [Batch 214/274] [Batch classify loss: 4.211467] 
[Epoch 5/10] [Batch 215/274] [Batch classify loss: 4.414242] 
[Epoch 5/10] [Batch 216/274] [Batch classify loss: 3.927413] 
[Epoch 5/10] [Batch 217/274] [Batch classify loss: 4.156571] 
[Epoch 5/10] [Batch 218/274] [Batch classify loss: 4.272195] 
[Epoch 5/10] [Batch 219/274] [Batch classify loss: 4.132560] 
[Epoch 5/10] [Batch 220/274] [Batch classify loss: 4.169339] 
[Epoch 5/10] [Batch 221/274] [Batch classify loss: 3.644553] 
[Epoch 5/10] [Batch 222/274] [Batch classify loss: 4.131216] 
[Epoch 5/10] [Batch 223/274] [Batch classify loss: 4.560547] 
[Epoch 5/10] [Batch 224/274] [Batch classify loss: 4.303813] 
[Epoch 5/10] [Batch 225/274] [Batch classify loss: 4.581544] 
[Epoch 5/10] [Batch 226/274] [Batch classify loss: 4.234751] 
[Epoch 5/10] [Batch 227/274] [Batch classify loss: 4.234163] 
[Epoch 5/10] [Batch 228/274] [Batch classify loss: 3.973333] 
[Epoch 5/10] [Batch 229/274] [Batch classify loss: 4.904919] 
[Epoch 5/10] [Batch 230/274] [Batch classify loss: 3.952693] 
[Epoch 5/10] [Batch 231/274] [Batch classify loss: 3.825541] 
[Epoch 5/10] [Batch 232/274] [Batch classify loss: 4.829207] 
[Epoch 5/10] [Batch 233/274] [Batch classify loss: 4.107750] 
[Epoch 5/10] [Batch 234/274] [Batch classify loss: 4.179219] 
[Epoch 5/10] [Batch 235/274] [Batch classify loss: 3.830404] 
[Epoch 5/10] [Batch 236/274] [Batch classify loss: 4.654179] 
[Epoch 5/10] [Batch 237/274] [Batch classify loss: 4.473256] 
[Epoch 5/10] [Batch 238/274] [Batch classify loss: 4.150533] 
[Epoch 5/10] [Batch 239/274] [Batch classify loss: 4.478005] 
[Epoch 5/10] [Batch 240/274] [Batch classify loss: 4.315891] 
[Epoch 5/10] [Batch 241/274] [Batch classify loss: 4.216366] 
[Epoch 5/10] [Batch 242/274] [Batch classify loss: 4.204923] 
[Epoch 5/10] [Batch 243/274] [Batch classify loss: 4.488872] 
[Epoch 5/10] [Batch 244/274] [Batch classify loss: 4.529486] 
[Epoch 5/10] [Batch 245/274] [Batch classify loss: 4.124393] 
[Epoch 5/10] [Batch 246/274] [Batch classify loss: 4.818010] 
[Epoch 5/10] [Batch 247/274] [Batch classify loss: 4.419171] 
[Epoch 5/10] [Batch 248/274] [Batch classify loss: 4.211598] 
[Epoch 5/10] [Batch 249/274] [Batch classify loss: 4.260343] 
[Epoch 5/10] [Batch 250/274] [Batch classify loss: 4.193295] 
[Epoch 5/10] [Batch 251/274] [Batch classify loss: 4.285067] 
[Epoch 5/10] [Batch 252/274] [Batch classify loss: 4.377776] 
[Epoch 5/10] [Batch 253/274] [Batch classify loss: 4.551623] 
[Epoch 5/10] [Batch 254/274] [Batch classify loss: 4.313856] 
[Epoch 5/10] [Batch 255/274] [Batch classify loss: 3.822613] 
[Epoch 5/10] [Batch 256/274] [Batch classify loss: 4.161858] 
[Epoch 5/10] [Batch 257/274] [Batch classify loss: 4.642280] 
[Epoch 5/10] [Batch 258/274] [Batch classify loss: 4.476301] 
[Epoch 5/10] [Batch 259/274] [Batch classify loss: 4.212574] 
[Epoch 5/10] [Batch 260/274] [Batch classify loss: 4.401209] 
[Epoch 5/10] [Batch 261/274] [Batch classify loss: 4.705834] 
[Epoch 5/10] [Batch 262/274] [Batch classify loss: 4.326938] 
[Epoch 5/10] [Batch 263/274] [Batch classify loss: 4.618541] 
[Epoch 5/10] [Batch 264/274] [Batch classify loss: 4.523830] 
[Epoch 5/10] [Batch 265/274] [Batch classify loss: 4.248785] 
[Epoch 5/10] [Batch 266/274] [Batch classify loss: 4.456832] 
[Epoch 5/10] [Batch 267/274] [Batch classify loss: 4.221932] 
[Epoch 5/10] [Batch 268/274] [Batch classify loss: 4.869136] 
[Epoch 5/10] [Batch 269/274] [Batch classify loss: 4.184453] 
[Epoch 5/10] [Batch 270/274] [Batch classify loss: 4.486035] 
[Epoch 5/10] [Batch 271/274] [Batch classify loss: 4.220323] 
[Epoch 5/10] [Batch 272/274] [Batch classify loss: 4.165413] 
[Epoch 5/10] [Batch 273/274] [Batch classify loss: 3.744532] 
[Epoch 5/10] [Batch 274/274] [Batch classify loss: 4.755645] 
0005 epoch mmat trained classifier accuary on the clean testing examples:94.6143%
0005 epoch mmat trained classifier loss on the clean testing examples:0.2234
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.4233%
mmat trained classifier loss on adversarial testset:4.523459434509277
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-cle
5epoch learning rate:0.01
[Epoch 6/10] [Batch 1/274] [Batch classify loss: 1.542766] 
[Epoch 6/10] [Batch 2/274] [Batch classify loss: 2.059793] 
[Epoch 6/10] [Batch 3/274] [Batch classify loss: 2.626242] 
[Epoch 6/10] [Batch 4/274] [Batch classify loss: 2.646293] 
[Epoch 6/10] [Batch 5/274] [Batch classify loss: 2.772259] 
[Epoch 6/10] [Batch 6/274] [Batch classify loss: 2.671251] 
[Epoch 6/10] [Batch 7/274] [Batch classify loss: 2.794665] 
[Epoch 6/10] [Batch 8/274] [Batch classify loss: 3.040686] 
[Epoch 6/10] [Batch 9/274] [Batch classify loss: 2.753680] 
[Epoch 6/10] [Batch 10/274] [Batch classify loss: 3.358476] 
[Epoch 6/10] [Batch 11/274] [Batch classify loss: 3.096645] 
[Epoch 6/10] [Batch 12/274] [Batch classify loss: 3.437320] 
[Epoch 6/10] [Batch 13/274] [Batch classify loss: 3.498935] 
[Epoch 6/10] [Batch 14/274] [Batch classify loss: 3.438473] 
[Epoch 6/10] [Batch 15/274] [Batch classify loss: 3.532582] 
[Epoch 6/10] [Batch 16/274] [Batch classify loss: 3.312884] 
[Epoch 6/10] [Batch 17/274] [Batch classify loss: 3.162143] 
[Epoch 6/10] [Batch 18/274] [Batch classify loss: 3.333359] 
[Epoch 6/10] [Batch 19/274] [Batch classify loss: 3.585222] 
[Epoch 6/10] [Batch 20/274] [Batch classify loss: 3.463338] 
[Epoch 6/10] [Batch 21/274] [Batch classify loss: 3.641845] 
[Epoch 6/10] [Batch 22/274] [Batch classify loss: 4.140102] 
[Epoch 6/10] [Batch 23/274] [Batch classify loss: 3.435388] 
[Epoch 6/10] [Batch 24/274] [Batch classify loss: 3.253725] 
[Epoch 6/10] [Batch 25/274] [Batch classify loss: 3.279186] 
[Epoch 6/10] [Batch 26/274] [Batch classify loss: 3.264461] 
[Epoch 6/10] [Batch 27/274] [Batch classify loss: 3.423116] 
[Epoch 6/10] [Batch 28/274] [Batch classify loss: 3.480584] 
[Epoch 6/10] [Batch 29/274] [Batch classify loss: 3.516670] 
[Epoch 6/10] [Batch 30/274] [Batch classify loss: 3.449564] 
[Epoch 6/10] [Batch 31/274] [Batch classify loss: 3.642679] 
[Epoch 6/10] [Batch 32/274] [Batch classify loss: 3.840517] 
[Epoch 6/10] [Batch 33/274] [Batch classify loss: 3.658298] 
[Epoch 6/10] [Batch 34/274] [Batch classify loss: 3.531389] 
[Epoch 6/10] [Batch 35/274] [Batch classify loss: 3.620915] 
[Epoch 6/10] [Batch 36/274] [Batch classify loss: 3.753787] 
[Epoch 6/10] [Batch 37/274] [Batch classify loss: 3.560368] 
[Epoch 6/10] [Batch 38/274] [Batch classify loss: 3.577874] 
[Epoch 6/10] [Batch 39/274] [Batch classify loss: 3.852411] 
[Epoch 6/10] [Batch 40/274] [Batch classify loss: 3.559872] 
[Epoch 6/10] [Batch 41/274] [Batch classify loss: 3.410152] 
[Epoch 6/10] [Batch 42/274] [Batch classify loss: 3.606597] 
[Epoch 6/10] [Batch 43/274] [Batch classify loss: 4.035118] 
[Epoch 6/10] [Batch 44/274] [Batch classify loss: 3.900655] 
[Epoch 6/10] [Batch 45/274] [Batch classify loss: 3.930824] 
[Epoch 6/10] [Batch 46/274] [Batch classify loss: 3.957728] 
[Epoch 6/10] [Batch 47/274] [Batch classify loss: 3.405638] 
[Epoch 6/10] [Batch 48/274] [Batch classify loss: 3.461400] 
[Epoch 6/10] [Batch 49/274] [Batch classify loss: 3.758536] 
[Epoch 6/10] [Batch 50/274] [Batch classify loss: 3.902421] 
[Epoch 6/10] [Batch 51/274] [Batch classify loss: 3.391394] 
[Epoch 6/10] [Batch 52/274] [Batch classify loss: 3.769192] 
[Epoch 6/10] [Batch 53/274] [Batch classify loss: 3.752926] 
[Epoch 6/10] [Batch 54/274] [Batch classify loss: 4.229346] 
[Epoch 6/10] [Batch 55/274] [Batch classify loss: 4.129953] 
[Epoch 6/10] [Batch 56/274] [Batch classify loss: 3.581424] 
[Epoch 6/10] [Batch 57/274] [Batch classify loss: 3.919601] 
[Epoch 6/10] [Batch 58/274] [Batch classify loss: 3.701514] 
[Epoch 6/10] [Batch 59/274] [Batch classify loss: 3.846880] 
[Epoch 6/10] [Batch 60/274] [Batch classify loss: 3.864197] 
[Epoch 6/10] [Batch 61/274] [Batch classify loss: 4.144929] 
[Epoch 6/10] [Batch 62/274] [Batch classify loss: 3.900991] 
[Epoch 6/10] [Batch 63/274] [Batch classify loss: 4.330107] 
[Epoch 6/10] [Batch 64/274] [Batch classify loss: 3.806331] 
[Epoch 6/10] [Batch 65/274] [Batch classify loss: 4.075887] 
[Epoch 6/10] [Batch 66/274] [Batch classify loss: 3.696328] 
[Epoch 6/10] [Batch 67/274] [Batch classify loss: 3.583760] 
[Epoch 6/10] [Batch 68/274] [Batch classify loss: 3.870009] 
[Epoch 6/10] [Batch 69/274] [Batch classify loss: 3.748121] 
[Epoch 6/10] [Batch 70/274] [Batch classify loss: 3.987874] 
[Epoch 6/10] [Batch 71/274] [Batch classify loss: 4.071674] 
[Epoch 6/10] [Batch 72/274] [Batch classify loss: 3.502299] 
[Epoch 6/10] [Batch 73/274] [Batch classify loss: 3.559893] 
[Epoch 6/10] [Batch 74/274] [Batch classify loss: 3.888904] 
[Epoch 6/10] [Batch 75/274] [Batch classify loss: 3.426080] 
[Epoch 6/10] [Batch 76/274] [Batch classify loss: 3.502605] 
[Epoch 6/10] [Batch 77/274] [Batch classify loss: 4.037158] 
[Epoch 6/10] [Batch 78/274] [Batch classify loss: 3.842025] 
[Epoch 6/10] [Batch 79/274] [Batch classify loss: 4.326627] 
[Epoch 6/10] [Batch 80/274] [Batch classify loss: 3.784783] 
[Epoch 6/10] [Batch 81/274] [Batch classify loss: 4.351893] 
[Epoch 6/10] [Batch 82/274] [Batch classify loss: 4.197476] 
[Epoch 6/10] [Batch 83/274] [Batch classify loss: 3.756839] 
[Epoch 6/10] [Batch 84/274] [Batch classify loss: 4.056685] 
[Epoch 6/10] [Batch 85/274] [Batch classify loss: 3.735869] 
[Epoch 6/10] [Batch 86/274] [Batch classify loss: 4.002477] 
[Epoch 6/10] [Batch 87/274] [Batch classify loss: 3.886351] 
[Epoch 6/10] [Batch 88/274] [Batch classify loss: 3.614370] 
[Epoch 6/10] [Batch 89/274] [Batch classify loss: 4.088335] 
[Epoch 6/10] [Batch 90/274] [Batch classify loss: 4.018733] 
[Epoch 6/10] [Batch 91/274] [Batch classify loss: 3.921665] 
[Epoch 6/10] [Batch 92/274] [Batch classify loss: 3.851532] 
[Epoch 6/10] [Batch 93/274] [Batch classify loss: 3.949670] 
[Epoch 6/10] [Batch 94/274] [Batch classify loss: 3.695296] 
[Epoch 6/10] [Batch 95/274] [Batch classify loss: 4.206594] 
[Epoch 6/10] [Batch 96/274] [Batch classify loss: 3.965258] 
[Epoch 6/10] [Batch 97/274] [Batch classify loss: 4.013570] 
[Epoch 6/10] [Batch 98/274] [Batch classify loss: 3.752937] 
[Epoch 6/10] [Batch 99/274] [Batch classify loss: 4.277555] 
[Epoch 6/10] [Batch 100/274] [Batch classify loss: 4.489831] 
[Epoch 6/10] [Batch 101/274] [Batch classify loss: 3.878119] 
[Epoch 6/10] [Batch 102/274] [Batch classify loss: 4.143618] 
[Epoch 6/10] [Batch 103/274] [Batch classify loss: 4.101698] 
[Epoch 6/10] [Batch 104/274] [Batch classify loss: 4.088777] 
[Epoch 6/10] [Batch 105/274] [Batch classify loss: 4.225684] 
[Epoch 6/10] [Batch 106/274] [Batch classify loss: 4.086206] 
[Epoch 6/10] [Batch 107/274] [Batch classify loss: 4.084118] 
[Epoch 6/10] [Batch 108/274] [Batch classify loss: 4.229575] 
[Epoch 6/10] [Batch 109/274] [Batch classify loss: 4.211547] 
[Epoch 6/10] [Batch 110/274] [Batch classify loss: 3.560287] 
[Epoch 6/10] [Batch 111/274] [Batch classify loss: 3.870545] 
[Epoch 6/10] [Batch 112/274] [Batch classify loss: 3.908410] 
[Epoch 6/10] [Batch 113/274] [Batch classify loss: 4.018770] 
[Epoch 6/10] [Batch 114/274] [Batch classify loss: 3.948777] 
[Epoch 6/10] [Batch 115/274] [Batch classify loss: 3.790267] 
[Epoch 6/10] [Batch 116/274] [Batch classify loss: 4.614217] 
[Epoch 6/10] [Batch 117/274] [Batch classify loss: 3.997350] 
[Epoch 6/10] [Batch 118/274] [Batch classify loss: 3.959366] 
[Epoch 6/10] [Batch 119/274] [Batch classify loss: 3.831304] 
[Epoch 6/10] [Batch 120/274] [Batch classify loss: 4.067772] 
[Epoch 6/10] [Batch 121/274] [Batch classify loss: 3.985882] 
[Epoch 6/10] [Batch 122/274] [Batch classify loss: 4.109877] 
[Epoch 6/10] [Batch 123/274] [Batch classify loss: 4.071027] 
[Epoch 6/10] [Batch 124/274] [Batch classify loss: 3.848006] 
[Epoch 6/10] [Batch 125/274] [Batch classify loss: 4.173813] 
[Epoch 6/10] [Batch 126/274] [Batch classify loss: 4.211150] 
[Epoch 6/10] [Batch 127/274] [Batch classify loss: 4.345149] 
[Epoch 6/10] [Batch 128/274] [Batch classify loss: 3.909816] 
[Epoch 6/10] [Batch 129/274] [Batch classify loss: 3.700017] 
[Epoch 6/10] [Batch 130/274] [Batch classify loss: 4.152432] 
[Epoch 6/10] [Batch 131/274] [Batch classify loss: 4.190155] 
[Epoch 6/10] [Batch 132/274] [Batch classify loss: 4.031924] 
[Epoch 6/10] [Batch 133/274] [Batch classify loss: 4.421728] 
[Epoch 6/10] [Batch 134/274] [Batch classify loss: 4.180704] 
[Epoch 6/10] [Batch 135/274] [Batch classify loss: 4.207271] 
[Epoch 6/10] [Batch 136/274] [Batch classify loss: 4.241042] 
[Epoch 6/10] [Batch 137/274] [Batch classify loss: 3.973811] 
[Epoch 6/10] [Batch 138/274] [Batch classify loss: 4.257400] 
[Epoch 6/10] [Batch 139/274] [Batch classify loss: 4.228777] 
[Epoch 6/10] [Batch 140/274] [Batch classify loss: 4.129971] 
[Epoch 6/10] [Batch 141/274] [Batch classify loss: 4.241941] 
[Epoch 6/10] [Batch 142/274] [Batch classify loss: 3.859454] 
[Epoch 6/10] [Batch 143/274] [Batch classify loss: 3.580836] 
[Epoch 6/10] [Batch 144/274] [Batch classify loss: 4.141071] 
[Epoch 6/10] [Batch 145/274] [Batch classify loss: 4.195103] 
[Epoch 6/10] [Batch 146/274] [Batch classify loss: 3.757230] 
[Epoch 6/10] [Batch 147/274] [Batch classify loss: 4.244586] 
[Epoch 6/10] [Batch 148/274] [Batch classify loss: 3.827948] 
[Epoch 6/10] [Batch 149/274] [Batch classify loss: 3.867410] 
[Epoch 6/10] [Batch 150/274] [Batch classify loss: 4.006167] 
[Epoch 6/10] [Batch 151/274] [Batch classify loss: 4.348761] 
[Epoch 6/10] [Batch 152/274] [Batch classify loss: 4.327879] 
[Epoch 6/10] [Batch 153/274] [Batch classify loss: 4.039639] 
[Epoch 6/10] [Batch 154/274] [Batch classify loss: 4.003633] 
[Epoch 6/10] [Batch 155/274] [Batch classify loss: 4.236522] 
[Epoch 6/10] [Batch 156/274] [Batch classify loss: 3.876332] 
[Epoch 6/10] [Batch 157/274] [Batch classify loss: 4.138671] 
[Epoch 6/10] [Batch 158/274] [Batch classify loss: 3.850269] 
[Epoch 6/10] [Batch 159/274] [Batch classify loss: 4.257177] 
[Epoch 6/10] [Batch 160/274] [Batch classify loss: 4.029860] 
[Epoch 6/10] [Batch 161/274] [Batch classify loss: 4.174373] 
[Epoch 6/10] [Batch 162/274] [Batch classify loss: 4.266900] 
[Epoch 6/10] [Batch 163/274] [Batch classify loss: 4.159108] 
[Epoch 6/10] [Batch 164/274] [Batch classify loss: 4.060099] 
[Epoch 6/10] [Batch 165/274] [Batch classify loss: 4.004192] 
[Epoch 6/10] [Batch 166/274] [Batch classify loss: 4.178383] 
[Epoch 6/10] [Batch 167/274] [Batch classify loss: 3.812554] 
[Epoch 6/10] [Batch 168/274] [Batch classify loss: 3.900867] 
[Epoch 6/10] [Batch 169/274] [Batch classify loss: 4.292840] 
[Epoch 6/10] [Batch 170/274] [Batch classify loss: 4.182783] 
[Epoch 6/10] [Batch 171/274] [Batch classify loss: 4.479398] 
[Epoch 6/10] [Batch 172/274] [Batch classify loss: 4.341397] 
[Epoch 6/10] [Batch 173/274] [Batch classify loss: 3.903331] 
[Epoch 6/10] [Batch 174/274] [Batch classify loss: 3.731752] 
[Epoch 6/10] [Batch 175/274] [Batch classify loss: 3.655039] 
[Epoch 6/10] [Batch 176/274] [Batch classify loss: 4.057643] 
[Epoch 6/10] [Batch 177/274] [Batch classify loss: 3.509512] 
[Epoch 6/10] [Batch 178/274] [Batch classify loss: 4.076999] 
[Epoch 6/10] [Batch 179/274] [Batch classify loss: 3.948047] 
[Epoch 6/10] [Batch 180/274] [Batch classify loss: 4.165260] 
[Epoch 6/10] [Batch 181/274] [Batch classify loss: 4.098171] 
[Epoch 6/10] [Batch 182/274] [Batch classify loss: 4.462841] 
[Epoch 6/10] [Batch 183/274] [Batch classify loss: 4.244891] 
[Epoch 6/10] [Batch 184/274] [Batch classify loss: 4.300240] 
[Epoch 6/10] [Batch 185/274] [Batch classify loss: 4.667650] 
[Epoch 6/10] [Batch 186/274] [Batch classify loss: 4.097361] 
[Epoch 6/10] [Batch 187/274] [Batch classify loss: 4.263353] 
[Epoch 6/10] [Batch 188/274] [Batch classify loss: 4.699975] 
[Epoch 6/10] [Batch 189/274] [Batch classify loss: 4.078048] 
[Epoch 6/10] [Batch 190/274] [Batch classify loss: 4.044766] 
[Epoch 6/10] [Batch 191/274] [Batch classify loss: 3.917259] 
[Epoch 6/10] [Batch 192/274] [Batch classify loss: 3.642333] 
[Epoch 6/10] [Batch 193/274] [Batch classify loss: 4.026815] 
[Epoch 6/10] [Batch 194/274] [Batch classify loss: 3.979872] 
[Epoch 6/10] [Batch 195/274] [Batch classify loss: 3.786304] 
[Epoch 6/10] [Batch 196/274] [Batch classify loss: 4.533483] 
[Epoch 6/10] [Batch 197/274] [Batch classify loss: 4.104814] 
[Epoch 6/10] [Batch 198/274] [Batch classify loss: 4.358230] 
[Epoch 6/10] [Batch 199/274] [Batch classify loss: 4.784797] 
[Epoch 6/10] [Batch 200/274] [Batch classify loss: 4.452507] 
[Epoch 6/10] [Batch 201/274] [Batch classify loss: 3.935291] 
[Epoch 6/10] [Batch 202/274] [Batch classify loss: 3.801970] 
[Epoch 6/10] [Batch 203/274] [Batch classify loss: 4.243216] 
[Epoch 6/10] [Batch 204/274] [Batch classify loss: 4.442622] 
[Epoch 6/10] [Batch 205/274] [Batch classify loss: 4.153099] 
[Epoch 6/10] [Batch 206/274] [Batch classify loss: 4.076906] 
[Epoch 6/10] [Batch 207/274] [Batch classify loss: 4.087219] 
[Epoch 6/10] [Batch 208/274] [Batch classify loss: 3.771663] 
[Epoch 6/10] [Batch 209/274] [Batch classify loss: 3.853385] 
[Epoch 6/10] [Batch 210/274] [Batch classify loss: 4.208375] 
[Epoch 6/10] [Batch 211/274] [Batch classify loss: 4.209517] 
[Epoch 6/10] [Batch 212/274] [Batch classify loss: 3.859687] 
[Epoch 6/10] [Batch 213/274] [Batch classify loss: 3.893981] 
[Epoch 6/10] [Batch 214/274] [Batch classify loss: 4.298235] 
[Epoch 6/10] [Batch 215/274] [Batch classify loss: 3.868284] 
[Epoch 6/10] [Batch 216/274] [Batch classify loss: 4.256766] 
[Epoch 6/10] [Batch 217/274] [Batch classify loss: 3.925310] 
[Epoch 6/10] [Batch 218/274] [Batch classify loss: 4.167044] 
[Epoch 6/10] [Batch 219/274] [Batch classify loss: 3.919195] 
[Epoch 6/10] [Batch 220/274] [Batch classify loss: 3.799593] 
[Epoch 6/10] [Batch 221/274] [Batch classify loss: 4.163105] 
[Epoch 6/10] [Batch 222/274] [Batch classify loss: 4.645166] 
[Epoch 6/10] [Batch 223/274] [Batch classify loss: 4.142763] 
[Epoch 6/10] [Batch 224/274] [Batch classify loss: 4.027513] 
[Epoch 6/10] [Batch 225/274] [Batch classify loss: 4.301872] 
[Epoch 6/10] [Batch 226/274] [Batch classify loss: 4.537424] 
[Epoch 6/10] [Batch 227/274] [Batch classify loss: 3.788733] 
[Epoch 6/10] [Batch 228/274] [Batch classify loss: 3.859356] 
[Epoch 6/10] [Batch 229/274] [Batch classify loss: 4.084779] 
[Epoch 6/10] [Batch 230/274] [Batch classify loss: 4.454513] 
[Epoch 6/10] [Batch 231/274] [Batch classify loss: 4.265034] 
[Epoch 6/10] [Batch 232/274] [Batch classify loss: 4.288679] 
[Epoch 6/10] [Batch 233/274] [Batch classify loss: 4.165998] 
[Epoch 6/10] [Batch 234/274] [Batch classify loss: 4.542288] 
[Epoch 6/10] [Batch 235/274] [Batch classify loss: 4.222702] 
[Epoch 6/10] [Batch 236/274] [Batch classify loss: 4.163407] 
[Epoch 6/10] [Batch 237/274] [Batch classify loss: 3.777911] 
[Epoch 6/10] [Batch 238/274] [Batch classify loss: 4.253852] 
[Epoch 6/10] [Batch 239/274] [Batch classify loss: 3.855646] 
[Epoch 6/10] [Batch 240/274] [Batch classify loss: 4.199629] 
[Epoch 6/10] [Batch 241/274] [Batch classify loss: 4.285599] 
[Epoch 6/10] [Batch 242/274] [Batch classify loss: 4.095694] 
[Epoch 6/10] [Batch 243/274] [Batch classify loss: 4.506723] 
[Epoch 6/10] [Batch 244/274] [Batch classify loss: 4.229567] 
[Epoch 6/10] [Batch 245/274] [Batch classify loss: 4.289517] 
[Epoch 6/10] [Batch 246/274] [Batch classify loss: 3.957161] 
[Epoch 6/10] [Batch 247/274] [Batch classify loss: 3.842765] 
[Epoch 6/10] [Batch 248/274] [Batch classify loss: 4.226453] 
[Epoch 6/10] [Batch 249/274] [Batch classify loss: 4.379798] 
[Epoch 6/10] [Batch 250/274] [Batch classify loss: 3.934049] 
[Epoch 6/10] [Batch 251/274] [Batch classify loss: 4.258600] 
[Epoch 6/10] [Batch 252/274] [Batch classify loss: 4.127811] 
[Epoch 6/10] [Batch 253/274] [Batch classify loss: 3.896358] 
[Epoch 6/10] [Batch 254/274] [Batch classify loss: 4.389967] 
[Epoch 6/10] [Batch 255/274] [Batch classify loss: 4.081870] 
[Epoch 6/10] [Batch 256/274] [Batch classify loss: 4.199965] 
[Epoch 6/10] [Batch 257/274] [Batch classify loss: 4.017478] 
[Epoch 6/10] [Batch 258/274] [Batch classify loss: 4.226810] 
[Epoch 6/10] [Batch 259/274] [Batch classify loss: 3.615937] 
[Epoch 6/10] [Batch 260/274] [Batch classify loss: 3.914690] 
[Epoch 6/10] [Batch 261/274] [Batch classify loss: 3.929807] 
[Epoch 6/10] [Batch 262/274] [Batch classify loss: 4.149133] 
[Epoch 6/10] [Batch 263/274] [Batch classify loss: 4.075046] 
[Epoch 6/10] [Batch 264/274] [Batch classify loss: 4.610905] 
[Epoch 6/10] [Batch 265/274] [Batch classify loss: 4.362617] 
[Epoch 6/10] [Batch 266/274] [Batch classify loss: 4.394627] 
[Epoch 6/10] [Batch 267/274] [Batch classify loss: 4.040415] 
[Epoch 6/10] [Batch 268/274] [Batch classify loss: 4.178827] 
[Epoch 6/10] [Batch 269/274] [Batch classify loss: 4.407362] 
[Epoch 6/10] [Batch 270/274] [Batch classify loss: 4.034188] 
[Epoch 6/10] [Batch 271/274] [Batch classify loss: 4.326465] 
[Epoch 6/10] [Batch 272/274] [Batch classify loss: 4.214252] 
[Epoch 6/10] [Batch 273/274] [Batch classify loss: 4.126441] 
[Epoch 6/10] [Batch 274/274] [Batch classify loss: 4.366737] 
0006 epoch mmat trained classifier accuary on the clean testing examples:94.6527%
0006 epoch mmat trained classifier loss on the clean testing examples:0.2230
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.4156%
mmat trained classifier loss on adversarial testset:4.521573543548584
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-cle
6epoch learning rate:0.01
[Epoch 7/10] [Batch 1/274] [Batch classify loss: 1.256287] 
[Epoch 7/10] [Batch 2/274] [Batch classify loss: 1.659953] 
[Epoch 7/10] [Batch 3/274] [Batch classify loss: 1.980599] 
[Epoch 7/10] [Batch 4/274] [Batch classify loss: 2.077226] 
[Epoch 7/10] [Batch 5/274] [Batch classify loss: 2.466188] 
[Epoch 7/10] [Batch 6/274] [Batch classify loss: 2.218176] 
[Epoch 7/10] [Batch 7/274] [Batch classify loss: 2.898687] 
[Epoch 7/10] [Batch 8/274] [Batch classify loss: 2.236361] 
[Epoch 7/10] [Batch 9/274] [Batch classify loss: 2.399191] 
[Epoch 7/10] [Batch 10/274] [Batch classify loss: 2.660961] 
[Epoch 7/10] [Batch 11/274] [Batch classify loss: 2.576057] 
[Epoch 7/10] [Batch 12/274] [Batch classify loss: 2.613865] 
[Epoch 7/10] [Batch 13/274] [Batch classify loss: 2.805997] 
[Epoch 7/10] [Batch 14/274] [Batch classify loss: 2.988416] 
[Epoch 7/10] [Batch 15/274] [Batch classify loss: 2.712883] 
[Epoch 7/10] [Batch 16/274] [Batch classify loss: 3.125800] 
[Epoch 7/10] [Batch 17/274] [Batch classify loss: 2.789230] 
[Epoch 7/10] [Batch 18/274] [Batch classify loss: 3.005074] 
[Epoch 7/10] [Batch 19/274] [Batch classify loss: 3.170216] 
[Epoch 7/10] [Batch 20/274] [Batch classify loss: 2.863474] 
[Epoch 7/10] [Batch 21/274] [Batch classify loss: 3.004724] 
[Epoch 7/10] [Batch 22/274] [Batch classify loss: 3.106659] 
[Epoch 7/10] [Batch 23/274] [Batch classify loss: 3.164171] 
[Epoch 7/10] [Batch 24/274] [Batch classify loss: 3.164354] 
[Epoch 7/10] [Batch 25/274] [Batch classify loss: 3.062761] 
[Epoch 7/10] [Batch 26/274] [Batch classify loss: 3.054858] 
[Epoch 7/10] [Batch 27/274] [Batch classify loss: 2.906946] 
[Epoch 7/10] [Batch 28/274] [Batch classify loss: 3.001107] 
[Epoch 7/10] [Batch 29/274] [Batch classify loss: 3.097811] 
[Epoch 7/10] [Batch 30/274] [Batch classify loss: 3.250639] 
[Epoch 7/10] [Batch 31/274] [Batch classify loss: 2.808389] 
[Epoch 7/10] [Batch 32/274] [Batch classify loss: 3.149216] 
[Epoch 7/10] [Batch 33/274] [Batch classify loss: 3.220769] 
[Epoch 7/10] [Batch 34/274] [Batch classify loss: 3.235050] 
[Epoch 7/10] [Batch 35/274] [Batch classify loss: 3.061590] 
[Epoch 7/10] [Batch 36/274] [Batch classify loss: 3.381580] 
[Epoch 7/10] [Batch 37/274] [Batch classify loss: 3.109612] 
[Epoch 7/10] [Batch 38/274] [Batch classify loss: 3.133255] 
[Epoch 7/10] [Batch 39/274] [Batch classify loss: 3.196489] 
[Epoch 7/10] [Batch 40/274] [Batch classify loss: 3.213305] 
[Epoch 7/10] [Batch 41/274] [Batch classify loss: 3.707468] 
[Epoch 7/10] [Batch 42/274] [Batch classify loss: 3.323780] 
[Epoch 7/10] [Batch 43/274] [Batch classify loss: 3.206903] 
[Epoch 7/10] [Batch 44/274] [Batch classify loss: 3.355784] 
[Epoch 7/10] [Batch 45/274] [Batch classify loss: 3.260299] 
[Epoch 7/10] [Batch 46/274] [Batch classify loss: 3.421091] 
[Epoch 7/10] [Batch 47/274] [Batch classify loss: 3.264632] 
[Epoch 7/10] [Batch 48/274] [Batch classify loss: 3.073255] 
[Epoch 7/10] [Batch 49/274] [Batch classify loss: 3.566852] 
[Epoch 7/10] [Batch 50/274] [Batch classify loss: 3.139904] 
[Epoch 7/10] [Batch 51/274] [Batch classify loss: 3.354170] 
[Epoch 7/10] [Batch 52/274] [Batch classify loss: 3.452372] 
[Epoch 7/10] [Batch 53/274] [Batch classify loss: 3.064820] 
[Epoch 7/10] [Batch 54/274] [Batch classify loss: 3.094010] 
[Epoch 7/10] [Batch 55/274] [Batch classify loss: 3.508956] 
[Epoch 7/10] [Batch 56/274] [Batch classify loss: 3.424645] 
[Epoch 7/10] [Batch 57/274] [Batch classify loss: 3.787169] 
[Epoch 7/10] [Batch 58/274] [Batch classify loss: 3.284400] 
[Epoch 7/10] [Batch 59/274] [Batch classify loss: 3.107479] 
[Epoch 7/10] [Batch 60/274] [Batch classify loss: 3.620132] 
[Epoch 7/10] [Batch 61/274] [Batch classify loss: 3.310347] 
[Epoch 7/10] [Batch 62/274] [Batch classify loss: 3.600981] 
[Epoch 7/10] [Batch 63/274] [Batch classify loss: 3.514608] 
[Epoch 7/10] [Batch 64/274] [Batch classify loss: 3.399626] 
[Epoch 7/10] [Batch 65/274] [Batch classify loss: 3.170355] 
[Epoch 7/10] [Batch 66/274] [Batch classify loss: 3.618957] 
[Epoch 7/10] [Batch 67/274] [Batch classify loss: 3.453317] 
[Epoch 7/10] [Batch 68/274] [Batch classify loss: 3.239656] 
[Epoch 7/10] [Batch 69/274] [Batch classify loss: 3.185256] 
[Epoch 7/10] [Batch 70/274] [Batch classify loss: 3.385346] 
[Epoch 7/10] [Batch 71/274] [Batch classify loss: 3.277336] 
[Epoch 7/10] [Batch 72/274] [Batch classify loss: 3.419150] 
[Epoch 7/10] [Batch 73/274] [Batch classify loss: 3.751086] 
[Epoch 7/10] [Batch 74/274] [Batch classify loss: 3.286499] 
[Epoch 7/10] [Batch 75/274] [Batch classify loss: 3.826148] 
[Epoch 7/10] [Batch 76/274] [Batch classify loss: 3.754055] 
[Epoch 7/10] [Batch 77/274] [Batch classify loss: 3.388362] 
[Epoch 7/10] [Batch 78/274] [Batch classify loss: 4.151421] 
[Epoch 7/10] [Batch 79/274] [Batch classify loss: 3.466527] 
[Epoch 7/10] [Batch 80/274] [Batch classify loss: 3.190890] 
[Epoch 7/10] [Batch 81/274] [Batch classify loss: 3.229148] 
[Epoch 7/10] [Batch 82/274] [Batch classify loss: 3.389004] 
[Epoch 7/10] [Batch 83/274] [Batch classify loss: 4.101948] 
[Epoch 7/10] [Batch 84/274] [Batch classify loss: 3.701573] 
[Epoch 7/10] [Batch 85/274] [Batch classify loss: 3.477406] 
[Epoch 7/10] [Batch 86/274] [Batch classify loss: 3.659768] 
[Epoch 7/10] [Batch 87/274] [Batch classify loss: 3.606893] 
[Epoch 7/10] [Batch 88/274] [Batch classify loss: 3.788414] 
[Epoch 7/10] [Batch 89/274] [Batch classify loss: 3.721752] 
[Epoch 7/10] [Batch 90/274] [Batch classify loss: 3.409611] 
[Epoch 7/10] [Batch 91/274] [Batch classify loss: 3.797823] 
[Epoch 7/10] [Batch 92/274] [Batch classify loss: 3.494911] 
[Epoch 7/10] [Batch 93/274] [Batch classify loss: 3.748090] 
[Epoch 7/10] [Batch 94/274] [Batch classify loss: 3.727541] 
[Epoch 7/10] [Batch 95/274] [Batch classify loss: 3.831394] 
[Epoch 7/10] [Batch 96/274] [Batch classify loss: 3.454419] 
[Epoch 7/10] [Batch 97/274] [Batch classify loss: 3.473997] 
[Epoch 7/10] [Batch 98/274] [Batch classify loss: 3.794997] 
[Epoch 7/10] [Batch 99/274] [Batch classify loss: 3.378786] 
[Epoch 7/10] [Batch 100/274] [Batch classify loss: 3.765519] 
[Epoch 7/10] [Batch 101/274] [Batch classify loss: 3.525763] 
[Epoch 7/10] [Batch 102/274] [Batch classify loss: 4.099483] 
[Epoch 7/10] [Batch 103/274] [Batch classify loss: 3.840919] 
[Epoch 7/10] [Batch 104/274] [Batch classify loss: 3.673215] 
[Epoch 7/10] [Batch 105/274] [Batch classify loss: 3.644387] 
[Epoch 7/10] [Batch 106/274] [Batch classify loss: 3.755483] 
[Epoch 7/10] [Batch 107/274] [Batch classify loss: 3.968519] 
[Epoch 7/10] [Batch 108/274] [Batch classify loss: 3.831724] 
[Epoch 7/10] [Batch 109/274] [Batch classify loss: 3.672519] 
[Epoch 7/10] [Batch 110/274] [Batch classify loss: 4.127063] 
[Epoch 7/10] [Batch 111/274] [Batch classify loss: 3.657412] 
[Epoch 7/10] [Batch 112/274] [Batch classify loss: 3.518313] 
[Epoch 7/10] [Batch 113/274] [Batch classify loss: 3.812875] 
[Epoch 7/10] [Batch 114/274] [Batch classify loss: 3.844575] 
[Epoch 7/10] [Batch 115/274] [Batch classify loss: 3.605847] 
[Epoch 7/10] [Batch 116/274] [Batch classify loss: 3.631073] 
[Epoch 7/10] [Batch 117/274] [Batch classify loss: 3.643991] 
[Epoch 7/10] [Batch 118/274] [Batch classify loss: 3.902354] 
[Epoch 7/10] [Batch 119/274] [Batch classify loss: 4.005101] 
[Epoch 7/10] [Batch 120/274] [Batch classify loss: 3.726308] 
[Epoch 7/10] [Batch 121/274] [Batch classify loss: 3.836574] 
[Epoch 7/10] [Batch 122/274] [Batch classify loss: 3.348943] 
[Epoch 7/10] [Batch 123/274] [Batch classify loss: 3.538216] 
[Epoch 7/10] [Batch 124/274] [Batch classify loss: 3.882937] 
[Epoch 7/10] [Batch 125/274] [Batch classify loss: 4.015821] 
[Epoch 7/10] [Batch 126/274] [Batch classify loss: 3.871209] 
[Epoch 7/10] [Batch 127/274] [Batch classify loss: 3.439606] 
[Epoch 7/10] [Batch 128/274] [Batch classify loss: 3.739810] 
[Epoch 7/10] [Batch 129/274] [Batch classify loss: 3.899706] 
[Epoch 7/10] [Batch 130/274] [Batch classify loss: 3.814999] 
[Epoch 7/10] [Batch 131/274] [Batch classify loss: 3.602912] 
[Epoch 7/10] [Batch 132/274] [Batch classify loss: 3.936222] 
[Epoch 7/10] [Batch 133/274] [Batch classify loss: 3.703390] 
[Epoch 7/10] [Batch 134/274] [Batch classify loss: 3.722735] 
[Epoch 7/10] [Batch 135/274] [Batch classify loss: 3.589259] 
[Epoch 7/10] [Batch 136/274] [Batch classify loss: 3.451141] 
[Epoch 7/10] [Batch 137/274] [Batch classify loss: 3.802382] 
[Epoch 7/10] [Batch 138/274] [Batch classify loss: 3.834817] 
[Epoch 7/10] [Batch 139/274] [Batch classify loss: 3.796250] 
[Epoch 7/10] [Batch 140/274] [Batch classify loss: 4.091033] 
[Epoch 7/10] [Batch 141/274] [Batch classify loss: 3.576640] 
[Epoch 7/10] [Batch 142/274] [Batch classify loss: 3.998618] 
[Epoch 7/10] [Batch 143/274] [Batch classify loss: 3.628454] 
[Epoch 7/10] [Batch 144/274] [Batch classify loss: 3.740153] 
[Epoch 7/10] [Batch 145/274] [Batch classify loss: 3.576040] 
[Epoch 7/10] [Batch 146/274] [Batch classify loss: 3.787333] 
[Epoch 7/10] [Batch 147/274] [Batch classify loss: 3.372461] 
[Epoch 7/10] [Batch 148/274] [Batch classify loss: 3.869524] 
[Epoch 7/10] [Batch 149/274] [Batch classify loss: 4.303469] 
[Epoch 7/10] [Batch 150/274] [Batch classify loss: 3.595213] 
[Epoch 7/10] [Batch 151/274] [Batch classify loss: 3.828507] 
[Epoch 7/10] [Batch 152/274] [Batch classify loss: 3.815554] 
[Epoch 7/10] [Batch 153/274] [Batch classify loss: 3.508634] 
[Epoch 7/10] [Batch 154/274] [Batch classify loss: 3.903759] 
[Epoch 7/10] [Batch 155/274] [Batch classify loss: 4.188913] 
[Epoch 7/10] [Batch 156/274] [Batch classify loss: 3.455131] 
[Epoch 7/10] [Batch 157/274] [Batch classify loss: 3.564945] 
[Epoch 7/10] [Batch 158/274] [Batch classify loss: 3.769621] 
[Epoch 7/10] [Batch 159/274] [Batch classify loss: 4.055200] 
[Epoch 7/10] [Batch 160/274] [Batch classify loss: 4.119594] 
[Epoch 7/10] [Batch 161/274] [Batch classify loss: 4.038644] 
[Epoch 7/10] [Batch 162/274] [Batch classify loss: 3.743744] 
[Epoch 7/10] [Batch 163/274] [Batch classify loss: 3.694376] 
[Epoch 7/10] [Batch 164/274] [Batch classify loss: 3.651627] 
[Epoch 7/10] [Batch 165/274] [Batch classify loss: 3.817157] 
[Epoch 7/10] [Batch 166/274] [Batch classify loss: 3.716378] 
[Epoch 7/10] [Batch 167/274] [Batch classify loss: 3.853437] 
[Epoch 7/10] [Batch 168/274] [Batch classify loss: 3.526361] 
[Epoch 7/10] [Batch 169/274] [Batch classify loss: 3.447291] 
[Epoch 7/10] [Batch 170/274] [Batch classify loss: 4.300687] 
[Epoch 7/10] [Batch 171/274] [Batch classify loss: 4.059186] 
[Epoch 7/10] [Batch 172/274] [Batch classify loss: 3.942223] 
[Epoch 7/10] [Batch 173/274] [Batch classify loss: 3.963726] 
[Epoch 7/10] [Batch 174/274] [Batch classify loss: 3.807804] 
[Epoch 7/10] [Batch 175/274] [Batch classify loss: 4.078985] 
[Epoch 7/10] [Batch 176/274] [Batch classify loss: 3.771901] 
[Epoch 7/10] [Batch 177/274] [Batch classify loss: 3.767462] 
[Epoch 7/10] [Batch 178/274] [Batch classify loss: 3.865661] 
[Epoch 7/10] [Batch 179/274] [Batch classify loss: 4.148225] 
[Epoch 7/10] [Batch 180/274] [Batch classify loss: 3.690871] 
[Epoch 7/10] [Batch 181/274] [Batch classify loss: 3.991982] 
[Epoch 7/10] [Batch 182/274] [Batch classify loss: 4.299198] 
[Epoch 7/10] [Batch 183/274] [Batch classify loss: 3.448911] 
[Epoch 7/10] [Batch 184/274] [Batch classify loss: 4.039186] 
[Epoch 7/10] [Batch 185/274] [Batch classify loss: 3.703043] 
[Epoch 7/10] [Batch 186/274] [Batch classify loss: 3.812088] 
[Epoch 7/10] [Batch 187/274] [Batch classify loss: 3.601138] 
[Epoch 7/10] [Batch 188/274] [Batch classify loss: 3.779933] 
[Epoch 7/10] [Batch 189/274] [Batch classify loss: 4.302971] 
[Epoch 7/10] [Batch 190/274] [Batch classify loss: 4.059790] 
[Epoch 7/10] [Batch 191/274] [Batch classify loss: 3.774640] 
[Epoch 7/10] [Batch 192/274] [Batch classify loss: 4.188900] 
[Epoch 7/10] [Batch 193/274] [Batch classify loss: 3.496255] 
[Epoch 7/10] [Batch 194/274] [Batch classify loss: 3.620277] 
[Epoch 7/10] [Batch 195/274] [Batch classify loss: 4.172829] 
[Epoch 7/10] [Batch 196/274] [Batch classify loss: 3.747610] 
[Epoch 7/10] [Batch 197/274] [Batch classify loss: 3.506775] 
[Epoch 7/10] [Batch 198/274] [Batch classify loss: 3.786576] 
[Epoch 7/10] [Batch 199/274] [Batch classify loss: 3.853275] 
[Epoch 7/10] [Batch 200/274] [Batch classify loss: 3.751165] 
[Epoch 7/10] [Batch 201/274] [Batch classify loss: 4.081184] 
[Epoch 7/10] [Batch 202/274] [Batch classify loss: 4.184786] 
[Epoch 7/10] [Batch 203/274] [Batch classify loss: 3.672463] 
[Epoch 7/10] [Batch 204/274] [Batch classify loss: 3.690890] 
[Epoch 7/10] [Batch 205/274] [Batch classify loss: 4.095160] 
[Epoch 7/10] [Batch 206/274] [Batch classify loss: 3.717040] 
[Epoch 7/10] [Batch 207/274] [Batch classify loss: 4.250204] 
[Epoch 7/10] [Batch 208/274] [Batch classify loss: 4.023272] 
[Epoch 7/10] [Batch 209/274] [Batch classify loss: 3.860217] 
[Epoch 7/10] [Batch 210/274] [Batch classify loss: 3.450957] 
[Epoch 7/10] [Batch 211/274] [Batch classify loss: 3.849970] 
[Epoch 7/10] [Batch 212/274] [Batch classify loss: 4.104762] 
[Epoch 7/10] [Batch 213/274] [Batch classify loss: 3.735843] 
[Epoch 7/10] [Batch 214/274] [Batch classify loss: 4.002792] 
[Epoch 7/10] [Batch 215/274] [Batch classify loss: 3.814543] 
[Epoch 7/10] [Batch 216/274] [Batch classify loss: 3.849391] 
[Epoch 7/10] [Batch 217/274] [Batch classify loss: 3.894446] 
[Epoch 7/10] [Batch 218/274] [Batch classify loss: 3.643177] 
[Epoch 7/10] [Batch 219/274] [Batch classify loss: 3.838097] 
[Epoch 7/10] [Batch 220/274] [Batch classify loss: 3.777682] 
[Epoch 7/10] [Batch 221/274] [Batch classify loss: 4.020236] 
[Epoch 7/10] [Batch 222/274] [Batch classify loss: 3.617032] 
[Epoch 7/10] [Batch 223/274] [Batch classify loss: 3.825945] 
[Epoch 7/10] [Batch 224/274] [Batch classify loss: 3.811109] 
[Epoch 7/10] [Batch 225/274] [Batch classify loss: 3.571217] 
[Epoch 7/10] [Batch 226/274] [Batch classify loss: 3.951706] 
[Epoch 7/10] [Batch 227/274] [Batch classify loss: 4.286111] 
[Epoch 7/10] [Batch 228/274] [Batch classify loss: 4.310390] 
[Epoch 7/10] [Batch 229/274] [Batch classify loss: 3.584232] 
[Epoch 7/10] [Batch 230/274] [Batch classify loss: 3.777640] 
[Epoch 7/10] [Batch 231/274] [Batch classify loss: 3.866352] 
[Epoch 7/10] [Batch 232/274] [Batch classify loss: 4.021456] 
[Epoch 7/10] [Batch 233/274] [Batch classify loss: 3.893922] 
[Epoch 7/10] [Batch 234/274] [Batch classify loss: 4.087767] 
[Epoch 7/10] [Batch 235/274] [Batch classify loss: 3.822544] 
[Epoch 7/10] [Batch 236/274] [Batch classify loss: 3.880136] 
[Epoch 7/10] [Batch 237/274] [Batch classify loss: 4.052997] 
[Epoch 7/10] [Batch 238/274] [Batch classify loss: 4.110932] 
[Epoch 7/10] [Batch 239/274] [Batch classify loss: 4.107506] 
[Epoch 7/10] [Batch 240/274] [Batch classify loss: 4.074006] 
[Epoch 7/10] [Batch 241/274] [Batch classify loss: 4.070944] 
[Epoch 7/10] [Batch 242/274] [Batch classify loss: 3.885084] 
[Epoch 7/10] [Batch 243/274] [Batch classify loss: 3.670994] 
[Epoch 7/10] [Batch 244/274] [Batch classify loss: 3.445526] 
[Epoch 7/10] [Batch 245/274] [Batch classify loss: 4.020391] 
[Epoch 7/10] [Batch 246/274] [Batch classify loss: 3.881316] 
[Epoch 7/10] [Batch 247/274] [Batch classify loss: 3.986496] 
[Epoch 7/10] [Batch 248/274] [Batch classify loss: 3.974871] 
[Epoch 7/10] [Batch 249/274] [Batch classify loss: 3.929606] 
[Epoch 7/10] [Batch 250/274] [Batch classify loss: 4.179565] 
[Epoch 7/10] [Batch 251/274] [Batch classify loss: 3.845100] 
[Epoch 7/10] [Batch 252/274] [Batch classify loss: 3.737455] 
[Epoch 7/10] [Batch 253/274] [Batch classify loss: 3.922356] 
[Epoch 7/10] [Batch 254/274] [Batch classify loss: 3.886353] 
[Epoch 7/10] [Batch 255/274] [Batch classify loss: 3.569231] 
[Epoch 7/10] [Batch 256/274] [Batch classify loss: 4.216518] 
[Epoch 7/10] [Batch 257/274] [Batch classify loss: 3.942594] 
[Epoch 7/10] [Batch 258/274] [Batch classify loss: 4.074177] 
[Epoch 7/10] [Batch 259/274] [Batch classify loss: 3.859650] 
[Epoch 7/10] [Batch 260/274] [Batch classify loss: 4.117912] 
[Epoch 7/10] [Batch 261/274] [Batch classify loss: 3.813236] 
[Epoch 7/10] [Batch 262/274] [Batch classify loss: 3.959280] 
[Epoch 7/10] [Batch 263/274] [Batch classify loss: 3.974786] 
[Epoch 7/10] [Batch 264/274] [Batch classify loss: 3.877090] 
[Epoch 7/10] [Batch 265/274] [Batch classify loss: 3.990443] 
[Epoch 7/10] [Batch 266/274] [Batch classify loss: 3.964016] 
[Epoch 7/10] [Batch 267/274] [Batch classify loss: 4.110620] 
[Epoch 7/10] [Batch 268/274] [Batch classify loss: 4.328647] 
[Epoch 7/10] [Batch 269/274] [Batch classify loss: 3.862003] 
[Epoch 7/10] [Batch 270/274] [Batch classify loss: 3.579004] 
[Epoch 7/10] [Batch 271/274] [Batch classify loss: 4.049660] 
[Epoch 7/10] [Batch 272/274] [Batch classify loss: 4.119545] 
[Epoch 7/10] [Batch 273/274] [Batch classify loss: 3.613316] 
[Epoch 7/10] [Batch 274/274] [Batch classify loss: 3.894294] 
0007 epoch mmat trained classifier accuary on the clean testing examples:94.6028%
0007 epoch mmat trained classifier loss on the clean testing examples:0.2241
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3081%
mmat trained classifier loss on adversarial testset:4.530491352081299
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-cle
7epoch learning rate:0.01
[Epoch 8/10] [Batch 1/274] [Batch classify loss: 1.655735] 
[Epoch 8/10] [Batch 2/274] [Batch classify loss: 1.334792] 
[Epoch 8/10] [Batch 3/274] [Batch classify loss: 1.698652] 
[Epoch 8/10] [Batch 4/274] [Batch classify loss: 1.556491] 
[Epoch 8/10] [Batch 5/274] [Batch classify loss: 1.824372] 
[Epoch 8/10] [Batch 6/274] [Batch classify loss: 1.802993] 
[Epoch 8/10] [Batch 7/274] [Batch classify loss: 1.760815] 
[Epoch 8/10] [Batch 8/274] [Batch classify loss: 2.181906] 
[Epoch 8/10] [Batch 9/274] [Batch classify loss: 2.089929] 
[Epoch 8/10] [Batch 10/274] [Batch classify loss: 2.513246] 
[Epoch 8/10] [Batch 11/274] [Batch classify loss: 2.193808] 
[Epoch 8/10] [Batch 12/274] [Batch classify loss: 2.356555] 
[Epoch 8/10] [Batch 13/274] [Batch classify loss: 2.091171] 
[Epoch 8/10] [Batch 14/274] [Batch classify loss: 2.355263] 
[Epoch 8/10] [Batch 15/274] [Batch classify loss: 2.284680] 
[Epoch 8/10] [Batch 16/274] [Batch classify loss: 2.156228] 
[Epoch 8/10] [Batch 17/274] [Batch classify loss: 2.542939] 
[Epoch 8/10] [Batch 18/274] [Batch classify loss: 2.649367] 
[Epoch 8/10] [Batch 19/274] [Batch classify loss: 2.699097] 
[Epoch 8/10] [Batch 20/274] [Batch classify loss: 2.436768] 
[Epoch 8/10] [Batch 21/274] [Batch classify loss: 2.592352] 
[Epoch 8/10] [Batch 22/274] [Batch classify loss: 2.640874] 
[Epoch 8/10] [Batch 23/274] [Batch classify loss: 2.684785] 
[Epoch 8/10] [Batch 24/274] [Batch classify loss: 2.692086] 
[Epoch 8/10] [Batch 25/274] [Batch classify loss: 2.281801] 
[Epoch 8/10] [Batch 26/274] [Batch classify loss: 2.661389] 
[Epoch 8/10] [Batch 27/274] [Batch classify loss: 2.582100] 
[Epoch 8/10] [Batch 28/274] [Batch classify loss: 3.111910] 
[Epoch 8/10] [Batch 29/274] [Batch classify loss: 2.705302] 
[Epoch 8/10] [Batch 30/274] [Batch classify loss: 2.700494] 
[Epoch 8/10] [Batch 31/274] [Batch classify loss: 2.536730] 
[Epoch 8/10] [Batch 32/274] [Batch classify loss: 2.759846] 
[Epoch 8/10] [Batch 33/274] [Batch classify loss: 2.637974] 
[Epoch 8/10] [Batch 34/274] [Batch classify loss: 2.311775] 
[Epoch 8/10] [Batch 35/274] [Batch classify loss: 2.772872] 
[Epoch 8/10] [Batch 36/274] [Batch classify loss: 2.874499] 
[Epoch 8/10] [Batch 37/274] [Batch classify loss: 3.080504] 
[Epoch 8/10] [Batch 38/274] [Batch classify loss: 2.879277] 
[Epoch 8/10] [Batch 39/274] [Batch classify loss: 2.865989] 
[Epoch 8/10] [Batch 40/274] [Batch classify loss: 3.025321] 
[Epoch 8/10] [Batch 41/274] [Batch classify loss: 2.957010] 
[Epoch 8/10] [Batch 42/274] [Batch classify loss: 2.646190] 
[Epoch 8/10] [Batch 43/274] [Batch classify loss: 2.707508] 
[Epoch 8/10] [Batch 44/274] [Batch classify loss: 2.984337] 
[Epoch 8/10] [Batch 45/274] [Batch classify loss: 3.176663] 
[Epoch 8/10] [Batch 46/274] [Batch classify loss: 3.004115] 
[Epoch 8/10] [Batch 47/274] [Batch classify loss: 2.918366] 
[Epoch 8/10] [Batch 48/274] [Batch classify loss: 3.215118] 
[Epoch 8/10] [Batch 49/274] [Batch classify loss: 2.695703] 
[Epoch 8/10] [Batch 50/274] [Batch classify loss: 2.551227] 
[Epoch 8/10] [Batch 51/274] [Batch classify loss: 3.099391] 
[Epoch 8/10] [Batch 52/274] [Batch classify loss: 2.922092] 
[Epoch 8/10] [Batch 53/274] [Batch classify loss: 3.259507] 
[Epoch 8/10] [Batch 54/274] [Batch classify loss: 2.942722] 
[Epoch 8/10] [Batch 55/274] [Batch classify loss: 3.265377] 
[Epoch 8/10] [Batch 56/274] [Batch classify loss: 2.624657] 
[Epoch 8/10] [Batch 57/274] [Batch classify loss: 2.890889] 
[Epoch 8/10] [Batch 58/274] [Batch classify loss: 2.545304] 
[Epoch 8/10] [Batch 59/274] [Batch classify loss: 3.009212] 
[Epoch 8/10] [Batch 60/274] [Batch classify loss: 3.403031] 
[Epoch 8/10] [Batch 61/274] [Batch classify loss: 3.324933] 
[Epoch 8/10] [Batch 62/274] [Batch classify loss: 2.911338] 
[Epoch 8/10] [Batch 63/274] [Batch classify loss: 3.034091] 
[Epoch 8/10] [Batch 64/274] [Batch classify loss: 3.073919] 
[Epoch 8/10] [Batch 65/274] [Batch classify loss: 2.772094] 
[Epoch 8/10] [Batch 66/274] [Batch classify loss: 3.098504] 
[Epoch 8/10] [Batch 67/274] [Batch classify loss: 2.975106] 
[Epoch 8/10] [Batch 68/274] [Batch classify loss: 3.589752] 
[Epoch 8/10] [Batch 69/274] [Batch classify loss: 3.076921] 
[Epoch 8/10] [Batch 70/274] [Batch classify loss: 2.908176] 
[Epoch 8/10] [Batch 71/274] [Batch classify loss: 3.183401] 
[Epoch 8/10] [Batch 72/274] [Batch classify loss: 3.121359] 
[Epoch 8/10] [Batch 73/274] [Batch classify loss: 2.823646] 
[Epoch 8/10] [Batch 74/274] [Batch classify loss: 3.453921] 
[Epoch 8/10] [Batch 75/274] [Batch classify loss: 2.876998] 
[Epoch 8/10] [Batch 76/274] [Batch classify loss: 3.484754] 
[Epoch 8/10] [Batch 77/274] [Batch classify loss: 3.451559] 
[Epoch 8/10] [Batch 78/274] [Batch classify loss: 3.171710] 
[Epoch 8/10] [Batch 79/274] [Batch classify loss: 3.260035] 
[Epoch 8/10] [Batch 80/274] [Batch classify loss: 3.302316] 
[Epoch 8/10] [Batch 81/274] [Batch classify loss: 3.191475] 
[Epoch 8/10] [Batch 82/274] [Batch classify loss: 3.212732] 
[Epoch 8/10] [Batch 83/274] [Batch classify loss: 2.816216] 
[Epoch 8/10] [Batch 84/274] [Batch classify loss: 2.808759] 
[Epoch 8/10] [Batch 85/274] [Batch classify loss: 3.201141] 
[Epoch 8/10] [Batch 86/274] [Batch classify loss: 3.754858] 
[Epoch 8/10] [Batch 87/274] [Batch classify loss: 3.029389] 
[Epoch 8/10] [Batch 88/274] [Batch classify loss: 3.392988] 
[Epoch 8/10] [Batch 89/274] [Batch classify loss: 3.388439] 
[Epoch 8/10] [Batch 90/274] [Batch classify loss: 3.213037] 
[Epoch 8/10] [Batch 91/274] [Batch classify loss: 2.999700] 
[Epoch 8/10] [Batch 92/274] [Batch classify loss: 3.102045] 
[Epoch 8/10] [Batch 93/274] [Batch classify loss: 3.008009] 
[Epoch 8/10] [Batch 94/274] [Batch classify loss: 3.534820] 
[Epoch 8/10] [Batch 95/274] [Batch classify loss: 3.419741] 
[Epoch 8/10] [Batch 96/274] [Batch classify loss: 3.317705] 
[Epoch 8/10] [Batch 97/274] [Batch classify loss: 3.096166] 
[Epoch 8/10] [Batch 98/274] [Batch classify loss: 3.508832] 
[Epoch 8/10] [Batch 99/274] [Batch classify loss: 3.204156] 
[Epoch 8/10] [Batch 100/274] [Batch classify loss: 3.059981] 
[Epoch 8/10] [Batch 101/274] [Batch classify loss: 3.687437] 
[Epoch 8/10] [Batch 102/274] [Batch classify loss: 3.020568] 
[Epoch 8/10] [Batch 103/274] [Batch classify loss: 3.248309] 
[Epoch 8/10] [Batch 104/274] [Batch classify loss: 3.562106] 
[Epoch 8/10] [Batch 105/274] [Batch classify loss: 3.511496] 
[Epoch 8/10] [Batch 106/274] [Batch classify loss: 3.257917] 
[Epoch 8/10] [Batch 107/274] [Batch classify loss: 3.009168] 
[Epoch 8/10] [Batch 108/274] [Batch classify loss: 3.009995] 
[Epoch 8/10] [Batch 109/274] [Batch classify loss: 3.737973] 
[Epoch 8/10] [Batch 110/274] [Batch classify loss: 3.152769] 
[Epoch 8/10] [Batch 111/274] [Batch classify loss: 3.059048] 
[Epoch 8/10] [Batch 112/274] [Batch classify loss: 3.093242] 
[Epoch 8/10] [Batch 113/274] [Batch classify loss: 3.094774] 
[Epoch 8/10] [Batch 114/274] [Batch classify loss: 3.407964] 
[Epoch 8/10] [Batch 115/274] [Batch classify loss: 3.363951] 
[Epoch 8/10] [Batch 116/274] [Batch classify loss: 3.214211] 
[Epoch 8/10] [Batch 117/274] [Batch classify loss: 3.324023] 
[Epoch 8/10] [Batch 118/274] [Batch classify loss: 3.134804] 
[Epoch 8/10] [Batch 119/274] [Batch classify loss: 3.494455] 
[Epoch 8/10] [Batch 120/274] [Batch classify loss: 3.269284] 
[Epoch 8/10] [Batch 121/274] [Batch classify loss: 3.080756] 
[Epoch 8/10] [Batch 122/274] [Batch classify loss: 3.253398] 
[Epoch 8/10] [Batch 123/274] [Batch classify loss: 3.385943] 
[Epoch 8/10] [Batch 124/274] [Batch classify loss: 3.028464] 
[Epoch 8/10] [Batch 125/274] [Batch classify loss: 3.366117] 
[Epoch 8/10] [Batch 126/274] [Batch classify loss: 3.413340] 
[Epoch 8/10] [Batch 127/274] [Batch classify loss: 2.933794] 
[Epoch 8/10] [Batch 128/274] [Batch classify loss: 3.158110] 
[Epoch 8/10] [Batch 129/274] [Batch classify loss: 3.284819] 
[Epoch 8/10] [Batch 130/274] [Batch classify loss: 3.118881] 
[Epoch 8/10] [Batch 131/274] [Batch classify loss: 3.188967] 
[Epoch 8/10] [Batch 132/274] [Batch classify loss: 3.684433] 
[Epoch 8/10] [Batch 133/274] [Batch classify loss: 3.229824] 
[Epoch 8/10] [Batch 134/274] [Batch classify loss: 3.721250] 
[Epoch 8/10] [Batch 135/274] [Batch classify loss: 3.250957] 
[Epoch 8/10] [Batch 136/274] [Batch classify loss: 3.560259] 
[Epoch 8/10] [Batch 137/274] [Batch classify loss: 3.338340] 
[Epoch 8/10] [Batch 138/274] [Batch classify loss: 3.569386] 
[Epoch 8/10] [Batch 139/274] [Batch classify loss: 3.173889] 
[Epoch 8/10] [Batch 140/274] [Batch classify loss: 3.254886] 
[Epoch 8/10] [Batch 141/274] [Batch classify loss: 3.451949] 
[Epoch 8/10] [Batch 142/274] [Batch classify loss: 3.169950] 
[Epoch 8/10] [Batch 143/274] [Batch classify loss: 3.390558] 
[Epoch 8/10] [Batch 144/274] [Batch classify loss: 3.180584] 
[Epoch 8/10] [Batch 145/274] [Batch classify loss: 3.186271] 
[Epoch 8/10] [Batch 146/274] [Batch classify loss: 3.263191] 
[Epoch 8/10] [Batch 147/274] [Batch classify loss: 3.414100] 
[Epoch 8/10] [Batch 148/274] [Batch classify loss: 3.196206] 
[Epoch 8/10] [Batch 149/274] [Batch classify loss: 3.577325] 
[Epoch 8/10] [Batch 150/274] [Batch classify loss: 3.529016] 
[Epoch 8/10] [Batch 151/274] [Batch classify loss: 3.604657] 
[Epoch 8/10] [Batch 152/274] [Batch classify loss: 3.648224] 
[Epoch 8/10] [Batch 153/274] [Batch classify loss: 3.553032] 
[Epoch 8/10] [Batch 154/274] [Batch classify loss: 3.323376] 
[Epoch 8/10] [Batch 155/274] [Batch classify loss: 3.292649] 
[Epoch 8/10] [Batch 156/274] [Batch classify loss: 3.391199] 
[Epoch 8/10] [Batch 157/274] [Batch classify loss: 3.608052] 
[Epoch 8/10] [Batch 158/274] [Batch classify loss: 4.208597] 
[Epoch 8/10] [Batch 159/274] [Batch classify loss: 3.280753] 
[Epoch 8/10] [Batch 160/274] [Batch classify loss: 3.374878] 
[Epoch 8/10] [Batch 161/274] [Batch classify loss: 3.775338] 
[Epoch 8/10] [Batch 162/274] [Batch classify loss: 3.165426] 
[Epoch 8/10] [Batch 163/274] [Batch classify loss: 3.688596] 
[Epoch 8/10] [Batch 164/274] [Batch classify loss: 3.319823] 
[Epoch 8/10] [Batch 165/274] [Batch classify loss: 3.739547] 
[Epoch 8/10] [Batch 166/274] [Batch classify loss: 3.533954] 
[Epoch 8/10] [Batch 167/274] [Batch classify loss: 3.233989] 
[Epoch 8/10] [Batch 168/274] [Batch classify loss: 3.122917] 
[Epoch 8/10] [Batch 169/274] [Batch classify loss: 3.419469] 
[Epoch 8/10] [Batch 170/274] [Batch classify loss: 3.153683] 
[Epoch 8/10] [Batch 171/274] [Batch classify loss: 3.387324] 
[Epoch 8/10] [Batch 172/274] [Batch classify loss: 3.498117] 
[Epoch 8/10] [Batch 173/274] [Batch classify loss: 3.097628] 
[Epoch 8/10] [Batch 174/274] [Batch classify loss: 3.839306] 
[Epoch 8/10] [Batch 175/274] [Batch classify loss: 3.351087] 
[Epoch 8/10] [Batch 176/274] [Batch classify loss: 3.757112] 
[Epoch 8/10] [Batch 177/274] [Batch classify loss: 3.460972] 
[Epoch 8/10] [Batch 178/274] [Batch classify loss: 3.412777] 
[Epoch 8/10] [Batch 179/274] [Batch classify loss: 3.178644] 
[Epoch 8/10] [Batch 180/274] [Batch classify loss: 3.146159] 
[Epoch 8/10] [Batch 181/274] [Batch classify loss: 3.492415] 
[Epoch 8/10] [Batch 182/274] [Batch classify loss: 3.487582] 
[Epoch 8/10] [Batch 183/274] [Batch classify loss: 3.320537] 
[Epoch 8/10] [Batch 184/274] [Batch classify loss: 3.790250] 
[Epoch 8/10] [Batch 185/274] [Batch classify loss: 3.286330] 
[Epoch 8/10] [Batch 186/274] [Batch classify loss: 3.678820] 
[Epoch 8/10] [Batch 187/274] [Batch classify loss: 3.647727] 
[Epoch 8/10] [Batch 188/274] [Batch classify loss: 3.291766] 
[Epoch 8/10] [Batch 189/274] [Batch classify loss: 3.430750] 
[Epoch 8/10] [Batch 190/274] [Batch classify loss: 3.409206] 
[Epoch 8/10] [Batch 191/274] [Batch classify loss: 3.791377] 
[Epoch 8/10] [Batch 192/274] [Batch classify loss: 3.361211] 
[Epoch 8/10] [Batch 193/274] [Batch classify loss: 3.532081] 
[Epoch 8/10] [Batch 194/274] [Batch classify loss: 3.324847] 
[Epoch 8/10] [Batch 195/274] [Batch classify loss: 3.331390] 
[Epoch 8/10] [Batch 196/274] [Batch classify loss: 3.466377] 
[Epoch 8/10] [Batch 197/274] [Batch classify loss: 3.544663] 
[Epoch 8/10] [Batch 198/274] [Batch classify loss: 3.379961] 
[Epoch 8/10] [Batch 199/274] [Batch classify loss: 3.886012] 
[Epoch 8/10] [Batch 200/274] [Batch classify loss: 3.444646] 
[Epoch 8/10] [Batch 201/274] [Batch classify loss: 3.175858] 
[Epoch 8/10] [Batch 202/274] [Batch classify loss: 3.504463] 
[Epoch 8/10] [Batch 203/274] [Batch classify loss: 3.443074] 
[Epoch 8/10] [Batch 204/274] [Batch classify loss: 3.264325] 
[Epoch 8/10] [Batch 205/274] [Batch classify loss: 3.441948] 
[Epoch 8/10] [Batch 206/274] [Batch classify loss: 3.406916] 
[Epoch 8/10] [Batch 207/274] [Batch classify loss: 3.348611] 
[Epoch 8/10] [Batch 208/274] [Batch classify loss: 3.452601] 
[Epoch 8/10] [Batch 209/274] [Batch classify loss: 3.702507] 
[Epoch 8/10] [Batch 210/274] [Batch classify loss: 3.271387] 
[Epoch 8/10] [Batch 211/274] [Batch classify loss: 3.377373] 
[Epoch 8/10] [Batch 212/274] [Batch classify loss: 3.438384] 
[Epoch 8/10] [Batch 213/274] [Batch classify loss: 3.880253] 
[Epoch 8/10] [Batch 214/274] [Batch classify loss: 3.713098] 
[Epoch 8/10] [Batch 215/274] [Batch classify loss: 3.599060] 
[Epoch 8/10] [Batch 216/274] [Batch classify loss: 3.539673] 
[Epoch 8/10] [Batch 217/274] [Batch classify loss: 3.608060] 
[Epoch 8/10] [Batch 218/274] [Batch classify loss: 3.376975] 
[Epoch 8/10] [Batch 219/274] [Batch classify loss: 4.168980] 
[Epoch 8/10] [Batch 220/274] [Batch classify loss: 3.957861] 
[Epoch 8/10] [Batch 221/274] [Batch classify loss: 3.448723] 
[Epoch 8/10] [Batch 222/274] [Batch classify loss: 3.852551] 
[Epoch 8/10] [Batch 223/274] [Batch classify loss: 3.800035] 
[Epoch 8/10] [Batch 224/274] [Batch classify loss: 3.695461] 
[Epoch 8/10] [Batch 225/274] [Batch classify loss: 3.708479] 
[Epoch 8/10] [Batch 226/274] [Batch classify loss: 3.511293] 
[Epoch 8/10] [Batch 227/274] [Batch classify loss: 4.009998] 
[Epoch 8/10] [Batch 228/274] [Batch classify loss: 3.461920] 
[Epoch 8/10] [Batch 229/274] [Batch classify loss: 3.429666] 
[Epoch 8/10] [Batch 230/274] [Batch classify loss: 3.470963] 
[Epoch 8/10] [Batch 231/274] [Batch classify loss: 3.479680] 
[Epoch 8/10] [Batch 232/274] [Batch classify loss: 3.418837] 
[Epoch 8/10] [Batch 233/274] [Batch classify loss: 3.152549] 
[Epoch 8/10] [Batch 234/274] [Batch classify loss: 3.552857] 
[Epoch 8/10] [Batch 235/274] [Batch classify loss: 3.888446] 
[Epoch 8/10] [Batch 236/274] [Batch classify loss: 3.317582] 
[Epoch 8/10] [Batch 237/274] [Batch classify loss: 3.828775] 
[Epoch 8/10] [Batch 238/274] [Batch classify loss: 3.648022] 
[Epoch 8/10] [Batch 239/274] [Batch classify loss: 3.653046] 
[Epoch 8/10] [Batch 240/274] [Batch classify loss: 3.236474] 
[Epoch 8/10] [Batch 241/274] [Batch classify loss: 3.476661] 
[Epoch 8/10] [Batch 242/274] [Batch classify loss: 3.595056] 
[Epoch 8/10] [Batch 243/274] [Batch classify loss: 3.625929] 
[Epoch 8/10] [Batch 244/274] [Batch classify loss: 3.727329] 
[Epoch 8/10] [Batch 245/274] [Batch classify loss: 3.624493] 
[Epoch 8/10] [Batch 246/274] [Batch classify loss: 3.520027] 
[Epoch 8/10] [Batch 247/274] [Batch classify loss: 3.396761] 
[Epoch 8/10] [Batch 248/274] [Batch classify loss: 3.544162] 
[Epoch 8/10] [Batch 249/274] [Batch classify loss: 3.392128] 
[Epoch 8/10] [Batch 250/274] [Batch classify loss: 3.501695] 
[Epoch 8/10] [Batch 251/274] [Batch classify loss: 3.516679] 
[Epoch 8/10] [Batch 252/274] [Batch classify loss: 3.530314] 
[Epoch 8/10] [Batch 253/274] [Batch classify loss: 3.677281] 
[Epoch 8/10] [Batch 254/274] [Batch classify loss: 4.100838] 
[Epoch 8/10] [Batch 255/274] [Batch classify loss: 3.929297] 
[Epoch 8/10] [Batch 256/274] [Batch classify loss: 3.347533] 
[Epoch 8/10] [Batch 257/274] [Batch classify loss: 3.608822] 
[Epoch 8/10] [Batch 258/274] [Batch classify loss: 3.484454] 
[Epoch 8/10] [Batch 259/274] [Batch classify loss: 3.117224] 
[Epoch 8/10] [Batch 260/274] [Batch classify loss: 3.788378] 
[Epoch 8/10] [Batch 261/274] [Batch classify loss: 3.385095] 
[Epoch 8/10] [Batch 262/274] [Batch classify loss: 3.631124] 
[Epoch 8/10] [Batch 263/274] [Batch classify loss: 3.543941] 
[Epoch 8/10] [Batch 264/274] [Batch classify loss: 3.189887] 
[Epoch 8/10] [Batch 265/274] [Batch classify loss: 3.482226] 
[Epoch 8/10] [Batch 266/274] [Batch classify loss: 3.757758] 
[Epoch 8/10] [Batch 267/274] [Batch classify loss: 3.801825] 
[Epoch 8/10] [Batch 268/274] [Batch classify loss: 3.520051] 
[Epoch 8/10] [Batch 269/274] [Batch classify loss: 3.538634] 
[Epoch 8/10] [Batch 270/274] [Batch classify loss: 3.384305] 
[Epoch 8/10] [Batch 271/274] [Batch classify loss: 3.765599] 
[Epoch 8/10] [Batch 272/274] [Batch classify loss: 3.596038] 
[Epoch 8/10] [Batch 273/274] [Batch classify loss: 3.240366] 
[Epoch 8/10] [Batch 274/274] [Batch classify loss: 3.059377] 
0008 epoch mmat trained classifier accuary on the clean testing examples:94.8486%
0008 epoch mmat trained classifier loss on the clean testing examples:0.2236
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2044%
mmat trained classifier loss on adversarial testset:4.507957458496094
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-cle
8epoch learning rate:0.01
[Epoch 9/10] [Batch 1/274] [Batch classify loss: 2.551941] 
[Epoch 9/10] [Batch 2/274] [Batch classify loss: 1.384531] 
[Epoch 9/10] [Batch 3/274] [Batch classify loss: 1.311747] 
[Epoch 9/10] [Batch 4/274] [Batch classify loss: 1.520130] 
[Epoch 9/10] [Batch 5/274] [Batch classify loss: 1.365336] 
[Epoch 9/10] [Batch 6/274] [Batch classify loss: 1.371591] 
[Epoch 9/10] [Batch 7/274] [Batch classify loss: 1.543433] 
[Epoch 9/10] [Batch 8/274] [Batch classify loss: 1.638710] 
[Epoch 9/10] [Batch 9/274] [Batch classify loss: 1.766508] 
[Epoch 9/10] [Batch 10/274] [Batch classify loss: 1.588364] 
[Epoch 9/10] [Batch 11/274] [Batch classify loss: 1.794779] 
[Epoch 9/10] [Batch 12/274] [Batch classify loss: 1.889481] 
[Epoch 9/10] [Batch 13/274] [Batch classify loss: 1.827214] 
[Epoch 9/10] [Batch 14/274] [Batch classify loss: 2.099263] 
[Epoch 9/10] [Batch 15/274] [Batch classify loss: 2.029873] 
[Epoch 9/10] [Batch 16/274] [Batch classify loss: 2.161003] 
[Epoch 9/10] [Batch 17/274] [Batch classify loss: 1.861675] 
[Epoch 9/10] [Batch 18/274] [Batch classify loss: 2.206682] 
[Epoch 9/10] [Batch 19/274] [Batch classify loss: 2.240778] 
[Epoch 9/10] [Batch 20/274] [Batch classify loss: 2.321708] 
[Epoch 9/10] [Batch 21/274] [Batch classify loss: 2.395224] 
[Epoch 9/10] [Batch 22/274] [Batch classify loss: 2.173522] 
[Epoch 9/10] [Batch 23/274] [Batch classify loss: 1.989540] 
[Epoch 9/10] [Batch 24/274] [Batch classify loss: 1.984111] 
[Epoch 9/10] [Batch 25/274] [Batch classify loss: 2.357982] 
[Epoch 9/10] [Batch 26/274] [Batch classify loss: 2.104626] 
[Epoch 9/10] [Batch 27/274] [Batch classify loss: 2.205771] 
[Epoch 9/10] [Batch 28/274] [Batch classify loss: 2.269742] 
[Epoch 9/10] [Batch 29/274] [Batch classify loss: 2.229328] 
[Epoch 9/10] [Batch 30/274] [Batch classify loss: 2.199307] 
[Epoch 9/10] [Batch 31/274] [Batch classify loss: 2.262498] 
[Epoch 9/10] [Batch 32/274] [Batch classify loss: 2.321599] 
[Epoch 9/10] [Batch 33/274] [Batch classify loss: 2.401597] 
[Epoch 9/10] [Batch 34/274] [Batch classify loss: 2.234461] 
[Epoch 9/10] [Batch 35/274] [Batch classify loss: 2.015277] 
[Epoch 9/10] [Batch 36/274] [Batch classify loss: 2.234214] 
[Epoch 9/10] [Batch 37/274] [Batch classify loss: 2.228086] 
[Epoch 9/10] [Batch 38/274] [Batch classify loss: 2.166897] 
[Epoch 9/10] [Batch 39/274] [Batch classify loss: 2.206491] 
[Epoch 9/10] [Batch 40/274] [Batch classify loss: 2.468111] 
[Epoch 9/10] [Batch 41/274] [Batch classify loss: 2.347966] 
[Epoch 9/10] [Batch 42/274] [Batch classify loss: 2.445059] 
[Epoch 9/10] [Batch 43/274] [Batch classify loss: 2.766133] 
[Epoch 9/10] [Batch 44/274] [Batch classify loss: 3.042917] 
[Epoch 9/10] [Batch 45/274] [Batch classify loss: 2.372801] 
[Epoch 9/10] [Batch 46/274] [Batch classify loss: 2.386762] 
[Epoch 9/10] [Batch 47/274] [Batch classify loss: 2.410515] 
[Epoch 9/10] [Batch 48/274] [Batch classify loss: 2.221975] 
[Epoch 9/10] [Batch 49/274] [Batch classify loss: 2.503686] 
[Epoch 9/10] [Batch 50/274] [Batch classify loss: 2.195431] 
[Epoch 9/10] [Batch 51/274] [Batch classify loss: 2.640683] 
[Epoch 9/10] [Batch 52/274] [Batch classify loss: 2.601336] 
[Epoch 9/10] [Batch 53/274] [Batch classify loss: 2.556601] 
[Epoch 9/10] [Batch 54/274] [Batch classify loss: 2.658519] 
[Epoch 9/10] [Batch 55/274] [Batch classify loss: 2.646594] 
[Epoch 9/10] [Batch 56/274] [Batch classify loss: 2.620962] 
[Epoch 9/10] [Batch 57/274] [Batch classify loss: 2.556324] 
[Epoch 9/10] [Batch 58/274] [Batch classify loss: 2.410428] 
[Epoch 9/10] [Batch 59/274] [Batch classify loss: 2.544919] 
[Epoch 9/10] [Batch 60/274] [Batch classify loss: 2.518386] 
[Epoch 9/10] [Batch 61/274] [Batch classify loss: 2.895515] 
[Epoch 9/10] [Batch 62/274] [Batch classify loss: 2.741825] 
[Epoch 9/10] [Batch 63/274] [Batch classify loss: 2.463704] 
[Epoch 9/10] [Batch 64/274] [Batch classify loss: 2.271550] 
[Epoch 9/10] [Batch 65/274] [Batch classify loss: 2.488088] 
[Epoch 9/10] [Batch 66/274] [Batch classify loss: 2.645136] 
[Epoch 9/10] [Batch 67/274] [Batch classify loss: 2.715624] 
[Epoch 9/10] [Batch 68/274] [Batch classify loss: 2.592575] 
[Epoch 9/10] [Batch 69/274] [Batch classify loss: 2.963485] 
[Epoch 9/10] [Batch 70/274] [Batch classify loss: 2.692925] 
[Epoch 9/10] [Batch 71/274] [Batch classify loss: 2.529785] 
[Epoch 9/10] [Batch 72/274] [Batch classify loss: 2.659760] 
[Epoch 9/10] [Batch 73/274] [Batch classify loss: 2.394434] 
[Epoch 9/10] [Batch 74/274] [Batch classify loss: 2.509251] 
[Epoch 9/10] [Batch 75/274] [Batch classify loss: 2.564059] 
[Epoch 9/10] [Batch 76/274] [Batch classify loss: 2.821625] 
[Epoch 9/10] [Batch 77/274] [Batch classify loss: 2.664374] 
[Epoch 9/10] [Batch 78/274] [Batch classify loss: 3.044857] 
[Epoch 9/10] [Batch 79/274] [Batch classify loss: 2.585777] 
[Epoch 9/10] [Batch 80/274] [Batch classify loss: 2.673603] 
[Epoch 9/10] [Batch 81/274] [Batch classify loss: 2.646439] 
[Epoch 9/10] [Batch 82/274] [Batch classify loss: 2.849485] 
[Epoch 9/10] [Batch 83/274] [Batch classify loss: 2.369322] 
[Epoch 9/10] [Batch 84/274] [Batch classify loss: 2.639499] 
[Epoch 9/10] [Batch 85/274] [Batch classify loss: 2.364639] 
[Epoch 9/10] [Batch 86/274] [Batch classify loss: 2.485226] 
[Epoch 9/10] [Batch 87/274] [Batch classify loss: 2.911120] 
[Epoch 9/10] [Batch 88/274] [Batch classify loss: 3.022283] 
[Epoch 9/10] [Batch 89/274] [Batch classify loss: 2.704140] 
[Epoch 9/10] [Batch 90/274] [Batch classify loss: 2.659634] 
[Epoch 9/10] [Batch 91/274] [Batch classify loss: 2.764610] 
[Epoch 9/10] [Batch 92/274] [Batch classify loss: 2.922265] 
[Epoch 9/10] [Batch 93/274] [Batch classify loss: 2.784119] 
[Epoch 9/10] [Batch 94/274] [Batch classify loss: 2.582915] 
[Epoch 9/10] [Batch 95/274] [Batch classify loss: 2.657844] 
[Epoch 9/10] [Batch 96/274] [Batch classify loss: 2.629004] 
[Epoch 9/10] [Batch 97/274] [Batch classify loss: 3.060244] 
[Epoch 9/10] [Batch 98/274] [Batch classify loss: 3.078578] 
[Epoch 9/10] [Batch 99/274] [Batch classify loss: 3.010059] 
[Epoch 9/10] [Batch 100/274] [Batch classify loss: 3.044271] 
[Epoch 9/10] [Batch 101/274] [Batch classify loss: 2.861847] 
[Epoch 9/10] [Batch 102/274] [Batch classify loss: 2.538787] 
[Epoch 9/10] [Batch 103/274] [Batch classify loss: 2.795732] 
[Epoch 9/10] [Batch 104/274] [Batch classify loss: 2.721815] 
[Epoch 9/10] [Batch 105/274] [Batch classify loss: 3.007455] 
[Epoch 9/10] [Batch 106/274] [Batch classify loss: 2.811593] 
[Epoch 9/10] [Batch 107/274] [Batch classify loss: 2.945286] 
[Epoch 9/10] [Batch 108/274] [Batch classify loss: 2.888644] 
[Epoch 9/10] [Batch 109/274] [Batch classify loss: 2.693654] 
[Epoch 9/10] [Batch 110/274] [Batch classify loss: 2.860744] 
[Epoch 9/10] [Batch 111/274] [Batch classify loss: 2.968192] 
[Epoch 9/10] [Batch 112/274] [Batch classify loss: 2.820992] 
[Epoch 9/10] [Batch 113/274] [Batch classify loss: 2.850024] 
[Epoch 9/10] [Batch 114/274] [Batch classify loss: 2.921043] 
[Epoch 9/10] [Batch 115/274] [Batch classify loss: 3.010749] 
[Epoch 9/10] [Batch 116/274] [Batch classify loss: 2.825031] 
[Epoch 9/10] [Batch 117/274] [Batch classify loss: 2.666759] 
[Epoch 9/10] [Batch 118/274] [Batch classify loss: 2.751892] 
[Epoch 9/10] [Batch 119/274] [Batch classify loss: 3.083246] 
[Epoch 9/10] [Batch 120/274] [Batch classify loss: 2.870666] 
[Epoch 9/10] [Batch 121/274] [Batch classify loss: 3.027743] 
[Epoch 9/10] [Batch 122/274] [Batch classify loss: 2.824746] 
[Epoch 9/10] [Batch 123/274] [Batch classify loss: 2.724900] 
[Epoch 9/10] [Batch 124/274] [Batch classify loss: 2.977668] 
[Epoch 9/10] [Batch 125/274] [Batch classify loss: 3.299201] 
[Epoch 9/10] [Batch 126/274] [Batch classify loss: 2.584585] 
[Epoch 9/10] [Batch 127/274] [Batch classify loss: 2.427181] 
[Epoch 9/10] [Batch 128/274] [Batch classify loss: 2.753891] 
[Epoch 9/10] [Batch 129/274] [Batch classify loss: 3.008549] 
[Epoch 9/10] [Batch 130/274] [Batch classify loss: 3.122606] 
[Epoch 9/10] [Batch 131/274] [Batch classify loss: 3.085432] 
[Epoch 9/10] [Batch 132/274] [Batch classify loss: 2.794161] 
[Epoch 9/10] [Batch 133/274] [Batch classify loss: 2.806002] 
[Epoch 9/10] [Batch 134/274] [Batch classify loss: 3.149270] 
[Epoch 9/10] [Batch 135/274] [Batch classify loss: 2.656076] 
[Epoch 9/10] [Batch 136/274] [Batch classify loss: 2.929832] 
[Epoch 9/10] [Batch 137/274] [Batch classify loss: 3.042381] 
[Epoch 9/10] [Batch 138/274] [Batch classify loss: 3.215086] 
[Epoch 9/10] [Batch 139/274] [Batch classify loss: 3.302517] 
[Epoch 9/10] [Batch 140/274] [Batch classify loss: 2.974553] 
[Epoch 9/10] [Batch 141/274] [Batch classify loss: 3.123707] 
[Epoch 9/10] [Batch 142/274] [Batch classify loss: 2.843626] 
[Epoch 9/10] [Batch 143/274] [Batch classify loss: 2.982284] 
[Epoch 9/10] [Batch 144/274] [Batch classify loss: 2.823175] 
[Epoch 9/10] [Batch 145/274] [Batch classify loss: 3.021455] 
[Epoch 9/10] [Batch 146/274] [Batch classify loss: 3.074536] 
[Epoch 9/10] [Batch 147/274] [Batch classify loss: 2.902780] 
[Epoch 9/10] [Batch 148/274] [Batch classify loss: 2.637659] 
[Epoch 9/10] [Batch 149/274] [Batch classify loss: 2.730150] 
[Epoch 9/10] [Batch 150/274] [Batch classify loss: 3.466381] 
[Epoch 9/10] [Batch 151/274] [Batch classify loss: 2.862802] 
[Epoch 9/10] [Batch 152/274] [Batch classify loss: 3.105190] 
[Epoch 9/10] [Batch 153/274] [Batch classify loss: 2.961642] 
[Epoch 9/10] [Batch 154/274] [Batch classify loss: 2.978732] 
[Epoch 9/10] [Batch 155/274] [Batch classify loss: 3.013433] 
[Epoch 9/10] [Batch 156/274] [Batch classify loss: 2.753036] 
[Epoch 9/10] [Batch 157/274] [Batch classify loss: 2.929860] 
[Epoch 9/10] [Batch 158/274] [Batch classify loss: 2.930264] 
[Epoch 9/10] [Batch 159/274] [Batch classify loss: 3.301190] 
[Epoch 9/10] [Batch 160/274] [Batch classify loss: 3.194322] 
[Epoch 9/10] [Batch 161/274] [Batch classify loss: 3.195245] 
[Epoch 9/10] [Batch 162/274] [Batch classify loss: 3.185282] 
[Epoch 9/10] [Batch 163/274] [Batch classify loss: 3.049809] 
[Epoch 9/10] [Batch 164/274] [Batch classify loss: 3.336804] 
[Epoch 9/10] [Batch 165/274] [Batch classify loss: 3.089578] 
[Epoch 9/10] [Batch 166/274] [Batch classify loss: 2.902255] 
[Epoch 9/10] [Batch 167/274] [Batch classify loss: 3.038101] 
[Epoch 9/10] [Batch 168/274] [Batch classify loss: 2.924446] 
[Epoch 9/10] [Batch 169/274] [Batch classify loss: 3.027389] 
[Epoch 9/10] [Batch 170/274] [Batch classify loss: 3.011631] 
[Epoch 9/10] [Batch 171/274] [Batch classify loss: 3.237931] 
[Epoch 9/10] [Batch 172/274] [Batch classify loss: 3.073508] 
[Epoch 9/10] [Batch 173/274] [Batch classify loss: 3.254726] 
[Epoch 9/10] [Batch 174/274] [Batch classify loss: 3.033167] 
[Epoch 9/10] [Batch 175/274] [Batch classify loss: 3.030853] 
[Epoch 9/10] [Batch 176/274] [Batch classify loss: 3.197381] 
[Epoch 9/10] [Batch 177/274] [Batch classify loss: 3.017708] 
[Epoch 9/10] [Batch 178/274] [Batch classify loss: 3.260164] 
[Epoch 9/10] [Batch 179/274] [Batch classify loss: 3.129258] 
[Epoch 9/10] [Batch 180/274] [Batch classify loss: 2.858559] 
[Epoch 9/10] [Batch 181/274] [Batch classify loss: 2.799803] 
[Epoch 9/10] [Batch 182/274] [Batch classify loss: 3.245437] 
[Epoch 9/10] [Batch 183/274] [Batch classify loss: 3.202676] 
[Epoch 9/10] [Batch 184/274] [Batch classify loss: 3.320643] 
[Epoch 9/10] [Batch 185/274] [Batch classify loss: 3.002516] 
[Epoch 9/10] [Batch 186/274] [Batch classify loss: 3.039864] 
[Epoch 9/10] [Batch 187/274] [Batch classify loss: 3.056761] 
[Epoch 9/10] [Batch 188/274] [Batch classify loss: 3.179082] 
[Epoch 9/10] [Batch 189/274] [Batch classify loss: 2.903119] 
[Epoch 9/10] [Batch 190/274] [Batch classify loss: 3.340012] 
[Epoch 9/10] [Batch 191/274] [Batch classify loss: 2.938181] 
[Epoch 9/10] [Batch 192/274] [Batch classify loss: 3.017276] 
[Epoch 9/10] [Batch 193/274] [Batch classify loss: 3.379469] 
[Epoch 9/10] [Batch 194/274] [Batch classify loss: 3.261685] 
[Epoch 9/10] [Batch 195/274] [Batch classify loss: 3.614128] 
[Epoch 9/10] [Batch 196/274] [Batch classify loss: 2.904995] 
[Epoch 9/10] [Batch 197/274] [Batch classify loss: 3.195358] 
[Epoch 9/10] [Batch 198/274] [Batch classify loss: 3.104350] 
[Epoch 9/10] [Batch 199/274] [Batch classify loss: 3.372734] 
[Epoch 9/10] [Batch 200/274] [Batch classify loss: 3.269786] 
[Epoch 9/10] [Batch 201/274] [Batch classify loss: 2.942601] 
[Epoch 9/10] [Batch 202/274] [Batch classify loss: 2.998424] 
[Epoch 9/10] [Batch 203/274] [Batch classify loss: 3.403167] 
[Epoch 9/10] [Batch 204/274] [Batch classify loss: 3.326827] 
[Epoch 9/10] [Batch 205/274] [Batch classify loss: 2.911056] 
[Epoch 9/10] [Batch 206/274] [Batch classify loss: 2.844401] 
[Epoch 9/10] [Batch 207/274] [Batch classify loss: 3.012021] 
[Epoch 9/10] [Batch 208/274] [Batch classify loss: 3.362981] 
[Epoch 9/10] [Batch 209/274] [Batch classify loss: 3.060006] 
[Epoch 9/10] [Batch 210/274] [Batch classify loss: 3.238534] 
[Epoch 9/10] [Batch 211/274] [Batch classify loss: 2.984103] 
[Epoch 9/10] [Batch 212/274] [Batch classify loss: 2.970501] 
[Epoch 9/10] [Batch 213/274] [Batch classify loss: 3.261555] 
[Epoch 9/10] [Batch 214/274] [Batch classify loss: 3.374261] 
[Epoch 9/10] [Batch 215/274] [Batch classify loss: 3.202464] 
[Epoch 9/10] [Batch 216/274] [Batch classify loss: 3.170284] 
[Epoch 9/10] [Batch 217/274] [Batch classify loss: 2.984222] 
[Epoch 9/10] [Batch 218/274] [Batch classify loss: 3.514632] 
[Epoch 9/10] [Batch 219/274] [Batch classify loss: 3.081425] 
[Epoch 9/10] [Batch 220/274] [Batch classify loss: 3.225936] 
[Epoch 9/10] [Batch 221/274] [Batch classify loss: 3.437117] 
[Epoch 9/10] [Batch 222/274] [Batch classify loss: 3.248002] 
[Epoch 9/10] [Batch 223/274] [Batch classify loss: 3.018072] 
[Epoch 9/10] [Batch 224/274] [Batch classify loss: 3.267194] 
[Epoch 9/10] [Batch 225/274] [Batch classify loss: 2.945658] 
[Epoch 9/10] [Batch 226/274] [Batch classify loss: 3.342235] 
[Epoch 9/10] [Batch 227/274] [Batch classify loss: 3.290892] 
[Epoch 9/10] [Batch 228/274] [Batch classify loss: 3.328356] 
[Epoch 9/10] [Batch 229/274] [Batch classify loss: 2.978939] 
[Epoch 9/10] [Batch 230/274] [Batch classify loss: 2.992617] 
[Epoch 9/10] [Batch 231/274] [Batch classify loss: 3.160336] 
[Epoch 9/10] [Batch 232/274] [Batch classify loss: 3.119263] 
[Epoch 9/10] [Batch 233/274] [Batch classify loss: 3.263401] 
[Epoch 9/10] [Batch 234/274] [Batch classify loss: 2.925112] 
[Epoch 9/10] [Batch 235/274] [Batch classify loss: 3.452881] 
[Epoch 9/10] [Batch 236/274] [Batch classify loss: 3.236703] 
[Epoch 9/10] [Batch 237/274] [Batch classify loss: 3.012846] 
[Epoch 9/10] [Batch 238/274] [Batch classify loss: 3.127285] 
[Epoch 9/10] [Batch 239/274] [Batch classify loss: 3.203123] 
[Epoch 9/10] [Batch 240/274] [Batch classify loss: 2.834713] 
[Epoch 9/10] [Batch 241/274] [Batch classify loss: 3.386267] 
[Epoch 9/10] [Batch 242/274] [Batch classify loss: 3.327342] 
[Epoch 9/10] [Batch 243/274] [Batch classify loss: 3.239403] 
[Epoch 9/10] [Batch 244/274] [Batch classify loss: 3.277916] 
[Epoch 9/10] [Batch 245/274] [Batch classify loss: 2.843601] 
[Epoch 9/10] [Batch 246/274] [Batch classify loss: 3.369638] 
[Epoch 9/10] [Batch 247/274] [Batch classify loss: 3.327777] 
[Epoch 9/10] [Batch 248/274] [Batch classify loss: 3.431527] 
[Epoch 9/10] [Batch 249/274] [Batch classify loss: 3.026642] 
[Epoch 9/10] [Batch 250/274] [Batch classify loss: 3.409121] 
[Epoch 9/10] [Batch 251/274] [Batch classify loss: 3.758490] 
[Epoch 9/10] [Batch 252/274] [Batch classify loss: 3.233640] 
[Epoch 9/10] [Batch 253/274] [Batch classify loss: 2.766803] 
[Epoch 9/10] [Batch 254/274] [Batch classify loss: 2.830228] 
[Epoch 9/10] [Batch 255/274] [Batch classify loss: 2.912189] 
[Epoch 9/10] [Batch 256/274] [Batch classify loss: 3.807946] 
[Epoch 9/10] [Batch 257/274] [Batch classify loss: 3.185426] 
[Epoch 9/10] [Batch 258/274] [Batch classify loss: 3.357539] 
[Epoch 9/10] [Batch 259/274] [Batch classify loss: 3.226310] 
[Epoch 9/10] [Batch 260/274] [Batch classify loss: 2.950404] 
[Epoch 9/10] [Batch 261/274] [Batch classify loss: 3.088610] 
[Epoch 9/10] [Batch 262/274] [Batch classify loss: 3.349788] 
[Epoch 9/10] [Batch 263/274] [Batch classify loss: 3.315613] 
[Epoch 9/10] [Batch 264/274] [Batch classify loss: 3.176537] 
[Epoch 9/10] [Batch 265/274] [Batch classify loss: 3.143981] 
[Epoch 9/10] [Batch 266/274] [Batch classify loss: 3.559986] 
[Epoch 9/10] [Batch 267/274] [Batch classify loss: 3.532935] 
[Epoch 9/10] [Batch 268/274] [Batch classify loss: 3.207298] 
[Epoch 9/10] [Batch 269/274] [Batch classify loss: 3.301651] 
[Epoch 9/10] [Batch 270/274] [Batch classify loss: 3.134704] 
[Epoch 9/10] [Batch 271/274] [Batch classify loss: 2.929038] 
[Epoch 9/10] [Batch 272/274] [Batch classify loss: 3.499172] 
[Epoch 9/10] [Batch 273/274] [Batch classify loss: 3.188008] 
[Epoch 9/10] [Batch 274/274] [Batch classify loss: 4.099288] 
0009 epoch mmat trained classifier accuary on the clean testing examples:94.7526%
0009 epoch mmat trained classifier loss on the clean testing examples:0.2216
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3388%
mmat trained classifier loss on adversarial testset:4.524186134338379
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-cle
9epoch learning rate:0.01
[Epoch 10/10] [Batch 1/274] [Batch classify loss: 2.607702] 
[Epoch 10/10] [Batch 2/274] [Batch classify loss: 2.133944] 
[Epoch 10/10] [Batch 3/274] [Batch classify loss: 1.556295] 
[Epoch 10/10] [Batch 4/274] [Batch classify loss: 1.391417] 
[Epoch 10/10] [Batch 5/274] [Batch classify loss: 1.282730] 
[Epoch 10/10] [Batch 6/274] [Batch classify loss: 1.202993] 
[Epoch 10/10] [Batch 7/274] [Batch classify loss: 1.242488] 
[Epoch 10/10] [Batch 8/274] [Batch classify loss: 1.319618] 
[Epoch 10/10] [Batch 9/274] [Batch classify loss: 1.567244] 
[Epoch 10/10] [Batch 10/274] [Batch classify loss: 1.454040] 
[Epoch 10/10] [Batch 11/274] [Batch classify loss: 1.510868] 
[Epoch 10/10] [Batch 12/274] [Batch classify loss: 1.663744] 
[Epoch 10/10] [Batch 13/274] [Batch classify loss: 1.372037] 
[Epoch 10/10] [Batch 14/274] [Batch classify loss: 1.550352] 
[Epoch 10/10] [Batch 15/274] [Batch classify loss: 1.614998] 
[Epoch 10/10] [Batch 16/274] [Batch classify loss: 1.457451] 
[Epoch 10/10] [Batch 17/274] [Batch classify loss: 1.649717] 
[Epoch 10/10] [Batch 18/274] [Batch classify loss: 1.671900] 
[Epoch 10/10] [Batch 19/274] [Batch classify loss: 1.684080] 
[Epoch 10/10] [Batch 20/274] [Batch classify loss: 1.689066] 
[Epoch 10/10] [Batch 21/274] [Batch classify loss: 1.658870] 
[Epoch 10/10] [Batch 22/274] [Batch classify loss: 1.601399] 
[Epoch 10/10] [Batch 23/274] [Batch classify loss: 2.136772] 
[Epoch 10/10] [Batch 24/274] [Batch classify loss: 1.791470] 
[Epoch 10/10] [Batch 25/274] [Batch classify loss: 1.720141] 
[Epoch 10/10] [Batch 26/274] [Batch classify loss: 1.709718] 
[Epoch 10/10] [Batch 27/274] [Batch classify loss: 2.030014] 
[Epoch 10/10] [Batch 28/274] [Batch classify loss: 1.469285] 
[Epoch 10/10] [Batch 29/274] [Batch classify loss: 2.018763] 
[Epoch 10/10] [Batch 30/274] [Batch classify loss: 1.823522] 
[Epoch 10/10] [Batch 31/274] [Batch classify loss: 1.831892] 
[Epoch 10/10] [Batch 32/274] [Batch classify loss: 1.754852] 
[Epoch 10/10] [Batch 33/274] [Batch classify loss: 1.984413] 
[Epoch 10/10] [Batch 34/274] [Batch classify loss: 1.724818] 
[Epoch 10/10] [Batch 35/274] [Batch classify loss: 1.594079] 
[Epoch 10/10] [Batch 36/274] [Batch classify loss: 2.330095] 
[Epoch 10/10] [Batch 37/274] [Batch classify loss: 1.907087] 
[Epoch 10/10] [Batch 38/274] [Batch classify loss: 1.977327] 
[Epoch 10/10] [Batch 39/274] [Batch classify loss: 1.996224] 
[Epoch 10/10] [Batch 40/274] [Batch classify loss: 2.022168] 
[Epoch 10/10] [Batch 41/274] [Batch classify loss: 1.824793] 
[Epoch 10/10] [Batch 42/274] [Batch classify loss: 2.023403] 
[Epoch 10/10] [Batch 43/274] [Batch classify loss: 1.634226] 
[Epoch 10/10] [Batch 44/274] [Batch classify loss: 1.685058] 
[Epoch 10/10] [Batch 45/274] [Batch classify loss: 2.046284] 
[Epoch 10/10] [Batch 46/274] [Batch classify loss: 2.049379] 
[Epoch 10/10] [Batch 47/274] [Batch classify loss: 2.206108] 
[Epoch 10/10] [Batch 48/274] [Batch classify loss: 1.922742] 
[Epoch 10/10] [Batch 49/274] [Batch classify loss: 2.238341] 
[Epoch 10/10] [Batch 50/274] [Batch classify loss: 2.220363] 
[Epoch 10/10] [Batch 51/274] [Batch classify loss: 1.901731] 
[Epoch 10/10] [Batch 52/274] [Batch classify loss: 1.905768] 
[Epoch 10/10] [Batch 53/274] [Batch classify loss: 2.183087] 
[Epoch 10/10] [Batch 54/274] [Batch classify loss: 1.927614] 
[Epoch 10/10] [Batch 55/274] [Batch classify loss: 2.058801] 
[Epoch 10/10] [Batch 56/274] [Batch classify loss: 2.407390] 
[Epoch 10/10] [Batch 57/274] [Batch classify loss: 2.096470] 
[Epoch 10/10] [Batch 58/274] [Batch classify loss: 2.054315] 
[Epoch 10/10] [Batch 59/274] [Batch classify loss: 2.447833] 
[Epoch 10/10] [Batch 60/274] [Batch classify loss: 2.137404] 
[Epoch 10/10] [Batch 61/274] [Batch classify loss: 2.147897] 
[Epoch 10/10] [Batch 62/274] [Batch classify loss: 2.158304] 
[Epoch 10/10] [Batch 63/274] [Batch classify loss: 2.211888] 
[Epoch 10/10] [Batch 64/274] [Batch classify loss: 1.904694] 
[Epoch 10/10] [Batch 65/274] [Batch classify loss: 2.185438] 
[Epoch 10/10] [Batch 66/274] [Batch classify loss: 2.161644] 
[Epoch 10/10] [Batch 67/274] [Batch classify loss: 2.200517] 
[Epoch 10/10] [Batch 68/274] [Batch classify loss: 1.966241] 
[Epoch 10/10] [Batch 69/274] [Batch classify loss: 2.073366] 
[Epoch 10/10] [Batch 70/274] [Batch classify loss: 1.883073] 
[Epoch 10/10] [Batch 71/274] [Batch classify loss: 2.375553] 
[Epoch 10/10] [Batch 72/274] [Batch classify loss: 2.359762] 
[Epoch 10/10] [Batch 73/274] [Batch classify loss: 2.125265] 
[Epoch 10/10] [Batch 74/274] [Batch classify loss: 2.432205] 
[Epoch 10/10] [Batch 75/274] [Batch classify loss: 2.531409] 
[Epoch 10/10] [Batch 76/274] [Batch classify loss: 2.080902] 
[Epoch 10/10] [Batch 77/274] [Batch classify loss: 2.210155] 
[Epoch 10/10] [Batch 78/274] [Batch classify loss: 2.047233] 
[Epoch 10/10] [Batch 79/274] [Batch classify loss: 1.954638] 
[Epoch 10/10] [Batch 80/274] [Batch classify loss: 2.298793] 
[Epoch 10/10] [Batch 81/274] [Batch classify loss: 2.157515] 
[Epoch 10/10] [Batch 82/274] [Batch classify loss: 2.500075] 
[Epoch 10/10] [Batch 83/274] [Batch classify loss: 2.089206] 
[Epoch 10/10] [Batch 84/274] [Batch classify loss: 2.376105] 
[Epoch 10/10] [Batch 85/274] [Batch classify loss: 2.449492] 
[Epoch 10/10] [Batch 86/274] [Batch classify loss: 2.294286] 
[Epoch 10/10] [Batch 87/274] [Batch classify loss: 2.131856] 
[Epoch 10/10] [Batch 88/274] [Batch classify loss: 2.189460] 
[Epoch 10/10] [Batch 89/274] [Batch classify loss: 2.408854] 
[Epoch 10/10] [Batch 90/274] [Batch classify loss: 2.313979] 
[Epoch 10/10] [Batch 91/274] [Batch classify loss: 2.441544] 
[Epoch 10/10] [Batch 92/274] [Batch classify loss: 2.197164] 
[Epoch 10/10] [Batch 93/274] [Batch classify loss: 2.206671] 
[Epoch 10/10] [Batch 94/274] [Batch classify loss: 2.424845] 
[Epoch 10/10] [Batch 95/274] [Batch classify loss: 2.764174] 
[Epoch 10/10] [Batch 96/274] [Batch classify loss: 2.169713] 
[Epoch 10/10] [Batch 97/274] [Batch classify loss: 2.530256] 
[Epoch 10/10] [Batch 98/274] [Batch classify loss: 2.246616] 
[Epoch 10/10] [Batch 99/274] [Batch classify loss: 2.361534] 
[Epoch 10/10] [Batch 100/274] [Batch classify loss: 2.292360] 
[Epoch 10/10] [Batch 101/274] [Batch classify loss: 2.563344] 
[Epoch 10/10] [Batch 102/274] [Batch classify loss: 2.568097] 
[Epoch 10/10] [Batch 103/274] [Batch classify loss: 2.397613] 
[Epoch 10/10] [Batch 104/274] [Batch classify loss: 2.246902] 
[Epoch 10/10] [Batch 105/274] [Batch classify loss: 2.369373] 
[Epoch 10/10] [Batch 106/274] [Batch classify loss: 2.469741] 
[Epoch 10/10] [Batch 107/274] [Batch classify loss: 2.687248] 
[Epoch 10/10] [Batch 108/274] [Batch classify loss: 2.281491] 
[Epoch 10/10] [Batch 109/274] [Batch classify loss: 2.462093] 
[Epoch 10/10] [Batch 110/274] [Batch classify loss: 2.367717] 
[Epoch 10/10] [Batch 111/274] [Batch classify loss: 2.223395] 
[Epoch 10/10] [Batch 112/274] [Batch classify loss: 2.434597] 
[Epoch 10/10] [Batch 113/274] [Batch classify loss: 2.360561] 
[Epoch 10/10] [Batch 114/274] [Batch classify loss: 2.592711] 
[Epoch 10/10] [Batch 115/274] [Batch classify loss: 2.578157] 
[Epoch 10/10] [Batch 116/274] [Batch classify loss: 2.588053] 
[Epoch 10/10] [Batch 117/274] [Batch classify loss: 2.491760] 
[Epoch 10/10] [Batch 118/274] [Batch classify loss: 2.428963] 
[Epoch 10/10] [Batch 119/274] [Batch classify loss: 2.461912] 
[Epoch 10/10] [Batch 120/274] [Batch classify loss: 2.283922] 
[Epoch 10/10] [Batch 121/274] [Batch classify loss: 2.444779] 
[Epoch 10/10] [Batch 122/274] [Batch classify loss: 2.782290] 
[Epoch 10/10] [Batch 123/274] [Batch classify loss: 2.432981] 
[Epoch 10/10] [Batch 124/274] [Batch classify loss: 2.671620] 
[Epoch 10/10] [Batch 125/274] [Batch classify loss: 2.144740] 
[Epoch 10/10] [Batch 126/274] [Batch classify loss: 2.719169] 
[Epoch 10/10] [Batch 127/274] [Batch classify loss: 2.363078] 
[Epoch 10/10] [Batch 128/274] [Batch classify loss: 2.356348] 
[Epoch 10/10] [Batch 129/274] [Batch classify loss: 2.150404] 
[Epoch 10/10] [Batch 130/274] [Batch classify loss: 2.578136] 
[Epoch 10/10] [Batch 131/274] [Batch classify loss: 2.567062] 
[Epoch 10/10] [Batch 132/274] [Batch classify loss: 2.521619] 
[Epoch 10/10] [Batch 133/274] [Batch classify loss: 2.592751] 
[Epoch 10/10] [Batch 134/274] [Batch classify loss: 2.567852] 
[Epoch 10/10] [Batch 135/274] [Batch classify loss: 2.426341] 
[Epoch 10/10] [Batch 136/274] [Batch classify loss: 2.470577] 
[Epoch 10/10] [Batch 137/274] [Batch classify loss: 2.595591] 
[Epoch 10/10] [Batch 138/274] [Batch classify loss: 2.514151] 
[Epoch 10/10] [Batch 139/274] [Batch classify loss: 2.455732] 
[Epoch 10/10] [Batch 140/274] [Batch classify loss: 2.912890] 
[Epoch 10/10] [Batch 141/274] [Batch classify loss: 2.334131] 
[Epoch 10/10] [Batch 142/274] [Batch classify loss: 2.510364] 
[Epoch 10/10] [Batch 143/274] [Batch classify loss: 2.379309] 
[Epoch 10/10] [Batch 144/274] [Batch classify loss: 2.677518] 
[Epoch 10/10] [Batch 145/274] [Batch classify loss: 2.661670] 
[Epoch 10/10] [Batch 146/274] [Batch classify loss: 2.442173] 
[Epoch 10/10] [Batch 147/274] [Batch classify loss: 2.366230] 
[Epoch 10/10] [Batch 148/274] [Batch classify loss: 2.551627] 
[Epoch 10/10] [Batch 149/274] [Batch classify loss: 2.441257] 
[Epoch 10/10] [Batch 150/274] [Batch classify loss: 2.671015] 
[Epoch 10/10] [Batch 151/274] [Batch classify loss: 2.447018] 
[Epoch 10/10] [Batch 152/274] [Batch classify loss: 2.578912] 
[Epoch 10/10] [Batch 153/274] [Batch classify loss: 2.122911] 
[Epoch 10/10] [Batch 154/274] [Batch classify loss: 2.409306] 
[Epoch 10/10] [Batch 155/274] [Batch classify loss: 2.471473] 
[Epoch 10/10] [Batch 156/274] [Batch classify loss: 2.769995] 
[Epoch 10/10] [Batch 157/274] [Batch classify loss: 2.515100] 
[Epoch 10/10] [Batch 158/274] [Batch classify loss: 2.545543] 
[Epoch 10/10] [Batch 159/274] [Batch classify loss: 2.592707] 
[Epoch 10/10] [Batch 160/274] [Batch classify loss: 2.605362] 
[Epoch 10/10] [Batch 161/274] [Batch classify loss: 2.427650] 
[Epoch 10/10] [Batch 162/274] [Batch classify loss: 2.687613] 
[Epoch 10/10] [Batch 163/274] [Batch classify loss: 2.809030] 
[Epoch 10/10] [Batch 164/274] [Batch classify loss: 2.656130] 
[Epoch 10/10] [Batch 165/274] [Batch classify loss: 2.492686] 
[Epoch 10/10] [Batch 166/274] [Batch classify loss: 2.663954] 
[Epoch 10/10] [Batch 167/274] [Batch classify loss: 2.526471] 
[Epoch 10/10] [Batch 168/274] [Batch classify loss: 2.626534] 
[Epoch 10/10] [Batch 169/274] [Batch classify loss: 2.468644] 
[Epoch 10/10] [Batch 170/274] [Batch classify loss: 2.872949] 
[Epoch 10/10] [Batch 171/274] [Batch classify loss: 2.542765] 
[Epoch 10/10] [Batch 172/274] [Batch classify loss: 2.412104] 
[Epoch 10/10] [Batch 173/274] [Batch classify loss: 2.390049] 
[Epoch 10/10] [Batch 174/274] [Batch classify loss: 2.675230] 
[Epoch 10/10] [Batch 175/274] [Batch classify loss: 2.615390] 
[Epoch 10/10] [Batch 176/274] [Batch classify loss: 2.511116] 
[Epoch 10/10] [Batch 177/274] [Batch classify loss: 2.872420] 
[Epoch 10/10] [Batch 178/274] [Batch classify loss: 2.553440] 
[Epoch 10/10] [Batch 179/274] [Batch classify loss: 2.710722] 
[Epoch 10/10] [Batch 180/274] [Batch classify loss: 2.612553] 
[Epoch 10/10] [Batch 181/274] [Batch classify loss: 2.888167] 
[Epoch 10/10] [Batch 182/274] [Batch classify loss: 2.642360] 
[Epoch 10/10] [Batch 183/274] [Batch classify loss: 2.734680] 
[Epoch 10/10] [Batch 184/274] [Batch classify loss: 2.680775] 
[Epoch 10/10] [Batch 185/274] [Batch classify loss: 2.688660] 
[Epoch 10/10] [Batch 186/274] [Batch classify loss: 2.734076] 
[Epoch 10/10] [Batch 187/274] [Batch classify loss: 2.573808] 
[Epoch 10/10] [Batch 188/274] [Batch classify loss: 2.615716] 
[Epoch 10/10] [Batch 189/274] [Batch classify loss: 2.631457] 
[Epoch 10/10] [Batch 190/274] [Batch classify loss: 2.919884] 
[Epoch 10/10] [Batch 191/274] [Batch classify loss: 2.674998] 
[Epoch 10/10] [Batch 192/274] [Batch classify loss: 2.646345] 
[Epoch 10/10] [Batch 193/274] [Batch classify loss: 2.755957] 
[Epoch 10/10] [Batch 194/274] [Batch classify loss: 2.801587] 
[Epoch 10/10] [Batch 195/274] [Batch classify loss: 2.817762] 
[Epoch 10/10] [Batch 196/274] [Batch classify loss: 2.646269] 
[Epoch 10/10] [Batch 197/274] [Batch classify loss: 2.647278] 
[Epoch 10/10] [Batch 198/274] [Batch classify loss: 2.919661] 
[Epoch 10/10] [Batch 199/274] [Batch classify loss: 2.661992] 
[Epoch 10/10] [Batch 200/274] [Batch classify loss: 2.780800] 
[Epoch 10/10] [Batch 201/274] [Batch classify loss: 2.395054] 
[Epoch 10/10] [Batch 202/274] [Batch classify loss: 2.677483] 
[Epoch 10/10] [Batch 203/274] [Batch classify loss: 2.640079] 
[Epoch 10/10] [Batch 204/274] [Batch classify loss: 2.560762] 
[Epoch 10/10] [Batch 205/274] [Batch classify loss: 2.733066] 
[Epoch 10/10] [Batch 206/274] [Batch classify loss: 2.374441] 
[Epoch 10/10] [Batch 207/274] [Batch classify loss: 2.877162] 
[Epoch 10/10] [Batch 208/274] [Batch classify loss: 2.809265] 
[Epoch 10/10] [Batch 209/274] [Batch classify loss: 2.772667] 
[Epoch 10/10] [Batch 210/274] [Batch classify loss: 2.680988] 
[Epoch 10/10] [Batch 211/274] [Batch classify loss: 2.677770] 
[Epoch 10/10] [Batch 212/274] [Batch classify loss: 2.827258] 
[Epoch 10/10] [Batch 213/274] [Batch classify loss: 2.601044] 
[Epoch 10/10] [Batch 214/274] [Batch classify loss: 2.987394] 
[Epoch 10/10] [Batch 215/274] [Batch classify loss: 2.675166] 
[Epoch 10/10] [Batch 216/274] [Batch classify loss: 2.898113] 
[Epoch 10/10] [Batch 217/274] [Batch classify loss: 2.743589] 
[Epoch 10/10] [Batch 218/274] [Batch classify loss: 2.747992] 
[Epoch 10/10] [Batch 219/274] [Batch classify loss: 2.917670] 
[Epoch 10/10] [Batch 220/274] [Batch classify loss: 2.587645] 
[Epoch 10/10] [Batch 221/274] [Batch classify loss: 2.870542] 
[Epoch 10/10] [Batch 222/274] [Batch classify loss: 2.875655] 
[Epoch 10/10] [Batch 223/274] [Batch classify loss: 2.800327] 
[Epoch 10/10] [Batch 224/274] [Batch classify loss: 2.611690] 
[Epoch 10/10] [Batch 225/274] [Batch classify loss: 2.805540] 
[Epoch 10/10] [Batch 226/274] [Batch classify loss: 2.898640] 
[Epoch 10/10] [Batch 227/274] [Batch classify loss: 2.468475] 
[Epoch 10/10] [Batch 228/274] [Batch classify loss: 2.887532] 
[Epoch 10/10] [Batch 229/274] [Batch classify loss: 3.126063] 
[Epoch 10/10] [Batch 230/274] [Batch classify loss: 2.624102] 
[Epoch 10/10] [Batch 231/274] [Batch classify loss: 2.733582] 
[Epoch 10/10] [Batch 232/274] [Batch classify loss: 3.045308] 
[Epoch 10/10] [Batch 233/274] [Batch classify loss: 2.697690] 
[Epoch 10/10] [Batch 234/274] [Batch classify loss: 2.934533] 
[Epoch 10/10] [Batch 235/274] [Batch classify loss: 2.766526] 
[Epoch 10/10] [Batch 236/274] [Batch classify loss: 2.549241] 
[Epoch 10/10] [Batch 237/274] [Batch classify loss: 2.664922] 
[Epoch 10/10] [Batch 238/274] [Batch classify loss: 2.568615] 
[Epoch 10/10] [Batch 239/274] [Batch classify loss: 2.958605] 
[Epoch 10/10] [Batch 240/274] [Batch classify loss: 2.473370] 
[Epoch 10/10] [Batch 241/274] [Batch classify loss: 2.895699] 
[Epoch 10/10] [Batch 242/274] [Batch classify loss: 3.351671] 
[Epoch 10/10] [Batch 243/274] [Batch classify loss: 2.706610] 
[Epoch 10/10] [Batch 244/274] [Batch classify loss: 2.899496] 
[Epoch 10/10] [Batch 245/274] [Batch classify loss: 2.710497] 
[Epoch 10/10] [Batch 246/274] [Batch classify loss: 2.436231] 
[Epoch 10/10] [Batch 247/274] [Batch classify loss: 2.811566] 
[Epoch 10/10] [Batch 248/274] [Batch classify loss: 3.023423] 
[Epoch 10/10] [Batch 249/274] [Batch classify loss: 2.508567] 
[Epoch 10/10] [Batch 250/274] [Batch classify loss: 2.749549] 
[Epoch 10/10] [Batch 251/274] [Batch classify loss: 2.975698] 
[Epoch 10/10] [Batch 252/274] [Batch classify loss: 2.784188] 
[Epoch 10/10] [Batch 253/274] [Batch classify loss: 2.780718] 
[Epoch 10/10] [Batch 254/274] [Batch classify loss: 3.096240] 
[Epoch 10/10] [Batch 255/274] [Batch classify loss: 2.682550] 
[Epoch 10/10] [Batch 256/274] [Batch classify loss: 2.463322] 
[Epoch 10/10] [Batch 257/274] [Batch classify loss: 3.192550] 
[Epoch 10/10] [Batch 258/274] [Batch classify loss: 2.609797] 
[Epoch 10/10] [Batch 259/274] [Batch classify loss: 2.467553] 
[Epoch 10/10] [Batch 260/274] [Batch classify loss: 2.295300] 
[Epoch 10/10] [Batch 261/274] [Batch classify loss: 2.798868] 
[Epoch 10/10] [Batch 262/274] [Batch classify loss: 2.746077] 
[Epoch 10/10] [Batch 263/274] [Batch classify loss: 3.079255] 
[Epoch 10/10] [Batch 264/274] [Batch classify loss: 2.838837] 
[Epoch 10/10] [Batch 265/274] [Batch classify loss: 2.888475] 
[Epoch 10/10] [Batch 266/274] [Batch classify loss: 2.729050] 
[Epoch 10/10] [Batch 267/274] [Batch classify loss: 2.562017] 
[Epoch 10/10] [Batch 268/274] [Batch classify loss: 2.924499] 
[Epoch 10/10] [Batch 269/274] [Batch classify loss: 2.792413] 
[Epoch 10/10] [Batch 270/274] [Batch classify loss: 2.951835] 
[Epoch 10/10] [Batch 271/274] [Batch classify loss: 2.671898] 
[Epoch 10/10] [Batch 272/274] [Batch classify loss: 2.720711] 
[Epoch 10/10] [Batch 273/274] [Batch classify loss: 2.788604] 
[Epoch 10/10] [Batch 274/274] [Batch classify loss: 2.899647] 
0010 epoch mmat trained classifier accuary on the clean testing examples:94.7027%
0010 epoch mmat trained classifier loss on the clean testing examples:0.2241
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3273%
mmat trained classifier loss on adversarial testset:4.5303144454956055
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00003/mmat-svhn-dataset/tensorboard-log-run-acc-cle
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2428%
mmat trained classifier loss on adversarial testset:4.524815559387207
mmat trained classifier accuary on clean testset:94.7065%
mmat trained classifier loss on clean testset:0.2234598696231842
---------------------------------------




---------------------------------------
Torch cuda is available
args.subcommand=run, run the command line
date: 20210919
Experiment result save dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00004
initilize the dataset loading parameters
Using downloaded and verified file: /home/data/maggie/svhn/train_32x32.mat
Loading *svhn* train dataloader finished !
Loading *svhn* test dataloader finished !
initlize classifier
learned calssify model != None
standard trained classifier *accuary* on adversarial testset:40.0776%
standard trained classifier *accuary* on clean testset:94.7910%
gen_network_pkl:  abc test
load mixed sampels from /home/maggie/mmat/result/interpolate/2mixup/basemixup/uniformsampler/stylegan2ada-svhn/20210917/00000/generate-svhn-trainset
共使用 70000 个混合样本
*only using mixed samples*
aug_x_train.shape: (70000, 3, 32, 32)
aug_y_train.shape: (70000, 10)
use 0/70000 clean sampels，70000/70000 mixed samples
/home/maggie/mmat/clamodels/classifier.py:900: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._adv_test_tensorset_x = torch.tensor(x_test_adv)
/home/maggie/mmat/clamodels/classifier.py:901: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._adv_test_tensorset_y = torch.tensor(y_test_adv)
/home/maggie/mmat/clamodels/classifier.py:903: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._cle_test_tensorset_x = torch.tensor(cle_x_test)
/home/maggie/mmat/clamodels/classifier.py:904: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._cle_test_tensorset_y = torch.tensor(cle_y_test)
self._train_tensorset_x.shape: torch.Size([70000, 3, 32, 32])
self._train_tensorset_y.shape: torch.Size([70000, 10])
self._adv_test_tensorset_x.shape: torch.Size([26032, 3, 32, 32])
self._adv_test_tensorset_y.shape: torch.Size([26032])
self._cle_test_tensorset_x.shape: torch.Size([26032, 3, 32, 32])
self._cle_test_tensorset_y.shape: torch.Size([26032])
self._train_tensorset_x[0]: tensor([[[-0.0075,  0.0271,  0.0305,  ..., -0.0441, -0.0458, -0.0717],
         [ 0.0557,  0.0355,  0.0406,  ..., -0.0151, -0.0264, -0.0772],
         [ 0.1221,  0.0934,  0.0969,  ...,  0.0472,  0.0461, -0.0229],
         ...,
         [ 0.0156, -0.0060, -0.0448,  ..., -0.0956, -0.1227, -0.1329],
         [-0.0852, -0.1374, -0.1736,  ..., -0.1825, -0.1830, -0.2094],
         [-0.1741, -0.2049, -0.2446,  ..., -0.2400, -0.2482, -0.2949]],

        [[ 0.0772,  0.1244,  0.1331,  ...,  0.0673,  0.0505,  0.0121],
         [ 0.1521,  0.1531,  0.1650,  ...,  0.1218,  0.0919,  0.0155],
         [ 0.2234,  0.2156,  0.2287,  ...,  0.1865,  0.1654,  0.0698],
         ...,
         [ 0.1392,  0.1378,  0.1032,  ..., -0.0367, -0.0660, -0.0801],
         [ 0.0239, -0.0010, -0.0295,  ..., -0.0926, -0.1037, -0.1443],
         [-0.0757, -0.0941, -0.1315,  ..., -0.1456, -0.1622, -0.2304]],

        [[ 0.1706,  0.2183,  0.2229,  ...,  0.2041,  0.1978,  0.1615],
         [ 0.2560,  0.2428,  0.2411,  ...,  0.2378,  0.2253,  0.1708],
         [ 0.3259,  0.2957,  0.2959,  ...,  0.2836,  0.2796,  0.2072],
         ...,
         [ 0.2475,  0.2496,  0.2232,  ...,  0.1950,  0.1576,  0.1337],
         [ 0.1670,  0.1625,  0.1481,  ...,  0.1463,  0.1306,  0.0747],
         [ 0.0956,  0.1138,  0.0871,  ...,  0.0971,  0.0654, -0.0267]]])
self._train_tensorset_y[0]: tensor([0.0000, 0.0000, 0.9842, 0.0000, 0.0000, 0.0158, 0.0000, 0.0000, 0.0000,
        0.0000])
self._train_tensorset_x[10]: tensor([[[-0.6798, -0.6672, -0.6475,  ..., -0.5674, -0.5721, -0.5550],
         [-0.6812, -0.6659, -0.6327,  ..., -0.5496, -0.5593, -0.5817],
         [-0.6625, -0.6501, -0.6175,  ..., -0.5537, -0.5607, -0.5810],
         ...,
         [-0.6654, -0.6459, -0.6004,  ..., -0.5362, -0.5503, -0.5666],
         [-0.6558, -0.6394, -0.6058,  ..., -0.5442, -0.5544, -0.5705],
         [-0.6589, -0.6353, -0.6000,  ..., -0.5501, -0.5637, -0.5372]],

        [[-0.3763, -0.3348, -0.3267,  ..., -0.2567, -0.2533, -0.2654],
         [-0.3503, -0.3389, -0.3193,  ..., -0.2616, -0.2571, -0.2553],
         [-0.3444, -0.3364, -0.3142,  ..., -0.2675, -0.2609, -0.2560],
         ...,
         [-0.3408, -0.3437, -0.3115,  ..., -0.1899, -0.1945, -0.1991],
         [-0.3398, -0.3356, -0.3151,  ..., -0.1946, -0.1964, -0.2011],
         [-0.3748, -0.3243, -0.3007,  ..., -0.1896, -0.1958, -0.2077]],

        [[-0.5941, -0.5718, -0.5541,  ..., -0.4559, -0.4606, -0.4524],
         [-0.5876, -0.5649, -0.5345,  ..., -0.4458, -0.4545, -0.4601],
         [-0.5771, -0.5575, -0.5263,  ..., -0.4550, -0.4596, -0.4604],
         ...,
         [-0.5526, -0.5452, -0.5034,  ..., -0.4320, -0.4327, -0.4251],
         [-0.5503, -0.5396, -0.5078,  ..., -0.4361, -0.4338, -0.4241],
         [-0.5610, -0.5280, -0.4924,  ..., -0.4203, -0.4222, -0.3991]]])
self._train_tensorset_y[10]: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8651, 0.1349, 0.0000, 0.0000,
        0.0000])
Traceback (most recent call last):
  File "tasklauncher-20210919.py", line 197, in <module>
    target_classifier.mmat(args, cle_x_train, cle_y_train, x_train_mix, y_train_mix, cle_x_test, cle_y_test, x_test_adv, y_test_adv, exp_result_dir) 
  File "/home/maggie/mmat/clamodels/classifier.py", line 892, in mmat
    self.__softtrain__(aug_x_train, aug_y_train, cle_x_test, cle_y_test,  x_test_adv, y_test_adv, exp_result_dir)
  File "/home/maggie/mmat/clamodels/classifier.py", line 921, in __softtrain__
    global_train_acc, global_adv_test_acc, global_cle_test_acc, global_train_loss, global_adv_test_loss, global_cle_test_loss = self.__traintensorsetloop__()
  File "/home/maggie/mmat/clamodels/classifier.py", line 955, in __traintensorsetloop__
    raise error
TypeError: exceptions must derive from BaseException


---------------------------------------
Torch cuda is available
args.subcommand=run, run the command line
date: 20210919
Experiment result save dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005
initilize the dataset loading parameters
Using downloaded and verified file: /home/data/maggie/svhn/train_32x32.mat
Loading *svhn* train dataloader finished !
Loading *svhn* test dataloader finished !
initlize classifier
learned calssify model != None
standard trained classifier *accuary* on adversarial testset:40.2005%
standard trained classifier *accuary* on clean testset:94.7257%
gen_network_pkl:  abc test
load mixed sampels from /home/maggie/mmat/result/interpolate/2mixup/basemixup/uniformsampler/stylegan2ada-svhn/20210917/00000/generate-svhn-trainset
共使用 70000 个混合样本
*only using mixed samples*
aug_x_train.shape: (70000, 3, 32, 32)
aug_y_train.shape: (70000, 10)
use 0/70000 clean sampels，70000/70000 mixed samples
/home/maggie/mmat/clamodels/classifier.py:900: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._adv_test_tensorset_x = torch.tensor(x_test_adv)
/home/maggie/mmat/clamodels/classifier.py:901: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._adv_test_tensorset_y = torch.tensor(y_test_adv)
/home/maggie/mmat/clamodels/classifier.py:903: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._cle_test_tensorset_x = torch.tensor(cle_x_test)
/home/maggie/mmat/clamodels/classifier.py:904: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self._cle_test_tensorset_y = torch.tensor(cle_y_test)
self._train_tensorset_x.shape: torch.Size([70000, 3, 32, 32])
self._train_tensorset_y.shape: torch.Size([70000, 10])
self._adv_test_tensorset_x.shape: torch.Size([26032, 3, 32, 32])
self._adv_test_tensorset_y.shape: torch.Size([26032])
self._cle_test_tensorset_x.shape: torch.Size([26032, 3, 32, 32])
self._cle_test_tensorset_y.shape: torch.Size([26032])
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
before mmat trained classifier accuary on adversarial testset:40.2658%
before mmat trained classifier loss on adversarial testset:4.5234904289245605
0epoch learning rate:0.1
[Epoch 1/10] [Batch 1/274] [Batch classify loss: 4.375055] 
[Epoch 1/10] [Batch 2/274] [Batch classify loss: 4.986950] 
[Epoch 1/10] [Batch 3/274] [Batch classify loss: 4.931792] 
[Epoch 1/10] [Batch 4/274] [Batch classify loss: 4.611008] 
[Epoch 1/10] [Batch 5/274] [Batch classify loss: 4.619811] 
[Epoch 1/10] [Batch 6/274] [Batch classify loss: 4.704443] 
[Epoch 1/10] [Batch 7/274] [Batch classify loss: 4.108943] 
[Epoch 1/10] [Batch 8/274] [Batch classify loss: 5.032466] 
[Epoch 1/10] [Batch 9/274] [Batch classify loss: 4.937185] 
[Epoch 1/10] [Batch 10/274] [Batch classify loss: 4.880139] 
[Epoch 1/10] [Batch 11/274] [Batch classify loss: 5.141090] 
[Epoch 1/10] [Batch 12/274] [Batch classify loss: 4.829524] 
[Epoch 1/10] [Batch 13/274] [Batch classify loss: 5.026700] 
[Epoch 1/10] [Batch 14/274] [Batch classify loss: 5.105282] 
[Epoch 1/10] [Batch 15/274] [Batch classify loss: 4.560937] 
[Epoch 1/10] [Batch 16/274] [Batch classify loss: 4.422988] 
[Epoch 1/10] [Batch 17/274] [Batch classify loss: 5.288415] 
[Epoch 1/10] [Batch 18/274] [Batch classify loss: 4.431067] 
[Epoch 1/10] [Batch 19/274] [Batch classify loss: 4.488090] 
[Epoch 1/10] [Batch 20/274] [Batch classify loss: 4.635698] 
[Epoch 1/10] [Batch 21/274] [Batch classify loss: 4.491753] 
[Epoch 1/10] [Batch 22/274] [Batch classify loss: 4.916021] 
[Epoch 1/10] [Batch 23/274] [Batch classify loss: 4.823849] 
[Epoch 1/10] [Batch 24/274] [Batch classify loss: 4.759004] 
[Epoch 1/10] [Batch 25/274] [Batch classify loss: 4.435089] 
[Epoch 1/10] [Batch 26/274] [Batch classify loss: 4.657627] 
[Epoch 1/10] [Batch 27/274] [Batch classify loss: 4.992319] 
[Epoch 1/10] [Batch 28/274] [Batch classify loss: 4.906325] 
[Epoch 1/10] [Batch 29/274] [Batch classify loss: 4.535667] 
[Epoch 1/10] [Batch 30/274] [Batch classify loss: 4.429775] 
[Epoch 1/10] [Batch 31/274] [Batch classify loss: 4.832245] 
[Epoch 1/10] [Batch 32/274] [Batch classify loss: 4.261420] 
[Epoch 1/10] [Batch 33/274] [Batch classify loss: 4.693694] 
[Epoch 1/10] [Batch 34/274] [Batch classify loss: 4.602312] 
[Epoch 1/10] [Batch 35/274] [Batch classify loss: 4.527070] 
[Epoch 1/10] [Batch 36/274] [Batch classify loss: 4.863003] 
[Epoch 1/10] [Batch 37/274] [Batch classify loss: 4.286036] 
[Epoch 1/10] [Batch 38/274] [Batch classify loss: 4.453636] 
[Epoch 1/10] [Batch 39/274] [Batch classify loss: 4.470317] 
[Epoch 1/10] [Batch 40/274] [Batch classify loss: 4.622199] 
[Epoch 1/10] [Batch 41/274] [Batch classify loss: 4.701640] 
[Epoch 1/10] [Batch 42/274] [Batch classify loss: 4.187994] 
[Epoch 1/10] [Batch 43/274] [Batch classify loss: 5.172942] 
[Epoch 1/10] [Batch 44/274] [Batch classify loss: 4.207035] 
[Epoch 1/10] [Batch 45/274] [Batch classify loss: 4.163751] 
[Epoch 1/10] [Batch 46/274] [Batch classify loss: 4.421201] 
[Epoch 1/10] [Batch 47/274] [Batch classify loss: 4.021539] 
[Epoch 1/10] [Batch 48/274] [Batch classify loss: 4.471724] 
[Epoch 1/10] [Batch 49/274] [Batch classify loss: 4.338444] 
[Epoch 1/10] [Batch 50/274] [Batch classify loss: 3.935873] 
[Epoch 1/10] [Batch 51/274] [Batch classify loss: 4.295790] 
[Epoch 1/10] [Batch 52/274] [Batch classify loss: 4.423421] 
[Epoch 1/10] [Batch 53/274] [Batch classify loss: 4.691222] 
[Epoch 1/10] [Batch 54/274] [Batch classify loss: 4.068444] 
[Epoch 1/10] [Batch 55/274] [Batch classify loss: 3.951287] 
[Epoch 1/10] [Batch 56/274] [Batch classify loss: 4.034902] 
[Epoch 1/10] [Batch 57/274] [Batch classify loss: 4.427348] 
[Epoch 1/10] [Batch 58/274] [Batch classify loss: 4.838831] 
[Epoch 1/10] [Batch 59/274] [Batch classify loss: 4.521197] 
[Epoch 1/10] [Batch 60/274] [Batch classify loss: 4.099307] 
[Epoch 1/10] [Batch 61/274] [Batch classify loss: 3.632205] 
[Epoch 1/10] [Batch 62/274] [Batch classify loss: 4.238712] 
[Epoch 1/10] [Batch 63/274] [Batch classify loss: 4.411057] 
[Epoch 1/10] [Batch 64/274] [Batch classify loss: 4.061355] 
[Epoch 1/10] [Batch 65/274] [Batch classify loss: 3.823172] 
[Epoch 1/10] [Batch 66/274] [Batch classify loss: 3.858412] 
[Epoch 1/10] [Batch 67/274] [Batch classify loss: 4.221583] 
[Epoch 1/10] [Batch 68/274] [Batch classify loss: 4.230493] 
[Epoch 1/10] [Batch 69/274] [Batch classify loss: 4.096158] 
[Epoch 1/10] [Batch 70/274] [Batch classify loss: 3.998727] 
[Epoch 1/10] [Batch 71/274] [Batch classify loss: 4.515010] 
[Epoch 1/10] [Batch 72/274] [Batch classify loss: 4.194318] 
[Epoch 1/10] [Batch 73/274] [Batch classify loss: 4.552920] 
[Epoch 1/10] [Batch 74/274] [Batch classify loss: 3.547817] 
[Epoch 1/10] [Batch 75/274] [Batch classify loss: 4.018357] 
[Epoch 1/10] [Batch 76/274] [Batch classify loss: 3.833045] 
[Epoch 1/10] [Batch 77/274] [Batch classify loss: 3.792425] 
[Epoch 1/10] [Batch 78/274] [Batch classify loss: 4.088049] 
[Epoch 1/10] [Batch 79/274] [Batch classify loss: 4.889697] 
[Epoch 1/10] [Batch 80/274] [Batch classify loss: 3.790946] 
[Epoch 1/10] [Batch 81/274] [Batch classify loss: 4.081832] 
[Epoch 1/10] [Batch 82/274] [Batch classify loss: 4.109878] 
[Epoch 1/10] [Batch 83/274] [Batch classify loss: 4.125910] 
[Epoch 1/10] [Batch 84/274] [Batch classify loss: 3.894704] 
[Epoch 1/10] [Batch 85/274] [Batch classify loss: 3.874529] 
[Epoch 1/10] [Batch 86/274] [Batch classify loss: 3.722080] 
[Epoch 1/10] [Batch 87/274] [Batch classify loss: 4.023217] 
[Epoch 1/10] [Batch 88/274] [Batch classify loss: 3.867188] 
[Epoch 1/10] [Batch 89/274] [Batch classify loss: 3.961892] 
[Epoch 1/10] [Batch 90/274] [Batch classify loss: 3.942915] 
[Epoch 1/10] [Batch 91/274] [Batch classify loss: 4.241925] 
[Epoch 1/10] [Batch 92/274] [Batch classify loss: 3.903394] 
[Epoch 1/10] [Batch 93/274] [Batch classify loss: 4.035107] 
[Epoch 1/10] [Batch 94/274] [Batch classify loss: 4.143596] 
[Epoch 1/10] [Batch 95/274] [Batch classify loss: 4.357117] 
[Epoch 1/10] [Batch 96/274] [Batch classify loss: 4.360674] 
[Epoch 1/10] [Batch 97/274] [Batch classify loss: 4.337984] 
[Epoch 1/10] [Batch 98/274] [Batch classify loss: 4.158552] 
[Epoch 1/10] [Batch 99/274] [Batch classify loss: 4.267125] 
[Epoch 1/10] [Batch 100/274] [Batch classify loss: 3.931723] 
[Epoch 1/10] [Batch 101/274] [Batch classify loss: 4.005133] 
[Epoch 1/10] [Batch 102/274] [Batch classify loss: 4.253539] 
[Epoch 1/10] [Batch 103/274] [Batch classify loss: 3.685732] 
[Epoch 1/10] [Batch 104/274] [Batch classify loss: 4.167292] 
[Epoch 1/10] [Batch 105/274] [Batch classify loss: 3.578294] 
[Epoch 1/10] [Batch 106/274] [Batch classify loss: 4.155064] 
[Epoch 1/10] [Batch 107/274] [Batch classify loss: 3.676748] 
[Epoch 1/10] [Batch 108/274] [Batch classify loss: 4.198073] 
[Epoch 1/10] [Batch 109/274] [Batch classify loss: 4.252356] 
[Epoch 1/10] [Batch 110/274] [Batch classify loss: 3.479995] 
[Epoch 1/10] [Batch 111/274] [Batch classify loss: 3.987962] 
[Epoch 1/10] [Batch 112/274] [Batch classify loss: 4.401389] 
[Epoch 1/10] [Batch 113/274] [Batch classify loss: 4.008942] 
[Epoch 1/10] [Batch 114/274] [Batch classify loss: 3.718060] 
[Epoch 1/10] [Batch 115/274] [Batch classify loss: 3.769477] 
[Epoch 1/10] [Batch 116/274] [Batch classify loss: 4.072018] 
[Epoch 1/10] [Batch 117/274] [Batch classify loss: 4.469880] 
[Epoch 1/10] [Batch 118/274] [Batch classify loss: 3.388325] 
[Epoch 1/10] [Batch 119/274] [Batch classify loss: 4.380775] 
[Epoch 1/10] [Batch 120/274] [Batch classify loss: 4.033964] 
[Epoch 1/10] [Batch 121/274] [Batch classify loss: 4.160151] 
[Epoch 1/10] [Batch 122/274] [Batch classify loss: 3.668645] 
[Epoch 1/10] [Batch 123/274] [Batch classify loss: 3.956667] 
[Epoch 1/10] [Batch 124/274] [Batch classify loss: 3.889577] 
[Epoch 1/10] [Batch 125/274] [Batch classify loss: 3.978336] 
[Epoch 1/10] [Batch 126/274] [Batch classify loss: 4.141193] 
[Epoch 1/10] [Batch 127/274] [Batch classify loss: 3.632628] 
[Epoch 1/10] [Batch 128/274] [Batch classify loss: 3.959324] 
[Epoch 1/10] [Batch 129/274] [Batch classify loss: 4.609706] 
[Epoch 1/10] [Batch 130/274] [Batch classify loss: 3.825893] 
[Epoch 1/10] [Batch 131/274] [Batch classify loss: 4.586317] 
[Epoch 1/10] [Batch 132/274] [Batch classify loss: 4.005392] 
[Epoch 1/10] [Batch 133/274] [Batch classify loss: 3.838501] 
[Epoch 1/10] [Batch 134/274] [Batch classify loss: 3.988315] 
[Epoch 1/10] [Batch 135/274] [Batch classify loss: 3.956868] 
[Epoch 1/10] [Batch 136/274] [Batch classify loss: 4.304661] 
[Epoch 1/10] [Batch 137/274] [Batch classify loss: 4.197579] 
[Epoch 1/10] [Batch 138/274] [Batch classify loss: 3.896947] 
[Epoch 1/10] [Batch 139/274] [Batch classify loss: 3.717690] 
[Epoch 1/10] [Batch 140/274] [Batch classify loss: 3.619009] 
[Epoch 1/10] [Batch 141/274] [Batch classify loss: 4.038368] 
[Epoch 1/10] [Batch 142/274] [Batch classify loss: 3.848680] 
[Epoch 1/10] [Batch 143/274] [Batch classify loss: 4.515944] 
[Epoch 1/10] [Batch 144/274] [Batch classify loss: 3.726216] 
[Epoch 1/10] [Batch 145/274] [Batch classify loss: 3.911665] 
[Epoch 1/10] [Batch 146/274] [Batch classify loss: 3.857115] 
[Epoch 1/10] [Batch 147/274] [Batch classify loss: 3.800530] 
[Epoch 1/10] [Batch 148/274] [Batch classify loss: 3.891406] 
[Epoch 1/10] [Batch 149/274] [Batch classify loss: 3.663589] 
[Epoch 1/10] [Batch 150/274] [Batch classify loss: 4.165183] 
[Epoch 1/10] [Batch 151/274] [Batch classify loss: 4.027782] 
[Epoch 1/10] [Batch 152/274] [Batch classify loss: 3.872545] 
[Epoch 1/10] [Batch 153/274] [Batch classify loss: 4.115638] 
[Epoch 1/10] [Batch 154/274] [Batch classify loss: 4.005374] 
[Epoch 1/10] [Batch 155/274] [Batch classify loss: 3.753706] 
[Epoch 1/10] [Batch 156/274] [Batch classify loss: 3.900134] 
[Epoch 1/10] [Batch 157/274] [Batch classify loss: 4.605975] 
[Epoch 1/10] [Batch 158/274] [Batch classify loss: 3.942527] 
[Epoch 1/10] [Batch 159/274] [Batch classify loss: 4.018796] 
[Epoch 1/10] [Batch 160/274] [Batch classify loss: 3.891124] 
[Epoch 1/10] [Batch 161/274] [Batch classify loss: 4.060961] 
[Epoch 1/10] [Batch 162/274] [Batch classify loss: 4.027013] 
[Epoch 1/10] [Batch 163/274] [Batch classify loss: 3.987465] 
[Epoch 1/10] [Batch 164/274] [Batch classify loss: 4.201462] 
[Epoch 1/10] [Batch 165/274] [Batch classify loss: 4.018613] 
[Epoch 1/10] [Batch 166/274] [Batch classify loss: 3.806601] 
[Epoch 1/10] [Batch 167/274] [Batch classify loss: 4.158663] 
[Epoch 1/10] [Batch 168/274] [Batch classify loss: 3.856185] 
[Epoch 1/10] [Batch 169/274] [Batch classify loss: 4.410242] 
[Epoch 1/10] [Batch 170/274] [Batch classify loss: 3.895825] 
[Epoch 1/10] [Batch 171/274] [Batch classify loss: 4.148957] 
[Epoch 1/10] [Batch 172/274] [Batch classify loss: 3.930313] 
[Epoch 1/10] [Batch 173/274] [Batch classify loss: 4.200436] 
[Epoch 1/10] [Batch 174/274] [Batch classify loss: 4.111170] 
[Epoch 1/10] [Batch 175/274] [Batch classify loss: 4.818501] 
[Epoch 1/10] [Batch 176/274] [Batch classify loss: 4.078563] 
[Epoch 1/10] [Batch 177/274] [Batch classify loss: 4.163628] 
[Epoch 1/10] [Batch 178/274] [Batch classify loss: 3.917857] 
[Epoch 1/10] [Batch 179/274] [Batch classify loss: 4.174367] 
[Epoch 1/10] [Batch 180/274] [Batch classify loss: 4.056365] 
[Epoch 1/10] [Batch 181/274] [Batch classify loss: 4.022997] 
[Epoch 1/10] [Batch 182/274] [Batch classify loss: 4.299436] 
[Epoch 1/10] [Batch 183/274] [Batch classify loss: 4.370133] 
[Epoch 1/10] [Batch 184/274] [Batch classify loss: 3.703671] 
[Epoch 1/10] [Batch 185/274] [Batch classify loss: 4.089731] 
[Epoch 1/10] [Batch 186/274] [Batch classify loss: 3.841637] 
[Epoch 1/10] [Batch 187/274] [Batch classify loss: 3.887479] 
[Epoch 1/10] [Batch 188/274] [Batch classify loss: 4.408682] 
[Epoch 1/10] [Batch 189/274] [Batch classify loss: 4.184968] 
[Epoch 1/10] [Batch 190/274] [Batch classify loss: 4.167693] 
[Epoch 1/10] [Batch 191/274] [Batch classify loss: 4.540699] 
[Epoch 1/10] [Batch 192/274] [Batch classify loss: 4.586820] 
[Epoch 1/10] [Batch 193/274] [Batch classify loss: 4.295404] 
[Epoch 1/10] [Batch 194/274] [Batch classify loss: 4.176019] 
[Epoch 1/10] [Batch 195/274] [Batch classify loss: 4.401282] 
[Epoch 1/10] [Batch 196/274] [Batch classify loss: 4.588692] 
[Epoch 1/10] [Batch 197/274] [Batch classify loss: 4.313643] 
[Epoch 1/10] [Batch 198/274] [Batch classify loss: 4.153432] 
[Epoch 1/10] [Batch 199/274] [Batch classify loss: 4.412274] 
[Epoch 1/10] [Batch 200/274] [Batch classify loss: 4.321239] 
[Epoch 1/10] [Batch 201/274] [Batch classify loss: 4.158262] 
[Epoch 1/10] [Batch 202/274] [Batch classify loss: 4.241615] 
[Epoch 1/10] [Batch 203/274] [Batch classify loss: 4.674093] 
[Epoch 1/10] [Batch 204/274] [Batch classify loss: 3.907516] 
[Epoch 1/10] [Batch 205/274] [Batch classify loss: 3.855215] 
[Epoch 1/10] [Batch 206/274] [Batch classify loss: 3.577601] 
[Epoch 1/10] [Batch 207/274] [Batch classify loss: 3.925730] 
[Epoch 1/10] [Batch 208/274] [Batch classify loss: 3.934843] 
[Epoch 1/10] [Batch 209/274] [Batch classify loss: 4.667018] 
[Epoch 1/10] [Batch 210/274] [Batch classify loss: 4.221786] 
[Epoch 1/10] [Batch 211/274] [Batch classify loss: 4.389565] 
[Epoch 1/10] [Batch 212/274] [Batch classify loss: 4.264569] 
[Epoch 1/10] [Batch 213/274] [Batch classify loss: 4.231180] 
[Epoch 1/10] [Batch 214/274] [Batch classify loss: 4.324369] 
[Epoch 1/10] [Batch 215/274] [Batch classify loss: 4.330893] 
[Epoch 1/10] [Batch 216/274] [Batch classify loss: 4.177207] 
[Epoch 1/10] [Batch 217/274] [Batch classify loss: 4.011707] 
[Epoch 1/10] [Batch 218/274] [Batch classify loss: 4.560464] 
[Epoch 1/10] [Batch 219/274] [Batch classify loss: 4.119094] 
[Epoch 1/10] [Batch 220/274] [Batch classify loss: 4.434339] 
[Epoch 1/10] [Batch 221/274] [Batch classify loss: 3.979392] 
[Epoch 1/10] [Batch 222/274] [Batch classify loss: 4.264059] 
[Epoch 1/10] [Batch 223/274] [Batch classify loss: 4.477013] 
[Epoch 1/10] [Batch 224/274] [Batch classify loss: 4.099616] 
[Epoch 1/10] [Batch 225/274] [Batch classify loss: 3.895423] 
[Epoch 1/10] [Batch 226/274] [Batch classify loss: 4.322340] 
[Epoch 1/10] [Batch 227/274] [Batch classify loss: 4.153750] 
[Epoch 1/10] [Batch 228/274] [Batch classify loss: 4.041602] 
[Epoch 1/10] [Batch 229/274] [Batch classify loss: 4.240141] 
[Epoch 1/10] [Batch 230/274] [Batch classify loss: 4.047876] 
[Epoch 1/10] [Batch 231/274] [Batch classify loss: 4.539434] 
[Epoch 1/10] [Batch 232/274] [Batch classify loss: 4.083120] 
[Epoch 1/10] [Batch 233/274] [Batch classify loss: 4.065934] 
[Epoch 1/10] [Batch 234/274] [Batch classify loss: 4.249243] 
[Epoch 1/10] [Batch 235/274] [Batch classify loss: 3.671103] 
[Epoch 1/10] [Batch 236/274] [Batch classify loss: 4.333923] 
[Epoch 1/10] [Batch 237/274] [Batch classify loss: 4.120116] 
[Epoch 1/10] [Batch 238/274] [Batch classify loss: 4.060999] 
[Epoch 1/10] [Batch 239/274] [Batch classify loss: 4.217167] 
[Epoch 1/10] [Batch 240/274] [Batch classify loss: 4.258128] 
[Epoch 1/10] [Batch 241/274] [Batch classify loss: 4.245247] 
[Epoch 1/10] [Batch 242/274] [Batch classify loss: 4.451772] 
[Epoch 1/10] [Batch 243/274] [Batch classify loss: 4.000928] 
[Epoch 1/10] [Batch 244/274] [Batch classify loss: 4.285026] 
[Epoch 1/10] [Batch 245/274] [Batch classify loss: 4.320635] 
[Epoch 1/10] [Batch 246/274] [Batch classify loss: 4.139780] 
[Epoch 1/10] [Batch 247/274] [Batch classify loss: 3.987136] 
[Epoch 1/10] [Batch 248/274] [Batch classify loss: 4.351744] 
[Epoch 1/10] [Batch 249/274] [Batch classify loss: 4.270447] 
[Epoch 1/10] [Batch 250/274] [Batch classify loss: 3.769319] 
[Epoch 1/10] [Batch 251/274] [Batch classify loss: 4.539633] 
[Epoch 1/10] [Batch 252/274] [Batch classify loss: 3.578878] 
[Epoch 1/10] [Batch 253/274] [Batch classify loss: 4.481577] 
[Epoch 1/10] [Batch 254/274] [Batch classify loss: 4.512175] 
[Epoch 1/10] [Batch 255/274] [Batch classify loss: 4.832756] 
[Epoch 1/10] [Batch 256/274] [Batch classify loss: 4.496445] 
[Epoch 1/10] [Batch 257/274] [Batch classify loss: 4.249274] 
[Epoch 1/10] [Batch 258/274] [Batch classify loss: 4.404512] 
[Epoch 1/10] [Batch 259/274] [Batch classify loss: 3.969023] 
[Epoch 1/10] [Batch 260/274] [Batch classify loss: 4.439226] 
[Epoch 1/10] [Batch 261/274] [Batch classify loss: 4.488465] 
[Epoch 1/10] [Batch 262/274] [Batch classify loss: 4.147589] 
[Epoch 1/10] [Batch 263/274] [Batch classify loss: 4.300999] 
[Epoch 1/10] [Batch 264/274] [Batch classify loss: 4.172656] 
[Epoch 1/10] [Batch 265/274] [Batch classify loss: 4.338449] 
[Epoch 1/10] [Batch 266/274] [Batch classify loss: 4.482974] 
[Epoch 1/10] [Batch 267/274] [Batch classify loss: 4.180867] 
[Epoch 1/10] [Batch 268/274] [Batch classify loss: 4.208614] 
[Epoch 1/10] [Batch 269/274] [Batch classify loss: 4.324611] 
[Epoch 1/10] [Batch 270/274] [Batch classify loss: 4.066647] 
[Epoch 1/10] [Batch 271/274] [Batch classify loss: 4.429209] 
[Epoch 1/10] [Batch 272/274] [Batch classify loss: 4.744144] 
[Epoch 1/10] [Batch 273/274] [Batch classify loss: 3.528954] 
[Epoch 1/10] [Batch 274/274] [Batch classify loss: 4.379168] 
0001 epoch mmat trained classifier accuary on the clean testing examples:94.7027%
0001 epoch mmat trained classifier loss on the clean testing examples:0.2211
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.1314%
mmat trained classifier loss on adversarial testset:4.5156168937683105
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-cle
1epoch learning rate:0.1
[Epoch 2/10] [Batch 1/274] [Batch classify loss: 3.674944] 
[Epoch 2/10] [Batch 2/274] [Batch classify loss: 4.617173] 
[Epoch 2/10] [Batch 3/274] [Batch classify loss: 4.869220] 
[Epoch 2/10] [Batch 4/274] [Batch classify loss: 4.877804] 
[Epoch 2/10] [Batch 5/274] [Batch classify loss: 4.849058] 
[Epoch 2/10] [Batch 6/274] [Batch classify loss: 4.781510] 
[Epoch 2/10] [Batch 7/274] [Batch classify loss: 4.861159] 
[Epoch 2/10] [Batch 8/274] [Batch classify loss: 5.142953] 
[Epoch 2/10] [Batch 9/274] [Batch classify loss: 4.432019] 
[Epoch 2/10] [Batch 10/274] [Batch classify loss: 4.751558] 
[Epoch 2/10] [Batch 11/274] [Batch classify loss: 5.004448] 
[Epoch 2/10] [Batch 12/274] [Batch classify loss: 4.789217] 
[Epoch 2/10] [Batch 13/274] [Batch classify loss: 5.172769] 
[Epoch 2/10] [Batch 14/274] [Batch classify loss: 4.682357] 
[Epoch 2/10] [Batch 15/274] [Batch classify loss: 4.894368] 
[Epoch 2/10] [Batch 16/274] [Batch classify loss: 4.417607] 
[Epoch 2/10] [Batch 17/274] [Batch classify loss: 4.692451] 
[Epoch 2/10] [Batch 18/274] [Batch classify loss: 4.706591] 
[Epoch 2/10] [Batch 19/274] [Batch classify loss: 4.851017] 
[Epoch 2/10] [Batch 20/274] [Batch classify loss: 4.504292] 
[Epoch 2/10] [Batch 21/274] [Batch classify loss: 4.466975] 
[Epoch 2/10] [Batch 22/274] [Batch classify loss: 4.280664] 
[Epoch 2/10] [Batch 23/274] [Batch classify loss: 4.849203] 
[Epoch 2/10] [Batch 24/274] [Batch classify loss: 5.049823] 
[Epoch 2/10] [Batch 25/274] [Batch classify loss: 5.055916] 
[Epoch 2/10] [Batch 26/274] [Batch classify loss: 4.574712] 
[Epoch 2/10] [Batch 27/274] [Batch classify loss: 4.791172] 
[Epoch 2/10] [Batch 28/274] [Batch classify loss: 4.497304] 
[Epoch 2/10] [Batch 29/274] [Batch classify loss: 4.824359] 
[Epoch 2/10] [Batch 30/274] [Batch classify loss: 4.761797] 
[Epoch 2/10] [Batch 31/274] [Batch classify loss: 4.524788] 
[Epoch 2/10] [Batch 32/274] [Batch classify loss: 4.669089] 
[Epoch 2/10] [Batch 33/274] [Batch classify loss: 4.571790] 
[Epoch 2/10] [Batch 34/274] [Batch classify loss: 5.042345] 
[Epoch 2/10] [Batch 35/274] [Batch classify loss: 4.570498] 
[Epoch 2/10] [Batch 36/274] [Batch classify loss: 5.163797] 
[Epoch 2/10] [Batch 37/274] [Batch classify loss: 4.494009] 
[Epoch 2/10] [Batch 38/274] [Batch classify loss: 4.409151] 
[Epoch 2/10] [Batch 39/274] [Batch classify loss: 4.740171] 
[Epoch 2/10] [Batch 40/274] [Batch classify loss: 4.760618] 
[Epoch 2/10] [Batch 41/274] [Batch classify loss: 5.349546] 
[Epoch 2/10] [Batch 42/274] [Batch classify loss: 4.418613] 
[Epoch 2/10] [Batch 43/274] [Batch classify loss: 4.482955] 
[Epoch 2/10] [Batch 44/274] [Batch classify loss: 4.441982] 
[Epoch 2/10] [Batch 45/274] [Batch classify loss: 4.270657] 
[Epoch 2/10] [Batch 46/274] [Batch classify loss: 4.243486] 
[Epoch 2/10] [Batch 47/274] [Batch classify loss: 4.736634] 
[Epoch 2/10] [Batch 48/274] [Batch classify loss: 4.553902] 
[Epoch 2/10] [Batch 49/274] [Batch classify loss: 4.432755] 
[Epoch 2/10] [Batch 50/274] [Batch classify loss: 4.403967] 
[Epoch 2/10] [Batch 51/274] [Batch classify loss: 4.504861] 
[Epoch 2/10] [Batch 52/274] [Batch classify loss: 4.238931] 
[Epoch 2/10] [Batch 53/274] [Batch classify loss: 4.604312] 
[Epoch 2/10] [Batch 54/274] [Batch classify loss: 4.619789] 
[Epoch 2/10] [Batch 55/274] [Batch classify loss: 4.853009] 
[Epoch 2/10] [Batch 56/274] [Batch classify loss: 5.057232] 
[Epoch 2/10] [Batch 57/274] [Batch classify loss: 4.762684] 
[Epoch 2/10] [Batch 58/274] [Batch classify loss: 4.489605] 
[Epoch 2/10] [Batch 59/274] [Batch classify loss: 4.100809] 
[Epoch 2/10] [Batch 60/274] [Batch classify loss: 4.544526] 
[Epoch 2/10] [Batch 61/274] [Batch classify loss: 4.550537] 
[Epoch 2/10] [Batch 62/274] [Batch classify loss: 4.509127] 
[Epoch 2/10] [Batch 63/274] [Batch classify loss: 4.303860] 
[Epoch 2/10] [Batch 64/274] [Batch classify loss: 4.179009] 
[Epoch 2/10] [Batch 65/274] [Batch classify loss: 4.633128] 
[Epoch 2/10] [Batch 66/274] [Batch classify loss: 4.568799] 
[Epoch 2/10] [Batch 67/274] [Batch classify loss: 4.334470] 
[Epoch 2/10] [Batch 68/274] [Batch classify loss: 4.479360] 
[Epoch 2/10] [Batch 69/274] [Batch classify loss: 4.068530] 
[Epoch 2/10] [Batch 70/274] [Batch classify loss: 4.523601] 
[Epoch 2/10] [Batch 71/274] [Batch classify loss: 4.153049] 
[Epoch 2/10] [Batch 72/274] [Batch classify loss: 4.388704] 
[Epoch 2/10] [Batch 73/274] [Batch classify loss: 4.772054] 
[Epoch 2/10] [Batch 74/274] [Batch classify loss: 4.255103] 
[Epoch 2/10] [Batch 75/274] [Batch classify loss: 4.545838] 
[Epoch 2/10] [Batch 76/274] [Batch classify loss: 4.636113] 
[Epoch 2/10] [Batch 77/274] [Batch classify loss: 4.661434] 
[Epoch 2/10] [Batch 78/274] [Batch classify loss: 4.504298] 
[Epoch 2/10] [Batch 79/274] [Batch classify loss: 4.366456] 
[Epoch 2/10] [Batch 80/274] [Batch classify loss: 4.629249] 
[Epoch 2/10] [Batch 81/274] [Batch classify loss: 4.249425] 
[Epoch 2/10] [Batch 82/274] [Batch classify loss: 4.487997] 
[Epoch 2/10] [Batch 83/274] [Batch classify loss: 4.357195] 
[Epoch 2/10] [Batch 84/274] [Batch classify loss: 4.890231] 
[Epoch 2/10] [Batch 85/274] [Batch classify loss: 4.025264] 
[Epoch 2/10] [Batch 86/274] [Batch classify loss: 4.212556] 
[Epoch 2/10] [Batch 87/274] [Batch classify loss: 4.296180] 
[Epoch 2/10] [Batch 88/274] [Batch classify loss: 4.214889] 
[Epoch 2/10] [Batch 89/274] [Batch classify loss: 4.520440] 
[Epoch 2/10] [Batch 90/274] [Batch classify loss: 5.151030] 
[Epoch 2/10] [Batch 91/274] [Batch classify loss: 4.403111] 
[Epoch 2/10] [Batch 92/274] [Batch classify loss: 4.343235] 
[Epoch 2/10] [Batch 93/274] [Batch classify loss: 4.574049] 
[Epoch 2/10] [Batch 94/274] [Batch classify loss: 4.635427] 
[Epoch 2/10] [Batch 95/274] [Batch classify loss: 4.072313] 
[Epoch 2/10] [Batch 96/274] [Batch classify loss: 4.639339] 
[Epoch 2/10] [Batch 97/274] [Batch classify loss: 4.590796] 
[Epoch 2/10] [Batch 98/274] [Batch classify loss: 4.631407] 
[Epoch 2/10] [Batch 99/274] [Batch classify loss: 4.090158] 
[Epoch 2/10] [Batch 100/274] [Batch classify loss: 4.250797] 
[Epoch 2/10] [Batch 101/274] [Batch classify loss: 4.497561] 
[Epoch 2/10] [Batch 102/274] [Batch classify loss: 4.301696] 
[Epoch 2/10] [Batch 103/274] [Batch classify loss: 4.194159] 
[Epoch 2/10] [Batch 104/274] [Batch classify loss: 3.963033] 
[Epoch 2/10] [Batch 105/274] [Batch classify loss: 4.569950] 
[Epoch 2/10] [Batch 106/274] [Batch classify loss: 4.357860] 
[Epoch 2/10] [Batch 107/274] [Batch classify loss: 4.214496] 
[Epoch 2/10] [Batch 108/274] [Batch classify loss: 4.302851] 
[Epoch 2/10] [Batch 109/274] [Batch classify loss: 4.052762] 
[Epoch 2/10] [Batch 110/274] [Batch classify loss: 4.213758] 
[Epoch 2/10] [Batch 111/274] [Batch classify loss: 4.107474] 
[Epoch 2/10] [Batch 112/274] [Batch classify loss: 4.371675] 
[Epoch 2/10] [Batch 113/274] [Batch classify loss: 4.172155] 
[Epoch 2/10] [Batch 114/274] [Batch classify loss: 4.597044] 
[Epoch 2/10] [Batch 115/274] [Batch classify loss: 4.114561] 
[Epoch 2/10] [Batch 116/274] [Batch classify loss: 3.982522] 
[Epoch 2/10] [Batch 117/274] [Batch classify loss: 3.853012] 
[Epoch 2/10] [Batch 118/274] [Batch classify loss: 4.028417] 
[Epoch 2/10] [Batch 119/274] [Batch classify loss: 4.232506] 
[Epoch 2/10] [Batch 120/274] [Batch classify loss: 4.182199] 
[Epoch 2/10] [Batch 121/274] [Batch classify loss: 4.349127] 
[Epoch 2/10] [Batch 122/274] [Batch classify loss: 4.374703] 
[Epoch 2/10] [Batch 123/274] [Batch classify loss: 4.790714] 
[Epoch 2/10] [Batch 124/274] [Batch classify loss: 4.053368] 
[Epoch 2/10] [Batch 125/274] [Batch classify loss: 4.628012] 
[Epoch 2/10] [Batch 126/274] [Batch classify loss: 4.213813] 
[Epoch 2/10] [Batch 127/274] [Batch classify loss: 4.415630] 
[Epoch 2/10] [Batch 128/274] [Batch classify loss: 3.963262] 
[Epoch 2/10] [Batch 129/274] [Batch classify loss: 4.030024] 
[Epoch 2/10] [Batch 130/274] [Batch classify loss: 4.025156] 
[Epoch 2/10] [Batch 131/274] [Batch classify loss: 4.198264] 
[Epoch 2/10] [Batch 132/274] [Batch classify loss: 3.805769] 
[Epoch 2/10] [Batch 133/274] [Batch classify loss: 3.879716] 
[Epoch 2/10] [Batch 134/274] [Batch classify loss: 4.839200] 
[Epoch 2/10] [Batch 135/274] [Batch classify loss: 4.363455] 
[Epoch 2/10] [Batch 136/274] [Batch classify loss: 4.316689] 
[Epoch 2/10] [Batch 137/274] [Batch classify loss: 4.599520] 
[Epoch 2/10] [Batch 138/274] [Batch classify loss: 4.481047] 
[Epoch 2/10] [Batch 139/274] [Batch classify loss: 4.346603] 
[Epoch 2/10] [Batch 140/274] [Batch classify loss: 4.003427] 
[Epoch 2/10] [Batch 141/274] [Batch classify loss: 4.493291] 
[Epoch 2/10] [Batch 142/274] [Batch classify loss: 3.248717] 
[Epoch 2/10] [Batch 143/274] [Batch classify loss: 4.222463] 
[Epoch 2/10] [Batch 144/274] [Batch classify loss: 4.194705] 
[Epoch 2/10] [Batch 145/274] [Batch classify loss: 3.447011] 
[Epoch 2/10] [Batch 146/274] [Batch classify loss: 4.220693] 
[Epoch 2/10] [Batch 147/274] [Batch classify loss: 4.036204] 
[Epoch 2/10] [Batch 148/274] [Batch classify loss: 3.854951] 
[Epoch 2/10] [Batch 149/274] [Batch classify loss: 3.956659] 
[Epoch 2/10] [Batch 150/274] [Batch classify loss: 4.690230] 
[Epoch 2/10] [Batch 151/274] [Batch classify loss: 4.099624] 
[Epoch 2/10] [Batch 152/274] [Batch classify loss: 4.263056] 
[Epoch 2/10] [Batch 153/274] [Batch classify loss: 3.632395] 
[Epoch 2/10] [Batch 154/274] [Batch classify loss: 3.807224] 
[Epoch 2/10] [Batch 155/274] [Batch classify loss: 3.845155] 
[Epoch 2/10] [Batch 156/274] [Batch classify loss: 4.221620] 
[Epoch 2/10] [Batch 157/274] [Batch classify loss: 4.176327] 
[Epoch 2/10] [Batch 158/274] [Batch classify loss: 4.319288] 
[Epoch 2/10] [Batch 159/274] [Batch classify loss: 4.361899] 
[Epoch 2/10] [Batch 160/274] [Batch classify loss: 3.951105] 
[Epoch 2/10] [Batch 161/274] [Batch classify loss: 4.513761] 
[Epoch 2/10] [Batch 162/274] [Batch classify loss: 4.020037] 
[Epoch 2/10] [Batch 163/274] [Batch classify loss: 4.350026] 
[Epoch 2/10] [Batch 164/274] [Batch classify loss: 4.202906] 
[Epoch 2/10] [Batch 165/274] [Batch classify loss: 4.026383] 
[Epoch 2/10] [Batch 166/274] [Batch classify loss: 4.572236] 
[Epoch 2/10] [Batch 167/274] [Batch classify loss: 3.530888] 
[Epoch 2/10] [Batch 168/274] [Batch classify loss: 4.374969] 
[Epoch 2/10] [Batch 169/274] [Batch classify loss: 4.358506] 
[Epoch 2/10] [Batch 170/274] [Batch classify loss: 3.911052] 
[Epoch 2/10] [Batch 171/274] [Batch classify loss: 4.445114] 
[Epoch 2/10] [Batch 172/274] [Batch classify loss: 4.018900] 
[Epoch 2/10] [Batch 173/274] [Batch classify loss: 3.911903] 
[Epoch 2/10] [Batch 174/274] [Batch classify loss: 3.881169] 
[Epoch 2/10] [Batch 175/274] [Batch classify loss: 3.931208] 
[Epoch 2/10] [Batch 176/274] [Batch classify loss: 4.002661] 
[Epoch 2/10] [Batch 177/274] [Batch classify loss: 4.185122] 
[Epoch 2/10] [Batch 178/274] [Batch classify loss: 4.026038] 
[Epoch 2/10] [Batch 179/274] [Batch classify loss: 4.284070] 
[Epoch 2/10] [Batch 180/274] [Batch classify loss: 3.916175] 
[Epoch 2/10] [Batch 181/274] [Batch classify loss: 4.302200] 
[Epoch 2/10] [Batch 182/274] [Batch classify loss: 4.279892] 
[Epoch 2/10] [Batch 183/274] [Batch classify loss: 4.266164] 
[Epoch 2/10] [Batch 184/274] [Batch classify loss: 4.003629] 
[Epoch 2/10] [Batch 185/274] [Batch classify loss: 4.431710] 
[Epoch 2/10] [Batch 186/274] [Batch classify loss: 4.438846] 
[Epoch 2/10] [Batch 187/274] [Batch classify loss: 4.036947] 
[Epoch 2/10] [Batch 188/274] [Batch classify loss: 4.298990] 
[Epoch 2/10] [Batch 189/274] [Batch classify loss: 4.102353] 
[Epoch 2/10] [Batch 190/274] [Batch classify loss: 4.170883] 
[Epoch 2/10] [Batch 191/274] [Batch classify loss: 4.353295] 
[Epoch 2/10] [Batch 192/274] [Batch classify loss: 4.055627] 
[Epoch 2/10] [Batch 193/274] [Batch classify loss: 3.928846] 
[Epoch 2/10] [Batch 194/274] [Batch classify loss: 3.780940] 
[Epoch 2/10] [Batch 195/274] [Batch classify loss: 4.467642] 
[Epoch 2/10] [Batch 196/274] [Batch classify loss: 3.914213] 
[Epoch 2/10] [Batch 197/274] [Batch classify loss: 4.010087] 
[Epoch 2/10] [Batch 198/274] [Batch classify loss: 4.243829] 
[Epoch 2/10] [Batch 199/274] [Batch classify loss: 4.113276] 
[Epoch 2/10] [Batch 200/274] [Batch classify loss: 3.894261] 
[Epoch 2/10] [Batch 201/274] [Batch classify loss: 4.060006] 
[Epoch 2/10] [Batch 202/274] [Batch classify loss: 4.601400] 
[Epoch 2/10] [Batch 203/274] [Batch classify loss: 4.138556] 
[Epoch 2/10] [Batch 204/274] [Batch classify loss: 4.360323] 
[Epoch 2/10] [Batch 205/274] [Batch classify loss: 4.068392] 
[Epoch 2/10] [Batch 206/274] [Batch classify loss: 4.262266] 
[Epoch 2/10] [Batch 207/274] [Batch classify loss: 4.010876] 
[Epoch 2/10] [Batch 208/274] [Batch classify loss: 3.886296] 
[Epoch 2/10] [Batch 209/274] [Batch classify loss: 3.911344] 
[Epoch 2/10] [Batch 210/274] [Batch classify loss: 4.411240] 
[Epoch 2/10] [Batch 211/274] [Batch classify loss: 4.178210] 
[Epoch 2/10] [Batch 212/274] [Batch classify loss: 3.735523] 
[Epoch 2/10] [Batch 213/274] [Batch classify loss: 3.860094] 
[Epoch 2/10] [Batch 214/274] [Batch classify loss: 4.305121] 
[Epoch 2/10] [Batch 215/274] [Batch classify loss: 4.246296] 
[Epoch 2/10] [Batch 216/274] [Batch classify loss: 3.958081] 
[Epoch 2/10] [Batch 217/274] [Batch classify loss: 4.070539] 
[Epoch 2/10] [Batch 218/274] [Batch classify loss: 4.171262] 
[Epoch 2/10] [Batch 219/274] [Batch classify loss: 4.349106] 
[Epoch 2/10] [Batch 220/274] [Batch classify loss: 3.932889] 
[Epoch 2/10] [Batch 221/274] [Batch classify loss: 3.864864] 
[Epoch 2/10] [Batch 222/274] [Batch classify loss: 3.883898] 
[Epoch 2/10] [Batch 223/274] [Batch classify loss: 3.700478] 
[Epoch 2/10] [Batch 224/274] [Batch classify loss: 4.158914] 
[Epoch 2/10] [Batch 225/274] [Batch classify loss: 4.506448] 
[Epoch 2/10] [Batch 226/274] [Batch classify loss: 4.493240] 
[Epoch 2/10] [Batch 227/274] [Batch classify loss: 4.014896] 
[Epoch 2/10] [Batch 228/274] [Batch classify loss: 4.186032] 
[Epoch 2/10] [Batch 229/274] [Batch classify loss: 4.463187] 
[Epoch 2/10] [Batch 230/274] [Batch classify loss: 3.798826] 
[Epoch 2/10] [Batch 231/274] [Batch classify loss: 4.114073] 
[Epoch 2/10] [Batch 232/274] [Batch classify loss: 4.269122] 
[Epoch 2/10] [Batch 233/274] [Batch classify loss: 4.397799] 
[Epoch 2/10] [Batch 234/274] [Batch classify loss: 3.807322] 
[Epoch 2/10] [Batch 235/274] [Batch classify loss: 4.009408] 
[Epoch 2/10] [Batch 236/274] [Batch classify loss: 3.928581] 
[Epoch 2/10] [Batch 237/274] [Batch classify loss: 4.377237] 
[Epoch 2/10] [Batch 238/274] [Batch classify loss: 3.980732] 
[Epoch 2/10] [Batch 239/274] [Batch classify loss: 4.481346] 
[Epoch 2/10] [Batch 240/274] [Batch classify loss: 4.319744] 
[Epoch 2/10] [Batch 241/274] [Batch classify loss: 4.052062] 
[Epoch 2/10] [Batch 242/274] [Batch classify loss: 4.115500] 
[Epoch 2/10] [Batch 243/274] [Batch classify loss: 4.148081] 
[Epoch 2/10] [Batch 244/274] [Batch classify loss: 4.337583] 
[Epoch 2/10] [Batch 245/274] [Batch classify loss: 4.519213] 
[Epoch 2/10] [Batch 246/274] [Batch classify loss: 3.835933] 
[Epoch 2/10] [Batch 247/274] [Batch classify loss: 3.867726] 
[Epoch 2/10] [Batch 248/274] [Batch classify loss: 4.181702] 
[Epoch 2/10] [Batch 249/274] [Batch classify loss: 4.770889] 
[Epoch 2/10] [Batch 250/274] [Batch classify loss: 3.936381] 
[Epoch 2/10] [Batch 251/274] [Batch classify loss: 4.020867] 
[Epoch 2/10] [Batch 252/274] [Batch classify loss: 4.123362] 
[Epoch 2/10] [Batch 253/274] [Batch classify loss: 3.534510] 
[Epoch 2/10] [Batch 254/274] [Batch classify loss: 3.718203] 
[Epoch 2/10] [Batch 255/274] [Batch classify loss: 4.081034] 
[Epoch 2/10] [Batch 256/274] [Batch classify loss: 4.221658] 
[Epoch 2/10] [Batch 257/274] [Batch classify loss: 3.848958] 
[Epoch 2/10] [Batch 258/274] [Batch classify loss: 3.871418] 
[Epoch 2/10] [Batch 259/274] [Batch classify loss: 4.172638] 
[Epoch 2/10] [Batch 260/274] [Batch classify loss: 3.995300] 
[Epoch 2/10] [Batch 261/274] [Batch classify loss: 4.376907] 
[Epoch 2/10] [Batch 262/274] [Batch classify loss: 4.040640] 
[Epoch 2/10] [Batch 263/274] [Batch classify loss: 4.271862] 
[Epoch 2/10] [Batch 264/274] [Batch classify loss: 3.711569] 
[Epoch 2/10] [Batch 265/274] [Batch classify loss: 3.976101] 
[Epoch 2/10] [Batch 266/274] [Batch classify loss: 3.950462] 
[Epoch 2/10] [Batch 267/274] [Batch classify loss: 3.737409] 
[Epoch 2/10] [Batch 268/274] [Batch classify loss: 4.194780] 
[Epoch 2/10] [Batch 269/274] [Batch classify loss: 3.873864] 
[Epoch 2/10] [Batch 270/274] [Batch classify loss: 3.595954] 
[Epoch 2/10] [Batch 271/274] [Batch classify loss: 3.799234] 
[Epoch 2/10] [Batch 272/274] [Batch classify loss: 4.060819] 
[Epoch 2/10] [Batch 273/274] [Batch classify loss: 4.714016] 
[Epoch 2/10] [Batch 274/274] [Batch classify loss: 3.928280] 
0002 epoch mmat trained classifier accuary on the clean testing examples:94.7219%
0002 epoch mmat trained classifier loss on the clean testing examples:0.2227
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3811%
mmat trained classifier loss on adversarial testset:4.518980503082275
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-cle
2epoch learning rate:0.1
[Epoch 3/10] [Batch 1/274] [Batch classify loss: 2.785177] 
[Epoch 3/10] [Batch 2/274] [Batch classify loss: 3.685781] 
[Epoch 3/10] [Batch 3/274] [Batch classify loss: 4.268132] 
[Epoch 3/10] [Batch 4/274] [Batch classify loss: 4.330191] 
[Epoch 3/10] [Batch 5/274] [Batch classify loss: 4.534684] 
[Epoch 3/10] [Batch 6/274] [Batch classify loss: 5.162004] 
[Epoch 3/10] [Batch 7/274] [Batch classify loss: 4.727810] 
[Epoch 3/10] [Batch 8/274] [Batch classify loss: 5.162431] 
[Epoch 3/10] [Batch 9/274] [Batch classify loss: 4.820532] 
[Epoch 3/10] [Batch 10/274] [Batch classify loss: 4.396780] 
[Epoch 3/10] [Batch 11/274] [Batch classify loss: 4.874105] 
[Epoch 3/10] [Batch 12/274] [Batch classify loss: 4.561027] 
[Epoch 3/10] [Batch 13/274] [Batch classify loss: 5.306788] 
[Epoch 3/10] [Batch 14/274] [Batch classify loss: 4.876442] 
[Epoch 3/10] [Batch 15/274] [Batch classify loss: 4.127402] 
[Epoch 3/10] [Batch 16/274] [Batch classify loss: 4.730784] 
[Epoch 3/10] [Batch 17/274] [Batch classify loss: 5.047068] 
[Epoch 3/10] [Batch 18/274] [Batch classify loss: 4.689866] 
[Epoch 3/10] [Batch 19/274] [Batch classify loss: 4.716780] 
[Epoch 3/10] [Batch 20/274] [Batch classify loss: 4.943535] 
[Epoch 3/10] [Batch 21/274] [Batch classify loss: 4.750396] 
[Epoch 3/10] [Batch 22/274] [Batch classify loss: 4.689412] 
[Epoch 3/10] [Batch 23/274] [Batch classify loss: 4.711371] 
[Epoch 3/10] [Batch 24/274] [Batch classify loss: 4.880770] 
[Epoch 3/10] [Batch 25/274] [Batch classify loss: 4.907084] 
[Epoch 3/10] [Batch 26/274] [Batch classify loss: 4.293594] 
[Epoch 3/10] [Batch 27/274] [Batch classify loss: 4.446864] 
[Epoch 3/10] [Batch 28/274] [Batch classify loss: 4.602622] 
[Epoch 3/10] [Batch 29/274] [Batch classify loss: 4.734484] 
[Epoch 3/10] [Batch 30/274] [Batch classify loss: 4.943549] 
[Epoch 3/10] [Batch 31/274] [Batch classify loss: 4.637873] 
[Epoch 3/10] [Batch 32/274] [Batch classify loss: 4.868039] 
[Epoch 3/10] [Batch 33/274] [Batch classify loss: 4.626276] 
[Epoch 3/10] [Batch 34/274] [Batch classify loss: 4.437154] 
[Epoch 3/10] [Batch 35/274] [Batch classify loss: 4.773291] 
[Epoch 3/10] [Batch 36/274] [Batch classify loss: 5.209501] 
[Epoch 3/10] [Batch 37/274] [Batch classify loss: 5.125088] 
[Epoch 3/10] [Batch 38/274] [Batch classify loss: 4.610099] 
[Epoch 3/10] [Batch 39/274] [Batch classify loss: 4.613847] 
[Epoch 3/10] [Batch 40/274] [Batch classify loss: 4.821638] 
[Epoch 3/10] [Batch 41/274] [Batch classify loss: 4.704863] 
[Epoch 3/10] [Batch 42/274] [Batch classify loss: 4.756146] 
[Epoch 3/10] [Batch 43/274] [Batch classify loss: 5.039313] 
[Epoch 3/10] [Batch 44/274] [Batch classify loss: 4.621614] 
[Epoch 3/10] [Batch 45/274] [Batch classify loss: 4.683067] 
[Epoch 3/10] [Batch 46/274] [Batch classify loss: 5.160644] 
[Epoch 3/10] [Batch 47/274] [Batch classify loss: 4.999331] 
[Epoch 3/10] [Batch 48/274] [Batch classify loss: 4.412139] 
[Epoch 3/10] [Batch 49/274] [Batch classify loss: 4.323542] 
[Epoch 3/10] [Batch 50/274] [Batch classify loss: 4.466584] 
[Epoch 3/10] [Batch 51/274] [Batch classify loss: 4.741641] 
[Epoch 3/10] [Batch 52/274] [Batch classify loss: 4.995504] 
[Epoch 3/10] [Batch 53/274] [Batch classify loss: 4.816445] 
[Epoch 3/10] [Batch 54/274] [Batch classify loss: 4.842469] 
[Epoch 3/10] [Batch 55/274] [Batch classify loss: 4.667296] 
[Epoch 3/10] [Batch 56/274] [Batch classify loss: 4.745845] 
[Epoch 3/10] [Batch 57/274] [Batch classify loss: 4.791559] 
[Epoch 3/10] [Batch 58/274] [Batch classify loss: 5.021109] 
[Epoch 3/10] [Batch 59/274] [Batch classify loss: 4.897513] 
[Epoch 3/10] [Batch 60/274] [Batch classify loss: 4.738639] 
[Epoch 3/10] [Batch 61/274] [Batch classify loss: 4.834505] 
[Epoch 3/10] [Batch 62/274] [Batch classify loss: 4.625504] 
[Epoch 3/10] [Batch 63/274] [Batch classify loss: 4.368419] 
[Epoch 3/10] [Batch 64/274] [Batch classify loss: 4.180480] 
[Epoch 3/10] [Batch 65/274] [Batch classify loss: 4.526652] 
[Epoch 3/10] [Batch 66/274] [Batch classify loss: 5.008106] 
[Epoch 3/10] [Batch 67/274] [Batch classify loss: 4.605411] 
[Epoch 3/10] [Batch 68/274] [Batch classify loss: 4.852661] 
[Epoch 3/10] [Batch 69/274] [Batch classify loss: 4.716315] 
[Epoch 3/10] [Batch 70/274] [Batch classify loss: 4.607148] 
[Epoch 3/10] [Batch 71/274] [Batch classify loss: 4.746594] 
[Epoch 3/10] [Batch 72/274] [Batch classify loss: 4.804851] 
[Epoch 3/10] [Batch 73/274] [Batch classify loss: 4.824479] 
[Epoch 3/10] [Batch 74/274] [Batch classify loss: 4.738302] 
[Epoch 3/10] [Batch 75/274] [Batch classify loss: 4.578039] 
[Epoch 3/10] [Batch 76/274] [Batch classify loss: 4.551281] 
[Epoch 3/10] [Batch 77/274] [Batch classify loss: 4.490626] 
[Epoch 3/10] [Batch 78/274] [Batch classify loss: 4.354698] 
[Epoch 3/10] [Batch 79/274] [Batch classify loss: 4.672981] 
[Epoch 3/10] [Batch 80/274] [Batch classify loss: 4.823701] 
[Epoch 3/10] [Batch 81/274] [Batch classify loss: 5.186171] 
[Epoch 3/10] [Batch 82/274] [Batch classify loss: 5.097161] 
[Epoch 3/10] [Batch 83/274] [Batch classify loss: 4.844397] 
[Epoch 3/10] [Batch 84/274] [Batch classify loss: 4.727333] 
[Epoch 3/10] [Batch 85/274] [Batch classify loss: 4.386441] 
[Epoch 3/10] [Batch 86/274] [Batch classify loss: 5.004063] 
[Epoch 3/10] [Batch 87/274] [Batch classify loss: 4.660641] 
[Epoch 3/10] [Batch 88/274] [Batch classify loss: 4.412292] 
[Epoch 3/10] [Batch 89/274] [Batch classify loss: 4.619653] 
[Epoch 3/10] [Batch 90/274] [Batch classify loss: 4.389484] 
[Epoch 3/10] [Batch 91/274] [Batch classify loss: 3.814395] 
[Epoch 3/10] [Batch 92/274] [Batch classify loss: 4.837257] 
[Epoch 3/10] [Batch 93/274] [Batch classify loss: 4.836454] 
[Epoch 3/10] [Batch 94/274] [Batch classify loss: 4.638819] 
[Epoch 3/10] [Batch 95/274] [Batch classify loss: 4.635299] 
[Epoch 3/10] [Batch 96/274] [Batch classify loss: 5.106367] 
[Epoch 3/10] [Batch 97/274] [Batch classify loss: 4.742771] 
[Epoch 3/10] [Batch 98/274] [Batch classify loss: 4.944120] 
[Epoch 3/10] [Batch 99/274] [Batch classify loss: 4.435125] 
[Epoch 3/10] [Batch 100/274] [Batch classify loss: 4.587228] 
[Epoch 3/10] [Batch 101/274] [Batch classify loss: 4.591200] 
[Epoch 3/10] [Batch 102/274] [Batch classify loss: 4.665552] 
[Epoch 3/10] [Batch 103/274] [Batch classify loss: 4.542953] 
[Epoch 3/10] [Batch 104/274] [Batch classify loss: 4.802172] 
[Epoch 3/10] [Batch 105/274] [Batch classify loss: 4.447455] 
[Epoch 3/10] [Batch 106/274] [Batch classify loss: 4.718745] 
[Epoch 3/10] [Batch 107/274] [Batch classify loss: 4.428005] 
[Epoch 3/10] [Batch 108/274] [Batch classify loss: 4.757247] 
[Epoch 3/10] [Batch 109/274] [Batch classify loss: 4.770250] 
[Epoch 3/10] [Batch 110/274] [Batch classify loss: 4.493360] 
[Epoch 3/10] [Batch 111/274] [Batch classify loss: 4.349543] 
[Epoch 3/10] [Batch 112/274] [Batch classify loss: 4.240510] 
[Epoch 3/10] [Batch 113/274] [Batch classify loss: 4.707793] 
[Epoch 3/10] [Batch 114/274] [Batch classify loss: 4.705647] 
[Epoch 3/10] [Batch 115/274] [Batch classify loss: 4.466417] 
[Epoch 3/10] [Batch 116/274] [Batch classify loss: 4.456285] 
[Epoch 3/10] [Batch 117/274] [Batch classify loss: 4.445466] 
[Epoch 3/10] [Batch 118/274] [Batch classify loss: 4.538176] 
[Epoch 3/10] [Batch 119/274] [Batch classify loss: 4.620633] 
[Epoch 3/10] [Batch 120/274] [Batch classify loss: 4.323998] 
[Epoch 3/10] [Batch 121/274] [Batch classify loss: 4.458694] 
[Epoch 3/10] [Batch 122/274] [Batch classify loss: 4.631218] 
[Epoch 3/10] [Batch 123/274] [Batch classify loss: 3.956214] 
[Epoch 3/10] [Batch 124/274] [Batch classify loss: 4.286410] 
[Epoch 3/10] [Batch 125/274] [Batch classify loss: 4.462274] 
[Epoch 3/10] [Batch 126/274] [Batch classify loss: 4.704587] 
[Epoch 3/10] [Batch 127/274] [Batch classify loss: 4.551192] 
[Epoch 3/10] [Batch 128/274] [Batch classify loss: 4.140840] 
[Epoch 3/10] [Batch 129/274] [Batch classify loss: 4.037284] 
[Epoch 3/10] [Batch 130/274] [Batch classify loss: 5.252704] 
[Epoch 3/10] [Batch 131/274] [Batch classify loss: 4.431798] 
[Epoch 3/10] [Batch 132/274] [Batch classify loss: 4.409694] 
[Epoch 3/10] [Batch 133/274] [Batch classify loss: 4.619732] 
[Epoch 3/10] [Batch 134/274] [Batch classify loss: 4.696531] 
[Epoch 3/10] [Batch 135/274] [Batch classify loss: 3.851360] 
[Epoch 3/10] [Batch 136/274] [Batch classify loss: 4.516837] 
[Epoch 3/10] [Batch 137/274] [Batch classify loss: 4.634632] 
[Epoch 3/10] [Batch 138/274] [Batch classify loss: 4.694931] 
[Epoch 3/10] [Batch 139/274] [Batch classify loss: 4.664476] 
[Epoch 3/10] [Batch 140/274] [Batch classify loss: 4.180194] 
[Epoch 3/10] [Batch 141/274] [Batch classify loss: 4.240618] 
[Epoch 3/10] [Batch 142/274] [Batch classify loss: 4.495656] 
[Epoch 3/10] [Batch 143/274] [Batch classify loss: 4.478260] 
[Epoch 3/10] [Batch 144/274] [Batch classify loss: 4.178082] 
[Epoch 3/10] [Batch 145/274] [Batch classify loss: 4.535750] 
[Epoch 3/10] [Batch 146/274] [Batch classify loss: 4.434516] 
[Epoch 3/10] [Batch 147/274] [Batch classify loss: 4.238863] 
[Epoch 3/10] [Batch 148/274] [Batch classify loss: 4.471173] 
[Epoch 3/10] [Batch 149/274] [Batch classify loss: 4.395502] 
[Epoch 3/10] [Batch 150/274] [Batch classify loss: 4.886329] 
[Epoch 3/10] [Batch 151/274] [Batch classify loss: 4.359076] 
[Epoch 3/10] [Batch 152/274] [Batch classify loss: 4.368286] 
[Epoch 3/10] [Batch 153/274] [Batch classify loss: 4.415128] 
[Epoch 3/10] [Batch 154/274] [Batch classify loss: 4.646240] 
[Epoch 3/10] [Batch 155/274] [Batch classify loss: 4.471795] 
[Epoch 3/10] [Batch 156/274] [Batch classify loss: 4.729824] 
[Epoch 3/10] [Batch 157/274] [Batch classify loss: 4.297539] 
[Epoch 3/10] [Batch 158/274] [Batch classify loss: 4.753021] 
[Epoch 3/10] [Batch 159/274] [Batch classify loss: 4.665952] 
[Epoch 3/10] [Batch 160/274] [Batch classify loss: 4.360730] 
[Epoch 3/10] [Batch 161/274] [Batch classify loss: 4.183451] 
[Epoch 3/10] [Batch 162/274] [Batch classify loss: 4.415302] 
[Epoch 3/10] [Batch 163/274] [Batch classify loss: 3.823192] 
[Epoch 3/10] [Batch 164/274] [Batch classify loss: 4.440738] 
[Epoch 3/10] [Batch 165/274] [Batch classify loss: 4.044168] 
[Epoch 3/10] [Batch 166/274] [Batch classify loss: 4.255856] 
[Epoch 3/10] [Batch 167/274] [Batch classify loss: 4.328038] 
[Epoch 3/10] [Batch 168/274] [Batch classify loss: 4.426806] 
[Epoch 3/10] [Batch 169/274] [Batch classify loss: 4.339669] 
[Epoch 3/10] [Batch 170/274] [Batch classify loss: 4.087868] 
[Epoch 3/10] [Batch 171/274] [Batch classify loss: 4.113345] 
[Epoch 3/10] [Batch 172/274] [Batch classify loss: 4.247950] 
[Epoch 3/10] [Batch 173/274] [Batch classify loss: 4.710602] 
[Epoch 3/10] [Batch 174/274] [Batch classify loss: 4.715141] 
[Epoch 3/10] [Batch 175/274] [Batch classify loss: 4.540686] 
[Epoch 3/10] [Batch 176/274] [Batch classify loss: 4.629072] 
[Epoch 3/10] [Batch 177/274] [Batch classify loss: 4.314457] 
[Epoch 3/10] [Batch 178/274] [Batch classify loss: 4.403817] 
[Epoch 3/10] [Batch 179/274] [Batch classify loss: 4.111294] 
[Epoch 3/10] [Batch 180/274] [Batch classify loss: 4.143043] 
[Epoch 3/10] [Batch 181/274] [Batch classify loss: 4.088780] 
[Epoch 3/10] [Batch 182/274] [Batch classify loss: 4.125746] 
[Epoch 3/10] [Batch 183/274] [Batch classify loss: 4.402519] 
[Epoch 3/10] [Batch 184/274] [Batch classify loss: 4.191393] 
[Epoch 3/10] [Batch 185/274] [Batch classify loss: 4.264145] 
[Epoch 3/10] [Batch 186/274] [Batch classify loss: 4.674524] 
[Epoch 3/10] [Batch 187/274] [Batch classify loss: 4.561758] 
[Epoch 3/10] [Batch 188/274] [Batch classify loss: 4.269880] 
[Epoch 3/10] [Batch 189/274] [Batch classify loss: 4.097048] 
[Epoch 3/10] [Batch 190/274] [Batch classify loss: 4.270350] 
[Epoch 3/10] [Batch 191/274] [Batch classify loss: 4.277722] 
[Epoch 3/10] [Batch 192/274] [Batch classify loss: 4.424812] 
[Epoch 3/10] [Batch 193/274] [Batch classify loss: 4.106696] 
[Epoch 3/10] [Batch 194/274] [Batch classify loss: 3.959081] 
[Epoch 3/10] [Batch 195/274] [Batch classify loss: 4.101642] 
[Epoch 3/10] [Batch 196/274] [Batch classify loss: 4.397251] 
[Epoch 3/10] [Batch 197/274] [Batch classify loss: 4.051790] 
[Epoch 3/10] [Batch 198/274] [Batch classify loss: 4.436745] 
[Epoch 3/10] [Batch 199/274] [Batch classify loss: 4.157726] 
[Epoch 3/10] [Batch 200/274] [Batch classify loss: 3.879415] 
[Epoch 3/10] [Batch 201/274] [Batch classify loss: 4.474366] 
[Epoch 3/10] [Batch 202/274] [Batch classify loss: 4.501861] 
[Epoch 3/10] [Batch 203/274] [Batch classify loss: 4.689461] 
[Epoch 3/10] [Batch 204/274] [Batch classify loss: 3.979361] 
[Epoch 3/10] [Batch 205/274] [Batch classify loss: 4.448087] 
[Epoch 3/10] [Batch 206/274] [Batch classify loss: 4.012851] 
[Epoch 3/10] [Batch 207/274] [Batch classify loss: 4.542484] 
[Epoch 3/10] [Batch 208/274] [Batch classify loss: 4.574619] 
[Epoch 3/10] [Batch 209/274] [Batch classify loss: 4.506879] 
[Epoch 3/10] [Batch 210/274] [Batch classify loss: 4.207683] 
[Epoch 3/10] [Batch 211/274] [Batch classify loss: 4.236518] 
[Epoch 3/10] [Batch 212/274] [Batch classify loss: 4.299563] 
[Epoch 3/10] [Batch 213/274] [Batch classify loss: 4.473109] 
[Epoch 3/10] [Batch 214/274] [Batch classify loss: 3.808193] 
[Epoch 3/10] [Batch 215/274] [Batch classify loss: 4.497396] 
[Epoch 3/10] [Batch 216/274] [Batch classify loss: 3.995654] 
[Epoch 3/10] [Batch 217/274] [Batch classify loss: 4.405567] 
[Epoch 3/10] [Batch 218/274] [Batch classify loss: 4.622350] 
[Epoch 3/10] [Batch 219/274] [Batch classify loss: 4.276618] 
[Epoch 3/10] [Batch 220/274] [Batch classify loss: 4.533853] 
[Epoch 3/10] [Batch 221/274] [Batch classify loss: 4.377635] 
[Epoch 3/10] [Batch 222/274] [Batch classify loss: 4.684865] 
[Epoch 3/10] [Batch 223/274] [Batch classify loss: 4.221339] 
[Epoch 3/10] [Batch 224/274] [Batch classify loss: 4.615742] 
[Epoch 3/10] [Batch 225/274] [Batch classify loss: 4.605428] 
[Epoch 3/10] [Batch 226/274] [Batch classify loss: 4.315003] 
[Epoch 3/10] [Batch 227/274] [Batch classify loss: 4.074900] 
[Epoch 3/10] [Batch 228/274] [Batch classify loss: 4.590668] 
[Epoch 3/10] [Batch 229/274] [Batch classify loss: 4.315843] 
[Epoch 3/10] [Batch 230/274] [Batch classify loss: 4.113735] 
[Epoch 3/10] [Batch 231/274] [Batch classify loss: 4.297729] 
[Epoch 3/10] [Batch 232/274] [Batch classify loss: 4.431263] 
[Epoch 3/10] [Batch 233/274] [Batch classify loss: 4.286829] 
[Epoch 3/10] [Batch 234/274] [Batch classify loss: 4.552058] 
[Epoch 3/10] [Batch 235/274] [Batch classify loss: 3.935080] 
[Epoch 3/10] [Batch 236/274] [Batch classify loss: 4.434698] 
[Epoch 3/10] [Batch 237/274] [Batch classify loss: 4.796866] 
[Epoch 3/10] [Batch 238/274] [Batch classify loss: 4.316538] 
[Epoch 3/10] [Batch 239/274] [Batch classify loss: 4.420403] 
[Epoch 3/10] [Batch 240/274] [Batch classify loss: 4.391335] 
[Epoch 3/10] [Batch 241/274] [Batch classify loss: 4.634674] 
[Epoch 3/10] [Batch 242/274] [Batch classify loss: 4.354639] 
[Epoch 3/10] [Batch 243/274] [Batch classify loss: 4.375153] 
[Epoch 3/10] [Batch 244/274] [Batch classify loss: 4.310874] 
[Epoch 3/10] [Batch 245/274] [Batch classify loss: 4.292891] 
[Epoch 3/10] [Batch 246/274] [Batch classify loss: 4.375962] 
[Epoch 3/10] [Batch 247/274] [Batch classify loss: 4.390012] 
[Epoch 3/10] [Batch 248/274] [Batch classify loss: 4.467675] 
[Epoch 3/10] [Batch 249/274] [Batch classify loss: 3.759980] 
[Epoch 3/10] [Batch 250/274] [Batch classify loss: 4.231493] 
[Epoch 3/10] [Batch 251/274] [Batch classify loss: 3.967903] 
[Epoch 3/10] [Batch 252/274] [Batch classify loss: 4.461957] 
[Epoch 3/10] [Batch 253/274] [Batch classify loss: 4.254663] 
[Epoch 3/10] [Batch 254/274] [Batch classify loss: 4.133425] 
[Epoch 3/10] [Batch 255/274] [Batch classify loss: 4.245422] 
[Epoch 3/10] [Batch 256/274] [Batch classify loss: 4.168683] 
[Epoch 3/10] [Batch 257/274] [Batch classify loss: 4.281480] 
[Epoch 3/10] [Batch 258/274] [Batch classify loss: 4.150854] 
[Epoch 3/10] [Batch 259/274] [Batch classify loss: 4.540917] 
[Epoch 3/10] [Batch 260/274] [Batch classify loss: 4.319852] 
[Epoch 3/10] [Batch 261/274] [Batch classify loss: 4.523397] 
[Epoch 3/10] [Batch 262/274] [Batch classify loss: 3.933816] 
[Epoch 3/10] [Batch 263/274] [Batch classify loss: 3.917906] 
[Epoch 3/10] [Batch 264/274] [Batch classify loss: 4.321178] 
[Epoch 3/10] [Batch 265/274] [Batch classify loss: 4.134366] 
[Epoch 3/10] [Batch 266/274] [Batch classify loss: 4.648964] 
[Epoch 3/10] [Batch 267/274] [Batch classify loss: 4.329576] 
[Epoch 3/10] [Batch 268/274] [Batch classify loss: 4.151597] 
[Epoch 3/10] [Batch 269/274] [Batch classify loss: 3.875880] 
[Epoch 3/10] [Batch 270/274] [Batch classify loss: 4.436981] 
[Epoch 3/10] [Batch 271/274] [Batch classify loss: 4.216187] 
[Epoch 3/10] [Batch 272/274] [Batch classify loss: 4.328868] 
[Epoch 3/10] [Batch 273/274] [Batch classify loss: 4.362664] 
[Epoch 3/10] [Batch 274/274] [Batch classify loss: 3.765105] 
0003 epoch mmat trained classifier accuary on the clean testing examples:94.6566%
0003 epoch mmat trained classifier loss on the clean testing examples:0.2232
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2658%
mmat trained classifier loss on adversarial testset:4.5261383056640625
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-cle
3epoch learning rate:0.1
[Epoch 4/10] [Batch 1/274] [Batch classify loss: 2.231872] 
[Epoch 4/10] [Batch 2/274] [Batch classify loss: 2.982326] 
[Epoch 4/10] [Batch 3/274] [Batch classify loss: 3.703270] 
[Epoch 4/10] [Batch 4/274] [Batch classify loss: 3.800646] 
[Epoch 4/10] [Batch 5/274] [Batch classify loss: 3.228756] 
[Epoch 4/10] [Batch 6/274] [Batch classify loss: 4.097113] 
[Epoch 4/10] [Batch 7/274] [Batch classify loss: 4.307840] 
[Epoch 4/10] [Batch 8/274] [Batch classify loss: 4.482166] 
[Epoch 4/10] [Batch 9/274] [Batch classify loss: 4.725824] 
[Epoch 4/10] [Batch 10/274] [Batch classify loss: 4.349862] 
[Epoch 4/10] [Batch 11/274] [Batch classify loss: 4.544199] 
[Epoch 4/10] [Batch 12/274] [Batch classify loss: 4.340023] 
[Epoch 4/10] [Batch 13/274] [Batch classify loss: 4.329704] 
[Epoch 4/10] [Batch 14/274] [Batch classify loss: 4.352645] 
[Epoch 4/10] [Batch 15/274] [Batch classify loss: 5.127488] 
[Epoch 4/10] [Batch 16/274] [Batch classify loss: 4.204337] 
[Epoch 4/10] [Batch 17/274] [Batch classify loss: 4.799230] 
[Epoch 4/10] [Batch 18/274] [Batch classify loss: 4.338309] 
[Epoch 4/10] [Batch 19/274] [Batch classify loss: 4.425984] 
[Epoch 4/10] [Batch 20/274] [Batch classify loss: 4.437690] 
[Epoch 4/10] [Batch 21/274] [Batch classify loss: 4.575346] 
[Epoch 4/10] [Batch 22/274] [Batch classify loss: 4.661099] 
[Epoch 4/10] [Batch 23/274] [Batch classify loss: 4.770010] 
[Epoch 4/10] [Batch 24/274] [Batch classify loss: 5.039233] 
[Epoch 4/10] [Batch 25/274] [Batch classify loss: 4.477601] 
[Epoch 4/10] [Batch 26/274] [Batch classify loss: 4.521652] 
[Epoch 4/10] [Batch 27/274] [Batch classify loss: 4.889572] 
[Epoch 4/10] [Batch 28/274] [Batch classify loss: 4.575472] 
[Epoch 4/10] [Batch 29/274] [Batch classify loss: 4.640543] 
[Epoch 4/10] [Batch 30/274] [Batch classify loss: 5.145593] 
[Epoch 4/10] [Batch 31/274] [Batch classify loss: 4.829728] 
[Epoch 4/10] [Batch 32/274] [Batch classify loss: 4.491062] 
[Epoch 4/10] [Batch 33/274] [Batch classify loss: 4.921053] 
[Epoch 4/10] [Batch 34/274] [Batch classify loss: 4.687388] 
[Epoch 4/10] [Batch 35/274] [Batch classify loss: 4.592484] 
[Epoch 4/10] [Batch 36/274] [Batch classify loss: 4.298074] 
[Epoch 4/10] [Batch 37/274] [Batch classify loss: 4.895839] 
[Epoch 4/10] [Batch 38/274] [Batch classify loss: 4.688086] 
[Epoch 4/10] [Batch 39/274] [Batch classify loss: 5.221719] 
[Epoch 4/10] [Batch 40/274] [Batch classify loss: 4.781302] 
[Epoch 4/10] [Batch 41/274] [Batch classify loss: 4.563864] 
[Epoch 4/10] [Batch 42/274] [Batch classify loss: 4.884833] 
[Epoch 4/10] [Batch 43/274] [Batch classify loss: 4.899094] 
[Epoch 4/10] [Batch 44/274] [Batch classify loss: 4.947014] 
[Epoch 4/10] [Batch 45/274] [Batch classify loss: 4.749378] 
[Epoch 4/10] [Batch 46/274] [Batch classify loss: 4.528195] 
[Epoch 4/10] [Batch 47/274] [Batch classify loss: 4.564548] 
[Epoch 4/10] [Batch 48/274] [Batch classify loss: 4.426866] 
[Epoch 4/10] [Batch 49/274] [Batch classify loss: 4.616601] 
[Epoch 4/10] [Batch 50/274] [Batch classify loss: 4.652856] 
[Epoch 4/10] [Batch 51/274] [Batch classify loss: 4.988537] 
[Epoch 4/10] [Batch 52/274] [Batch classify loss: 5.024453] 
[Epoch 4/10] [Batch 53/274] [Batch classify loss: 4.704529] 
[Epoch 4/10] [Batch 54/274] [Batch classify loss: 4.889672] 
[Epoch 4/10] [Batch 55/274] [Batch classify loss: 4.606361] 
[Epoch 4/10] [Batch 56/274] [Batch classify loss: 4.785468] 
[Epoch 4/10] [Batch 57/274] [Batch classify loss: 4.797772] 
[Epoch 4/10] [Batch 58/274] [Batch classify loss: 4.903956] 
[Epoch 4/10] [Batch 59/274] [Batch classify loss: 4.822422] 
[Epoch 4/10] [Batch 60/274] [Batch classify loss: 4.839418] 
[Epoch 4/10] [Batch 61/274] [Batch classify loss: 5.383022] 
[Epoch 4/10] [Batch 62/274] [Batch classify loss: 4.650149] 
[Epoch 4/10] [Batch 63/274] [Batch classify loss: 4.732529] 
[Epoch 4/10] [Batch 64/274] [Batch classify loss: 4.652519] 
[Epoch 4/10] [Batch 65/274] [Batch classify loss: 4.673500] 
[Epoch 4/10] [Batch 66/274] [Batch classify loss: 5.017373] 
[Epoch 4/10] [Batch 67/274] [Batch classify loss: 4.584130] 
[Epoch 4/10] [Batch 68/274] [Batch classify loss: 4.795648] 
[Epoch 4/10] [Batch 69/274] [Batch classify loss: 4.363154] 
[Epoch 4/10] [Batch 70/274] [Batch classify loss: 5.294444] 
[Epoch 4/10] [Batch 71/274] [Batch classify loss: 4.576636] 
[Epoch 4/10] [Batch 72/274] [Batch classify loss: 5.184527] 
[Epoch 4/10] [Batch 73/274] [Batch classify loss: 4.481042] 
[Epoch 4/10] [Batch 74/274] [Batch classify loss: 4.019048] 
[Epoch 4/10] [Batch 75/274] [Batch classify loss: 4.725846] 
[Epoch 4/10] [Batch 76/274] [Batch classify loss: 5.168210] 
[Epoch 4/10] [Batch 77/274] [Batch classify loss: 4.322856] 
[Epoch 4/10] [Batch 78/274] [Batch classify loss: 4.484270] 
[Epoch 4/10] [Batch 79/274] [Batch classify loss: 4.806793] 
[Epoch 4/10] [Batch 80/274] [Batch classify loss: 4.493311] 
[Epoch 4/10] [Batch 81/274] [Batch classify loss: 4.916003] 
[Epoch 4/10] [Batch 82/274] [Batch classify loss: 4.503681] 
[Epoch 4/10] [Batch 83/274] [Batch classify loss: 4.795647] 
[Epoch 4/10] [Batch 84/274] [Batch classify loss: 4.525521] 
[Epoch 4/10] [Batch 85/274] [Batch classify loss: 4.467802] 
[Epoch 4/10] [Batch 86/274] [Batch classify loss: 4.679374] 
[Epoch 4/10] [Batch 87/274] [Batch classify loss: 4.621480] 
[Epoch 4/10] [Batch 88/274] [Batch classify loss: 5.021838] 
[Epoch 4/10] [Batch 89/274] [Batch classify loss: 4.798566] 
[Epoch 4/10] [Batch 90/274] [Batch classify loss: 4.509755] 
[Epoch 4/10] [Batch 91/274] [Batch classify loss: 4.830605] 
[Epoch 4/10] [Batch 92/274] [Batch classify loss: 4.771868] 
[Epoch 4/10] [Batch 93/274] [Batch classify loss: 4.804281] 
[Epoch 4/10] [Batch 94/274] [Batch classify loss: 4.758173] 
[Epoch 4/10] [Batch 95/274] [Batch classify loss: 4.987419] 
[Epoch 4/10] [Batch 96/274] [Batch classify loss: 4.689189] 
[Epoch 4/10] [Batch 97/274] [Batch classify loss: 4.106215] 
[Epoch 4/10] [Batch 98/274] [Batch classify loss: 4.399369] 
[Epoch 4/10] [Batch 99/274] [Batch classify loss: 4.497451] 
[Epoch 4/10] [Batch 100/274] [Batch classify loss: 5.136787] 
[Epoch 4/10] [Batch 101/274] [Batch classify loss: 4.951298] 
[Epoch 4/10] [Batch 102/274] [Batch classify loss: 4.794566] 
[Epoch 4/10] [Batch 103/274] [Batch classify loss: 4.663355] 
[Epoch 4/10] [Batch 104/274] [Batch classify loss: 4.215885] 
[Epoch 4/10] [Batch 105/274] [Batch classify loss: 4.755472] 
[Epoch 4/10] [Batch 106/274] [Batch classify loss: 4.926809] 
[Epoch 4/10] [Batch 107/274] [Batch classify loss: 4.611542] 
[Epoch 4/10] [Batch 108/274] [Batch classify loss: 4.975911] 
[Epoch 4/10] [Batch 109/274] [Batch classify loss: 4.734310] 
[Epoch 4/10] [Batch 110/274] [Batch classify loss: 4.626293] 
[Epoch 4/10] [Batch 111/274] [Batch classify loss: 4.739367] 
[Epoch 4/10] [Batch 112/274] [Batch classify loss: 4.592209] 
[Epoch 4/10] [Batch 113/274] [Batch classify loss: 4.499141] 
[Epoch 4/10] [Batch 114/274] [Batch classify loss: 4.948078] 
[Epoch 4/10] [Batch 115/274] [Batch classify loss: 5.088872] 
[Epoch 4/10] [Batch 116/274] [Batch classify loss: 4.388658] 
[Epoch 4/10] [Batch 117/274] [Batch classify loss: 4.828709] 
[Epoch 4/10] [Batch 118/274] [Batch classify loss: 4.799788] 
[Epoch 4/10] [Batch 119/274] [Batch classify loss: 4.768516] 
[Epoch 4/10] [Batch 120/274] [Batch classify loss: 4.569756] 
[Epoch 4/10] [Batch 121/274] [Batch classify loss: 4.368689] 
[Epoch 4/10] [Batch 122/274] [Batch classify loss: 4.433223] 
[Epoch 4/10] [Batch 123/274] [Batch classify loss: 4.486594] 
[Epoch 4/10] [Batch 124/274] [Batch classify loss: 4.965433] 
[Epoch 4/10] [Batch 125/274] [Batch classify loss: 4.607788] 
[Epoch 4/10] [Batch 126/274] [Batch classify loss: 4.682481] 
[Epoch 4/10] [Batch 127/274] [Batch classify loss: 4.544061] 
[Epoch 4/10] [Batch 128/274] [Batch classify loss: 4.803609] 
[Epoch 4/10] [Batch 129/274] [Batch classify loss: 5.224137] 
[Epoch 4/10] [Batch 130/274] [Batch classify loss: 4.652276] 
[Epoch 4/10] [Batch 131/274] [Batch classify loss: 4.526386] 
[Epoch 4/10] [Batch 132/274] [Batch classify loss: 4.999482] 
[Epoch 4/10] [Batch 133/274] [Batch classify loss: 4.668300] 
[Epoch 4/10] [Batch 134/274] [Batch classify loss: 4.221884] 
[Epoch 4/10] [Batch 135/274] [Batch classify loss: 4.060748] 
[Epoch 4/10] [Batch 136/274] [Batch classify loss: 4.485377] 
[Epoch 4/10] [Batch 137/274] [Batch classify loss: 4.432484] 
[Epoch 4/10] [Batch 138/274] [Batch classify loss: 4.640437] 
[Epoch 4/10] [Batch 139/274] [Batch classify loss: 4.523886] 
[Epoch 4/10] [Batch 140/274] [Batch classify loss: 4.527027] 
[Epoch 4/10] [Batch 141/274] [Batch classify loss: 4.576888] 
[Epoch 4/10] [Batch 142/274] [Batch classify loss: 4.626787] 
[Epoch 4/10] [Batch 143/274] [Batch classify loss: 4.847772] 
[Epoch 4/10] [Batch 144/274] [Batch classify loss: 4.567475] 
[Epoch 4/10] [Batch 145/274] [Batch classify loss: 4.545222] 
[Epoch 4/10] [Batch 146/274] [Batch classify loss: 4.719556] 
[Epoch 4/10] [Batch 147/274] [Batch classify loss: 4.842644] 
[Epoch 4/10] [Batch 148/274] [Batch classify loss: 4.392664] 
[Epoch 4/10] [Batch 149/274] [Batch classify loss: 4.987705] 
[Epoch 4/10] [Batch 150/274] [Batch classify loss: 4.412263] 
[Epoch 4/10] [Batch 151/274] [Batch classify loss: 5.423281] 
[Epoch 4/10] [Batch 152/274] [Batch classify loss: 4.354836] 
[Epoch 4/10] [Batch 153/274] [Batch classify loss: 4.649546] 
[Epoch 4/10] [Batch 154/274] [Batch classify loss: 4.600281] 
[Epoch 4/10] [Batch 155/274] [Batch classify loss: 4.506521] 
[Epoch 4/10] [Batch 156/274] [Batch classify loss: 4.449057] 
[Epoch 4/10] [Batch 157/274] [Batch classify loss: 5.247589] 
[Epoch 4/10] [Batch 158/274] [Batch classify loss: 4.780232] 
[Epoch 4/10] [Batch 159/274] [Batch classify loss: 4.418644] 
[Epoch 4/10] [Batch 160/274] [Batch classify loss: 4.760463] 
[Epoch 4/10] [Batch 161/274] [Batch classify loss: 4.272837] 
[Epoch 4/10] [Batch 162/274] [Batch classify loss: 4.098718] 
[Epoch 4/10] [Batch 163/274] [Batch classify loss: 4.765265] 
[Epoch 4/10] [Batch 164/274] [Batch classify loss: 4.795877] 
[Epoch 4/10] [Batch 165/274] [Batch classify loss: 4.317249] 
[Epoch 4/10] [Batch 166/274] [Batch classify loss: 4.849473] 
[Epoch 4/10] [Batch 167/274] [Batch classify loss: 4.566763] 
[Epoch 4/10] [Batch 168/274] [Batch classify loss: 4.268551] 
[Epoch 4/10] [Batch 169/274] [Batch classify loss: 4.801156] 
[Epoch 4/10] [Batch 170/274] [Batch classify loss: 4.697529] 
[Epoch 4/10] [Batch 171/274] [Batch classify loss: 4.374227] 
[Epoch 4/10] [Batch 172/274] [Batch classify loss: 4.592339] 
[Epoch 4/10] [Batch 173/274] [Batch classify loss: 4.473057] 
[Epoch 4/10] [Batch 174/274] [Batch classify loss: 4.707769] 
[Epoch 4/10] [Batch 175/274] [Batch classify loss: 4.151381] 
[Epoch 4/10] [Batch 176/274] [Batch classify loss: 4.827060] 
[Epoch 4/10] [Batch 177/274] [Batch classify loss: 5.144910] 
[Epoch 4/10] [Batch 178/274] [Batch classify loss: 4.741335] 
[Epoch 4/10] [Batch 179/274] [Batch classify loss: 4.790945] 
[Epoch 4/10] [Batch 180/274] [Batch classify loss: 4.488336] 
[Epoch 4/10] [Batch 181/274] [Batch classify loss: 4.450160] 
[Epoch 4/10] [Batch 182/274] [Batch classify loss: 4.112638] 
[Epoch 4/10] [Batch 183/274] [Batch classify loss: 4.504099] 
[Epoch 4/10] [Batch 184/274] [Batch classify loss: 4.646749] 
[Epoch 4/10] [Batch 185/274] [Batch classify loss: 4.453879] 
[Epoch 4/10] [Batch 186/274] [Batch classify loss: 4.905084] 
[Epoch 4/10] [Batch 187/274] [Batch classify loss: 4.642250] 
[Epoch 4/10] [Batch 188/274] [Batch classify loss: 4.378647] 
[Epoch 4/10] [Batch 189/274] [Batch classify loss: 4.540956] 
[Epoch 4/10] [Batch 190/274] [Batch classify loss: 4.399638] 
[Epoch 4/10] [Batch 191/274] [Batch classify loss: 4.726834] 
[Epoch 4/10] [Batch 192/274] [Batch classify loss: 4.726050] 
[Epoch 4/10] [Batch 193/274] [Batch classify loss: 4.152780] 
[Epoch 4/10] [Batch 194/274] [Batch classify loss: 4.566310] 
[Epoch 4/10] [Batch 195/274] [Batch classify loss: 4.288638] 
[Epoch 4/10] [Batch 196/274] [Batch classify loss: 4.543920] 
[Epoch 4/10] [Batch 197/274] [Batch classify loss: 4.498529] 
[Epoch 4/10] [Batch 198/274] [Batch classify loss: 4.939737] 
[Epoch 4/10] [Batch 199/274] [Batch classify loss: 4.619643] 
[Epoch 4/10] [Batch 200/274] [Batch classify loss: 4.321939] 
[Epoch 4/10] [Batch 201/274] [Batch classify loss: 4.678328] 
[Epoch 4/10] [Batch 202/274] [Batch classify loss: 4.851447] 
[Epoch 4/10] [Batch 203/274] [Batch classify loss: 4.446669] 
[Epoch 4/10] [Batch 204/274] [Batch classify loss: 4.707467] 
[Epoch 4/10] [Batch 205/274] [Batch classify loss: 4.436737] 
[Epoch 4/10] [Batch 206/274] [Batch classify loss: 4.562285] 
[Epoch 4/10] [Batch 207/274] [Batch classify loss: 4.754642] 
[Epoch 4/10] [Batch 208/274] [Batch classify loss: 4.132883] 
[Epoch 4/10] [Batch 209/274] [Batch classify loss: 4.496243] 
[Epoch 4/10] [Batch 210/274] [Batch classify loss: 4.602600] 
[Epoch 4/10] [Batch 211/274] [Batch classify loss: 4.866573] 
[Epoch 4/10] [Batch 212/274] [Batch classify loss: 4.448192] 
[Epoch 4/10] [Batch 213/274] [Batch classify loss: 4.862393] 
[Epoch 4/10] [Batch 214/274] [Batch classify loss: 5.003207] 
[Epoch 4/10] [Batch 215/274] [Batch classify loss: 4.722224] 
[Epoch 4/10] [Batch 216/274] [Batch classify loss: 4.458091] 
[Epoch 4/10] [Batch 217/274] [Batch classify loss: 4.456816] 
[Epoch 4/10] [Batch 218/274] [Batch classify loss: 4.555767] 
[Epoch 4/10] [Batch 219/274] [Batch classify loss: 4.509048] 
[Epoch 4/10] [Batch 220/274] [Batch classify loss: 4.454476] 
[Epoch 4/10] [Batch 221/274] [Batch classify loss: 4.485846] 
[Epoch 4/10] [Batch 222/274] [Batch classify loss: 4.770154] 
[Epoch 4/10] [Batch 223/274] [Batch classify loss: 4.057358] 
[Epoch 4/10] [Batch 224/274] [Batch classify loss: 4.510845] 
[Epoch 4/10] [Batch 225/274] [Batch classify loss: 4.496129] 
[Epoch 4/10] [Batch 226/274] [Batch classify loss: 3.846875] 
[Epoch 4/10] [Batch 227/274] [Batch classify loss: 4.548933] 
[Epoch 4/10] [Batch 228/274] [Batch classify loss: 4.641382] 
[Epoch 4/10] [Batch 229/274] [Batch classify loss: 4.779392] 
[Epoch 4/10] [Batch 230/274] [Batch classify loss: 4.140364] 
[Epoch 4/10] [Batch 231/274] [Batch classify loss: 4.512132] 
[Epoch 4/10] [Batch 232/274] [Batch classify loss: 4.429219] 
[Epoch 4/10] [Batch 233/274] [Batch classify loss: 5.016321] 
[Epoch 4/10] [Batch 234/274] [Batch classify loss: 4.704739] 
[Epoch 4/10] [Batch 235/274] [Batch classify loss: 4.711523] 
[Epoch 4/10] [Batch 236/274] [Batch classify loss: 4.943594] 
[Epoch 4/10] [Batch 237/274] [Batch classify loss: 4.235787] 
[Epoch 4/10] [Batch 238/274] [Batch classify loss: 4.631981] 
[Epoch 4/10] [Batch 239/274] [Batch classify loss: 4.868682] 
[Epoch 4/10] [Batch 240/274] [Batch classify loss: 4.116569] 
[Epoch 4/10] [Batch 241/274] [Batch classify loss: 4.530295] 
[Epoch 4/10] [Batch 242/274] [Batch classify loss: 4.190475] 
[Epoch 4/10] [Batch 243/274] [Batch classify loss: 4.650048] 
[Epoch 4/10] [Batch 244/274] [Batch classify loss: 4.251925] 
[Epoch 4/10] [Batch 245/274] [Batch classify loss: 4.270867] 
[Epoch 4/10] [Batch 246/274] [Batch classify loss: 4.287149] 
[Epoch 4/10] [Batch 247/274] [Batch classify loss: 4.962982] 
[Epoch 4/10] [Batch 248/274] [Batch classify loss: 4.242499] 
[Epoch 4/10] [Batch 249/274] [Batch classify loss: 4.185497] 
[Epoch 4/10] [Batch 250/274] [Batch classify loss: 4.490405] 
[Epoch 4/10] [Batch 251/274] [Batch classify loss: 4.815016] 
[Epoch 4/10] [Batch 252/274] [Batch classify loss: 4.996589] 
[Epoch 4/10] [Batch 253/274] [Batch classify loss: 4.475590] 
[Epoch 4/10] [Batch 254/274] [Batch classify loss: 4.465451] 
[Epoch 4/10] [Batch 255/274] [Batch classify loss: 4.646926] 
[Epoch 4/10] [Batch 256/274] [Batch classify loss: 4.914098] 
[Epoch 4/10] [Batch 257/274] [Batch classify loss: 4.496054] 
[Epoch 4/10] [Batch 258/274] [Batch classify loss: 4.217555] 
[Epoch 4/10] [Batch 259/274] [Batch classify loss: 4.108231] 
[Epoch 4/10] [Batch 260/274] [Batch classify loss: 4.551860] 
[Epoch 4/10] [Batch 261/274] [Batch classify loss: 4.501269] 
[Epoch 4/10] [Batch 262/274] [Batch classify loss: 4.563116] 
[Epoch 4/10] [Batch 263/274] [Batch classify loss: 4.725848] 
[Epoch 4/10] [Batch 264/274] [Batch classify loss: 4.733714] 
[Epoch 4/10] [Batch 265/274] [Batch classify loss: 4.225838] 
[Epoch 4/10] [Batch 266/274] [Batch classify loss: 4.505308] 
[Epoch 4/10] [Batch 267/274] [Batch classify loss: 4.456682] 
[Epoch 4/10] [Batch 268/274] [Batch classify loss: 4.298545] 
[Epoch 4/10] [Batch 269/274] [Batch classify loss: 4.526441] 
[Epoch 4/10] [Batch 270/274] [Batch classify loss: 4.208965] 
[Epoch 4/10] [Batch 271/274] [Batch classify loss: 4.349908] 
[Epoch 4/10] [Batch 272/274] [Batch classify loss: 4.500968] 
[Epoch 4/10] [Batch 273/274] [Batch classify loss: 4.507701] 
[Epoch 4/10] [Batch 274/274] [Batch classify loss: 4.037662] 
0004 epoch mmat trained classifier accuary on the clean testing examples:94.6335%
0004 epoch mmat trained classifier loss on the clean testing examples:0.2240
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2850%
mmat trained classifier loss on adversarial testset:4.524903774261475
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-cle
4epoch learning rate:0.1
[Epoch 5/10] [Batch 1/274] [Batch classify loss: 1.897622] 
[Epoch 5/10] [Batch 2/274] [Batch classify loss: 2.701377] 
[Epoch 5/10] [Batch 3/274] [Batch classify loss: 2.732987] 
[Epoch 5/10] [Batch 4/274] [Batch classify loss: 2.614915] 
[Epoch 5/10] [Batch 5/274] [Batch classify loss: 3.356987] 
[Epoch 5/10] [Batch 6/274] [Batch classify loss: 3.208023] 
[Epoch 5/10] [Batch 7/274] [Batch classify loss: 3.520857] 
[Epoch 5/10] [Batch 8/274] [Batch classify loss: 3.577346] 
[Epoch 5/10] [Batch 9/274] [Batch classify loss: 3.770848] 
[Epoch 5/10] [Batch 10/274] [Batch classify loss: 3.674661] 
[Epoch 5/10] [Batch 11/274] [Batch classify loss: 3.824005] 
[Epoch 5/10] [Batch 12/274] [Batch classify loss: 4.024127] 
[Epoch 5/10] [Batch 13/274] [Batch classify loss: 3.627800] 
[Epoch 5/10] [Batch 14/274] [Batch classify loss: 4.092685] 
[Epoch 5/10] [Batch 15/274] [Batch classify loss: 4.196362] 
[Epoch 5/10] [Batch 16/274] [Batch classify loss: 4.103839] 
[Epoch 5/10] [Batch 17/274] [Batch classify loss: 3.747804] 
[Epoch 5/10] [Batch 18/274] [Batch classify loss: 4.020311] 
[Epoch 5/10] [Batch 19/274] [Batch classify loss: 4.250463] 
[Epoch 5/10] [Batch 20/274] [Batch classify loss: 4.249125] 
[Epoch 5/10] [Batch 21/274] [Batch classify loss: 4.296381] 
[Epoch 5/10] [Batch 22/274] [Batch classify loss: 3.919384] 
[Epoch 5/10] [Batch 23/274] [Batch classify loss: 4.001749] 
[Epoch 5/10] [Batch 24/274] [Batch classify loss: 3.705240] 
[Epoch 5/10] [Batch 25/274] [Batch classify loss: 3.776945] 
[Epoch 5/10] [Batch 26/274] [Batch classify loss: 4.157941] 
[Epoch 5/10] [Batch 27/274] [Batch classify loss: 4.401146] 
[Epoch 5/10] [Batch 28/274] [Batch classify loss: 4.031942] 
[Epoch 5/10] [Batch 29/274] [Batch classify loss: 4.881288] 
[Epoch 5/10] [Batch 30/274] [Batch classify loss: 4.173878] 
[Epoch 5/10] [Batch 31/274] [Batch classify loss: 4.210630] 
[Epoch 5/10] [Batch 32/274] [Batch classify loss: 4.537127] 
[Epoch 5/10] [Batch 33/274] [Batch classify loss: 4.435489] 
[Epoch 5/10] [Batch 34/274] [Batch classify loss: 3.972035] 
[Epoch 5/10] [Batch 35/274] [Batch classify loss: 4.526861] 
[Epoch 5/10] [Batch 36/274] [Batch classify loss: 4.231884] 
[Epoch 5/10] [Batch 37/274] [Batch classify loss: 4.585341] 
[Epoch 5/10] [Batch 38/274] [Batch classify loss: 4.344533] 
[Epoch 5/10] [Batch 39/274] [Batch classify loss: 4.534916] 
[Epoch 5/10] [Batch 40/274] [Batch classify loss: 4.118795] 
[Epoch 5/10] [Batch 41/274] [Batch classify loss: 4.624965] 
[Epoch 5/10] [Batch 42/274] [Batch classify loss: 4.691027] 
[Epoch 5/10] [Batch 43/274] [Batch classify loss: 4.338295] 
[Epoch 5/10] [Batch 44/274] [Batch classify loss: 4.451769] 
[Epoch 5/10] [Batch 45/274] [Batch classify loss: 4.334586] 
[Epoch 5/10] [Batch 46/274] [Batch classify loss: 4.643403] 
[Epoch 5/10] [Batch 47/274] [Batch classify loss: 4.800701] 
[Epoch 5/10] [Batch 48/274] [Batch classify loss: 4.176667] 
[Epoch 5/10] [Batch 49/274] [Batch classify loss: 4.250358] 
[Epoch 5/10] [Batch 50/274] [Batch classify loss: 4.679523] 
[Epoch 5/10] [Batch 51/274] [Batch classify loss: 4.394377] 
[Epoch 5/10] [Batch 52/274] [Batch classify loss: 4.476989] 
[Epoch 5/10] [Batch 53/274] [Batch classify loss: 4.256153] 
[Epoch 5/10] [Batch 54/274] [Batch classify loss: 4.213690] 
[Epoch 5/10] [Batch 55/274] [Batch classify loss: 4.705605] 
[Epoch 5/10] [Batch 56/274] [Batch classify loss: 4.593213] 
[Epoch 5/10] [Batch 57/274] [Batch classify loss: 4.794480] 
[Epoch 5/10] [Batch 58/274] [Batch classify loss: 4.586950] 
[Epoch 5/10] [Batch 59/274] [Batch classify loss: 4.433130] 
[Epoch 5/10] [Batch 60/274] [Batch classify loss: 4.633629] 
[Epoch 5/10] [Batch 61/274] [Batch classify loss: 4.814980] 
[Epoch 5/10] [Batch 62/274] [Batch classify loss: 5.012938] 
[Epoch 5/10] [Batch 63/274] [Batch classify loss: 4.252825] 
[Epoch 5/10] [Batch 64/274] [Batch classify loss: 4.316524] 
[Epoch 5/10] [Batch 65/274] [Batch classify loss: 4.636595] 
[Epoch 5/10] [Batch 66/274] [Batch classify loss: 3.885389] 
[Epoch 5/10] [Batch 67/274] [Batch classify loss: 4.263728] 
[Epoch 5/10] [Batch 68/274] [Batch classify loss: 4.342231] 
[Epoch 5/10] [Batch 69/274] [Batch classify loss: 4.963264] 
[Epoch 5/10] [Batch 70/274] [Batch classify loss: 4.354465] 
[Epoch 5/10] [Batch 71/274] [Batch classify loss: 4.367033] 
[Epoch 5/10] [Batch 72/274] [Batch classify loss: 4.790898] 
[Epoch 5/10] [Batch 73/274] [Batch classify loss: 4.132138] 
[Epoch 5/10] [Batch 74/274] [Batch classify loss: 5.133286] 
[Epoch 5/10] [Batch 75/274] [Batch classify loss: 4.363273] 
[Epoch 5/10] [Batch 76/274] [Batch classify loss: 4.490553] 
[Epoch 5/10] [Batch 77/274] [Batch classify loss: 4.498715] 
[Epoch 5/10] [Batch 78/274] [Batch classify loss: 4.552238] 
[Epoch 5/10] [Batch 79/274] [Batch classify loss: 4.467515] 
[Epoch 5/10] [Batch 80/274] [Batch classify loss: 4.537769] 
[Epoch 5/10] [Batch 81/274] [Batch classify loss: 4.371702] 
[Epoch 5/10] [Batch 82/274] [Batch classify loss: 4.559737] 
[Epoch 5/10] [Batch 83/274] [Batch classify loss: 4.783568] 
[Epoch 5/10] [Batch 84/274] [Batch classify loss: 4.932415] 
[Epoch 5/10] [Batch 85/274] [Batch classify loss: 4.356123] 
[Epoch 5/10] [Batch 86/274] [Batch classify loss: 4.675238] 
[Epoch 5/10] [Batch 87/274] [Batch classify loss: 4.930051] 
[Epoch 5/10] [Batch 88/274] [Batch classify loss: 4.303776] 
[Epoch 5/10] [Batch 89/274] [Batch classify loss: 4.590247] 
[Epoch 5/10] [Batch 90/274] [Batch classify loss: 4.185529] 
[Epoch 5/10] [Batch 91/274] [Batch classify loss: 4.825504] 
[Epoch 5/10] [Batch 92/274] [Batch classify loss: 4.305850] 
[Epoch 5/10] [Batch 93/274] [Batch classify loss: 5.201818] 
[Epoch 5/10] [Batch 94/274] [Batch classify loss: 4.970843] 
[Epoch 5/10] [Batch 95/274] [Batch classify loss: 4.653134] 
[Epoch 5/10] [Batch 96/274] [Batch classify loss: 4.636569] 
[Epoch 5/10] [Batch 97/274] [Batch classify loss: 4.629928] 
[Epoch 5/10] [Batch 98/274] [Batch classify loss: 4.269891] 
[Epoch 5/10] [Batch 99/274] [Batch classify loss: 4.890073] 
[Epoch 5/10] [Batch 100/274] [Batch classify loss: 4.061057] 
[Epoch 5/10] [Batch 101/274] [Batch classify loss: 4.342884] 
[Epoch 5/10] [Batch 102/274] [Batch classify loss: 4.441337] 
[Epoch 5/10] [Batch 103/274] [Batch classify loss: 4.515108] 
[Epoch 5/10] [Batch 104/274] [Batch classify loss: 4.747414] 
[Epoch 5/10] [Batch 105/274] [Batch classify loss: 4.827603] 
[Epoch 5/10] [Batch 106/274] [Batch classify loss: 4.507250] 
[Epoch 5/10] [Batch 107/274] [Batch classify loss: 4.692708] 
[Epoch 5/10] [Batch 108/274] [Batch classify loss: 4.516596] 
[Epoch 5/10] [Batch 109/274] [Batch classify loss: 4.484795] 
[Epoch 5/10] [Batch 110/274] [Batch classify loss: 4.723866] 
[Epoch 5/10] [Batch 111/274] [Batch classify loss: 4.557952] 
[Epoch 5/10] [Batch 112/274] [Batch classify loss: 4.504674] 
[Epoch 5/10] [Batch 113/274] [Batch classify loss: 5.038487] 
[Epoch 5/10] [Batch 114/274] [Batch classify loss: 4.638936] 
[Epoch 5/10] [Batch 115/274] [Batch classify loss: 4.826079] 
[Epoch 5/10] [Batch 116/274] [Batch classify loss: 4.586012] 
[Epoch 5/10] [Batch 117/274] [Batch classify loss: 5.211043] 
[Epoch 5/10] [Batch 118/274] [Batch classify loss: 4.662344] 
[Epoch 5/10] [Batch 119/274] [Batch classify loss: 4.343535] 
[Epoch 5/10] [Batch 120/274] [Batch classify loss: 4.532754] 
[Epoch 5/10] [Batch 121/274] [Batch classify loss: 4.714128] 
[Epoch 5/10] [Batch 122/274] [Batch classify loss: 4.758609] 
[Epoch 5/10] [Batch 123/274] [Batch classify loss: 4.902461] 
[Epoch 5/10] [Batch 124/274] [Batch classify loss: 4.336700] 
[Epoch 5/10] [Batch 125/274] [Batch classify loss: 4.548926] 
[Epoch 5/10] [Batch 126/274] [Batch classify loss: 4.508021] 
[Epoch 5/10] [Batch 127/274] [Batch classify loss: 4.213497] 
[Epoch 5/10] [Batch 128/274] [Batch classify loss: 4.926635] 
[Epoch 5/10] [Batch 129/274] [Batch classify loss: 4.244085] 
[Epoch 5/10] [Batch 130/274] [Batch classify loss: 4.455529] 
[Epoch 5/10] [Batch 131/274] [Batch classify loss: 5.101717] 
[Epoch 5/10] [Batch 132/274] [Batch classify loss: 4.853632] 
[Epoch 5/10] [Batch 133/274] [Batch classify loss: 4.818620] 
[Epoch 5/10] [Batch 134/274] [Batch classify loss: 4.602846] 
[Epoch 5/10] [Batch 135/274] [Batch classify loss: 4.721505] 
[Epoch 5/10] [Batch 136/274] [Batch classify loss: 4.440904] 
[Epoch 5/10] [Batch 137/274] [Batch classify loss: 4.468421] 
[Epoch 5/10] [Batch 138/274] [Batch classify loss: 4.579161] 
[Epoch 5/10] [Batch 139/274] [Batch classify loss: 4.829048] 
[Epoch 5/10] [Batch 140/274] [Batch classify loss: 4.623262] 
[Epoch 5/10] [Batch 141/274] [Batch classify loss: 4.443312] 
[Epoch 5/10] [Batch 142/274] [Batch classify loss: 4.474108] 
[Epoch 5/10] [Batch 143/274] [Batch classify loss: 4.673184] 
[Epoch 5/10] [Batch 144/274] [Batch classify loss: 4.357975] 
[Epoch 5/10] [Batch 145/274] [Batch classify loss: 5.023172] 
[Epoch 5/10] [Batch 146/274] [Batch classify loss: 4.581154] 
[Epoch 5/10] [Batch 147/274] [Batch classify loss: 4.681883] 
[Epoch 5/10] [Batch 148/274] [Batch classify loss: 4.914728] 
[Epoch 5/10] [Batch 149/274] [Batch classify loss: 4.730837] 
[Epoch 5/10] [Batch 150/274] [Batch classify loss: 4.362197] 
[Epoch 5/10] [Batch 151/274] [Batch classify loss: 4.553207] 
[Epoch 5/10] [Batch 152/274] [Batch classify loss: 4.330694] 
[Epoch 5/10] [Batch 153/274] [Batch classify loss: 4.731411] 
[Epoch 5/10] [Batch 154/274] [Batch classify loss: 4.469049] 
[Epoch 5/10] [Batch 155/274] [Batch classify loss: 4.686053] 
[Epoch 5/10] [Batch 156/274] [Batch classify loss: 4.946232] 
[Epoch 5/10] [Batch 157/274] [Batch classify loss: 4.817051] 
[Epoch 5/10] [Batch 158/274] [Batch classify loss: 4.444417] 
[Epoch 5/10] [Batch 159/274] [Batch classify loss: 4.820678] 
[Epoch 5/10] [Batch 160/274] [Batch classify loss: 4.536221] 
[Epoch 5/10] [Batch 161/274] [Batch classify loss: 4.558580] 
[Epoch 5/10] [Batch 162/274] [Batch classify loss: 4.849440] 
[Epoch 5/10] [Batch 163/274] [Batch classify loss: 4.521455] 
[Epoch 5/10] [Batch 164/274] [Batch classify loss: 4.437901] 
[Epoch 5/10] [Batch 165/274] [Batch classify loss: 4.410535] 
[Epoch 5/10] [Batch 166/274] [Batch classify loss: 4.855483] 
[Epoch 5/10] [Batch 167/274] [Batch classify loss: 4.875469] 
[Epoch 5/10] [Batch 168/274] [Batch classify loss: 4.540966] 
[Epoch 5/10] [Batch 169/274] [Batch classify loss: 5.032514] 
[Epoch 5/10] [Batch 170/274] [Batch classify loss: 4.399863] 
[Epoch 5/10] [Batch 171/274] [Batch classify loss: 4.220800] 
[Epoch 5/10] [Batch 172/274] [Batch classify loss: 4.715515] 
[Epoch 5/10] [Batch 173/274] [Batch classify loss: 4.659316] 
[Epoch 5/10] [Batch 174/274] [Batch classify loss: 5.014543] 
[Epoch 5/10] [Batch 175/274] [Batch classify loss: 4.388617] 
[Epoch 5/10] [Batch 176/274] [Batch classify loss: 4.751451] 
[Epoch 5/10] [Batch 177/274] [Batch classify loss: 4.701732] 
[Epoch 5/10] [Batch 178/274] [Batch classify loss: 4.582275] 
[Epoch 5/10] [Batch 179/274] [Batch classify loss: 4.653033] 
[Epoch 5/10] [Batch 180/274] [Batch classify loss: 4.572519] 
[Epoch 5/10] [Batch 181/274] [Batch classify loss: 5.041384] 
[Epoch 5/10] [Batch 182/274] [Batch classify loss: 4.616645] 
[Epoch 5/10] [Batch 183/274] [Batch classify loss: 4.239900] 
[Epoch 5/10] [Batch 184/274] [Batch classify loss: 5.111532] 
[Epoch 5/10] [Batch 185/274] [Batch classify loss: 4.819965] 
[Epoch 5/10] [Batch 186/274] [Batch classify loss: 4.217908] 
[Epoch 5/10] [Batch 187/274] [Batch classify loss: 5.064694] 
[Epoch 5/10] [Batch 188/274] [Batch classify loss: 4.575555] 
[Epoch 5/10] [Batch 189/274] [Batch classify loss: 5.154573] 
[Epoch 5/10] [Batch 190/274] [Batch classify loss: 4.458467] 
[Epoch 5/10] [Batch 191/274] [Batch classify loss: 4.477096] 
[Epoch 5/10] [Batch 192/274] [Batch classify loss: 4.437388] 
[Epoch 5/10] [Batch 193/274] [Batch classify loss: 4.837892] 
[Epoch 5/10] [Batch 194/274] [Batch classify loss: 4.959612] 
[Epoch 5/10] [Batch 195/274] [Batch classify loss: 5.104538] 
[Epoch 5/10] [Batch 196/274] [Batch classify loss: 4.453607] 
[Epoch 5/10] [Batch 197/274] [Batch classify loss: 5.048091] 
[Epoch 5/10] [Batch 198/274] [Batch classify loss: 4.476396] 
[Epoch 5/10] [Batch 199/274] [Batch classify loss: 3.984638] 
[Epoch 5/10] [Batch 200/274] [Batch classify loss: 4.225403] 
[Epoch 5/10] [Batch 201/274] [Batch classify loss: 4.322299] 
[Epoch 5/10] [Batch 202/274] [Batch classify loss: 4.528575] 
[Epoch 5/10] [Batch 203/274] [Batch classify loss: 4.504675] 
[Epoch 5/10] [Batch 204/274] [Batch classify loss: 4.821686] 
[Epoch 5/10] [Batch 205/274] [Batch classify loss: 4.264671] 
[Epoch 5/10] [Batch 206/274] [Batch classify loss: 4.497612] 
[Epoch 5/10] [Batch 207/274] [Batch classify loss: 4.278940] 
[Epoch 5/10] [Batch 208/274] [Batch classify loss: 4.341568] 
[Epoch 5/10] [Batch 209/274] [Batch classify loss: 4.751228] 
[Epoch 5/10] [Batch 210/274] [Batch classify loss: 4.888191] 
[Epoch 5/10] [Batch 211/274] [Batch classify loss: 4.266845] 
[Epoch 5/10] [Batch 212/274] [Batch classify loss: 4.402454] 
[Epoch 5/10] [Batch 213/274] [Batch classify loss: 4.539325] 
[Epoch 5/10] [Batch 214/274] [Batch classify loss: 4.398159] 
[Epoch 5/10] [Batch 215/274] [Batch classify loss: 4.353114] 
[Epoch 5/10] [Batch 216/274] [Batch classify loss: 4.697043] 
[Epoch 5/10] [Batch 217/274] [Batch classify loss: 4.718019] 
[Epoch 5/10] [Batch 218/274] [Batch classify loss: 4.546061] 
[Epoch 5/10] [Batch 219/274] [Batch classify loss: 4.748442] 
[Epoch 5/10] [Batch 220/274] [Batch classify loss: 5.337007] 
[Epoch 5/10] [Batch 221/274] [Batch classify loss: 4.552039] 
[Epoch 5/10] [Batch 222/274] [Batch classify loss: 4.770582] 
[Epoch 5/10] [Batch 223/274] [Batch classify loss: 4.351489] 
[Epoch 5/10] [Batch 224/274] [Batch classify loss: 4.495111] 
[Epoch 5/10] [Batch 225/274] [Batch classify loss: 4.661213] 
[Epoch 5/10] [Batch 226/274] [Batch classify loss: 4.701702] 
[Epoch 5/10] [Batch 227/274] [Batch classify loss: 5.117384] 
[Epoch 5/10] [Batch 228/274] [Batch classify loss: 5.220620] 
[Epoch 5/10] [Batch 229/274] [Batch classify loss: 4.376222] 
[Epoch 5/10] [Batch 230/274] [Batch classify loss: 4.774706] 
[Epoch 5/10] [Batch 231/274] [Batch classify loss: 4.610983] 
[Epoch 5/10] [Batch 232/274] [Batch classify loss: 4.652868] 
[Epoch 5/10] [Batch 233/274] [Batch classify loss: 4.871287] 
[Epoch 5/10] [Batch 234/274] [Batch classify loss: 4.775103] 
[Epoch 5/10] [Batch 235/274] [Batch classify loss: 3.883083] 
[Epoch 5/10] [Batch 236/274] [Batch classify loss: 4.123353] 
[Epoch 5/10] [Batch 237/274] [Batch classify loss: 4.290209] 
[Epoch 5/10] [Batch 238/274] [Batch classify loss: 4.316520] 
[Epoch 5/10] [Batch 239/274] [Batch classify loss: 4.284194] 
[Epoch 5/10] [Batch 240/274] [Batch classify loss: 4.507051] 
[Epoch 5/10] [Batch 241/274] [Batch classify loss: 4.387195] 
[Epoch 5/10] [Batch 242/274] [Batch classify loss: 4.560722] 
[Epoch 5/10] [Batch 243/274] [Batch classify loss: 4.450622] 
[Epoch 5/10] [Batch 244/274] [Batch classify loss: 4.612745] 
[Epoch 5/10] [Batch 245/274] [Batch classify loss: 4.527448] 
[Epoch 5/10] [Batch 246/274] [Batch classify loss: 4.714051] 
[Epoch 5/10] [Batch 247/274] [Batch classify loss: 4.635046] 
[Epoch 5/10] [Batch 248/274] [Batch classify loss: 4.491815] 
[Epoch 5/10] [Batch 249/274] [Batch classify loss: 4.559941] 
[Epoch 5/10] [Batch 250/274] [Batch classify loss: 4.211112] 
[Epoch 5/10] [Batch 251/274] [Batch classify loss: 4.777222] 
[Epoch 5/10] [Batch 252/274] [Batch classify loss: 4.615536] 
[Epoch 5/10] [Batch 253/274] [Batch classify loss: 4.841955] 
[Epoch 5/10] [Batch 254/274] [Batch classify loss: 4.430739] 
[Epoch 5/10] [Batch 255/274] [Batch classify loss: 5.198861] 
[Epoch 5/10] [Batch 256/274] [Batch classify loss: 4.280884] 
[Epoch 5/10] [Batch 257/274] [Batch classify loss: 4.915745] 
[Epoch 5/10] [Batch 258/274] [Batch classify loss: 4.437012] 
[Epoch 5/10] [Batch 259/274] [Batch classify loss: 4.459194] 
[Epoch 5/10] [Batch 260/274] [Batch classify loss: 4.823473] 
[Epoch 5/10] [Batch 261/274] [Batch classify loss: 4.530710] 
[Epoch 5/10] [Batch 262/274] [Batch classify loss: 4.276859] 
[Epoch 5/10] [Batch 263/274] [Batch classify loss: 4.624208] 
[Epoch 5/10] [Batch 264/274] [Batch classify loss: 4.341249] 
[Epoch 5/10] [Batch 265/274] [Batch classify loss: 4.612978] 
[Epoch 5/10] [Batch 266/274] [Batch classify loss: 3.952229] 
[Epoch 5/10] [Batch 267/274] [Batch classify loss: 4.919633] 
[Epoch 5/10] [Batch 268/274] [Batch classify loss: 4.238193] 
[Epoch 5/10] [Batch 269/274] [Batch classify loss: 4.799397] 
[Epoch 5/10] [Batch 270/274] [Batch classify loss: 4.281957] 
[Epoch 5/10] [Batch 271/274] [Batch classify loss: 4.549821] 
[Epoch 5/10] [Batch 272/274] [Batch classify loss: 4.823818] 
[Epoch 5/10] [Batch 273/274] [Batch classify loss: 4.828567] 
[Epoch 5/10] [Batch 274/274] [Batch classify loss: 4.599428] 
0005 epoch mmat trained classifier accuary on the clean testing examples:94.7910%
0005 epoch mmat trained classifier loss on the clean testing examples:0.2229
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2389%
mmat trained classifier loss on adversarial testset:4.532322883605957
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-cle
5epoch learning rate:0.1
[Epoch 6/10] [Batch 1/274] [Batch classify loss: 1.534590] 
[Epoch 6/10] [Batch 2/274] [Batch classify loss: 2.150418] 
[Epoch 6/10] [Batch 3/274] [Batch classify loss: 2.266922] 
[Epoch 6/10] [Batch 4/274] [Batch classify loss: 2.369261] 
[Epoch 6/10] [Batch 5/274] [Batch classify loss: 2.665898] 
[Epoch 6/10] [Batch 6/274] [Batch classify loss: 2.550976] 
[Epoch 6/10] [Batch 7/274] [Batch classify loss: 2.633501] 
[Epoch 6/10] [Batch 8/274] [Batch classify loss: 2.905196] 
[Epoch 6/10] [Batch 9/274] [Batch classify loss: 3.128608] 
[Epoch 6/10] [Batch 10/274] [Batch classify loss: 3.074416] 
[Epoch 6/10] [Batch 11/274] [Batch classify loss: 2.814837] 
[Epoch 6/10] [Batch 12/274] [Batch classify loss: 2.990202] 
[Epoch 6/10] [Batch 13/274] [Batch classify loss: 3.038139] 
[Epoch 6/10] [Batch 14/274] [Batch classify loss: 3.003591] 
[Epoch 6/10] [Batch 15/274] [Batch classify loss: 3.333733] 
[Epoch 6/10] [Batch 16/274] [Batch classify loss: 3.176540] 
[Epoch 6/10] [Batch 17/274] [Batch classify loss: 3.226604] 
[Epoch 6/10] [Batch 18/274] [Batch classify loss: 3.328422] 
[Epoch 6/10] [Batch 19/274] [Batch classify loss: 3.597354] 
[Epoch 6/10] [Batch 20/274] [Batch classify loss: 3.259161] 
[Epoch 6/10] [Batch 21/274] [Batch classify loss: 3.519726] 
[Epoch 6/10] [Batch 22/274] [Batch classify loss: 3.196707] 
[Epoch 6/10] [Batch 23/274] [Batch classify loss: 3.829851] 
[Epoch 6/10] [Batch 24/274] [Batch classify loss: 3.473327] 
[Epoch 6/10] [Batch 25/274] [Batch classify loss: 3.479792] 
[Epoch 6/10] [Batch 26/274] [Batch classify loss: 3.628251] 
[Epoch 6/10] [Batch 27/274] [Batch classify loss: 3.246887] 
[Epoch 6/10] [Batch 28/274] [Batch classify loss: 3.613039] 
[Epoch 6/10] [Batch 29/274] [Batch classify loss: 3.673522] 
[Epoch 6/10] [Batch 30/274] [Batch classify loss: 3.846597] 
[Epoch 6/10] [Batch 31/274] [Batch classify loss: 3.576796] 
[Epoch 6/10] [Batch 32/274] [Batch classify loss: 3.812273] 
[Epoch 6/10] [Batch 33/274] [Batch classify loss: 3.516159] 
[Epoch 6/10] [Batch 34/274] [Batch classify loss: 3.505349] 
[Epoch 6/10] [Batch 35/274] [Batch classify loss: 3.879399] 
[Epoch 6/10] [Batch 36/274] [Batch classify loss: 3.731577] 
[Epoch 6/10] [Batch 37/274] [Batch classify loss: 3.747721] 
[Epoch 6/10] [Batch 38/274] [Batch classify loss: 3.882186] 
[Epoch 6/10] [Batch 39/274] [Batch classify loss: 3.704964] 
[Epoch 6/10] [Batch 40/274] [Batch classify loss: 3.894319] 
[Epoch 6/10] [Batch 41/274] [Batch classify loss: 4.061430] 
[Epoch 6/10] [Batch 42/274] [Batch classify loss: 3.988539] 
[Epoch 6/10] [Batch 43/274] [Batch classify loss: 4.077838] 
[Epoch 6/10] [Batch 44/274] [Batch classify loss: 4.195364] 
[Epoch 6/10] [Batch 45/274] [Batch classify loss: 3.975677] 
[Epoch 6/10] [Batch 46/274] [Batch classify loss: 3.899480] 
[Epoch 6/10] [Batch 47/274] [Batch classify loss: 3.856869] 
[Epoch 6/10] [Batch 48/274] [Batch classify loss: 4.147706] 
[Epoch 6/10] [Batch 49/274] [Batch classify loss: 3.985857] 
[Epoch 6/10] [Batch 50/274] [Batch classify loss: 4.312181] 
[Epoch 6/10] [Batch 51/274] [Batch classify loss: 4.264763] 
[Epoch 6/10] [Batch 52/274] [Batch classify loss: 4.248461] 
[Epoch 6/10] [Batch 53/274] [Batch classify loss: 3.602417] 
[Epoch 6/10] [Batch 54/274] [Batch classify loss: 4.326755] 
[Epoch 6/10] [Batch 55/274] [Batch classify loss: 3.777453] 
[Epoch 6/10] [Batch 56/274] [Batch classify loss: 4.314267] 
[Epoch 6/10] [Batch 57/274] [Batch classify loss: 4.421676] 
[Epoch 6/10] [Batch 58/274] [Batch classify loss: 4.206517] 
[Epoch 6/10] [Batch 59/274] [Batch classify loss: 3.923706] 
[Epoch 6/10] [Batch 60/274] [Batch classify loss: 3.956239] 
[Epoch 6/10] [Batch 61/274] [Batch classify loss: 4.468714] 
[Epoch 6/10] [Batch 62/274] [Batch classify loss: 4.358214] 
[Epoch 6/10] [Batch 63/274] [Batch classify loss: 3.924539] 
[Epoch 6/10] [Batch 64/274] [Batch classify loss: 3.877192] 
[Epoch 6/10] [Batch 65/274] [Batch classify loss: 4.089334] 
[Epoch 6/10] [Batch 66/274] [Batch classify loss: 4.271523] 
[Epoch 6/10] [Batch 67/274] [Batch classify loss: 4.510812] 
[Epoch 6/10] [Batch 68/274] [Batch classify loss: 4.383271] 
[Epoch 6/10] [Batch 69/274] [Batch classify loss: 3.890919] 
[Epoch 6/10] [Batch 70/274] [Batch classify loss: 4.081052] 
[Epoch 6/10] [Batch 71/274] [Batch classify loss: 4.128136] 
[Epoch 6/10] [Batch 72/274] [Batch classify loss: 4.453222] 
[Epoch 6/10] [Batch 73/274] [Batch classify loss: 4.692993] 
[Epoch 6/10] [Batch 74/274] [Batch classify loss: 4.273615] 
[Epoch 6/10] [Batch 75/274] [Batch classify loss: 4.333427] 
[Epoch 6/10] [Batch 76/274] [Batch classify loss: 3.689586] 
[Epoch 6/10] [Batch 77/274] [Batch classify loss: 4.106745] 
[Epoch 6/10] [Batch 78/274] [Batch classify loss: 4.490863] 
[Epoch 6/10] [Batch 79/274] [Batch classify loss: 4.491649] 
[Epoch 6/10] [Batch 80/274] [Batch classify loss: 4.029848] 
[Epoch 6/10] [Batch 81/274] [Batch classify loss: 3.894086] 
[Epoch 6/10] [Batch 82/274] [Batch classify loss: 4.793871] 
[Epoch 6/10] [Batch 83/274] [Batch classify loss: 4.208039] 
[Epoch 6/10] [Batch 84/274] [Batch classify loss: 4.223959] 
[Epoch 6/10] [Batch 85/274] [Batch classify loss: 4.282531] 
[Epoch 6/10] [Batch 86/274] [Batch classify loss: 3.706018] 
[Epoch 6/10] [Batch 87/274] [Batch classify loss: 4.157517] 
[Epoch 6/10] [Batch 88/274] [Batch classify loss: 4.401381] 
[Epoch 6/10] [Batch 89/274] [Batch classify loss: 4.325574] 
[Epoch 6/10] [Batch 90/274] [Batch classify loss: 4.497523] 
[Epoch 6/10] [Batch 91/274] [Batch classify loss: 4.185682] 
[Epoch 6/10] [Batch 92/274] [Batch classify loss: 4.104534] 
[Epoch 6/10] [Batch 93/274] [Batch classify loss: 3.972896] 
[Epoch 6/10] [Batch 94/274] [Batch classify loss: 4.082870] 
[Epoch 6/10] [Batch 95/274] [Batch classify loss: 4.209314] 
[Epoch 6/10] [Batch 96/274] [Batch classify loss: 3.760703] 
[Epoch 6/10] [Batch 97/274] [Batch classify loss: 4.202555] 
[Epoch 6/10] [Batch 98/274] [Batch classify loss: 4.447920] 
[Epoch 6/10] [Batch 99/274] [Batch classify loss: 4.531116] 
[Epoch 6/10] [Batch 100/274] [Batch classify loss: 4.518548] 
[Epoch 6/10] [Batch 101/274] [Batch classify loss: 4.286520] 
[Epoch 6/10] [Batch 102/274] [Batch classify loss: 4.541199] 
[Epoch 6/10] [Batch 103/274] [Batch classify loss: 4.699956] 
[Epoch 6/10] [Batch 104/274] [Batch classify loss: 4.448111] 
[Epoch 6/10] [Batch 105/274] [Batch classify loss: 4.502671] 
[Epoch 6/10] [Batch 106/274] [Batch classify loss: 4.007092] 
[Epoch 6/10] [Batch 107/274] [Batch classify loss: 4.037113] 
[Epoch 6/10] [Batch 108/274] [Batch classify loss: 4.648308] 
[Epoch 6/10] [Batch 109/274] [Batch classify loss: 4.205532] 
[Epoch 6/10] [Batch 110/274] [Batch classify loss: 4.028902] 
[Epoch 6/10] [Batch 111/274] [Batch classify loss: 4.264394] 
[Epoch 6/10] [Batch 112/274] [Batch classify loss: 4.401173] 
[Epoch 6/10] [Batch 113/274] [Batch classify loss: 4.605067] 
[Epoch 6/10] [Batch 114/274] [Batch classify loss: 4.093349] 
[Epoch 6/10] [Batch 115/274] [Batch classify loss: 4.481256] 
[Epoch 6/10] [Batch 116/274] [Batch classify loss: 3.763325] 
[Epoch 6/10] [Batch 117/274] [Batch classify loss: 4.146842] 
[Epoch 6/10] [Batch 118/274] [Batch classify loss: 3.971258] 
[Epoch 6/10] [Batch 119/274] [Batch classify loss: 4.165799] 
[Epoch 6/10] [Batch 120/274] [Batch classify loss: 4.607647] 
[Epoch 6/10] [Batch 121/274] [Batch classify loss: 4.250026] 
[Epoch 6/10] [Batch 122/274] [Batch classify loss: 4.160792] 
[Epoch 6/10] [Batch 123/274] [Batch classify loss: 4.362626] 
[Epoch 6/10] [Batch 124/274] [Batch classify loss: 4.451995] 
[Epoch 6/10] [Batch 125/274] [Batch classify loss: 4.710680] 
[Epoch 6/10] [Batch 126/274] [Batch classify loss: 4.032458] 
[Epoch 6/10] [Batch 127/274] [Batch classify loss: 4.562963] 
[Epoch 6/10] [Batch 128/274] [Batch classify loss: 3.980965] 
[Epoch 6/10] [Batch 129/274] [Batch classify loss: 4.518196] 
[Epoch 6/10] [Batch 130/274] [Batch classify loss: 4.476751] 
[Epoch 6/10] [Batch 131/274] [Batch classify loss: 4.625633] 
[Epoch 6/10] [Batch 132/274] [Batch classify loss: 4.194278] 
[Epoch 6/10] [Batch 133/274] [Batch classify loss: 3.852182] 
[Epoch 6/10] [Batch 134/274] [Batch classify loss: 4.298727] 
[Epoch 6/10] [Batch 135/274] [Batch classify loss: 4.577946] 
[Epoch 6/10] [Batch 136/274] [Batch classify loss: 4.550141] 
[Epoch 6/10] [Batch 137/274] [Batch classify loss: 4.532710] 
[Epoch 6/10] [Batch 138/274] [Batch classify loss: 4.400510] 
[Epoch 6/10] [Batch 139/274] [Batch classify loss: 4.410355] 
[Epoch 6/10] [Batch 140/274] [Batch classify loss: 4.546598] 
[Epoch 6/10] [Batch 141/274] [Batch classify loss: 4.663914] 
[Epoch 6/10] [Batch 142/274] [Batch classify loss: 4.072650] 
[Epoch 6/10] [Batch 143/274] [Batch classify loss: 4.847452] 
[Epoch 6/10] [Batch 144/274] [Batch classify loss: 4.247483] 
[Epoch 6/10] [Batch 145/274] [Batch classify loss: 4.439445] 
[Epoch 6/10] [Batch 146/274] [Batch classify loss: 4.511481] 
[Epoch 6/10] [Batch 147/274] [Batch classify loss: 4.860857] 
[Epoch 6/10] [Batch 148/274] [Batch classify loss: 4.449188] 
[Epoch 6/10] [Batch 149/274] [Batch classify loss: 4.341794] 
[Epoch 6/10] [Batch 150/274] [Batch classify loss: 4.670518] 
[Epoch 6/10] [Batch 151/274] [Batch classify loss: 4.222156] 
[Epoch 6/10] [Batch 152/274] [Batch classify loss: 4.564368] 
[Epoch 6/10] [Batch 153/274] [Batch classify loss: 4.240608] 
[Epoch 6/10] [Batch 154/274] [Batch classify loss: 4.496617] 
[Epoch 6/10] [Batch 155/274] [Batch classify loss: 4.337859] 
[Epoch 6/10] [Batch 156/274] [Batch classify loss: 4.851166] 
[Epoch 6/10] [Batch 157/274] [Batch classify loss: 4.717433] 
[Epoch 6/10] [Batch 158/274] [Batch classify loss: 4.236781] 
[Epoch 6/10] [Batch 159/274] [Batch classify loss: 4.418951] 
[Epoch 6/10] [Batch 160/274] [Batch classify loss: 4.356209] 
[Epoch 6/10] [Batch 161/274] [Batch classify loss: 4.712907] 
[Epoch 6/10] [Batch 162/274] [Batch classify loss: 4.253346] 
[Epoch 6/10] [Batch 163/274] [Batch classify loss: 4.491843] 
[Epoch 6/10] [Batch 164/274] [Batch classify loss: 5.005483] 
[Epoch 6/10] [Batch 165/274] [Batch classify loss: 4.330224] 
[Epoch 6/10] [Batch 166/274] [Batch classify loss: 4.148660] 
[Epoch 6/10] [Batch 167/274] [Batch classify loss: 4.609289] 
[Epoch 6/10] [Batch 168/274] [Batch classify loss: 4.165815] 
[Epoch 6/10] [Batch 169/274] [Batch classify loss: 3.998206] 
[Epoch 6/10] [Batch 170/274] [Batch classify loss: 4.337359] 
[Epoch 6/10] [Batch 171/274] [Batch classify loss: 4.200426] 
[Epoch 6/10] [Batch 172/274] [Batch classify loss: 4.134266] 
[Epoch 6/10] [Batch 173/274] [Batch classify loss: 4.449403] 
[Epoch 6/10] [Batch 174/274] [Batch classify loss: 4.200322] 
[Epoch 6/10] [Batch 175/274] [Batch classify loss: 4.246414] 
[Epoch 6/10] [Batch 176/274] [Batch classify loss: 4.946544] 
[Epoch 6/10] [Batch 177/274] [Batch classify loss: 4.422702] 
[Epoch 6/10] [Batch 178/274] [Batch classify loss: 3.944566] 
[Epoch 6/10] [Batch 179/274] [Batch classify loss: 4.010643] 
[Epoch 6/10] [Batch 180/274] [Batch classify loss: 4.904662] 
[Epoch 6/10] [Batch 181/274] [Batch classify loss: 4.259750] 
[Epoch 6/10] [Batch 182/274] [Batch classify loss: 4.223931] 
[Epoch 6/10] [Batch 183/274] [Batch classify loss: 4.318555] 
[Epoch 6/10] [Batch 184/274] [Batch classify loss: 4.853886] 
[Epoch 6/10] [Batch 185/274] [Batch classify loss: 4.804151] 
[Epoch 6/10] [Batch 186/274] [Batch classify loss: 5.112486] 
[Epoch 6/10] [Batch 187/274] [Batch classify loss: 4.029282] 
[Epoch 6/10] [Batch 188/274] [Batch classify loss: 4.432360] 
[Epoch 6/10] [Batch 189/274] [Batch classify loss: 4.606374] 
[Epoch 6/10] [Batch 190/274] [Batch classify loss: 4.379424] 
[Epoch 6/10] [Batch 191/274] [Batch classify loss: 4.158805] 
[Epoch 6/10] [Batch 192/274] [Batch classify loss: 4.249165] 
[Epoch 6/10] [Batch 193/274] [Batch classify loss: 4.308050] 
[Epoch 6/10] [Batch 194/274] [Batch classify loss: 3.930235] 
[Epoch 6/10] [Batch 195/274] [Batch classify loss: 4.008663] 
[Epoch 6/10] [Batch 196/274] [Batch classify loss: 4.556851] 
[Epoch 6/10] [Batch 197/274] [Batch classify loss: 4.588410] 
[Epoch 6/10] [Batch 198/274] [Batch classify loss: 5.016223] 
[Epoch 6/10] [Batch 199/274] [Batch classify loss: 4.705314] 
[Epoch 6/10] [Batch 200/274] [Batch classify loss: 4.520828] 
[Epoch 6/10] [Batch 201/274] [Batch classify loss: 4.970210] 
[Epoch 6/10] [Batch 202/274] [Batch classify loss: 4.453655] 
[Epoch 6/10] [Batch 203/274] [Batch classify loss: 4.329177] 
[Epoch 6/10] [Batch 204/274] [Batch classify loss: 4.280212] 
[Epoch 6/10] [Batch 205/274] [Batch classify loss: 4.706885] 
[Epoch 6/10] [Batch 206/274] [Batch classify loss: 4.706213] 
[Epoch 6/10] [Batch 207/274] [Batch classify loss: 4.332037] 
[Epoch 6/10] [Batch 208/274] [Batch classify loss: 4.950784] 
[Epoch 6/10] [Batch 209/274] [Batch classify loss: 5.223920] 
[Epoch 6/10] [Batch 210/274] [Batch classify loss: 4.137262] 
[Epoch 6/10] [Batch 211/274] [Batch classify loss: 4.599545] 
[Epoch 6/10] [Batch 212/274] [Batch classify loss: 4.326344] 
[Epoch 6/10] [Batch 213/274] [Batch classify loss: 4.134349] 
[Epoch 6/10] [Batch 214/274] [Batch classify loss: 4.460743] 
[Epoch 6/10] [Batch 215/274] [Batch classify loss: 4.197973] 
[Epoch 6/10] [Batch 216/274] [Batch classify loss: 4.555255] 
[Epoch 6/10] [Batch 217/274] [Batch classify loss: 4.516293] 
[Epoch 6/10] [Batch 218/274] [Batch classify loss: 4.418169] 
[Epoch 6/10] [Batch 219/274] [Batch classify loss: 4.150222] 
[Epoch 6/10] [Batch 220/274] [Batch classify loss: 4.669215] 
[Epoch 6/10] [Batch 221/274] [Batch classify loss: 4.171681] 
[Epoch 6/10] [Batch 222/274] [Batch classify loss: 4.507561] 
[Epoch 6/10] [Batch 223/274] [Batch classify loss: 4.794172] 
[Epoch 6/10] [Batch 224/274] [Batch classify loss: 4.563478] 
[Epoch 6/10] [Batch 225/274] [Batch classify loss: 4.837938] 
[Epoch 6/10] [Batch 226/274] [Batch classify loss: 4.800111] 
[Epoch 6/10] [Batch 227/274] [Batch classify loss: 4.384876] 
[Epoch 6/10] [Batch 228/274] [Batch classify loss: 4.605415] 
[Epoch 6/10] [Batch 229/274] [Batch classify loss: 4.538460] 
[Epoch 6/10] [Batch 230/274] [Batch classify loss: 4.429546] 
[Epoch 6/10] [Batch 231/274] [Batch classify loss: 4.465211] 
[Epoch 6/10] [Batch 232/274] [Batch classify loss: 4.325357] 
[Epoch 6/10] [Batch 233/274] [Batch classify loss: 4.350436] 
[Epoch 6/10] [Batch 234/274] [Batch classify loss: 4.300865] 
[Epoch 6/10] [Batch 235/274] [Batch classify loss: 4.575150] 
[Epoch 6/10] [Batch 236/274] [Batch classify loss: 4.377086] 
[Epoch 6/10] [Batch 237/274] [Batch classify loss: 4.296671] 
[Epoch 6/10] [Batch 238/274] [Batch classify loss: 4.547661] 
[Epoch 6/10] [Batch 239/274] [Batch classify loss: 4.141613] 
[Epoch 6/10] [Batch 240/274] [Batch classify loss: 4.698104] 
[Epoch 6/10] [Batch 241/274] [Batch classify loss: 4.270668] 
[Epoch 6/10] [Batch 242/274] [Batch classify loss: 4.871999] 
[Epoch 6/10] [Batch 243/274] [Batch classify loss: 4.192413] 
[Epoch 6/10] [Batch 244/274] [Batch classify loss: 4.512584] 
[Epoch 6/10] [Batch 245/274] [Batch classify loss: 4.143159] 
[Epoch 6/10] [Batch 246/274] [Batch classify loss: 4.442964] 
[Epoch 6/10] [Batch 247/274] [Batch classify loss: 4.711679] 
[Epoch 6/10] [Batch 248/274] [Batch classify loss: 4.638052] 
[Epoch 6/10] [Batch 249/274] [Batch classify loss: 4.692623] 
[Epoch 6/10] [Batch 250/274] [Batch classify loss: 4.251127] 
[Epoch 6/10] [Batch 251/274] [Batch classify loss: 4.885230] 
[Epoch 6/10] [Batch 252/274] [Batch classify loss: 4.257674] 
[Epoch 6/10] [Batch 253/274] [Batch classify loss: 4.855186] 
[Epoch 6/10] [Batch 254/274] [Batch classify loss: 4.307366] 
[Epoch 6/10] [Batch 255/274] [Batch classify loss: 4.627976] 
[Epoch 6/10] [Batch 256/274] [Batch classify loss: 4.556458] 
[Epoch 6/10] [Batch 257/274] [Batch classify loss: 4.698009] 
[Epoch 6/10] [Batch 258/274] [Batch classify loss: 4.840274] 
[Epoch 6/10] [Batch 259/274] [Batch classify loss: 4.689819] 
[Epoch 6/10] [Batch 260/274] [Batch classify loss: 4.355289] 
[Epoch 6/10] [Batch 261/274] [Batch classify loss: 4.401001] 
[Epoch 6/10] [Batch 262/274] [Batch classify loss: 4.398592] 
[Epoch 6/10] [Batch 263/274] [Batch classify loss: 4.675204] 
[Epoch 6/10] [Batch 264/274] [Batch classify loss: 4.362618] 
[Epoch 6/10] [Batch 265/274] [Batch classify loss: 4.408434] 
[Epoch 6/10] [Batch 266/274] [Batch classify loss: 4.574434] 
[Epoch 6/10] [Batch 267/274] [Batch classify loss: 3.826242] 
[Epoch 6/10] [Batch 268/274] [Batch classify loss: 4.821441] 
[Epoch 6/10] [Batch 269/274] [Batch classify loss: 4.284041] 
[Epoch 6/10] [Batch 270/274] [Batch classify loss: 4.229957] 
[Epoch 6/10] [Batch 271/274] [Batch classify loss: 4.788354] 
[Epoch 6/10] [Batch 272/274] [Batch classify loss: 4.433648] 
[Epoch 6/10] [Batch 273/274] [Batch classify loss: 4.299586] 
[Epoch 6/10] [Batch 274/274] [Batch classify loss: 4.908014] 
0006 epoch mmat trained classifier accuary on the clean testing examples:94.6643%
0006 epoch mmat trained classifier loss on the clean testing examples:0.2202
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.0853%
mmat trained classifier loss on adversarial testset:4.523523330688477
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-cle
6epoch learning rate:0.1
[Epoch 7/10] [Batch 1/274] [Batch classify loss: 1.292550] 
[Epoch 7/10] [Batch 2/274] [Batch classify loss: 1.558827] 
[Epoch 7/10] [Batch 3/274] [Batch classify loss: 2.213870] 
[Epoch 7/10] [Batch 4/274] [Batch classify loss: 1.973505] 
[Epoch 7/10] [Batch 5/274] [Batch classify loss: 2.059209] 
[Epoch 7/10] [Batch 6/274] [Batch classify loss: 2.088742] 
[Epoch 7/10] [Batch 7/274] [Batch classify loss: 2.205813] 
[Epoch 7/10] [Batch 8/274] [Batch classify loss: 2.464574] 
[Epoch 7/10] [Batch 9/274] [Batch classify loss: 2.250574] 
[Epoch 7/10] [Batch 10/274] [Batch classify loss: 2.681998] 
[Epoch 7/10] [Batch 11/274] [Batch classify loss: 2.563226] 
[Epoch 7/10] [Batch 12/274] [Batch classify loss: 2.309659] 
[Epoch 7/10] [Batch 13/274] [Batch classify loss: 2.727239] 
[Epoch 7/10] [Batch 14/274] [Batch classify loss: 2.761682] 
[Epoch 7/10] [Batch 15/274] [Batch classify loss: 2.965751] 
[Epoch 7/10] [Batch 16/274] [Batch classify loss: 2.826184] 
[Epoch 7/10] [Batch 17/274] [Batch classify loss: 3.084013] 
[Epoch 7/10] [Batch 18/274] [Batch classify loss: 2.729460] 
[Epoch 7/10] [Batch 19/274] [Batch classify loss: 2.875205] 
[Epoch 7/10] [Batch 20/274] [Batch classify loss: 2.879716] 
[Epoch 7/10] [Batch 21/274] [Batch classify loss: 2.739902] 
[Epoch 7/10] [Batch 22/274] [Batch classify loss: 2.506323] 
[Epoch 7/10] [Batch 23/274] [Batch classify loss: 3.101888] 
[Epoch 7/10] [Batch 24/274] [Batch classify loss: 2.815265] 
[Epoch 7/10] [Batch 25/274] [Batch classify loss: 3.080592] 
[Epoch 7/10] [Batch 26/274] [Batch classify loss: 3.039557] 
[Epoch 7/10] [Batch 27/274] [Batch classify loss: 3.189904] 
[Epoch 7/10] [Batch 28/274] [Batch classify loss: 3.094320] 
[Epoch 7/10] [Batch 29/274] [Batch classify loss: 3.335408] 
[Epoch 7/10] [Batch 30/274] [Batch classify loss: 2.913958] 
[Epoch 7/10] [Batch 31/274] [Batch classify loss: 3.132268] 
[Epoch 7/10] [Batch 32/274] [Batch classify loss: 3.170125] 
[Epoch 7/10] [Batch 33/274] [Batch classify loss: 3.031643] 
[Epoch 7/10] [Batch 34/274] [Batch classify loss: 3.154450] 
[Epoch 7/10] [Batch 35/274] [Batch classify loss: 3.393577] 
[Epoch 7/10] [Batch 36/274] [Batch classify loss: 3.293699] 
[Epoch 7/10] [Batch 37/274] [Batch classify loss: 3.145089] 
[Epoch 7/10] [Batch 38/274] [Batch classify loss: 3.108109] 
[Epoch 7/10] [Batch 39/274] [Batch classify loss: 3.164033] 
[Epoch 7/10] [Batch 40/274] [Batch classify loss: 3.218972] 
[Epoch 7/10] [Batch 41/274] [Batch classify loss: 3.052561] 
[Epoch 7/10] [Batch 42/274] [Batch classify loss: 3.269162] 
[Epoch 7/10] [Batch 43/274] [Batch classify loss: 3.408853] 
[Epoch 7/10] [Batch 44/274] [Batch classify loss: 3.007751] 
[Epoch 7/10] [Batch 45/274] [Batch classify loss: 3.576488] 
[Epoch 7/10] [Batch 46/274] [Batch classify loss: 3.285681] 
[Epoch 7/10] [Batch 47/274] [Batch classify loss: 3.559389] 
[Epoch 7/10] [Batch 48/274] [Batch classify loss: 2.876300] 
[Epoch 7/10] [Batch 49/274] [Batch classify loss: 3.456885] 
[Epoch 7/10] [Batch 50/274] [Batch classify loss: 3.656514] 
[Epoch 7/10] [Batch 51/274] [Batch classify loss: 3.561032] 
[Epoch 7/10] [Batch 52/274] [Batch classify loss: 3.359924] 
[Epoch 7/10] [Batch 53/274] [Batch classify loss: 3.308806] 
[Epoch 7/10] [Batch 54/274] [Batch classify loss: 3.297500] 
[Epoch 7/10] [Batch 55/274] [Batch classify loss: 3.728061] 
[Epoch 7/10] [Batch 56/274] [Batch classify loss: 3.483729] 
[Epoch 7/10] [Batch 57/274] [Batch classify loss: 3.685642] 
[Epoch 7/10] [Batch 58/274] [Batch classify loss: 3.418961] 
[Epoch 7/10] [Batch 59/274] [Batch classify loss: 3.090564] 
[Epoch 7/10] [Batch 60/274] [Batch classify loss: 3.504383] 
[Epoch 7/10] [Batch 61/274] [Batch classify loss: 3.500164] 
[Epoch 7/10] [Batch 62/274] [Batch classify loss: 3.618239] 
[Epoch 7/10] [Batch 63/274] [Batch classify loss: 3.595757] 
[Epoch 7/10] [Batch 64/274] [Batch classify loss: 3.723090] 
[Epoch 7/10] [Batch 65/274] [Batch classify loss: 3.501378] 
[Epoch 7/10] [Batch 66/274] [Batch classify loss: 3.444335] 
[Epoch 7/10] [Batch 67/274] [Batch classify loss: 3.615814] 
[Epoch 7/10] [Batch 68/274] [Batch classify loss: 3.546207] 
[Epoch 7/10] [Batch 69/274] [Batch classify loss: 3.660809] 
[Epoch 7/10] [Batch 70/274] [Batch classify loss: 3.490359] 
[Epoch 7/10] [Batch 71/274] [Batch classify loss: 3.634982] 
[Epoch 7/10] [Batch 72/274] [Batch classify loss: 3.855210] 
[Epoch 7/10] [Batch 73/274] [Batch classify loss: 3.782531] 
[Epoch 7/10] [Batch 74/274] [Batch classify loss: 3.772404] 
[Epoch 7/10] [Batch 75/274] [Batch classify loss: 3.639524] 
[Epoch 7/10] [Batch 76/274] [Batch classify loss: 3.782891] 
[Epoch 7/10] [Batch 77/274] [Batch classify loss: 3.865038] 
[Epoch 7/10] [Batch 78/274] [Batch classify loss: 3.322708] 
[Epoch 7/10] [Batch 79/274] [Batch classify loss: 3.456388] 
[Epoch 7/10] [Batch 80/274] [Batch classify loss: 3.850253] 
[Epoch 7/10] [Batch 81/274] [Batch classify loss: 3.821184] 
[Epoch 7/10] [Batch 82/274] [Batch classify loss: 3.652203] 
[Epoch 7/10] [Batch 83/274] [Batch classify loss: 3.539496] 
[Epoch 7/10] [Batch 84/274] [Batch classify loss: 4.214029] 
[Epoch 7/10] [Batch 85/274] [Batch classify loss: 3.717044] 
[Epoch 7/10] [Batch 86/274] [Batch classify loss: 4.057405] 
[Epoch 7/10] [Batch 87/274] [Batch classify loss: 3.801961] 
[Epoch 7/10] [Batch 88/274] [Batch classify loss: 3.802727] 
[Epoch 7/10] [Batch 89/274] [Batch classify loss: 3.903076] 
[Epoch 7/10] [Batch 90/274] [Batch classify loss: 3.765144] 
[Epoch 7/10] [Batch 91/274] [Batch classify loss: 3.297981] 
[Epoch 7/10] [Batch 92/274] [Batch classify loss: 3.912397] 
[Epoch 7/10] [Batch 93/274] [Batch classify loss: 3.481033] 
[Epoch 7/10] [Batch 94/274] [Batch classify loss: 3.418819] 
[Epoch 7/10] [Batch 95/274] [Batch classify loss: 3.641738] 
[Epoch 7/10] [Batch 96/274] [Batch classify loss: 3.563773] 
[Epoch 7/10] [Batch 97/274] [Batch classify loss: 3.828471] 
[Epoch 7/10] [Batch 98/274] [Batch classify loss: 3.897219] 
[Epoch 7/10] [Batch 99/274] [Batch classify loss: 4.041100] 
[Epoch 7/10] [Batch 100/274] [Batch classify loss: 3.667459] 
[Epoch 7/10] [Batch 101/274] [Batch classify loss: 3.667119] 
[Epoch 7/10] [Batch 102/274] [Batch classify loss: 3.318593] 
[Epoch 7/10] [Batch 103/274] [Batch classify loss: 4.028749] 
[Epoch 7/10] [Batch 104/274] [Batch classify loss: 3.616416] 
[Epoch 7/10] [Batch 105/274] [Batch classify loss: 3.811573] 
[Epoch 7/10] [Batch 106/274] [Batch classify loss: 3.691817] 
[Epoch 7/10] [Batch 107/274] [Batch classify loss: 3.963937] 
[Epoch 7/10] [Batch 108/274] [Batch classify loss: 3.639177] 
[Epoch 7/10] [Batch 109/274] [Batch classify loss: 4.007925] 
[Epoch 7/10] [Batch 110/274] [Batch classify loss: 3.935547] 
[Epoch 7/10] [Batch 111/274] [Batch classify loss: 3.915444] 
[Epoch 7/10] [Batch 112/274] [Batch classify loss: 3.766570] 
[Epoch 7/10] [Batch 113/274] [Batch classify loss: 3.986448] 
[Epoch 7/10] [Batch 114/274] [Batch classify loss: 4.052596] 
[Epoch 7/10] [Batch 115/274] [Batch classify loss: 4.002975] 
[Epoch 7/10] [Batch 116/274] [Batch classify loss: 3.698123] 
[Epoch 7/10] [Batch 117/274] [Batch classify loss: 4.205412] 
[Epoch 7/10] [Batch 118/274] [Batch classify loss: 3.676934] 
[Epoch 7/10] [Batch 119/274] [Batch classify loss: 3.718730] 
[Epoch 7/10] [Batch 120/274] [Batch classify loss: 3.774363] 
[Epoch 7/10] [Batch 121/274] [Batch classify loss: 3.686706] 
[Epoch 7/10] [Batch 122/274] [Batch classify loss: 3.990407] 
[Epoch 7/10] [Batch 123/274] [Batch classify loss: 4.140580] 
[Epoch 7/10] [Batch 124/274] [Batch classify loss: 3.898060] 
[Epoch 7/10] [Batch 125/274] [Batch classify loss: 3.945465] 
[Epoch 7/10] [Batch 126/274] [Batch classify loss: 4.069519] 
[Epoch 7/10] [Batch 127/274] [Batch classify loss: 3.804217] 
[Epoch 7/10] [Batch 128/274] [Batch classify loss: 3.452256] 
[Epoch 7/10] [Batch 129/274] [Batch classify loss: 3.861463] 
[Epoch 7/10] [Batch 130/274] [Batch classify loss: 4.198044] 
[Epoch 7/10] [Batch 131/274] [Batch classify loss: 3.790590] 
[Epoch 7/10] [Batch 132/274] [Batch classify loss: 3.697088] 
[Epoch 7/10] [Batch 133/274] [Batch classify loss: 3.675130] 
[Epoch 7/10] [Batch 134/274] [Batch classify loss: 3.816674] 
[Epoch 7/10] [Batch 135/274] [Batch classify loss: 3.711191] 
[Epoch 7/10] [Batch 136/274] [Batch classify loss: 3.636765] 
[Epoch 7/10] [Batch 137/274] [Batch classify loss: 3.783308] 
[Epoch 7/10] [Batch 138/274] [Batch classify loss: 3.977458] 
[Epoch 7/10] [Batch 139/274] [Batch classify loss: 3.959355] 
[Epoch 7/10] [Batch 140/274] [Batch classify loss: 4.140519] 
[Epoch 7/10] [Batch 141/274] [Batch classify loss: 4.100469] 
[Epoch 7/10] [Batch 142/274] [Batch classify loss: 4.060339] 
[Epoch 7/10] [Batch 143/274] [Batch classify loss: 3.908478] 
[Epoch 7/10] [Batch 144/274] [Batch classify loss: 3.946617] 
[Epoch 7/10] [Batch 145/274] [Batch classify loss: 4.362127] 
[Epoch 7/10] [Batch 146/274] [Batch classify loss: 4.342998] 
[Epoch 7/10] [Batch 147/274] [Batch classify loss: 3.366284] 
[Epoch 7/10] [Batch 148/274] [Batch classify loss: 4.290662] 
[Epoch 7/10] [Batch 149/274] [Batch classify loss: 4.181548] 
[Epoch 7/10] [Batch 150/274] [Batch classify loss: 4.189943] 
[Epoch 7/10] [Batch 151/274] [Batch classify loss: 4.088811] 
[Epoch 7/10] [Batch 152/274] [Batch classify loss: 3.640500] 
[Epoch 7/10] [Batch 153/274] [Batch classify loss: 4.162467] 
[Epoch 7/10] [Batch 154/274] [Batch classify loss: 4.308269] 
[Epoch 7/10] [Batch 155/274] [Batch classify loss: 4.356373] 
[Epoch 7/10] [Batch 156/274] [Batch classify loss: 3.723461] 
[Epoch 7/10] [Batch 157/274] [Batch classify loss: 4.243429] 
[Epoch 7/10] [Batch 158/274] [Batch classify loss: 3.831464] 
[Epoch 7/10] [Batch 159/274] [Batch classify loss: 4.664355] 
[Epoch 7/10] [Batch 160/274] [Batch classify loss: 3.651404] 
[Epoch 7/10] [Batch 161/274] [Batch classify loss: 4.109511] 
[Epoch 7/10] [Batch 162/274] [Batch classify loss: 4.161984] 
[Epoch 7/10] [Batch 163/274] [Batch classify loss: 4.256156] 
[Epoch 7/10] [Batch 164/274] [Batch classify loss: 3.655759] 
[Epoch 7/10] [Batch 165/274] [Batch classify loss: 3.700586] 
[Epoch 7/10] [Batch 166/274] [Batch classify loss: 4.246424] 
[Epoch 7/10] [Batch 167/274] [Batch classify loss: 3.932927] 
[Epoch 7/10] [Batch 168/274] [Batch classify loss: 4.347852] 
[Epoch 7/10] [Batch 169/274] [Batch classify loss: 4.269023] 
[Epoch 7/10] [Batch 170/274] [Batch classify loss: 3.862118] 
[Epoch 7/10] [Batch 171/274] [Batch classify loss: 3.862027] 
[Epoch 7/10] [Batch 172/274] [Batch classify loss: 4.030888] 
[Epoch 7/10] [Batch 173/274] [Batch classify loss: 3.748540] 
[Epoch 7/10] [Batch 174/274] [Batch classify loss: 3.990356] 
[Epoch 7/10] [Batch 175/274] [Batch classify loss: 4.022018] 
[Epoch 7/10] [Batch 176/274] [Batch classify loss: 3.910012] 
[Epoch 7/10] [Batch 177/274] [Batch classify loss: 4.083848] 
[Epoch 7/10] [Batch 178/274] [Batch classify loss: 3.864069] 
[Epoch 7/10] [Batch 179/274] [Batch classify loss: 4.078443] 
[Epoch 7/10] [Batch 180/274] [Batch classify loss: 3.959366] 
[Epoch 7/10] [Batch 181/274] [Batch classify loss: 3.855275] 
[Epoch 7/10] [Batch 182/274] [Batch classify loss: 4.036056] 
[Epoch 7/10] [Batch 183/274] [Batch classify loss: 4.039635] 
[Epoch 7/10] [Batch 184/274] [Batch classify loss: 4.086179] 
[Epoch 7/10] [Batch 185/274] [Batch classify loss: 4.181452] 
[Epoch 7/10] [Batch 186/274] [Batch classify loss: 4.281532] 
[Epoch 7/10] [Batch 187/274] [Batch classify loss: 3.943243] 
[Epoch 7/10] [Batch 188/274] [Batch classify loss: 4.003989] 
[Epoch 7/10] [Batch 189/274] [Batch classify loss: 3.777046] 
[Epoch 7/10] [Batch 190/274] [Batch classify loss: 4.143135] 
[Epoch 7/10] [Batch 191/274] [Batch classify loss: 3.740204] 
[Epoch 7/10] [Batch 192/274] [Batch classify loss: 4.489258] 
[Epoch 7/10] [Batch 193/274] [Batch classify loss: 3.426289] 
[Epoch 7/10] [Batch 194/274] [Batch classify loss: 4.344991] 
[Epoch 7/10] [Batch 195/274] [Batch classify loss: 3.839028] 
[Epoch 7/10] [Batch 196/274] [Batch classify loss: 3.701016] 
[Epoch 7/10] [Batch 197/274] [Batch classify loss: 3.692428] 
[Epoch 7/10] [Batch 198/274] [Batch classify loss: 3.694707] 
[Epoch 7/10] [Batch 199/274] [Batch classify loss: 3.725469] 
[Epoch 7/10] [Batch 200/274] [Batch classify loss: 4.160132] 
[Epoch 7/10] [Batch 201/274] [Batch classify loss: 4.238773] 
[Epoch 7/10] [Batch 202/274] [Batch classify loss: 3.929742] 
[Epoch 7/10] [Batch 203/274] [Batch classify loss: 4.312632] 
[Epoch 7/10] [Batch 204/274] [Batch classify loss: 4.147274] 
[Epoch 7/10] [Batch 205/274] [Batch classify loss: 3.762361] 
[Epoch 7/10] [Batch 206/274] [Batch classify loss: 4.061005] 
[Epoch 7/10] [Batch 207/274] [Batch classify loss: 3.922110] 
[Epoch 7/10] [Batch 208/274] [Batch classify loss: 4.578868] 
[Epoch 7/10] [Batch 209/274] [Batch classify loss: 4.100158] 
[Epoch 7/10] [Batch 210/274] [Batch classify loss: 4.047361] 
[Epoch 7/10] [Batch 211/274] [Batch classify loss: 4.187539] 
[Epoch 7/10] [Batch 212/274] [Batch classify loss: 3.927576] 
[Epoch 7/10] [Batch 213/274] [Batch classify loss: 4.200658] 
[Epoch 7/10] [Batch 214/274] [Batch classify loss: 3.957417] 
[Epoch 7/10] [Batch 215/274] [Batch classify loss: 4.151915] 
[Epoch 7/10] [Batch 216/274] [Batch classify loss: 4.232103] 
[Epoch 7/10] [Batch 217/274] [Batch classify loss: 3.786015] 
[Epoch 7/10] [Batch 218/274] [Batch classify loss: 4.329539] 
[Epoch 7/10] [Batch 219/274] [Batch classify loss: 4.094021] 
[Epoch 7/10] [Batch 220/274] [Batch classify loss: 3.896355] 
[Epoch 7/10] [Batch 221/274] [Batch classify loss: 4.166023] 
[Epoch 7/10] [Batch 222/274] [Batch classify loss: 4.130092] 
[Epoch 7/10] [Batch 223/274] [Batch classify loss: 4.413985] 
[Epoch 7/10] [Batch 224/274] [Batch classify loss: 4.213403] 
[Epoch 7/10] [Batch 225/274] [Batch classify loss: 4.180936] 
[Epoch 7/10] [Batch 226/274] [Batch classify loss: 4.042329] 
[Epoch 7/10] [Batch 227/274] [Batch classify loss: 4.033329] 
[Epoch 7/10] [Batch 228/274] [Batch classify loss: 4.040191] 
[Epoch 7/10] [Batch 229/274] [Batch classify loss: 4.172331] 
[Epoch 7/10] [Batch 230/274] [Batch classify loss: 3.868516] 
[Epoch 7/10] [Batch 231/274] [Batch classify loss: 3.927642] 
[Epoch 7/10] [Batch 232/274] [Batch classify loss: 4.055316] 
[Epoch 7/10] [Batch 233/274] [Batch classify loss: 4.422397] 
[Epoch 7/10] [Batch 234/274] [Batch classify loss: 4.375123] 
[Epoch 7/10] [Batch 235/274] [Batch classify loss: 4.398673] 
[Epoch 7/10] [Batch 236/274] [Batch classify loss: 3.798482] 
[Epoch 7/10] [Batch 237/274] [Batch classify loss: 3.996177] 
[Epoch 7/10] [Batch 238/274] [Batch classify loss: 4.295716] 
[Epoch 7/10] [Batch 239/274] [Batch classify loss: 4.590074] 
[Epoch 7/10] [Batch 240/274] [Batch classify loss: 4.005234] 
[Epoch 7/10] [Batch 241/274] [Batch classify loss: 4.305087] 
[Epoch 7/10] [Batch 242/274] [Batch classify loss: 4.148797] 
[Epoch 7/10] [Batch 243/274] [Batch classify loss: 3.863906] 
[Epoch 7/10] [Batch 244/274] [Batch classify loss: 4.389705] 
[Epoch 7/10] [Batch 245/274] [Batch classify loss: 4.078720] 
[Epoch 7/10] [Batch 246/274] [Batch classify loss: 4.442735] 
[Epoch 7/10] [Batch 247/274] [Batch classify loss: 3.921159] 
[Epoch 7/10] [Batch 248/274] [Batch classify loss: 4.081505] 
[Epoch 7/10] [Batch 249/274] [Batch classify loss: 4.036579] 
[Epoch 7/10] [Batch 250/274] [Batch classify loss: 4.353303] 
[Epoch 7/10] [Batch 251/274] [Batch classify loss: 4.122429] 
[Epoch 7/10] [Batch 252/274] [Batch classify loss: 4.037280] 
[Epoch 7/10] [Batch 253/274] [Batch classify loss: 4.471242] 
[Epoch 7/10] [Batch 254/274] [Batch classify loss: 4.637165] 
[Epoch 7/10] [Batch 255/274] [Batch classify loss: 4.203873] 
[Epoch 7/10] [Batch 256/274] [Batch classify loss: 4.303992] 
[Epoch 7/10] [Batch 257/274] [Batch classify loss: 4.017698] 
[Epoch 7/10] [Batch 258/274] [Batch classify loss: 4.370043] 
[Epoch 7/10] [Batch 259/274] [Batch classify loss: 4.090003] 
[Epoch 7/10] [Batch 260/274] [Batch classify loss: 3.988242] 
[Epoch 7/10] [Batch 261/274] [Batch classify loss: 4.066706] 
[Epoch 7/10] [Batch 262/274] [Batch classify loss: 3.880476] 
[Epoch 7/10] [Batch 263/274] [Batch classify loss: 4.187521] 
[Epoch 7/10] [Batch 264/274] [Batch classify loss: 4.433897] 
[Epoch 7/10] [Batch 265/274] [Batch classify loss: 4.161031] 
[Epoch 7/10] [Batch 266/274] [Batch classify loss: 4.792720] 
[Epoch 7/10] [Batch 267/274] [Batch classify loss: 4.333547] 
[Epoch 7/10] [Batch 268/274] [Batch classify loss: 4.066207] 
[Epoch 7/10] [Batch 269/274] [Batch classify loss: 4.170171] 
[Epoch 7/10] [Batch 270/274] [Batch classify loss: 4.116128] 
[Epoch 7/10] [Batch 271/274] [Batch classify loss: 4.241234] 
[Epoch 7/10] [Batch 272/274] [Batch classify loss: 4.586056] 
[Epoch 7/10] [Batch 273/274] [Batch classify loss: 3.893018] 
[Epoch 7/10] [Batch 274/274] [Batch classify loss: 4.158786] 
0007 epoch mmat trained classifier accuary on the clean testing examples:94.7142%
0007 epoch mmat trained classifier loss on the clean testing examples:0.2231
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2966%
mmat trained classifier loss on adversarial testset:4.534469127655029
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-cle
7epoch learning rate:0.1
[Epoch 8/10] [Batch 1/274] [Batch classify loss: 1.234167] 
[Epoch 8/10] [Batch 2/274] [Batch classify loss: 1.360220] 
[Epoch 8/10] [Batch 3/274] [Batch classify loss: 1.630064] 
[Epoch 8/10] [Batch 4/274] [Batch classify loss: 1.608205] 
[Epoch 8/10] [Batch 5/274] [Batch classify loss: 1.776432] 
[Epoch 8/10] [Batch 6/274] [Batch classify loss: 1.778165] 
[Epoch 8/10] [Batch 7/274] [Batch classify loss: 1.793502] 
[Epoch 8/10] [Batch 8/274] [Batch classify loss: 1.937151] 
[Epoch 8/10] [Batch 9/274] [Batch classify loss: 2.110359] 
[Epoch 8/10] [Batch 10/274] [Batch classify loss: 2.271718] 
[Epoch 8/10] [Batch 11/274] [Batch classify loss: 1.987475] 
[Epoch 8/10] [Batch 12/274] [Batch classify loss: 2.306408] 
[Epoch 8/10] [Batch 13/274] [Batch classify loss: 2.245602] 
[Epoch 8/10] [Batch 14/274] [Batch classify loss: 2.203846] 
[Epoch 8/10] [Batch 15/274] [Batch classify loss: 1.937115] 
[Epoch 8/10] [Batch 16/274] [Batch classify loss: 2.112540] 
[Epoch 8/10] [Batch 17/274] [Batch classify loss: 2.358080] 
[Epoch 8/10] [Batch 18/274] [Batch classify loss: 2.572610] 
[Epoch 8/10] [Batch 19/274] [Batch classify loss: 2.274108] 
[Epoch 8/10] [Batch 20/274] [Batch classify loss: 2.254610] 
[Epoch 8/10] [Batch 21/274] [Batch classify loss: 2.322273] 
[Epoch 8/10] [Batch 22/274] [Batch classify loss: 2.406919] 
[Epoch 8/10] [Batch 23/274] [Batch classify loss: 2.448505] 
[Epoch 8/10] [Batch 24/274] [Batch classify loss: 2.697596] 
[Epoch 8/10] [Batch 25/274] [Batch classify loss: 2.741027] 
[Epoch 8/10] [Batch 26/274] [Batch classify loss: 2.355753] 
[Epoch 8/10] [Batch 27/274] [Batch classify loss: 2.521001] 
[Epoch 8/10] [Batch 28/274] [Batch classify loss: 2.291418] 
[Epoch 8/10] [Batch 29/274] [Batch classify loss: 2.604800] 
[Epoch 8/10] [Batch 30/274] [Batch classify loss: 2.554168] 
[Epoch 8/10] [Batch 31/274] [Batch classify loss: 2.601875] 
[Epoch 8/10] [Batch 32/274] [Batch classify loss: 2.795096] 
[Epoch 8/10] [Batch 33/274] [Batch classify loss: 2.719161] 
[Epoch 8/10] [Batch 34/274] [Batch classify loss: 2.727288] 
[Epoch 8/10] [Batch 35/274] [Batch classify loss: 2.974120] 
[Epoch 8/10] [Batch 36/274] [Batch classify loss: 2.610716] 
[Epoch 8/10] [Batch 37/274] [Batch classify loss: 2.394446] 
[Epoch 8/10] [Batch 38/274] [Batch classify loss: 2.590442] 
[Epoch 8/10] [Batch 39/274] [Batch classify loss: 2.633889] 
[Epoch 8/10] [Batch 40/274] [Batch classify loss: 2.628365] 
[Epoch 8/10] [Batch 41/274] [Batch classify loss: 2.706599] 
[Epoch 8/10] [Batch 42/274] [Batch classify loss: 2.883319] 
[Epoch 8/10] [Batch 43/274] [Batch classify loss: 2.693034] 
[Epoch 8/10] [Batch 44/274] [Batch classify loss: 2.748286] 
[Epoch 8/10] [Batch 45/274] [Batch classify loss: 2.928535] 
[Epoch 8/10] [Batch 46/274] [Batch classify loss: 2.471457] 
[Epoch 8/10] [Batch 47/274] [Batch classify loss: 3.106992] 
[Epoch 8/10] [Batch 48/274] [Batch classify loss: 2.700333] 
[Epoch 8/10] [Batch 49/274] [Batch classify loss: 2.892630] 
[Epoch 8/10] [Batch 50/274] [Batch classify loss: 2.789747] 
[Epoch 8/10] [Batch 51/274] [Batch classify loss: 2.977686] 
[Epoch 8/10] [Batch 52/274] [Batch classify loss: 3.033045] 
[Epoch 8/10] [Batch 53/274] [Batch classify loss: 2.986136] 
[Epoch 8/10] [Batch 54/274] [Batch classify loss: 2.821155] 
[Epoch 8/10] [Batch 55/274] [Batch classify loss: 3.109523] 
[Epoch 8/10] [Batch 56/274] [Batch classify loss: 2.922836] 
[Epoch 8/10] [Batch 57/274] [Batch classify loss: 2.595849] 
[Epoch 8/10] [Batch 58/274] [Batch classify loss: 2.828988] 
[Epoch 8/10] [Batch 59/274] [Batch classify loss: 3.114450] 
[Epoch 8/10] [Batch 60/274] [Batch classify loss: 2.685226] 
[Epoch 8/10] [Batch 61/274] [Batch classify loss: 2.846062] 
[Epoch 8/10] [Batch 62/274] [Batch classify loss: 2.475770] 
[Epoch 8/10] [Batch 63/274] [Batch classify loss: 3.013408] 
[Epoch 8/10] [Batch 64/274] [Batch classify loss: 2.811795] 
[Epoch 8/10] [Batch 65/274] [Batch classify loss: 3.029463] 
[Epoch 8/10] [Batch 66/274] [Batch classify loss: 3.383695] 
[Epoch 8/10] [Batch 67/274] [Batch classify loss: 3.262434] 
[Epoch 8/10] [Batch 68/274] [Batch classify loss: 3.341506] 
[Epoch 8/10] [Batch 69/274] [Batch classify loss: 3.062607] 
[Epoch 8/10] [Batch 70/274] [Batch classify loss: 3.201278] 
[Epoch 8/10] [Batch 71/274] [Batch classify loss: 3.260887] 
[Epoch 8/10] [Batch 72/274] [Batch classify loss: 2.786989] 
[Epoch 8/10] [Batch 73/274] [Batch classify loss: 3.163589] 
[Epoch 8/10] [Batch 74/274] [Batch classify loss: 2.852097] 
[Epoch 8/10] [Batch 75/274] [Batch classify loss: 3.092791] 
[Epoch 8/10] [Batch 76/274] [Batch classify loss: 2.808375] 
[Epoch 8/10] [Batch 77/274] [Batch classify loss: 3.161900] 
[Epoch 8/10] [Batch 78/274] [Batch classify loss: 3.089804] 
[Epoch 8/10] [Batch 79/274] [Batch classify loss: 3.032055] 
[Epoch 8/10] [Batch 80/274] [Batch classify loss: 2.756108] 
[Epoch 8/10] [Batch 81/274] [Batch classify loss: 3.133078] 
[Epoch 8/10] [Batch 82/274] [Batch classify loss: 3.397743] 
[Epoch 8/10] [Batch 83/274] [Batch classify loss: 3.046045] 
[Epoch 8/10] [Batch 84/274] [Batch classify loss: 3.574963] 
[Epoch 8/10] [Batch 85/274] [Batch classify loss: 3.649427] 
[Epoch 8/10] [Batch 86/274] [Batch classify loss: 3.506339] 
[Epoch 8/10] [Batch 87/274] [Batch classify loss: 3.130383] 
[Epoch 8/10] [Batch 88/274] [Batch classify loss: 2.821671] 
[Epoch 8/10] [Batch 89/274] [Batch classify loss: 2.987947] 
[Epoch 8/10] [Batch 90/274] [Batch classify loss: 3.101285] 
[Epoch 8/10] [Batch 91/274] [Batch classify loss: 3.165244] 
[Epoch 8/10] [Batch 92/274] [Batch classify loss: 3.185839] 
[Epoch 8/10] [Batch 93/274] [Batch classify loss: 2.765916] 
[Epoch 8/10] [Batch 94/274] [Batch classify loss: 3.109305] 
[Epoch 8/10] [Batch 95/274] [Batch classify loss: 3.390365] 
[Epoch 8/10] [Batch 96/274] [Batch classify loss: 3.579440] 
[Epoch 8/10] [Batch 97/274] [Batch classify loss: 3.474543] 
[Epoch 8/10] [Batch 98/274] [Batch classify loss: 3.188456] 
[Epoch 8/10] [Batch 99/274] [Batch classify loss: 3.222071] 
[Epoch 8/10] [Batch 100/274] [Batch classify loss: 3.460573] 
[Epoch 8/10] [Batch 101/274] [Batch classify loss: 2.969307] 
[Epoch 8/10] [Batch 102/274] [Batch classify loss: 3.309212] 
[Epoch 8/10] [Batch 103/274] [Batch classify loss: 3.311973] 
[Epoch 8/10] [Batch 104/274] [Batch classify loss: 3.336056] 
[Epoch 8/10] [Batch 105/274] [Batch classify loss: 3.350714] 
[Epoch 8/10] [Batch 106/274] [Batch classify loss: 3.355761] 
[Epoch 8/10] [Batch 107/274] [Batch classify loss: 3.292753] 
[Epoch 8/10] [Batch 108/274] [Batch classify loss: 3.152025] 
[Epoch 8/10] [Batch 109/274] [Batch classify loss: 3.172734] 
[Epoch 8/10] [Batch 110/274] [Batch classify loss: 3.371937] 
[Epoch 8/10] [Batch 111/274] [Batch classify loss: 3.854915] 
[Epoch 8/10] [Batch 112/274] [Batch classify loss: 3.574547] 
[Epoch 8/10] [Batch 113/274] [Batch classify loss: 3.611252] 
[Epoch 8/10] [Batch 114/274] [Batch classify loss: 3.710727] 
[Epoch 8/10] [Batch 115/274] [Batch classify loss: 3.359026] 
[Epoch 8/10] [Batch 116/274] [Batch classify loss: 3.428917] 
[Epoch 8/10] [Batch 117/274] [Batch classify loss: 3.510264] 
[Epoch 8/10] [Batch 118/274] [Batch classify loss: 3.210378] 
[Epoch 8/10] [Batch 119/274] [Batch classify loss: 3.728993] 
[Epoch 8/10] [Batch 120/274] [Batch classify loss: 3.269423] 
[Epoch 8/10] [Batch 121/274] [Batch classify loss: 3.255160] 
[Epoch 8/10] [Batch 122/274] [Batch classify loss: 3.270642] 
[Epoch 8/10] [Batch 123/274] [Batch classify loss: 3.674117] 
[Epoch 8/10] [Batch 124/274] [Batch classify loss: 3.204288] 
[Epoch 8/10] [Batch 125/274] [Batch classify loss: 3.354401] 
[Epoch 8/10] [Batch 126/274] [Batch classify loss: 3.403188] 
[Epoch 8/10] [Batch 127/274] [Batch classify loss: 3.404251] 
[Epoch 8/10] [Batch 128/274] [Batch classify loss: 3.109177] 
[Epoch 8/10] [Batch 129/274] [Batch classify loss: 3.327682] 
[Epoch 8/10] [Batch 130/274] [Batch classify loss: 3.245977] 
[Epoch 8/10] [Batch 131/274] [Batch classify loss: 3.231484] 
[Epoch 8/10] [Batch 132/274] [Batch classify loss: 3.476023] 
[Epoch 8/10] [Batch 133/274] [Batch classify loss: 3.429358] 
[Epoch 8/10] [Batch 134/274] [Batch classify loss: 3.448896] 
[Epoch 8/10] [Batch 135/274] [Batch classify loss: 3.502681] 
[Epoch 8/10] [Batch 136/274] [Batch classify loss: 3.444501] 
[Epoch 8/10] [Batch 137/274] [Batch classify loss: 3.491461] 
[Epoch 8/10] [Batch 138/274] [Batch classify loss: 3.270359] 
[Epoch 8/10] [Batch 139/274] [Batch classify loss: 3.669051] 
[Epoch 8/10] [Batch 140/274] [Batch classify loss: 3.489772] 
[Epoch 8/10] [Batch 141/274] [Batch classify loss: 3.130317] 
[Epoch 8/10] [Batch 142/274] [Batch classify loss: 3.331234] 
[Epoch 8/10] [Batch 143/274] [Batch classify loss: 3.658743] 
[Epoch 8/10] [Batch 144/274] [Batch classify loss: 3.750707] 
[Epoch 8/10] [Batch 145/274] [Batch classify loss: 3.482476] 
[Epoch 8/10] [Batch 146/274] [Batch classify loss: 3.191436] 
[Epoch 8/10] [Batch 147/274] [Batch classify loss: 3.818789] 
[Epoch 8/10] [Batch 148/274] [Batch classify loss: 3.278210] 
[Epoch 8/10] [Batch 149/274] [Batch classify loss: 3.019696] 
[Epoch 8/10] [Batch 150/274] [Batch classify loss: 3.534503] 
[Epoch 8/10] [Batch 151/274] [Batch classify loss: 3.183402] 
[Epoch 8/10] [Batch 152/274] [Batch classify loss: 3.863178] 
[Epoch 8/10] [Batch 153/274] [Batch classify loss: 3.637229] 
[Epoch 8/10] [Batch 154/274] [Batch classify loss: 3.778171] 
[Epoch 8/10] [Batch 155/274] [Batch classify loss: 3.538548] 
[Epoch 8/10] [Batch 156/274] [Batch classify loss: 3.592855] 
[Epoch 8/10] [Batch 157/274] [Batch classify loss: 3.176541] 
[Epoch 8/10] [Batch 158/274] [Batch classify loss: 3.518282] 
[Epoch 8/10] [Batch 159/274] [Batch classify loss: 3.484831] 
[Epoch 8/10] [Batch 160/274] [Batch classify loss: 3.710097] 
[Epoch 8/10] [Batch 161/274] [Batch classify loss: 3.807211] 
[Epoch 8/10] [Batch 162/274] [Batch classify loss: 3.938264] 
[Epoch 8/10] [Batch 163/274] [Batch classify loss: 3.097083] 
[Epoch 8/10] [Batch 164/274] [Batch classify loss: 3.462790] 
[Epoch 8/10] [Batch 165/274] [Batch classify loss: 3.880532] 
[Epoch 8/10] [Batch 166/274] [Batch classify loss: 3.230685] 
[Epoch 8/10] [Batch 167/274] [Batch classify loss: 3.636473] 
[Epoch 8/10] [Batch 168/274] [Batch classify loss: 3.754107] 
[Epoch 8/10] [Batch 169/274] [Batch classify loss: 3.436537] 
[Epoch 8/10] [Batch 170/274] [Batch classify loss: 3.525783] 
[Epoch 8/10] [Batch 171/274] [Batch classify loss: 3.364054] 
[Epoch 8/10] [Batch 172/274] [Batch classify loss: 3.314163] 
[Epoch 8/10] [Batch 173/274] [Batch classify loss: 3.321209] 
[Epoch 8/10] [Batch 174/274] [Batch classify loss: 3.717036] 
[Epoch 8/10] [Batch 175/274] [Batch classify loss: 3.491499] 
[Epoch 8/10] [Batch 176/274] [Batch classify loss: 3.564340] 
[Epoch 8/10] [Batch 177/274] [Batch classify loss: 3.751976] 
[Epoch 8/10] [Batch 178/274] [Batch classify loss: 3.795333] 
[Epoch 8/10] [Batch 179/274] [Batch classify loss: 3.321486] 
[Epoch 8/10] [Batch 180/274] [Batch classify loss: 3.531923] 
[Epoch 8/10] [Batch 181/274] [Batch classify loss: 3.271463] 
[Epoch 8/10] [Batch 182/274] [Batch classify loss: 2.938355] 
[Epoch 8/10] [Batch 183/274] [Batch classify loss: 3.750108] 
[Epoch 8/10] [Batch 184/274] [Batch classify loss: 3.338284] 
[Epoch 8/10] [Batch 185/274] [Batch classify loss: 3.640988] 
[Epoch 8/10] [Batch 186/274] [Batch classify loss: 3.647266] 
[Epoch 8/10] [Batch 187/274] [Batch classify loss: 3.800580] 
[Epoch 8/10] [Batch 188/274] [Batch classify loss: 3.311447] 
[Epoch 8/10] [Batch 189/274] [Batch classify loss: 3.658880] 
[Epoch 8/10] [Batch 190/274] [Batch classify loss: 3.553789] 
[Epoch 8/10] [Batch 191/274] [Batch classify loss: 3.359614] 
[Epoch 8/10] [Batch 192/274] [Batch classify loss: 3.633419] 
[Epoch 8/10] [Batch 193/274] [Batch classify loss: 3.663863] 
[Epoch 8/10] [Batch 194/274] [Batch classify loss: 3.778578] 
[Epoch 8/10] [Batch 195/274] [Batch classify loss: 3.534522] 
[Epoch 8/10] [Batch 196/274] [Batch classify loss: 3.669621] 
[Epoch 8/10] [Batch 197/274] [Batch classify loss: 3.479664] 
[Epoch 8/10] [Batch 198/274] [Batch classify loss: 4.043085] 
[Epoch 8/10] [Batch 199/274] [Batch classify loss: 3.643998] 
[Epoch 8/10] [Batch 200/274] [Batch classify loss: 3.504516] 
[Epoch 8/10] [Batch 201/274] [Batch classify loss: 3.631619] 
[Epoch 8/10] [Batch 202/274] [Batch classify loss: 3.349121] 
[Epoch 8/10] [Batch 203/274] [Batch classify loss: 3.884593] 
[Epoch 8/10] [Batch 204/274] [Batch classify loss: 3.984838] 
[Epoch 8/10] [Batch 205/274] [Batch classify loss: 3.803815] 
[Epoch 8/10] [Batch 206/274] [Batch classify loss: 3.968793] 
[Epoch 8/10] [Batch 207/274] [Batch classify loss: 3.421453] 
[Epoch 8/10] [Batch 208/274] [Batch classify loss: 3.703743] 
[Epoch 8/10] [Batch 209/274] [Batch classify loss: 3.487960] 
[Epoch 8/10] [Batch 210/274] [Batch classify loss: 3.634869] 
[Epoch 8/10] [Batch 211/274] [Batch classify loss: 3.105472] 
[Epoch 8/10] [Batch 212/274] [Batch classify loss: 3.596410] 
[Epoch 8/10] [Batch 213/274] [Batch classify loss: 3.608251] 
[Epoch 8/10] [Batch 214/274] [Batch classify loss: 4.012989] 
[Epoch 8/10] [Batch 215/274] [Batch classify loss: 3.126768] 
[Epoch 8/10] [Batch 216/274] [Batch classify loss: 3.735801] 
[Epoch 8/10] [Batch 217/274] [Batch classify loss: 3.845787] 
[Epoch 8/10] [Batch 218/274] [Batch classify loss: 3.565148] 
[Epoch 8/10] [Batch 219/274] [Batch classify loss: 3.931829] 
[Epoch 8/10] [Batch 220/274] [Batch classify loss: 3.715018] 
[Epoch 8/10] [Batch 221/274] [Batch classify loss: 3.746365] 
[Epoch 8/10] [Batch 222/274] [Batch classify loss: 3.969586] 
[Epoch 8/10] [Batch 223/274] [Batch classify loss: 4.009706] 
[Epoch 8/10] [Batch 224/274] [Batch classify loss: 3.878739] 
[Epoch 8/10] [Batch 225/274] [Batch classify loss: 3.115906] 
[Epoch 8/10] [Batch 226/274] [Batch classify loss: 3.540421] 
[Epoch 8/10] [Batch 227/274] [Batch classify loss: 3.891506] 
[Epoch 8/10] [Batch 228/274] [Batch classify loss: 3.506350] 
[Epoch 8/10] [Batch 229/274] [Batch classify loss: 3.658008] 
[Epoch 8/10] [Batch 230/274] [Batch classify loss: 3.567046] 
[Epoch 8/10] [Batch 231/274] [Batch classify loss: 3.462299] 
[Epoch 8/10] [Batch 232/274] [Batch classify loss: 3.895638] 
[Epoch 8/10] [Batch 233/274] [Batch classify loss: 3.660178] 
[Epoch 8/10] [Batch 234/274] [Batch classify loss: 3.830579] 
[Epoch 8/10] [Batch 235/274] [Batch classify loss: 3.773586] 
[Epoch 8/10] [Batch 236/274] [Batch classify loss: 3.466657] 
[Epoch 8/10] [Batch 237/274] [Batch classify loss: 4.156154] 
[Epoch 8/10] [Batch 238/274] [Batch classify loss: 4.019134] 
[Epoch 8/10] [Batch 239/274] [Batch classify loss: 3.527596] 
[Epoch 8/10] [Batch 240/274] [Batch classify loss: 3.587698] 
[Epoch 8/10] [Batch 241/274] [Batch classify loss: 3.660963] 
[Epoch 8/10] [Batch 242/274] [Batch classify loss: 3.960499] 
[Epoch 8/10] [Batch 243/274] [Batch classify loss: 3.931535] 
[Epoch 8/10] [Batch 244/274] [Batch classify loss: 3.860638] 
[Epoch 8/10] [Batch 245/274] [Batch classify loss: 3.679642] 
[Epoch 8/10] [Batch 246/274] [Batch classify loss: 3.484183] 
[Epoch 8/10] [Batch 247/274] [Batch classify loss: 3.842933] 
[Epoch 8/10] [Batch 248/274] [Batch classify loss: 3.776796] 
[Epoch 8/10] [Batch 249/274] [Batch classify loss: 3.324369] 
[Epoch 8/10] [Batch 250/274] [Batch classify loss: 3.770427] 
[Epoch 8/10] [Batch 251/274] [Batch classify loss: 3.796451] 
[Epoch 8/10] [Batch 252/274] [Batch classify loss: 3.571176] 
[Epoch 8/10] [Batch 253/274] [Batch classify loss: 3.852249] 
[Epoch 8/10] [Batch 254/274] [Batch classify loss: 3.617201] 
[Epoch 8/10] [Batch 255/274] [Batch classify loss: 3.721401] 
[Epoch 8/10] [Batch 256/274] [Batch classify loss: 3.733092] 
[Epoch 8/10] [Batch 257/274] [Batch classify loss: 3.660100] 
[Epoch 8/10] [Batch 258/274] [Batch classify loss: 3.812249] 
[Epoch 8/10] [Batch 259/274] [Batch classify loss: 3.874677] 
[Epoch 8/10] [Batch 260/274] [Batch classify loss: 3.491370] 
[Epoch 8/10] [Batch 261/274] [Batch classify loss: 3.730130] 
[Epoch 8/10] [Batch 262/274] [Batch classify loss: 3.705857] 
[Epoch 8/10] [Batch 263/274] [Batch classify loss: 3.568914] 
[Epoch 8/10] [Batch 264/274] [Batch classify loss: 3.795289] 
[Epoch 8/10] [Batch 265/274] [Batch classify loss: 3.765380] 
[Epoch 8/10] [Batch 266/274] [Batch classify loss: 3.701320] 
[Epoch 8/10] [Batch 267/274] [Batch classify loss: 3.482033] 
[Epoch 8/10] [Batch 268/274] [Batch classify loss: 3.798372] 
[Epoch 8/10] [Batch 269/274] [Batch classify loss: 3.652810] 
[Epoch 8/10] [Batch 270/274] [Batch classify loss: 3.767045] 
[Epoch 8/10] [Batch 271/274] [Batch classify loss: 3.542181] 
[Epoch 8/10] [Batch 272/274] [Batch classify loss: 3.655186] 
[Epoch 8/10] [Batch 273/274] [Batch classify loss: 3.657950] 
[Epoch 8/10] [Batch 274/274] [Batch classify loss: 3.697766] 
0008 epoch mmat trained classifier accuary on the clean testing examples:94.6182%
0008 epoch mmat trained classifier loss on the clean testing examples:0.2230
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2197%
mmat trained classifier loss on adversarial testset:4.5261030197143555
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-cle
8epoch learning rate:0.1
[Epoch 9/10] [Batch 1/274] [Batch classify loss: 1.286235] 
[Epoch 9/10] [Batch 2/274] [Batch classify loss: 1.235091] 
[Epoch 9/10] [Batch 3/274] [Batch classify loss: 1.342673] 
[Epoch 9/10] [Batch 4/274] [Batch classify loss: 1.479975] 
[Epoch 9/10] [Batch 5/274] [Batch classify loss: 1.431238] 
[Epoch 9/10] [Batch 6/274] [Batch classify loss: 1.485315] 
[Epoch 9/10] [Batch 7/274] [Batch classify loss: 1.489242] 
[Epoch 9/10] [Batch 8/274] [Batch classify loss: 1.356608] 
[Epoch 9/10] [Batch 9/274] [Batch classify loss: 1.672907] 
[Epoch 9/10] [Batch 10/274] [Batch classify loss: 1.704927] 
[Epoch 9/10] [Batch 11/274] [Batch classify loss: 1.787631] 
[Epoch 9/10] [Batch 12/274] [Batch classify loss: 1.980423] 
[Epoch 9/10] [Batch 13/274] [Batch classify loss: 1.808890] 
[Epoch 9/10] [Batch 14/274] [Batch classify loss: 1.754645] 
[Epoch 9/10] [Batch 15/274] [Batch classify loss: 1.777305] 
[Epoch 9/10] [Batch 16/274] [Batch classify loss: 1.700445] 
[Epoch 9/10] [Batch 17/274] [Batch classify loss: 1.853612] 
[Epoch 9/10] [Batch 18/274] [Batch classify loss: 1.985313] 
[Epoch 9/10] [Batch 19/274] [Batch classify loss: 1.899601] 
[Epoch 9/10] [Batch 20/274] [Batch classify loss: 1.992848] 
[Epoch 9/10] [Batch 21/274] [Batch classify loss: 2.053305] 
[Epoch 9/10] [Batch 22/274] [Batch classify loss: 2.235134] 
[Epoch 9/10] [Batch 23/274] [Batch classify loss: 2.257983] 
[Epoch 9/10] [Batch 24/274] [Batch classify loss: 1.900004] 
[Epoch 9/10] [Batch 25/274] [Batch classify loss: 1.854366] 
[Epoch 9/10] [Batch 26/274] [Batch classify loss: 2.124500] 
[Epoch 9/10] [Batch 27/274] [Batch classify loss: 1.795688] 
[Epoch 9/10] [Batch 28/274] [Batch classify loss: 2.051039] 
[Epoch 9/10] [Batch 29/274] [Batch classify loss: 2.103034] 
[Epoch 9/10] [Batch 30/274] [Batch classify loss: 2.367400] 
[Epoch 9/10] [Batch 31/274] [Batch classify loss: 2.217320] 
[Epoch 9/10] [Batch 32/274] [Batch classify loss: 2.274598] 
[Epoch 9/10] [Batch 33/274] [Batch classify loss: 2.247731] 
[Epoch 9/10] [Batch 34/274] [Batch classify loss: 2.137225] 
[Epoch 9/10] [Batch 35/274] [Batch classify loss: 2.054312] 
[Epoch 9/10] [Batch 36/274] [Batch classify loss: 2.264949] 
[Epoch 9/10] [Batch 37/274] [Batch classify loss: 2.333181] 
[Epoch 9/10] [Batch 38/274] [Batch classify loss: 2.122378] 
[Epoch 9/10] [Batch 39/274] [Batch classify loss: 2.291278] 
[Epoch 9/10] [Batch 40/274] [Batch classify loss: 2.119369] 
[Epoch 9/10] [Batch 41/274] [Batch classify loss: 2.265328] 
[Epoch 9/10] [Batch 42/274] [Batch classify loss: 2.336405] 
[Epoch 9/10] [Batch 43/274] [Batch classify loss: 2.407998] 
[Epoch 9/10] [Batch 44/274] [Batch classify loss: 2.369266] 
[Epoch 9/10] [Batch 45/274] [Batch classify loss: 2.255785] 
[Epoch 9/10] [Batch 46/274] [Batch classify loss: 2.487622] 
[Epoch 9/10] [Batch 47/274] [Batch classify loss: 2.425968] 
[Epoch 9/10] [Batch 48/274] [Batch classify loss: 2.260468] 
[Epoch 9/10] [Batch 49/274] [Batch classify loss: 2.323246] 
[Epoch 9/10] [Batch 50/274] [Batch classify loss: 2.504080] 
[Epoch 9/10] [Batch 51/274] [Batch classify loss: 2.676598] 
[Epoch 9/10] [Batch 52/274] [Batch classify loss: 2.401350] 
[Epoch 9/10] [Batch 53/274] [Batch classify loss: 2.394897] 
[Epoch 9/10] [Batch 54/274] [Batch classify loss: 2.555651] 
[Epoch 9/10] [Batch 55/274] [Batch classify loss: 2.587196] 
[Epoch 9/10] [Batch 56/274] [Batch classify loss: 2.220569] 
[Epoch 9/10] [Batch 57/274] [Batch classify loss: 2.439136] 
[Epoch 9/10] [Batch 58/274] [Batch classify loss: 2.843682] 
[Epoch 9/10] [Batch 59/274] [Batch classify loss: 2.377248] 
[Epoch 9/10] [Batch 60/274] [Batch classify loss: 2.535552] 
[Epoch 9/10] [Batch 61/274] [Batch classify loss: 2.439110] 
[Epoch 9/10] [Batch 62/274] [Batch classify loss: 2.690427] 
[Epoch 9/10] [Batch 63/274] [Batch classify loss: 2.445813] 
[Epoch 9/10] [Batch 64/274] [Batch classify loss: 2.483757] 
[Epoch 9/10] [Batch 65/274] [Batch classify loss: 2.498577] 
[Epoch 9/10] [Batch 66/274] [Batch classify loss: 2.286890] 
[Epoch 9/10] [Batch 67/274] [Batch classify loss: 2.703079] 
[Epoch 9/10] [Batch 68/274] [Batch classify loss: 2.657571] 
[Epoch 9/10] [Batch 69/274] [Batch classify loss: 2.537864] 
[Epoch 9/10] [Batch 70/274] [Batch classify loss: 2.413447] 
[Epoch 9/10] [Batch 71/274] [Batch classify loss: 2.486069] 
[Epoch 9/10] [Batch 72/274] [Batch classify loss: 2.615178] 
[Epoch 9/10] [Batch 73/274] [Batch classify loss: 2.892658] 
[Epoch 9/10] [Batch 74/274] [Batch classify loss: 2.931745] 
[Epoch 9/10] [Batch 75/274] [Batch classify loss: 2.454919] 
[Epoch 9/10] [Batch 76/274] [Batch classify loss: 2.954044] 
[Epoch 9/10] [Batch 77/274] [Batch classify loss: 2.633459] 
[Epoch 9/10] [Batch 78/274] [Batch classify loss: 2.566211] 
[Epoch 9/10] [Batch 79/274] [Batch classify loss: 2.807356] 
[Epoch 9/10] [Batch 80/274] [Batch classify loss: 2.574053] 
[Epoch 9/10] [Batch 81/274] [Batch classify loss: 2.795069] 
[Epoch 9/10] [Batch 82/274] [Batch classify loss: 2.754865] 
[Epoch 9/10] [Batch 83/274] [Batch classify loss: 2.760544] 
[Epoch 9/10] [Batch 84/274] [Batch classify loss: 2.331757] 
[Epoch 9/10] [Batch 85/274] [Batch classify loss: 2.542416] 
[Epoch 9/10] [Batch 86/274] [Batch classify loss: 2.582230] 
[Epoch 9/10] [Batch 87/274] [Batch classify loss: 2.418649] 
[Epoch 9/10] [Batch 88/274] [Batch classify loss: 2.727492] 
[Epoch 9/10] [Batch 89/274] [Batch classify loss: 2.918396] 
[Epoch 9/10] [Batch 90/274] [Batch classify loss: 2.487379] 
[Epoch 9/10] [Batch 91/274] [Batch classify loss: 2.947050] 
[Epoch 9/10] [Batch 92/274] [Batch classify loss: 2.550673] 
[Epoch 9/10] [Batch 93/274] [Batch classify loss: 2.735580] 
[Epoch 9/10] [Batch 94/274] [Batch classify loss: 2.519619] 
[Epoch 9/10] [Batch 95/274] [Batch classify loss: 2.561228] 
[Epoch 9/10] [Batch 96/274] [Batch classify loss: 3.057623] 
[Epoch 9/10] [Batch 97/274] [Batch classify loss: 2.693355] 
[Epoch 9/10] [Batch 98/274] [Batch classify loss: 2.762323] 
[Epoch 9/10] [Batch 99/274] [Batch classify loss: 2.570624] 
[Epoch 9/10] [Batch 100/274] [Batch classify loss: 3.048402] 
[Epoch 9/10] [Batch 101/274] [Batch classify loss: 2.774699] 
[Epoch 9/10] [Batch 102/274] [Batch classify loss: 2.615362] 
[Epoch 9/10] [Batch 103/274] [Batch classify loss: 2.587404] 
[Epoch 9/10] [Batch 104/274] [Batch classify loss: 2.576832] 
[Epoch 9/10] [Batch 105/274] [Batch classify loss: 2.414067] 
[Epoch 9/10] [Batch 106/274] [Batch classify loss: 2.759127] 
[Epoch 9/10] [Batch 107/274] [Batch classify loss: 2.795745] 
[Epoch 9/10] [Batch 108/274] [Batch classify loss: 2.874505] 
[Epoch 9/10] [Batch 109/274] [Batch classify loss: 2.598704] 
[Epoch 9/10] [Batch 110/274] [Batch classify loss: 2.627659] 
[Epoch 9/10] [Batch 111/274] [Batch classify loss: 2.848931] 
[Epoch 9/10] [Batch 112/274] [Batch classify loss: 2.931159] 
[Epoch 9/10] [Batch 113/274] [Batch classify loss: 2.641932] 
[Epoch 9/10] [Batch 114/274] [Batch classify loss: 2.808542] 
[Epoch 9/10] [Batch 115/274] [Batch classify loss: 3.317925] 
[Epoch 9/10] [Batch 116/274] [Batch classify loss: 2.857048] 
[Epoch 9/10] [Batch 117/274] [Batch classify loss: 2.775846] 
[Epoch 9/10] [Batch 118/274] [Batch classify loss: 2.789747] 
[Epoch 9/10] [Batch 119/274] [Batch classify loss: 3.079318] 
[Epoch 9/10] [Batch 120/274] [Batch classify loss: 2.425205] 
[Epoch 9/10] [Batch 121/274] [Batch classify loss: 2.784610] 
[Epoch 9/10] [Batch 122/274] [Batch classify loss: 3.069338] 
[Epoch 9/10] [Batch 123/274] [Batch classify loss: 3.058572] 
[Epoch 9/10] [Batch 124/274] [Batch classify loss: 2.733846] 
[Epoch 9/10] [Batch 125/274] [Batch classify loss: 3.026817] 
[Epoch 9/10] [Batch 126/274] [Batch classify loss: 3.017363] 
[Epoch 9/10] [Batch 127/274] [Batch classify loss: 2.812064] 
[Epoch 9/10] [Batch 128/274] [Batch classify loss: 2.598239] 
[Epoch 9/10] [Batch 129/274] [Batch classify loss: 3.066083] 
[Epoch 9/10] [Batch 130/274] [Batch classify loss: 2.756167] 
[Epoch 9/10] [Batch 131/274] [Batch classify loss: 2.569814] 
[Epoch 9/10] [Batch 132/274] [Batch classify loss: 2.904150] 
[Epoch 9/10] [Batch 133/274] [Batch classify loss: 2.788541] 
[Epoch 9/10] [Batch 134/274] [Batch classify loss: 3.102341] 
[Epoch 9/10] [Batch 135/274] [Batch classify loss: 2.897877] 
[Epoch 9/10] [Batch 136/274] [Batch classify loss: 2.979010] 
[Epoch 9/10] [Batch 137/274] [Batch classify loss: 2.898945] 
[Epoch 9/10] [Batch 138/274] [Batch classify loss: 2.672943] 
[Epoch 9/10] [Batch 139/274] [Batch classify loss: 2.734482] 
[Epoch 9/10] [Batch 140/274] [Batch classify loss: 2.892521] 
[Epoch 9/10] [Batch 141/274] [Batch classify loss: 3.049228] 
[Epoch 9/10] [Batch 142/274] [Batch classify loss: 3.071741] 
[Epoch 9/10] [Batch 143/274] [Batch classify loss: 2.473450] 
[Epoch 9/10] [Batch 144/274] [Batch classify loss: 2.982329] 
[Epoch 9/10] [Batch 145/274] [Batch classify loss: 2.999610] 
[Epoch 9/10] [Batch 146/274] [Batch classify loss: 3.364469] 
[Epoch 9/10] [Batch 147/274] [Batch classify loss: 3.144844] 
[Epoch 9/10] [Batch 148/274] [Batch classify loss: 3.028336] 
[Epoch 9/10] [Batch 149/274] [Batch classify loss: 3.046037] 
[Epoch 9/10] [Batch 150/274] [Batch classify loss: 2.851143] 
[Epoch 9/10] [Batch 151/274] [Batch classify loss: 2.899190] 
[Epoch 9/10] [Batch 152/274] [Batch classify loss: 2.935473] 
[Epoch 9/10] [Batch 153/274] [Batch classify loss: 2.757865] 
[Epoch 9/10] [Batch 154/274] [Batch classify loss: 3.085507] 
[Epoch 9/10] [Batch 155/274] [Batch classify loss: 3.231800] 
[Epoch 9/10] [Batch 156/274] [Batch classify loss: 2.610307] 
[Epoch 9/10] [Batch 157/274] [Batch classify loss: 2.578626] 
[Epoch 9/10] [Batch 158/274] [Batch classify loss: 2.949214] 
[Epoch 9/10] [Batch 159/274] [Batch classify loss: 2.856922] 
[Epoch 9/10] [Batch 160/274] [Batch classify loss: 2.900048] 
[Epoch 9/10] [Batch 161/274] [Batch classify loss: 3.020623] 
[Epoch 9/10] [Batch 162/274] [Batch classify loss: 2.831371] 
[Epoch 9/10] [Batch 163/274] [Batch classify loss: 2.797501] 
[Epoch 9/10] [Batch 164/274] [Batch classify loss: 3.249311] 
[Epoch 9/10] [Batch 165/274] [Batch classify loss: 2.776697] 
[Epoch 9/10] [Batch 166/274] [Batch classify loss: 3.032231] 
[Epoch 9/10] [Batch 167/274] [Batch classify loss: 2.945908] 
[Epoch 9/10] [Batch 168/274] [Batch classify loss: 3.075634] 
[Epoch 9/10] [Batch 169/274] [Batch classify loss: 2.861853] 
[Epoch 9/10] [Batch 170/274] [Batch classify loss: 3.211404] 
[Epoch 9/10] [Batch 171/274] [Batch classify loss: 3.324079] 
[Epoch 9/10] [Batch 172/274] [Batch classify loss: 3.618110] 
[Epoch 9/10] [Batch 173/274] [Batch classify loss: 3.056374] 
[Epoch 9/10] [Batch 174/274] [Batch classify loss: 3.293948] 
[Epoch 9/10] [Batch 175/274] [Batch classify loss: 2.927268] 
[Epoch 9/10] [Batch 176/274] [Batch classify loss: 2.908666] 
[Epoch 9/10] [Batch 177/274] [Batch classify loss: 2.965473] 
[Epoch 9/10] [Batch 178/274] [Batch classify loss: 3.097807] 
[Epoch 9/10] [Batch 179/274] [Batch classify loss: 2.884766] 
[Epoch 9/10] [Batch 180/274] [Batch classify loss: 2.952654] 
[Epoch 9/10] [Batch 181/274] [Batch classify loss: 2.774337] 
[Epoch 9/10] [Batch 182/274] [Batch classify loss: 2.995556] 
[Epoch 9/10] [Batch 183/274] [Batch classify loss: 3.377618] 
[Epoch 9/10] [Batch 184/274] [Batch classify loss: 3.059126] 
[Epoch 9/10] [Batch 185/274] [Batch classify loss: 2.889134] 
[Epoch 9/10] [Batch 186/274] [Batch classify loss: 3.251540] 
[Epoch 9/10] [Batch 187/274] [Batch classify loss: 3.198645] 
[Epoch 9/10] [Batch 188/274] [Batch classify loss: 3.120726] 
[Epoch 9/10] [Batch 189/274] [Batch classify loss: 2.783983] 
[Epoch 9/10] [Batch 190/274] [Batch classify loss: 3.211125] 
[Epoch 9/10] [Batch 191/274] [Batch classify loss: 2.932600] 
[Epoch 9/10] [Batch 192/274] [Batch classify loss: 3.166399] 
[Epoch 9/10] [Batch 193/274] [Batch classify loss: 3.052626] 
[Epoch 9/10] [Batch 194/274] [Batch classify loss: 3.220488] 
[Epoch 9/10] [Batch 195/274] [Batch classify loss: 2.838891] 
[Epoch 9/10] [Batch 196/274] [Batch classify loss: 2.988161] 
[Epoch 9/10] [Batch 197/274] [Batch classify loss: 3.192893] 
[Epoch 9/10] [Batch 198/274] [Batch classify loss: 3.172057] 
[Epoch 9/10] [Batch 199/274] [Batch classify loss: 2.647961] 
[Epoch 9/10] [Batch 200/274] [Batch classify loss: 3.395895] 
[Epoch 9/10] [Batch 201/274] [Batch classify loss: 2.791152] 
[Epoch 9/10] [Batch 202/274] [Batch classify loss: 2.895001] 
[Epoch 9/10] [Batch 203/274] [Batch classify loss: 3.132644] 
[Epoch 9/10] [Batch 204/274] [Batch classify loss: 3.021341] 
[Epoch 9/10] [Batch 205/274] [Batch classify loss: 3.062571] 
[Epoch 9/10] [Batch 206/274] [Batch classify loss: 3.001354] 
[Epoch 9/10] [Batch 207/274] [Batch classify loss: 3.412452] 
[Epoch 9/10] [Batch 208/274] [Batch classify loss: 3.141866] 
[Epoch 9/10] [Batch 209/274] [Batch classify loss: 3.718702] 
[Epoch 9/10] [Batch 210/274] [Batch classify loss: 3.319031] 
[Epoch 9/10] [Batch 211/274] [Batch classify loss: 3.372792] 
[Epoch 9/10] [Batch 212/274] [Batch classify loss: 2.964342] 
[Epoch 9/10] [Batch 213/274] [Batch classify loss: 2.975000] 
[Epoch 9/10] [Batch 214/274] [Batch classify loss: 3.037504] 
[Epoch 9/10] [Batch 215/274] [Batch classify loss: 3.339478] 
[Epoch 9/10] [Batch 216/274] [Batch classify loss: 3.408465] 
[Epoch 9/10] [Batch 217/274] [Batch classify loss: 3.149744] 
[Epoch 9/10] [Batch 218/274] [Batch classify loss: 3.017429] 
[Epoch 9/10] [Batch 219/274] [Batch classify loss: 3.217296] 
[Epoch 9/10] [Batch 220/274] [Batch classify loss: 2.752819] 
[Epoch 9/10] [Batch 221/274] [Batch classify loss: 3.334599] 
[Epoch 9/10] [Batch 222/274] [Batch classify loss: 2.923728] 
[Epoch 9/10] [Batch 223/274] [Batch classify loss: 3.185646] 
[Epoch 9/10] [Batch 224/274] [Batch classify loss: 3.160562] 
[Epoch 9/10] [Batch 225/274] [Batch classify loss: 3.252100] 
[Epoch 9/10] [Batch 226/274] [Batch classify loss: 2.924058] 
[Epoch 9/10] [Batch 227/274] [Batch classify loss: 3.128138] 
[Epoch 9/10] [Batch 228/274] [Batch classify loss: 3.410600] 
[Epoch 9/10] [Batch 229/274] [Batch classify loss: 2.929678] 
[Epoch 9/10] [Batch 230/274] [Batch classify loss: 3.339640] 
[Epoch 9/10] [Batch 231/274] [Batch classify loss: 2.812871] 
[Epoch 9/10] [Batch 232/274] [Batch classify loss: 3.697263] 
[Epoch 9/10] [Batch 233/274] [Batch classify loss: 2.953092] 
[Epoch 9/10] [Batch 234/274] [Batch classify loss: 3.220014] 
[Epoch 9/10] [Batch 235/274] [Batch classify loss: 3.129826] 
[Epoch 9/10] [Batch 236/274] [Batch classify loss: 3.007273] 
[Epoch 9/10] [Batch 237/274] [Batch classify loss: 3.255930] 
[Epoch 9/10] [Batch 238/274] [Batch classify loss: 3.408043] 
[Epoch 9/10] [Batch 239/274] [Batch classify loss: 2.793296] 
[Epoch 9/10] [Batch 240/274] [Batch classify loss: 2.868362] 
[Epoch 9/10] [Batch 241/274] [Batch classify loss: 2.966696] 
[Epoch 9/10] [Batch 242/274] [Batch classify loss: 3.579447] 
[Epoch 9/10] [Batch 243/274] [Batch classify loss: 3.293231] 
[Epoch 9/10] [Batch 244/274] [Batch classify loss: 3.203135] 
[Epoch 9/10] [Batch 245/274] [Batch classify loss: 3.162464] 
[Epoch 9/10] [Batch 246/274] [Batch classify loss: 2.964055] 
[Epoch 9/10] [Batch 247/274] [Batch classify loss: 3.015619] 
[Epoch 9/10] [Batch 248/274] [Batch classify loss: 3.106646] 
[Epoch 9/10] [Batch 249/274] [Batch classify loss: 2.948770] 
[Epoch 9/10] [Batch 250/274] [Batch classify loss: 3.283753] 
[Epoch 9/10] [Batch 251/274] [Batch classify loss: 3.257145] 
[Epoch 9/10] [Batch 252/274] [Batch classify loss: 2.896707] 
[Epoch 9/10] [Batch 253/274] [Batch classify loss: 3.212509] 
[Epoch 9/10] [Batch 254/274] [Batch classify loss: 3.268009] 
[Epoch 9/10] [Batch 255/274] [Batch classify loss: 2.949151] 
[Epoch 9/10] [Batch 256/274] [Batch classify loss: 3.440618] 
[Epoch 9/10] [Batch 257/274] [Batch classify loss: 3.280473] 
[Epoch 9/10] [Batch 258/274] [Batch classify loss: 3.351545] 
[Epoch 9/10] [Batch 259/274] [Batch classify loss: 3.515198] 
[Epoch 9/10] [Batch 260/274] [Batch classify loss: 3.100251] 
[Epoch 9/10] [Batch 261/274] [Batch classify loss: 3.346950] 
[Epoch 9/10] [Batch 262/274] [Batch classify loss: 3.313121] 
[Epoch 9/10] [Batch 263/274] [Batch classify loss: 3.140900] 
[Epoch 9/10] [Batch 264/274] [Batch classify loss: 3.284277] 
[Epoch 9/10] [Batch 265/274] [Batch classify loss: 3.550977] 
[Epoch 9/10] [Batch 266/274] [Batch classify loss: 3.367768] 
[Epoch 9/10] [Batch 267/274] [Batch classify loss: 2.930668] 
[Epoch 9/10] [Batch 268/274] [Batch classify loss: 3.216077] 
[Epoch 9/10] [Batch 269/274] [Batch classify loss: 3.221995] 
[Epoch 9/10] [Batch 270/274] [Batch classify loss: 3.455652] 
[Epoch 9/10] [Batch 271/274] [Batch classify loss: 3.046747] 
[Epoch 9/10] [Batch 272/274] [Batch classify loss: 3.213038] 
[Epoch 9/10] [Batch 273/274] [Batch classify loss: 3.199709] 
[Epoch 9/10] [Batch 274/274] [Batch classify loss: 3.117898] 
0009 epoch mmat trained classifier accuary on the clean testing examples:94.6988%
0009 epoch mmat trained classifier loss on the clean testing examples:0.2257
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3158%
mmat trained classifier loss on adversarial testset:4.505611896514893
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-cle
9epoch learning rate:0.1
[Epoch 10/10] [Batch 1/274] [Batch classify loss: 1.402376] 
[Epoch 10/10] [Batch 2/274] [Batch classify loss: 1.102225] 
[Epoch 10/10] [Batch 3/274] [Batch classify loss: 1.113215] 
[Epoch 10/10] [Batch 4/274] [Batch classify loss: 1.345492] 
[Epoch 10/10] [Batch 5/274] [Batch classify loss: 1.333318] 
[Epoch 10/10] [Batch 6/274] [Batch classify loss: 1.258502] 
[Epoch 10/10] [Batch 7/274] [Batch classify loss: 1.157491] 
[Epoch 10/10] [Batch 8/274] [Batch classify loss: 1.339677] 
[Epoch 10/10] [Batch 9/274] [Batch classify loss: 1.397888] 
[Epoch 10/10] [Batch 10/274] [Batch classify loss: 1.447661] 
[Epoch 10/10] [Batch 11/274] [Batch classify loss: 1.343505] 
[Epoch 10/10] [Batch 12/274] [Batch classify loss: 1.350823] 
[Epoch 10/10] [Batch 13/274] [Batch classify loss: 1.442579] 
[Epoch 10/10] [Batch 14/274] [Batch classify loss: 1.554105] 
[Epoch 10/10] [Batch 15/274] [Batch classify loss: 1.451376] 
[Epoch 10/10] [Batch 16/274] [Batch classify loss: 1.551081] 
[Epoch 10/10] [Batch 17/274] [Batch classify loss: 1.662045] 
[Epoch 10/10] [Batch 18/274] [Batch classify loss: 1.755922] 
[Epoch 10/10] [Batch 19/274] [Batch classify loss: 1.691912] 
[Epoch 10/10] [Batch 20/274] [Batch classify loss: 1.548157] 
[Epoch 10/10] [Batch 21/274] [Batch classify loss: 1.805315] 
[Epoch 10/10] [Batch 22/274] [Batch classify loss: 1.697903] 
[Epoch 10/10] [Batch 23/274] [Batch classify loss: 1.669826] 
[Epoch 10/10] [Batch 24/274] [Batch classify loss: 1.738296] 
[Epoch 10/10] [Batch 25/274] [Batch classify loss: 1.592879] 
[Epoch 10/10] [Batch 26/274] [Batch classify loss: 1.913237] 
[Epoch 10/10] [Batch 27/274] [Batch classify loss: 1.837648] 
[Epoch 10/10] [Batch 28/274] [Batch classify loss: 1.677024] 
[Epoch 10/10] [Batch 29/274] [Batch classify loss: 1.758095] 
[Epoch 10/10] [Batch 30/274] [Batch classify loss: 1.810371] 
[Epoch 10/10] [Batch 31/274] [Batch classify loss: 1.770670] 
[Epoch 10/10] [Batch 32/274] [Batch classify loss: 1.854154] 
[Epoch 10/10] [Batch 33/274] [Batch classify loss: 1.956066] 
[Epoch 10/10] [Batch 34/274] [Batch classify loss: 1.601186] 
[Epoch 10/10] [Batch 35/274] [Batch classify loss: 1.693520] 
[Epoch 10/10] [Batch 36/274] [Batch classify loss: 2.126584] 
[Epoch 10/10] [Batch 37/274] [Batch classify loss: 1.970755] 
[Epoch 10/10] [Batch 38/274] [Batch classify loss: 1.768641] 
[Epoch 10/10] [Batch 39/274] [Batch classify loss: 1.914973] 
[Epoch 10/10] [Batch 40/274] [Batch classify loss: 2.082286] 
[Epoch 10/10] [Batch 41/274] [Batch classify loss: 1.987797] 
[Epoch 10/10] [Batch 42/274] [Batch classify loss: 1.831136] 
[Epoch 10/10] [Batch 43/274] [Batch classify loss: 1.994472] 
[Epoch 10/10] [Batch 44/274] [Batch classify loss: 1.810229] 
[Epoch 10/10] [Batch 45/274] [Batch classify loss: 1.891153] 
[Epoch 10/10] [Batch 46/274] [Batch classify loss: 2.286175] 
[Epoch 10/10] [Batch 47/274] [Batch classify loss: 2.081586] 
[Epoch 10/10] [Batch 48/274] [Batch classify loss: 2.012938] 
[Epoch 10/10] [Batch 49/274] [Batch classify loss: 2.026548] 
[Epoch 10/10] [Batch 50/274] [Batch classify loss: 2.014545] 
[Epoch 10/10] [Batch 51/274] [Batch classify loss: 1.805280] 
[Epoch 10/10] [Batch 52/274] [Batch classify loss: 1.705592] 
[Epoch 10/10] [Batch 53/274] [Batch classify loss: 2.000070] 
[Epoch 10/10] [Batch 54/274] [Batch classify loss: 2.120110] 
[Epoch 10/10] [Batch 55/274] [Batch classify loss: 1.986022] 
[Epoch 10/10] [Batch 56/274] [Batch classify loss: 1.921794] 
[Epoch 10/10] [Batch 57/274] [Batch classify loss: 1.914369] 
[Epoch 10/10] [Batch 58/274] [Batch classify loss: 2.103009] 
[Epoch 10/10] [Batch 59/274] [Batch classify loss: 2.053428] 
[Epoch 10/10] [Batch 60/274] [Batch classify loss: 1.942019] 
[Epoch 10/10] [Batch 61/274] [Batch classify loss: 2.222337] 
[Epoch 10/10] [Batch 62/274] [Batch classify loss: 2.217686] 
[Epoch 10/10] [Batch 63/274] [Batch classify loss: 1.960751] 
[Epoch 10/10] [Batch 64/274] [Batch classify loss: 2.127596] 
[Epoch 10/10] [Batch 65/274] [Batch classify loss: 2.001971] 
[Epoch 10/10] [Batch 66/274] [Batch classify loss: 2.102467] 
[Epoch 10/10] [Batch 67/274] [Batch classify loss: 2.022174] 
[Epoch 10/10] [Batch 68/274] [Batch classify loss: 2.116043] 
[Epoch 10/10] [Batch 69/274] [Batch classify loss: 2.297129] 
[Epoch 10/10] [Batch 70/274] [Batch classify loss: 2.137916] 
[Epoch 10/10] [Batch 71/274] [Batch classify loss: 2.210699] 
[Epoch 10/10] [Batch 72/274] [Batch classify loss: 2.102812] 
[Epoch 10/10] [Batch 73/274] [Batch classify loss: 2.126110] 
[Epoch 10/10] [Batch 74/274] [Batch classify loss: 2.378976] 
[Epoch 10/10] [Batch 75/274] [Batch classify loss: 2.284555] 
[Epoch 10/10] [Batch 76/274] [Batch classify loss: 1.755454] 
[Epoch 10/10] [Batch 77/274] [Batch classify loss: 2.169108] 
[Epoch 10/10] [Batch 78/274] [Batch classify loss: 1.942167] 
[Epoch 10/10] [Batch 79/274] [Batch classify loss: 2.219173] 
[Epoch 10/10] [Batch 80/274] [Batch classify loss: 2.217583] 
[Epoch 10/10] [Batch 81/274] [Batch classify loss: 2.344518] 
[Epoch 10/10] [Batch 82/274] [Batch classify loss: 2.101880] 
[Epoch 10/10] [Batch 83/274] [Batch classify loss: 2.321874] 
[Epoch 10/10] [Batch 84/274] [Batch classify loss: 2.084245] 
[Epoch 10/10] [Batch 85/274] [Batch classify loss: 2.002994] 
[Epoch 10/10] [Batch 86/274] [Batch classify loss: 2.119503] 
[Epoch 10/10] [Batch 87/274] [Batch classify loss: 2.326552] 
[Epoch 10/10] [Batch 88/274] [Batch classify loss: 2.217697] 
[Epoch 10/10] [Batch 89/274] [Batch classify loss: 2.079432] 
[Epoch 10/10] [Batch 90/274] [Batch classify loss: 2.421268] 
[Epoch 10/10] [Batch 91/274] [Batch classify loss: 2.511497] 
[Epoch 10/10] [Batch 92/274] [Batch classify loss: 2.452271] 
[Epoch 10/10] [Batch 93/274] [Batch classify loss: 2.215239] 
[Epoch 10/10] [Batch 94/274] [Batch classify loss: 2.293012] 
[Epoch 10/10] [Batch 95/274] [Batch classify loss: 2.289476] 
[Epoch 10/10] [Batch 96/274] [Batch classify loss: 2.292598] 
[Epoch 10/10] [Batch 97/274] [Batch classify loss: 2.098209] 
[Epoch 10/10] [Batch 98/274] [Batch classify loss: 2.456800] 
[Epoch 10/10] [Batch 99/274] [Batch classify loss: 2.418439] 
[Epoch 10/10] [Batch 100/274] [Batch classify loss: 2.425674] 
[Epoch 10/10] [Batch 101/274] [Batch classify loss: 2.394397] 
[Epoch 10/10] [Batch 102/274] [Batch classify loss: 2.495544] 
[Epoch 10/10] [Batch 103/274] [Batch classify loss: 2.451974] 
[Epoch 10/10] [Batch 104/274] [Batch classify loss: 2.403619] 
[Epoch 10/10] [Batch 105/274] [Batch classify loss: 2.503705] 
[Epoch 10/10] [Batch 106/274] [Batch classify loss: 1.859678] 
[Epoch 10/10] [Batch 107/274] [Batch classify loss: 1.908049] 
[Epoch 10/10] [Batch 108/274] [Batch classify loss: 2.392404] 
[Epoch 10/10] [Batch 109/274] [Batch classify loss: 2.578437] 
[Epoch 10/10] [Batch 110/274] [Batch classify loss: 2.138457] 
[Epoch 10/10] [Batch 111/274] [Batch classify loss: 2.601612] 
[Epoch 10/10] [Batch 112/274] [Batch classify loss: 2.599669] 
[Epoch 10/10] [Batch 113/274] [Batch classify loss: 2.579732] 
[Epoch 10/10] [Batch 114/274] [Batch classify loss: 2.589018] 
[Epoch 10/10] [Batch 115/274] [Batch classify loss: 2.205280] 
[Epoch 10/10] [Batch 116/274] [Batch classify loss: 2.516618] 
[Epoch 10/10] [Batch 117/274] [Batch classify loss: 2.558750] 
[Epoch 10/10] [Batch 118/274] [Batch classify loss: 2.281393] 
[Epoch 10/10] [Batch 119/274] [Batch classify loss: 2.647343] 
[Epoch 10/10] [Batch 120/274] [Batch classify loss: 2.536061] 
[Epoch 10/10] [Batch 121/274] [Batch classify loss: 2.517635] 
[Epoch 10/10] [Batch 122/274] [Batch classify loss: 2.454700] 
[Epoch 10/10] [Batch 123/274] [Batch classify loss: 2.313418] 
[Epoch 10/10] [Batch 124/274] [Batch classify loss: 2.431043] 
[Epoch 10/10] [Batch 125/274] [Batch classify loss: 2.155754] 
[Epoch 10/10] [Batch 126/274] [Batch classify loss: 2.513064] 
[Epoch 10/10] [Batch 127/274] [Batch classify loss: 2.200502] 
[Epoch 10/10] [Batch 128/274] [Batch classify loss: 2.610393] 
[Epoch 10/10] [Batch 129/274] [Batch classify loss: 2.694303] 
[Epoch 10/10] [Batch 130/274] [Batch classify loss: 2.341103] 
[Epoch 10/10] [Batch 131/274] [Batch classify loss: 2.575998] 
[Epoch 10/10] [Batch 132/274] [Batch classify loss: 2.587764] 
[Epoch 10/10] [Batch 133/274] [Batch classify loss: 2.496255] 
[Epoch 10/10] [Batch 134/274] [Batch classify loss: 2.390653] 
[Epoch 10/10] [Batch 135/274] [Batch classify loss: 2.619174] 
[Epoch 10/10] [Batch 136/274] [Batch classify loss: 2.554349] 
[Epoch 10/10] [Batch 137/274] [Batch classify loss: 2.370099] 
[Epoch 10/10] [Batch 138/274] [Batch classify loss: 2.560061] 
[Epoch 10/10] [Batch 139/274] [Batch classify loss: 2.476135] 
[Epoch 10/10] [Batch 140/274] [Batch classify loss: 3.054177] 
[Epoch 10/10] [Batch 141/274] [Batch classify loss: 2.319614] 
[Epoch 10/10] [Batch 142/274] [Batch classify loss: 2.813827] 
[Epoch 10/10] [Batch 143/274] [Batch classify loss: 2.571052] 
[Epoch 10/10] [Batch 144/274] [Batch classify loss: 2.345856] 
[Epoch 10/10] [Batch 145/274] [Batch classify loss: 3.096092] 
[Epoch 10/10] [Batch 146/274] [Batch classify loss: 2.055769] 
[Epoch 10/10] [Batch 147/274] [Batch classify loss: 2.441189] 
[Epoch 10/10] [Batch 148/274] [Batch classify loss: 2.363837] 
[Epoch 10/10] [Batch 149/274] [Batch classify loss: 2.811031] 
[Epoch 10/10] [Batch 150/274] [Batch classify loss: 2.374457] 
[Epoch 10/10] [Batch 151/274] [Batch classify loss: 2.276283] 
[Epoch 10/10] [Batch 152/274] [Batch classify loss: 2.199293] 
[Epoch 10/10] [Batch 153/274] [Batch classify loss: 2.730512] 
[Epoch 10/10] [Batch 154/274] [Batch classify loss: 2.289796] 
[Epoch 10/10] [Batch 155/274] [Batch classify loss: 2.241923] 
[Epoch 10/10] [Batch 156/274] [Batch classify loss: 2.455301] 
[Epoch 10/10] [Batch 157/274] [Batch classify loss: 2.438137] 
[Epoch 10/10] [Batch 158/274] [Batch classify loss: 2.362834] 
[Epoch 10/10] [Batch 159/274] [Batch classify loss: 2.423336] 
[Epoch 10/10] [Batch 160/274] [Batch classify loss: 2.162947] 
[Epoch 10/10] [Batch 161/274] [Batch classify loss: 2.265886] 
[Epoch 10/10] [Batch 162/274] [Batch classify loss: 2.509339] 
[Epoch 10/10] [Batch 163/274] [Batch classify loss: 2.266030] 
[Epoch 10/10] [Batch 164/274] [Batch classify loss: 2.371898] 
[Epoch 10/10] [Batch 165/274] [Batch classify loss: 2.412628] 
[Epoch 10/10] [Batch 166/274] [Batch classify loss: 2.470071] 
[Epoch 10/10] [Batch 167/274] [Batch classify loss: 2.454174] 
[Epoch 10/10] [Batch 168/274] [Batch classify loss: 2.433999] 
[Epoch 10/10] [Batch 169/274] [Batch classify loss: 2.580447] 
[Epoch 10/10] [Batch 170/274] [Batch classify loss: 2.675483] 
[Epoch 10/10] [Batch 171/274] [Batch classify loss: 2.540046] 
[Epoch 10/10] [Batch 172/274] [Batch classify loss: 2.858678] 
[Epoch 10/10] [Batch 173/274] [Batch classify loss: 2.142044] 
[Epoch 10/10] [Batch 174/274] [Batch classify loss: 2.759090] 
[Epoch 10/10] [Batch 175/274] [Batch classify loss: 2.667872] 
[Epoch 10/10] [Batch 176/274] [Batch classify loss: 2.503703] 
[Epoch 10/10] [Batch 177/274] [Batch classify loss: 2.367163] 
[Epoch 10/10] [Batch 178/274] [Batch classify loss: 2.512302] 
[Epoch 10/10] [Batch 179/274] [Batch classify loss: 2.570314] 
[Epoch 10/10] [Batch 180/274] [Batch classify loss: 2.628741] 
[Epoch 10/10] [Batch 181/274] [Batch classify loss: 2.524729] 
[Epoch 10/10] [Batch 182/274] [Batch classify loss: 2.342412] 
[Epoch 10/10] [Batch 183/274] [Batch classify loss: 2.463532] 
[Epoch 10/10] [Batch 184/274] [Batch classify loss: 2.244464] 
[Epoch 10/10] [Batch 185/274] [Batch classify loss: 2.637281] 
[Epoch 10/10] [Batch 186/274] [Batch classify loss: 2.387119] 
[Epoch 10/10] [Batch 187/274] [Batch classify loss: 2.957086] 
[Epoch 10/10] [Batch 188/274] [Batch classify loss: 2.539631] 
[Epoch 10/10] [Batch 189/274] [Batch classify loss: 2.803475] 
[Epoch 10/10] [Batch 190/274] [Batch classify loss: 2.549756] 
[Epoch 10/10] [Batch 191/274] [Batch classify loss: 2.488173] 
[Epoch 10/10] [Batch 192/274] [Batch classify loss: 2.689918] 
[Epoch 10/10] [Batch 193/274] [Batch classify loss: 2.650098] 
[Epoch 10/10] [Batch 194/274] [Batch classify loss: 2.743348] 
[Epoch 10/10] [Batch 195/274] [Batch classify loss: 2.649943] 
[Epoch 10/10] [Batch 196/274] [Batch classify loss: 2.407761] 
[Epoch 10/10] [Batch 197/274] [Batch classify loss: 2.744805] 
[Epoch 10/10] [Batch 198/274] [Batch classify loss: 2.651340] 
[Epoch 10/10] [Batch 199/274] [Batch classify loss: 2.574915] 
[Epoch 10/10] [Batch 200/274] [Batch classify loss: 3.172218] 
[Epoch 10/10] [Batch 201/274] [Batch classify loss: 2.624499] 
[Epoch 10/10] [Batch 202/274] [Batch classify loss: 2.586925] 
[Epoch 10/10] [Batch 203/274] [Batch classify loss: 2.608069] 
[Epoch 10/10] [Batch 204/274] [Batch classify loss: 2.278013] 
[Epoch 10/10] [Batch 205/274] [Batch classify loss: 2.663612] 
[Epoch 10/10] [Batch 206/274] [Batch classify loss: 2.962054] 
[Epoch 10/10] [Batch 207/274] [Batch classify loss: 2.540903] 
[Epoch 10/10] [Batch 208/274] [Batch classify loss: 2.742532] 
[Epoch 10/10] [Batch 209/274] [Batch classify loss: 2.889267] 
[Epoch 10/10] [Batch 210/274] [Batch classify loss: 2.793434] 
[Epoch 10/10] [Batch 211/274] [Batch classify loss: 2.882198] 
[Epoch 10/10] [Batch 212/274] [Batch classify loss: 2.966104] 
[Epoch 10/10] [Batch 213/274] [Batch classify loss: 2.529062] 
[Epoch 10/10] [Batch 214/274] [Batch classify loss: 2.482931] 
[Epoch 10/10] [Batch 215/274] [Batch classify loss: 2.815505] 
[Epoch 10/10] [Batch 216/274] [Batch classify loss: 2.777229] 
[Epoch 10/10] [Batch 217/274] [Batch classify loss: 2.744648] 
[Epoch 10/10] [Batch 218/274] [Batch classify loss: 2.795780] 
[Epoch 10/10] [Batch 219/274] [Batch classify loss: 2.473465] 
[Epoch 10/10] [Batch 220/274] [Batch classify loss: 2.516357] 
[Epoch 10/10] [Batch 221/274] [Batch classify loss: 2.889977] 
[Epoch 10/10] [Batch 222/274] [Batch classify loss: 2.629861] 
[Epoch 10/10] [Batch 223/274] [Batch classify loss: 2.703807] 
[Epoch 10/10] [Batch 224/274] [Batch classify loss: 2.879104] 
[Epoch 10/10] [Batch 225/274] [Batch classify loss: 2.903737] 
[Epoch 10/10] [Batch 226/274] [Batch classify loss: 2.714258] 
[Epoch 10/10] [Batch 227/274] [Batch classify loss: 2.520569] 
[Epoch 10/10] [Batch 228/274] [Batch classify loss: 2.566482] 
[Epoch 10/10] [Batch 229/274] [Batch classify loss: 2.518922] 
[Epoch 10/10] [Batch 230/274] [Batch classify loss: 2.472059] 
[Epoch 10/10] [Batch 231/274] [Batch classify loss: 2.583664] 
[Epoch 10/10] [Batch 232/274] [Batch classify loss: 2.926261] 
[Epoch 10/10] [Batch 233/274] [Batch classify loss: 2.761097] 
[Epoch 10/10] [Batch 234/274] [Batch classify loss: 2.736101] 
[Epoch 10/10] [Batch 235/274] [Batch classify loss: 3.043355] 
[Epoch 10/10] [Batch 236/274] [Batch classify loss: 2.613401] 
[Epoch 10/10] [Batch 237/274] [Batch classify loss: 2.321931] 
[Epoch 10/10] [Batch 238/274] [Batch classify loss: 2.573263] 
[Epoch 10/10] [Batch 239/274] [Batch classify loss: 2.341367] 
[Epoch 10/10] [Batch 240/274] [Batch classify loss: 2.582573] 
[Epoch 10/10] [Batch 241/274] [Batch classify loss: 2.903409] 
[Epoch 10/10] [Batch 242/274] [Batch classify loss: 2.804898] 
[Epoch 10/10] [Batch 243/274] [Batch classify loss: 2.809425] 
[Epoch 10/10] [Batch 244/274] [Batch classify loss: 2.639993] 
[Epoch 10/10] [Batch 245/274] [Batch classify loss: 2.737391] 
[Epoch 10/10] [Batch 246/274] [Batch classify loss: 2.601674] 
[Epoch 10/10] [Batch 247/274] [Batch classify loss: 2.703014] 
[Epoch 10/10] [Batch 248/274] [Batch classify loss: 3.053685] 
[Epoch 10/10] [Batch 249/274] [Batch classify loss: 2.881170] 
[Epoch 10/10] [Batch 250/274] [Batch classify loss: 2.649202] 
[Epoch 10/10] [Batch 251/274] [Batch classify loss: 2.773680] 
[Epoch 10/10] [Batch 252/274] [Batch classify loss: 2.987257] 
[Epoch 10/10] [Batch 253/274] [Batch classify loss: 2.117610] 
[Epoch 10/10] [Batch 254/274] [Batch classify loss: 2.556916] 
[Epoch 10/10] [Batch 255/274] [Batch classify loss: 2.704732] 
[Epoch 10/10] [Batch 256/274] [Batch classify loss: 3.048862] 
[Epoch 10/10] [Batch 257/274] [Batch classify loss: 2.915822] 
[Epoch 10/10] [Batch 258/274] [Batch classify loss: 2.957311] 
[Epoch 10/10] [Batch 259/274] [Batch classify loss: 2.783575] 
[Epoch 10/10] [Batch 260/274] [Batch classify loss: 2.625589] 
[Epoch 10/10] [Batch 261/274] [Batch classify loss: 2.560699] 
[Epoch 10/10] [Batch 262/274] [Batch classify loss: 2.745786] 
[Epoch 10/10] [Batch 263/274] [Batch classify loss: 2.864365] 
[Epoch 10/10] [Batch 264/274] [Batch classify loss: 2.805999] 
[Epoch 10/10] [Batch 265/274] [Batch classify loss: 2.543759] 
[Epoch 10/10] [Batch 266/274] [Batch classify loss: 2.721069] 
[Epoch 10/10] [Batch 267/274] [Batch classify loss: 2.827076] 
[Epoch 10/10] [Batch 268/274] [Batch classify loss: 2.986729] 
[Epoch 10/10] [Batch 269/274] [Batch classify loss: 2.792981] 
[Epoch 10/10] [Batch 270/274] [Batch classify loss: 2.914032] 
[Epoch 10/10] [Batch 271/274] [Batch classify loss: 2.735331] 
[Epoch 10/10] [Batch 272/274] [Batch classify loss: 2.619462] 
[Epoch 10/10] [Batch 273/274] [Batch classify loss: 2.636664] 
[Epoch 10/10] [Batch 274/274] [Batch classify loss: 2.658118] 
0010 epoch mmat trained classifier accuary on the clean testing examples:94.6796%
0010 epoch mmat trained classifier loss on the clean testing examples:0.2233
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.3542%
mmat trained classifier loss on adversarial testset:4.51979398727417
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-adv
tensorboard_log_dir: /home/maggie/mmat/result/defense/mmat/fgsm/basemixup-uniformsampler/alexnet-svhn/20210919/00005/mmat-svhn-dataset/tensorboard-log-run-acc-cle
initlize classifier
learned calssify model != None
Get FGSM examples generate model
self._args.attack_eps: 0.2
generating testset adversarial examples...
finished generate testset adversarial examples !
mmat trained classifier accuary on adversarial testset:40.2005%
mmat trained classifier loss on adversarial testset:4.532487392425537
mmat trained classifier accuary on clean testset:94.7104%
mmat trained classifier loss on clean testset:0.2221115082502365
---------------------------------------


