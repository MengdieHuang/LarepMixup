

---------------------------------------
Torch cuda is available
args.subcommand=run, run the command line
date: 20220702
whitebox attack
Experiment result save dir: /home/data/maggie/result-newhome/attack/pgd/preactresnet18-cifar10/20220702/00000
initilize the dataset loading parameters
load cifar10 dataset
Loading *cifar10* train dataloader finished !
Loading *cifar10* test dataloader finished !
eps: 0.02
latent adversarial attack.............
cla_network_pkl: /home/data/maggie/result-newhome/train/cla-train/preactresnet18-cifar10/20210924/00001-teatacc-87.37/train-cifar10-dataset/standard-trained-classifier-preactresnet18-on-clean-cifar10-epoch-0011.pkl
initlize classifier
learned calssify model != None
cle_w_test.shape: torch.Size([10000, 8, 512])
cle_y_test.shape: torch.Size([10000])
initlize attack classifier
generate latent adversarial exampels
latent pgd attack
cle_w_test.shape: torch.Size([10000, 8, 512])
cle_y_test.shape: torch.Size([10000])
testset_total_num: 10000
batch_size: 32
batch_num: 313
batch_index: 0
Setting up PyTorch plugin "bias_act_plugin"... /home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/utils/cpp_extension.py:286: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... /home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/utils/cpp_extension.py:286: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
Done.
Traceback (most recent call last):
  File "tasklauncher-20220702.py", line 144, in <module>
    adv_x_test, adv_y_test = latent_attacker.generatelatentadv(exp_result_dir, cle_test_dataloader, cle_w_test, cle_y_test, gan_net)             
  File "/home/maggie/mmat/attacks/advattack.py", line 332, in generatelatentadv
    adv_w_batch = self._attacker.perturb(cle_w_batch, cle_y_batch)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/advertorch/attacks/iterative_projected_gradient.py", line 189, in perturb
    l1_sparsity=self.l1_sparsity,
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/advertorch/attacks/iterative_projected_gradient.py", line 65, in perturb_iterative
    outputs = predict(xvar + delta)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 479, in forward
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 413, in forward
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "<string>", line 308, in forward
  File "/home/maggie/mmat/utils/stylegan2ada/torch_utils/misc.py", line 102, in decorator
    return fn(*args, **kwargs)
  File "<string>", line 66, in modulated_conv2d
RuntimeError: CUDA out of memory. Tried to allocate 288.00 MiB (GPU 0; 10.76 GiB total capacity; 2.49 GiB already allocated; 137.25 MiB free; 2.71 GiB reserved in total by PyTorch)


---------------------------------------
Torch cuda is available
args.subcommand=run, run the command line
date: 20220702
whitebox attack
Experiment result save dir: /home/data/maggie/result-newhome/attack/pgd/preactresnet18-cifar10/20220702/00001
initilize the dataset loading parameters
load cifar10 dataset
Loading *cifar10* train dataloader finished !
Loading *cifar10* test dataloader finished !
eps: 0.05
latent adversarial attack.............
cla_network_pkl: /home/data/maggie/result-newhome/train/cla-train/preactresnet18-cifar10/20210924/00001-teatacc-87.37/train-cifar10-dataset/standard-trained-classifier-preactresnet18-on-clean-cifar10-epoch-0011.pkl
initlize classifier
learned calssify model != None
Traceback (most recent call last):
  File "tasklauncher-20220702.py", line 113, in <module>
    cle_w_test, cle_y_test = target_classifier.getproset(args.projected_dataset)
  File "/home/maggie/mmat/clamodels/classifier.py", line 912, in getproset
    pro_wset_tensor, pro_yset_tensor = self.__getprosettensor__(pro_dataset_path)
  File "/home/maggie/mmat/clamodels/classifier.py", line 956, in __getprosettensor__
    y = np.load(label_npz_path)['w']
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/numpy/lib/npyio.py", line 248, in __getitem__
    bytes = self.zip.open(key)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/zipfile.py", line 1519, in open
    fheader = zef_file.read(sizeFileHeader)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/zipfile.py", line 754, in read
    data = self._file.read(n)
KeyboardInterrupt


---------------------------------------
Torch cuda is available
args.subcommand=run, run the command line
date: 20220703
whitebox attack
Experiment result save dir: /home/data/maggie/result-newhome/attack/pgd/preactresnet18-cifar10/20220703/00000
initilize the dataset loading parameters
load cifar10 dataset
Loading *cifar10* train dataloader finished !
Loading *cifar10* test dataloader finished !
eps: 0.02
latent adversarial attack.............
cla_network_pkl: /home/data/maggie/result-newhome/train/cla-train/preactresnet18-cifar10/20210924/00001-teatacc-87.37/train-cifar10-dataset/standard-trained-classifier-preactresnet18-on-clean-cifar10-epoch-0011.pkl
initlize classifier
learned calssify model != None
cle_w_test.shape: torch.Size([10000, 8, 512])
cle_y_test.shape: torch.Size([10000])
initlize attack classifier
generate latent adversarial exampels
latent pgd attack
cle_w_test.shape: torch.Size([10000, 8, 512])
cle_y_test.shape: torch.Size([10000])
testset_total_num: 10000
batch_size: 32
batch_num: 313
batch_index: 0
Setting up PyTorch plugin "bias_act_plugin"... /home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/utils/cpp_extension.py:286: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... /home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/utils/cpp_extension.py:286: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
Done.
batch_index: 1
batch_index: 2
batch_index: 3
batch_index: 4
batch_index: 5
batch_index: 6
batch_index: 7
batch_index: 8
batch_index: 9
batch_index: 10
batch_index: 11
batch_index: 12
batch_index: 13
batch_index: 14
batch_index: 15
batch_index: 16
batch_index: 17
batch_index: 18
batch_index: 19
batch_index: 20
batch_index: 21
batch_index: 22
batch_index: 23
batch_index: 24
batch_index: 25
batch_index: 26
batch_index: 27
batch_index: 28
batch_index: 29
batch_index: 30
batch_index: 31
batch_index: 32
batch_index: 33
batch_index: 34
batch_index: 35
batch_index: 36
batch_index: 37
batch_index: 38
batch_index: 39
batch_index: 40
batch_index: 41
batch_index: 42
batch_index: 43
batch_index: 44
batch_index: 45
batch_index: 46
batch_index: 47
batch_index: 48
batch_index: 49
batch_index: 50
batch_index: 51
batch_index: 52
batch_index: 53
batch_index: 54
batch_index: 55
batch_index: 56
batch_index: 57
batch_index: 58
batch_index: 59
batch_index: 60
batch_index: 61
batch_index: 62
batch_index: 63
batch_index: 64
batch_index: 65
batch_index: 66
batch_index: 67
batch_index: 68
batch_index: 69
batch_index: 70
batch_index: 71
batch_index: 72
batch_index: 73
batch_index: 74
batch_index: 75
batch_index: 76
batch_index: 77
batch_index: 78
batch_index: 79
batch_index: 80
batch_index: 81
batch_index: 82
batch_index: 83
batch_index: 84
batch_index: 85
batch_index: 86
batch_index: 87
batch_index: 88
batch_index: 89
batch_index: 90
batch_index: 91
batch_index: 92
batch_index: 93
batch_index: 94
batch_index: 95
batch_index: 96
batch_index: 97
batch_index: 98
batch_index: 99
batch_index: 100
batch_index: 101
batch_index: 102
batch_index: 103
batch_index: 104
batch_index: 105
batch_index: 106
batch_index: 107
batch_index: 108
batch_index: 109
batch_index: 110
batch_index: 111
batch_index: 112
batch_index: 113
batch_index: 114
batch_index: 115
batch_index: 116
batch_index: 117
batch_index: 118
batch_index: 119
batch_index: 120
batch_index: 121
batch_index: 122
batch_index: 123
batch_index: 124
batch_index: 125
batch_index: 126
batch_index: 127
batch_index: 128
batch_index: 129
batch_index: 130
batch_index: 131
batch_index: 132
batch_index: 133
batch_index: 134
batch_index: 135
batch_index: 136
batch_index: 137
batch_index: 138
batch_index: 139
batch_index: 140
batch_index: 141
batch_index: 142
batch_index: 143
batch_index: 144
batch_index: 145
batch_index: 146
batch_index: 147
batch_index: 148
batch_index: 149
batch_index: 150
batch_index: 151
batch_index: 152
batch_index: 153
batch_index: 154
batch_index: 155
batch_index: 156
batch_index: 157
batch_index: 158
batch_index: 159
batch_index: 160
batch_index: 161
batch_index: 162
batch_index: 163
batch_index: 164
batch_index: 165
batch_index: 166
batch_index: 167
batch_index: 168
batch_index: 169
batch_index: 170
batch_index: 171
batch_index: 172
batch_index: 173
