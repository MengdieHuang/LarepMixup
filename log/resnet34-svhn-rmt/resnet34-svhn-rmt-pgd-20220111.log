

---------------------------------------
Torch cuda is available
args.subcommand=run, run the command line
date: 20220111
whitebox attack
Experiment result save dir: /home/maggie/mmat/result/defense/rmt/pgd/basemixup-betasampler/resnet34-svhn/whitebox/20220111/00000
initilize the dataset loading parameters
Using downloaded and verified file: /home/data/maggie/svhn/train_32x32.mat
Loading *svhn* train dataloader finished !
Loading *svhn* test dataloader finished !
initlize classifier
learned calssify model != None
args.adv_dataset： /home/maggie/mmat/result/attack/pgd/resnet34-svhn/20210915/00000-attackacc-0.173901/attack-svhn-dataset/samples
Accuary of before rmt trained classifier on clean testset:93.4312%
Loss of before mmat trained classifier clean testset:0.25741657614707947
args.mix_mode: basemixup
args.mix_w_num: 2
args.beta_alpha: 0.5
args.dirichlet_gama: 1
cle_w_train.shape: torch.Size([24004, 8, 512])
cle_y_train.shape: torch.Size([24004, 8])
cle_x_test.shape: torch.Size([26032, 3, 32, 32])
cle_y_test.shape: torch.Size([26032])
adv_x_test.shape: torch.Size([26032, 3, 32, 32])
adv_y_test.shape: torch.Size([26032])
cle_train_dataloader.len: 287
initlize attack classifier
generate pixel adversarial exampels
generating testset adversarial examples...
PGD - Batches:   0%|          | 0/814 [00:00<?, ?it/s]/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/art/estimators/classification/pytorch.py:1143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x_grad = torch.tensor(x).to(self._device)
/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/art/estimators/classification/pytorch.py:1144: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  y_grad = torch.tensor(y).to(self._device)
PGD - Batches:   0%|          | 1/814 [00:02<36:40,  2.71s/it]PGD - Batches:   0%|          | 2/814 [00:05<36:38,  2.71s/it]PGD - Batches:   0%|          | 3/814 [00:08<36:36,  2.71s/it]PGD - Batches:   0%|          | 4/814 [00:10<36:04,  2.67s/it]PGD - Batches:   1%|          | 5/814 [00:13<35:24,  2.63s/it]PGD - Batches:   1%|          | 6/814 [00:15<35:04,  2.60s/it]PGD - Batches:   1%|          | 7/814 [00:18<34:48,  2.59s/it]PGD - Batches:   1%|          | 8/814 [00:20<34:19,  2.56s/it]PGD - Batches:   1%|          | 9/814 [00:23<34:06,  2.54s/it]PGD - Batches:   1%|          | 10/814 [00:25<33:59,  2.54s/it]PGD - Batches:   1%|▏         | 11/814 [00:28<33:22,  2.49s/it]PGD - Batches:   1%|▏         | 12/814 [00:30<32:59,  2.47s/it]PGD - Batches:   2%|▏         | 13/814 [00:33<33:12,  2.49s/it]                                                               Traceback (most recent call last):
  File "tasklauncher-20220111.py", line 223, in <module>
    target_classifier.rmt(args,cle_w_train,cle_y_train, cle_train_dataloader, cle_x_test,cle_y_test,adv_x_test,adv_y_test,exp_result_dir,stylegan2ada_config_kwargs)
  File "/home/maggie/mmat/clamodels/classifier.py", line 1479, in rmt
    epoch_x_test_adv, epoch_y_test_adv = epoch_attack_classifier.generateadvfromtestsettensor(self._cle_test_tensorset_x, self._cle_test_tensorset_y) 
  File "/home/maggie/mmat/attacks/advattack.py", line 408, in generateadvfromtestsettensor
    self._x_test_adv = self._advgenmodel.generate(x = self._x_test, y = self._y_test)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/art/attacks/attack.py", line 74, in replacement_function
    return fdict[func_name](self, *args, **kwargs)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent.py", line 181, in generate
    return self._attack.generate(x=x, y=y, **kwargs)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/art/attacks/attack.py", line 74, in replacement_function
    return fdict[func_name](self, *args, **kwargs)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py", line 196, in generate
    x=batch, targets=batch_labels, mask=mask_batch, eps=batch_eps, eps_step=batch_eps_step
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py", line 252, in _generate_batch
    adv_x, inputs, targets, mask, eps, eps_step, self.num_random_init > 0 and i_max_iter == 0,
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py", line 385, in _compute_torch
    perturbation = self._compute_perturbation(x_adv, y, mask)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py", line 279, in _compute_perturbation
    grad = self.estimator.loss_gradient(x=x, y=y) * (1 - 2 * int(self.targeted))
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/art/estimators/classification/pytorch.py", line 1164, in loss_gradient
    model_outputs = self._model(inputs_t)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/art/estimators/classification/pytorch.py", line 1393, in forward
    x = self._model(x)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torchvision/models/resnet.py", line 255, in forward
    return self._forward_impl(x)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torchvision/models/resnet.py", line 245, in _forward_impl
    x = self.layer3(x)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torchvision/models/resnet.py", line 78, in forward
    identity = self.downsample(x)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
KeyboardInterrupt


---------------------------------------
Torch cuda is available
args.subcommand=run, run the command line
date: 20220112
blackbox attack
Experiment result save dir: /home/maggie/mmat/result/defense/rmt/pgd/basemixup-betasampler/resnet34-svhn/blackbox/20220112/00000
initilize the dataset loading parameters
Using downloaded and verified file: /home/data/maggie/svhn/train_32x32.mat
Loading *svhn* train dataloader finished !
Loading *svhn* test dataloader finished !
initlize classifier
learned calssify model != None
args.adv_dataset： /home/maggie/mmat/result/attack/pgd/resnet34-svhn/20220111/00000-eps-0.3-acc-10.4833/attack-svhn-dataset/samples
Accuary of before rmt trained classifier on clean testset:93.4312%
Loss of before mmat trained classifier clean testset:0.25741657614707947
args.mix_mode: basemixup
args.mix_w_num: 2
args.beta_alpha: 2.0
args.dirichlet_gama: 1
cle_w_train.shape: torch.Size([24004, 8, 512])
cle_y_train.shape: torch.Size([24004, 8])
cle_x_test.shape: torch.Size([26032, 3, 32, 32])
cle_y_test.shape: torch.Size([26032])
adv_x_test.shape: torch.Size([26032, 3, 32, 32])
adv_y_test.shape: torch.Size([26032])
cle_train_dataloader.len: 287
Accuary of before rmt trained classifier on adversarial testset:10.4833%
Loss of before mmat trained classifier on adversarial testset:15.790162086486816
w_trainset_len: 24004
batch_size: 256
w_batch_num: 94


0epoch learning rate:0.001
Setting up PyTorch plugin "bias_act_plugin"... /home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/utils/cpp_extension.py:286: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... /home/xieyi/anaconda3/envs/mmat/lib/python3.7/site-packages/torch/utils/cpp_extension.py:286: UserWarning: 

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) is not compatible with the compiler Pytorch was
built with for this platform, which is g++ on linux. Please
use g++ to to compile your extension. Alternatively, you may
compile PyTorch from source using c++, and then you can also use
c++ to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  platform=sys.platform))
Done.
[Epoch 1/40] [Batch 1/287] [Batch classify loss: 2.509279]
[Epoch 1/40] [Batch 2/287] [Batch classify loss: 1.928019]
[Epoch 1/40] [Batch 3/287] [Batch classify loss: 1.554088]
[Epoch 1/40] [Batch 4/287] [Batch classify loss: 1.461680]
[Epoch 1/40] [Batch 5/287] [Batch classify loss: 1.336631]
[Epoch 1/40] [Batch 6/287] [Batch classify loss: 1.323829]
[Epoch 1/40] [Batch 7/287] [Batch classify loss: 1.336102]
[Epoch 1/40] [Batch 8/287] [Batch classify loss: 1.328595]
[Epoch 1/40] [Batch 9/287] [Batch classify loss: 1.287975]
[Epoch 1/40] [Batch 10/287] [Batch classify loss: 1.230539]
[Epoch 1/40] [Batch 11/287] [Batch classify loss: 1.167563]
[Epoch 1/40] [Batch 12/287] [Batch classify loss: 1.166011]
[Epoch 1/40] [Batch 13/287] [Batch classify loss: 1.238717]
[Epoch 1/40] [Batch 14/287] [Batch classify loss: 1.284658]
[Epoch 1/40] [Batch 15/287] [Batch classify loss: 1.206015]
[Epoch 1/40] [Batch 16/287] [Batch classify loss: 1.249865]
[Epoch 1/40] [Batch 17/287] [Batch classify loss: 1.183508]
[Epoch 1/40] [Batch 18/287] [Batch classify loss: 1.189806]
[Epoch 1/40] [Batch 19/287] [Batch classify loss: 1.200350]
[Epoch 1/40] [Batch 20/287] [Batch classify loss: 1.195497]
[Epoch 1/40] [Batch 21/287] [Batch classify loss: 1.211826]
[Epoch 1/40] [Batch 22/287] [Batch classify loss: 1.138686]
[Epoch 1/40] [Batch 23/287] [Batch classify loss: 1.107741]
[Epoch 1/40] [Batch 24/287] [Batch classify loss: 1.154262]
[Epoch 1/40] [Batch 25/287] [Batch classify loss: 1.192050]
[Epoch 1/40] [Batch 26/287] [Batch classify loss: 1.159788]
[Epoch 1/40] [Batch 27/287] [Batch classify loss: 1.177474]
[Epoch 1/40] [Batch 28/287] [Batch classify loss: 1.189546]
[Epoch 1/40] [Batch 29/287] [Batch classify loss: 1.155817]
[Epoch 1/40] [Batch 30/287] [Batch classify loss: 1.152737]
[Epoch 1/40] [Batch 31/287] [Batch classify loss: 1.206349]
[Epoch 1/40] [Batch 32/287] [Batch classify loss: 1.126053]
[Epoch 1/40] [Batch 33/287] [Batch classify loss: 1.104481]
[Epoch 1/40] [Batch 34/287] [Batch classify loss: 1.129775]
[Epoch 1/40] [Batch 35/287] [Batch classify loss: 1.142955]
[Epoch 1/40] [Batch 36/287] [Batch classify loss: 1.094264]
[Epoch 1/40] [Batch 37/287] [Batch classify loss: 1.155561]
[Epoch 1/40] [Batch 38/287] [Batch classify loss: 1.146394]
[Epoch 1/40] [Batch 39/287] [Batch classify loss: 1.219651]
[Epoch 1/40] [Batch 40/287] [Batch classify loss: 1.120062]
[Epoch 1/40] [Batch 41/287] [Batch classify loss: 1.193934]
[Epoch 1/40] [Batch 42/287] [Batch classify loss: 1.134744]
[Epoch 1/40] [Batch 43/287] [Batch classify loss: 1.217173]
[Epoch 1/40] [Batch 44/287] [Batch classify loss: 1.137614]
[Epoch 1/40] [Batch 45/287] [Batch classify loss: 1.137841]
[Epoch 1/40] [Batch 46/287] [Batch classify loss: 1.129767]
[Epoch 1/40] [Batch 47/287] [Batch classify loss: 1.140387]
[Epoch 1/40] [Batch 48/287] [Batch classify loss: 1.103970]
[Epoch 1/40] [Batch 49/287] [Batch classify loss: 1.146884]
[Epoch 1/40] [Batch 50/287] [Batch classify loss: 1.084633]
[Epoch 1/40] [Batch 51/287] [Batch classify loss: 1.163209]
[Epoch 1/40] [Batch 52/287] [Batch classify loss: 1.128453]
[Epoch 1/40] [Batch 53/287] [Batch classify loss: 1.194106]
[Epoch 1/40] [Batch 54/287] [Batch classify loss: 1.133730]
[Epoch 1/40] [Batch 55/287] [Batch classify loss: 1.131170]
[Epoch 1/40] [Batch 56/287] [Batch classify loss: 1.189140]
[Epoch 1/40] [Batch 57/287] [Batch classify loss: 1.187057]
[Epoch 1/40] [Batch 58/287] [Batch classify loss: 1.171284]
[Epoch 1/40] [Batch 59/287] [Batch classify loss: 1.098213]
[Epoch 1/40] [Batch 60/287] [Batch classify loss: 1.122269]
[Epoch 1/40] [Batch 61/287] [Batch classify loss: 1.107458]
[Epoch 1/40] [Batch 62/287] [Batch classify loss: 1.111769]
[Epoch 1/40] [Batch 63/287] [Batch classify loss: 1.082023]
[Epoch 1/40] [Batch 64/287] [Batch classify loss: 1.126585]
[Epoch 1/40] [Batch 65/287] [Batch classify loss: 1.129781]
[Epoch 1/40] [Batch 66/287] [Batch classify loss: 1.222931]
[Epoch 1/40] [Batch 67/287] [Batch classify loss: 1.137623]
[Epoch 1/40] [Batch 68/287] [Batch classify loss: 1.173081]
[Epoch 1/40] [Batch 69/287] [Batch classify loss: 1.118529]
[Epoch 1/40] [Batch 70/287] [Batch classify loss: 1.101595]
[Epoch 1/40] [Batch 71/287] [Batch classify loss: 1.080853]
[Epoch 1/40] [Batch 72/287] [Batch classify loss: 1.159503]
[Epoch 1/40] [Batch 73/287] [Batch classify loss: 1.138702]
[Epoch 1/40] [Batch 74/287] [Batch classify loss: 1.075935]
[Epoch 1/40] [Batch 75/287] [Batch classify loss: 1.091841]
[Epoch 1/40] [Batch 76/287] [Batch classify loss: 1.124735]
[Epoch 1/40] [Batch 77/287] [Batch classify loss: 1.180155]
[Epoch 1/40] [Batch 78/287] [Batch classify loss: 1.110430]
[Epoch 1/40] [Batch 79/287] [Batch classify loss: 1.113050]
[Epoch 1/40] [Batch 80/287] [Batch classify loss: 1.112550]
[Epoch 1/40] [Batch 81/287] [Batch classify loss: 1.098238]
[Epoch 1/40] [Batch 82/287] [Batch classify loss: 1.177505]
[Epoch 1/40] [Batch 83/287] [Batch classify loss: 1.100468]
[Epoch 1/40] [Batch 84/287] [Batch classify loss: 1.057651]
[Epoch 1/40] [Batch 85/287] [Batch classify loss: 1.130442]
[Epoch 1/40] [Batch 86/287] [Batch classify loss: 1.080577]
[Epoch 1/40] [Batch 87/287] [Batch classify loss: 1.095501]
[Epoch 1/40] [Batch 88/287] [Batch classify loss: 1.106937]
[Epoch 1/40] [Batch 89/287] [Batch classify loss: 1.159936]
[Epoch 1/40] [Batch 90/287] [Batch classify loss: 1.041180]
[Epoch 1/40] [Batch 91/287] [Batch classify loss: 1.085193]
[Epoch 1/40] [Batch 92/287] [Batch classify loss: 1.094578]
[Epoch 1/40] [Batch 93/287] [Batch classify loss: 1.086096]
[Epoch 1/40] [Batch 94/287] [Batch classify loss: 0.994038]
[Epoch 1/40] [Batch 95/287] [Batch classify loss: 1.129820]
[Epoch 1/40] [Batch 96/287] [Batch classify loss: 0.993135]
[Epoch 1/40] [Batch 97/287] [Batch classify loss: 0.995163]
[Epoch 1/40] [Batch 98/287] [Batch classify loss: 1.115606]
[Epoch 1/40] [Batch 99/287] [Batch classify loss: 1.006023]
[Epoch 1/40] [Batch 100/287] [Batch classify loss: 1.088832]
[Epoch 1/40] [Batch 101/287] [Batch classify loss: 1.099934]
[Epoch 1/40] [Batch 102/287] [Batch classify loss: 1.123839]
[Epoch 1/40] [Batch 103/287] [Batch classify loss: 1.126878]
[Epoch 1/40] [Batch 104/287] [Batch classify loss: 1.129230]
[Epoch 1/40] [Batch 105/287] [Batch classify loss: 1.109829]
[Epoch 1/40] [Batch 106/287] [Batch classify loss: 1.219235]
[Epoch 1/40] [Batch 107/287] [Batch classify loss: 1.098509]
[Epoch 1/40] [Batch 108/287] [Batch classify loss: 1.148591]
[Epoch 1/40] [Batch 109/287] [Batch classify loss: 1.099810]
[Epoch 1/40] [Batch 110/287] [Batch classify loss: 1.123702]
[Epoch 1/40] [Batch 111/287] [Batch classify loss: 1.120201]
[Epoch 1/40] [Batch 112/287] [Batch classify loss: 1.039838]
[Epoch 1/40] [Batch 113/287] [Batch classify loss: 1.077718]
[Epoch 1/40] [Batch 114/287] [Batch classify loss: 1.114005]
[Epoch 1/40] [Batch 115/287] [Batch classify loss: 1.134413]
[Epoch 1/40] [Batch 116/287] [Batch classify loss: 1.065872]
[Epoch 1/40] [Batch 117/287] [Batch classify loss: 1.040732]
[Epoch 1/40] [Batch 118/287] [Batch classify loss: 1.093316]
[Epoch 1/40] [Batch 119/287] [Batch classify loss: 1.140502]
[Epoch 1/40] [Batch 120/287] [Batch classify loss: 1.105566]
[Epoch 1/40] [Batch 121/287] [Batch classify loss: 1.086624]
[Epoch 1/40] [Batch 122/287] [Batch classify loss: 1.147839]
[Epoch 1/40] [Batch 123/287] [Batch classify loss: 1.120811]
[Epoch 1/40] [Batch 124/287] [Batch classify loss: 1.105862]
[Epoch 1/40] [Batch 125/287] [Batch classify loss: 1.112903]
[Epoch 1/40] [Batch 126/287] [Batch classify loss: 1.116351]
[Epoch 1/40] [Batch 127/287] [Batch classify loss: 1.145853]
[Epoch 1/40] [Batch 128/287] [Batch classify loss: 1.128539]
[Epoch 1/40] [Batch 129/287] [Batch classify loss: 1.100011]
[Epoch 1/40] [Batch 130/287] [Batch classify loss: 1.077120]
[Epoch 1/40] [Batch 131/287] [Batch classify loss: 1.103692]
[Epoch 1/40] [Batch 132/287] [Batch classify loss: 1.125493]
[Epoch 1/40] [Batch 133/287] [Batch classify loss: 1.097887]
[Epoch 1/40] [Batch 134/287] [Batch classify loss: 1.054038]
[Epoch 1/40] [Batch 135/287] [Batch classify loss: 1.122566]
[Epoch 1/40] [Batch 136/287] [Batch classify loss: 1.177397]
[Epoch 1/40] [Batch 137/287] [Batch classify loss: 1.205186]
[Epoch 1/40] [Batch 138/287] [Batch classify loss: 1.107083]
[Epoch 1/40] [Batch 139/287] [Batch classify loss: 1.089499]
[Epoch 1/40] [Batch 140/287] [Batch classify loss: 1.141309]
[Epoch 1/40] [Batch 141/287] [Batch classify loss: 1.132193]
[Epoch 1/40] [Batch 142/287] [Batch classify loss: 1.133163]
[Epoch 1/40] [Batch 143/287] [Batch classify loss: 1.145663]
[Epoch 1/40] [Batch 144/287] [Batch classify loss: 1.134910]
[Epoch 1/40] [Batch 145/287] [Batch classify loss: 1.147448]
[Epoch 1/40] [Batch 146/287] [Batch classify loss: 1.096508]
[Epoch 1/40] [Batch 147/287] [Batch classify loss: 1.082741]
[Epoch 1/40] [Batch 148/287] [Batch classify loss: 1.104505]
[Epoch 1/40] [Batch 149/287] [Batch classify loss: 1.141804]
[Epoch 1/40] [Batch 150/287] [Batch classify loss: 1.171901]
[Epoch 1/40] [Batch 151/287] [Batch classify loss: 1.101207]
[Epoch 1/40] [Batch 152/287] [Batch classify loss: 1.164206]
[Epoch 1/40] [Batch 153/287] [Batch classify loss: 1.081561]
[Epoch 1/40] [Batch 154/287] [Batch classify loss: 1.093960]
[Epoch 1/40] [Batch 155/287] [Batch classify loss: 1.069764]
[Epoch 1/40] [Batch 156/287] [Batch classify loss: 1.071094]
[Epoch 1/40] [Batch 157/287] [Batch classify loss: 1.072613]
[Epoch 1/40] [Batch 158/287] [Batch classify loss: 1.141862]
[Epoch 1/40] [Batch 159/287] [Batch classify loss: 1.107068]
[Epoch 1/40] [Batch 160/287] [Batch classify loss: 1.163438]
[Epoch 1/40] [Batch 161/287] [Batch classify loss: 1.120841]
[Epoch 1/40] [Batch 162/287] [Batch classify loss: 1.098717]
[Epoch 1/40] [Batch 163/287] [Batch classify loss: 1.110772]
[Epoch 1/40] [Batch 164/287] [Batch classify loss: 1.108359]
[Epoch 1/40] [Batch 165/287] [Batch classify loss: 1.107700]
[Epoch 1/40] [Batch 166/287] [Batch classify loss: 1.084325]
[Epoch 1/40] [Batch 167/287] [Batch classify loss: 1.159496]
[Epoch 1/40] [Batch 168/287] [Batch classify loss: 1.139359]
[Epoch 1/40] [Batch 169/287] [Batch classify loss: 1.099179]
[Epoch 1/40] [Batch 170/287] [Batch classify loss: 1.128901]
[Epoch 1/40] [Batch 171/287] [Batch classify loss: 1.092492]
[Epoch 1/40] [Batch 172/287] [Batch classify loss: 1.095275]
[Epoch 1/40] [Batch 173/287] [Batch classify loss: 1.111069]
[Epoch 1/40] [Batch 174/287] [Batch classify loss: 1.116909]
[Epoch 1/40] [Batch 175/287] [Batch classify loss: 1.075610]
[Epoch 1/40] [Batch 176/287] [Batch classify loss: 1.064657]
[Epoch 1/40] [Batch 177/287] [Batch classify loss: 1.056592]
[Epoch 1/40] [Batch 178/287] [Batch classify loss: 1.100529]
[Epoch 1/40] [Batch 179/287] [Batch classify loss: 1.104050]
[Epoch 1/40] [Batch 180/287] [Batch classify loss: 1.173287]
[Epoch 1/40] [Batch 181/287] [Batch classify loss: 1.045816]
[Epoch 1/40] [Batch 182/287] [Batch classify loss: 1.119553]
[Epoch 1/40] [Batch 183/287] [Batch classify loss: 1.106661]
[Epoch 1/40] [Batch 184/287] [Batch classify loss: 1.045113]
[Epoch 1/40] [Batch 185/287] [Batch classify loss: 1.168830]
[Epoch 1/40] [Batch 186/287] [Batch classify loss: 1.099735]
[Epoch 1/40] [Batch 187/287] [Batch classify loss: 1.111292]
[Epoch 1/40] [Batch 188/287] [Batch classify loss: 1.021601]
[Epoch 1/40] [Batch 189/287] [Batch classify loss: 1.165619]
[Epoch 1/40] [Batch 190/287] [Batch classify loss: 1.098046]
[Epoch 1/40] [Batch 191/287] [Batch classify loss: 1.040008]
[Epoch 1/40] [Batch 192/287] [Batch classify loss: 1.117427]
[Epoch 1/40] [Batch 193/287] [Batch classify loss: 1.113944]
[Epoch 1/40] [Batch 194/287] [Batch classify loss: 1.100558]
[Epoch 1/40] [Batch 195/287] [Batch classify loss: 1.073892]
[Epoch 1/40] [Batch 196/287] [Batch classify loss: 1.123311]
[Epoch 1/40] [Batch 197/287] [Batch classify loss: 1.112545]
[Epoch 1/40] [Batch 198/287] [Batch classify loss: 1.063115]
[Epoch 1/40] [Batch 199/287] [Batch classify loss: 1.087349]
[Epoch 1/40] [Batch 200/287] [Batch classify loss: 1.071190]
[Epoch 1/40] [Batch 201/287] [Batch classify loss: 1.113796]
[Epoch 1/40] [Batch 202/287] [Batch classify loss: 1.160273]
[Epoch 1/40] [Batch 203/287] [Batch classify loss: 1.133458]
[Epoch 1/40] [Batch 204/287] [Batch classify loss: 1.092441]
[Epoch 1/40] [Batch 205/287] [Batch classify loss: 1.123168]
[Epoch 1/40] [Batch 206/287] [Batch classify loss: 1.052577]
[Epoch 1/40] [Batch 207/287] [Batch classify loss: 1.108967]
[Epoch 1/40] [Batch 208/287] [Batch classify loss: 1.086362]
[Epoch 1/40] [Batch 209/287] [Batch classify loss: 1.139558]
[Epoch 1/40] [Batch 210/287] [Batch classify loss: 1.080188]
[Epoch 1/40] [Batch 211/287] [Batch classify loss: 1.076683]
[Epoch 1/40] [Batch 212/287] [Batch classify loss: 1.173351]
[Epoch 1/40] [Batch 213/287] [Batch classify loss: 1.126886]
[Epoch 1/40] [Batch 214/287] [Batch classify loss: 1.102466]
[Epoch 1/40] [Batch 215/287] [Batch classify loss: 1.118980]
[Epoch 1/40] [Batch 216/287] [Batch classify loss: 1.101668]
[Epoch 1/40] [Batch 217/287] [Batch classify loss: 1.026496]
[Epoch 1/40] [Batch 218/287] [Batch classify loss: 1.164094]
[Epoch 1/40] [Batch 219/287] [Batch classify loss: 1.105094]
[Epoch 1/40] [Batch 220/287] [Batch classify loss: 1.074957]
[Epoch 1/40] [Batch 221/287] [Batch classify loss: 1.128190]
[Epoch 1/40] [Batch 222/287] [Batch classify loss: 1.099821]
[Epoch 1/40] [Batch 223/287] [Batch classify loss: 1.105103]
[Epoch 1/40] [Batch 224/287] [Batch classify loss: 1.085348]
[Epoch 1/40] [Batch 225/287] [Batch classify loss: 1.075292]
[Epoch 1/40] [Batch 226/287] [Batch classify loss: 1.111793]
[Epoch 1/40] [Batch 227/287] [Batch classify loss: 1.108842]
[Epoch 1/40] [Batch 228/287] [Batch classify loss: 1.028390]
[Epoch 1/40] [Batch 229/287] [Batch classify loss: 1.145199]
[Epoch 1/40] [Batch 230/287] [Batch classify loss: 1.172945]
[Epoch 1/40] [Batch 231/287] [Batch classify loss: 1.025425]
[Epoch 1/40] [Batch 232/287] [Batch classify loss: 1.086516]
[Epoch 1/40] [Batch 233/287] [Batch classify loss: 1.093974]
[Epoch 1/40] [Batch 234/287] [Batch classify loss: 1.155438]
[Epoch 1/40] [Batch 235/287] [Batch classify loss: 1.042835]
[Epoch 1/40] [Batch 236/287] [Batch classify loss: 1.075096]
[Epoch 1/40] [Batch 237/287] [Batch classify loss: 1.101450]
[Epoch 1/40] [Batch 238/287] [Batch classify loss: 1.074398]
[Epoch 1/40] [Batch 239/287] [Batch classify loss: 1.132231]
[Epoch 1/40] [Batch 240/287] [Batch classify loss: 1.074339]
[Epoch 1/40] [Batch 241/287] [Batch classify loss: 1.097400]
[Epoch 1/40] [Batch 242/287] [Batch classify loss: 1.077398]
[Epoch 1/40] [Batch 243/287] [Batch classify loss: 1.100629]
[Epoch 1/40] [Batch 244/287] [Batch classify loss: 1.124545]
[Epoch 1/40] [Batch 245/287] [Batch classify loss: 1.163811]
[Epoch 1/40] [Batch 246/287] [Batch classify loss: 1.109416]
[Epoch 1/40] [Batch 247/287] [Batch classify loss: 1.111611]
[Epoch 1/40] [Batch 248/287] [Batch classify loss: 1.085984]
[Epoch 1/40] [Batch 249/287] [Batch classify loss: 1.101656]
[Epoch 1/40] [Batch 250/287] [Batch classify loss: 1.103267]
[Epoch 1/40] [Batch 251/287] [Batch classify loss: 1.083036]
[Epoch 1/40] [Batch 252/287] [Batch classify loss: 1.072576]
[Epoch 1/40] [Batch 253/287] [Batch classify loss: 1.050356]
[Epoch 1/40] [Batch 254/287] [Batch classify loss: 1.121564]
[Epoch 1/40] [Batch 255/287] [Batch classify loss: 1.097745]
[Epoch 1/40] [Batch 256/287] [Batch classify loss: 1.093290]
[Epoch 1/40] [Batch 257/287] [Batch classify loss: 1.055741]
[Epoch 1/40] [Batch 258/287] [Batch classify loss: 1.105561]
[Epoch 1/40] [Batch 259/287] [Batch classify loss: 1.054630]
[Epoch 1/40] [Batch 260/287] [Batch classify loss: 1.126559]
[Epoch 1/40] [Batch 261/287] [Batch classify loss: 1.063669]
[Epoch 1/40] [Batch 262/287] [Batch classify loss: 1.079056]
[Epoch 1/40] [Batch 263/287] [Batch classify loss: 1.147103]
[Epoch 1/40] [Batch 264/287] [Batch classify loss: 1.121835]
[Epoch 1/40] [Batch 265/287] [Batch classify loss: 1.118392]
[Epoch 1/40] [Batch 266/287] [Batch classify loss: 1.067918]
[Epoch 1/40] [Batch 267/287] [Batch classify loss: 1.080608]
[Epoch 1/40] [Batch 268/287] [Batch classify loss: 1.099626]
[Epoch 1/40] [Batch 269/287] [Batch classify loss: 1.092913]
[Epoch 1/40] [Batch 270/287] [Batch classify loss: 1.090770]
[Epoch 1/40] [Batch 271/287] [Batch classify loss: 1.086161]
[Epoch 1/40] [Batch 272/287] [Batch classify loss: 1.039351]
[Epoch 1/40] [Batch 273/287] [Batch classify loss: 1.068748]
[Epoch 1/40] [Batch 274/287] [Batch classify loss: 1.080714]
[Epoch 1/40] [Batch 275/287] [Batch classify loss: 1.086589]
[Epoch 1/40] [Batch 276/287] [Batch classify loss: 1.048340]
[Epoch 1/40] [Batch 277/287] [Batch classify loss: 1.112692]
[Epoch 1/40] [Batch 278/287] [Batch classify loss: 1.107492]
[Epoch 1/40] [Batch 279/287] [Batch classify loss: 1.091596]
[Epoch 1/40] [Batch 280/287] [Batch classify loss: 1.029135]
[Epoch 1/40] [Batch 281/287] [Batch classify loss: 1.101318]
[Epoch 1/40] [Batch 282/287] [Batch classify loss: 0.994827]
[Epoch 1/40] [Batch 283/287] [Batch classify loss: 1.118130]
[Epoch 1/40] [Batch 284/287] [Batch classify loss: 1.111307]
[Epoch 1/40] [Batch 285/287] [Batch classify loss: 1.064388]
[Epoch 1/40] [Batch 286/287] [Batch classify loss: 1.057861]
[Epoch 1/40] [Batch 287/287] [Batch classify loss: 1.685648]
0001 epoch rmt trained classifier accuary on the clean testing examples:89.7088%
0001 epoch rmt trained classifier loss on the clean testing examples:0.4539
0001 epoch rmt trained classifier accuary on adversarial testset:13.5333%
0001 epoch rmt trained classifier loss on adversarial testset:5.026303768157959


1epoch learning rate:0.001
[Epoch 2/40] [Batch 1/287] [Batch classify loss: 1.034588]
[Epoch 2/40] [Batch 2/287] [Batch classify loss: 1.118398]
[Epoch 2/40] [Batch 3/287] [Batch classify loss: 1.076981]
[Epoch 2/40] [Batch 4/287] [Batch classify loss: 1.072772]
[Epoch 2/40] [Batch 5/287] [Batch classify loss: 0.979865]
[Epoch 2/40] [Batch 6/287] [Batch classify loss: 1.042073]
[Epoch 2/40] [Batch 7/287] [Batch classify loss: 1.063168]
[Epoch 2/40] [Batch 8/287] [Batch classify loss: 1.060799]
[Epoch 2/40] [Batch 9/287] [Batch classify loss: 1.010159]
[Epoch 2/40] [Batch 10/287] [Batch classify loss: 1.098629]
[Epoch 2/40] [Batch 11/287] [Batch classify loss: 1.052440]
[Epoch 2/40] [Batch 12/287] [Batch classify loss: 1.092011]
[Epoch 2/40] [Batch 13/287] [Batch classify loss: 1.015388]
[Epoch 2/40] [Batch 14/287] [Batch classify loss: 1.057718]
[Epoch 2/40] [Batch 15/287] [Batch classify loss: 1.002873]
[Epoch 2/40] [Batch 16/287] [Batch classify loss: 1.055606]
[Epoch 2/40] [Batch 17/287] [Batch classify loss: 1.026957]
[Epoch 2/40] [Batch 18/287] [Batch classify loss: 1.090513]
[Epoch 2/40] [Batch 19/287] [Batch classify loss: 1.103084]
[Epoch 2/40] [Batch 20/287] [Batch classify loss: 1.104681]
[Epoch 2/40] [Batch 21/287] [Batch classify loss: 1.096172]
[Epoch 2/40] [Batch 22/287] [Batch classify loss: 1.071015]
[Epoch 2/40] [Batch 23/287] [Batch classify loss: 1.110355]
[Epoch 2/40] [Batch 24/287] [Batch classify loss: 1.097649]
[Epoch 2/40] [Batch 25/287] [Batch classify loss: 1.085510]
[Epoch 2/40] [Batch 26/287] [Batch classify loss: 1.085889]
[Epoch 2/40] [Batch 27/287] [Batch classify loss: 1.047699]
[Epoch 2/40] [Batch 28/287] [Batch classify loss: 1.114257]
[Epoch 2/40] [Batch 29/287] [Batch classify loss: 1.005433]
[Epoch 2/40] [Batch 30/287] [Batch classify loss: 1.014894]
[Epoch 2/40] [Batch 31/287] [Batch classify loss: 1.013895]
[Epoch 2/40] [Batch 32/287] [Batch classify loss: 1.082265]
[Epoch 2/40] [Batch 33/287] [Batch classify loss: 1.055858]
[Epoch 2/40] [Batch 34/287] [Batch classify loss: 1.098479]
[Epoch 2/40] [Batch 35/287] [Batch classify loss: 1.118157]
[Epoch 2/40] [Batch 36/287] [Batch classify loss: 1.082894]
[Epoch 2/40] [Batch 37/287] [Batch classify loss: 1.032189]
[Epoch 2/40] [Batch 38/287] [Batch classify loss: 1.138902]
[Epoch 2/40] [Batch 39/287] [Batch classify loss: 1.051057]
[Epoch 2/40] [Batch 40/287] [Batch classify loss: 1.106614]
[Epoch 2/40] [Batch 41/287] [Batch classify loss: 1.107785]
[Epoch 2/40] [Batch 42/287] [Batch classify loss: 1.069717]
[Epoch 2/40] [Batch 43/287] [Batch classify loss: 1.028666]
[Epoch 2/40] [Batch 44/287] [Batch classify loss: 1.044609]
[Epoch 2/40] [Batch 45/287] [Batch classify loss: 1.048834]
[Epoch 2/40] [Batch 46/287] [Batch classify loss: 1.083544]
[Epoch 2/40] [Batch 47/287] [Batch classify loss: 1.076514]
[Epoch 2/40] [Batch 48/287] [Batch classify loss: 1.096917]
[Epoch 2/40] [Batch 49/287] [Batch classify loss: 1.098317]
[Epoch 2/40] [Batch 50/287] [Batch classify loss: 1.052150]
[Epoch 2/40] [Batch 51/287] [Batch classify loss: 1.098950]
[Epoch 2/40] [Batch 52/287] [Batch classify loss: 1.098783]
[Epoch 2/40] [Batch 53/287] [Batch classify loss: 1.133037]
[Epoch 2/40] [Batch 54/287] [Batch classify loss: 1.051762]
[Epoch 2/40] [Batch 55/287] [Batch classify loss: 1.124074]
[Epoch 2/40] [Batch 56/287] [Batch classify loss: 1.031857]
[Epoch 2/40] [Batch 57/287] [Batch classify loss: 1.045000]
[Epoch 2/40] [Batch 58/287] [Batch classify loss: 1.049983]
[Epoch 2/40] [Batch 59/287] [Batch classify loss: 1.042096]
[Epoch 2/40] [Batch 60/287] [Batch classify loss: 1.015366]
[Epoch 2/40] [Batch 61/287] [Batch classify loss: 1.073745]
[Epoch 2/40] [Batch 62/287] [Batch classify loss: 1.089552]
[Epoch 2/40] [Batch 63/287] [Batch classify loss: 1.058830]
[Epoch 2/40] [Batch 64/287] [Batch classify loss: 1.057394]
[Epoch 2/40] [Batch 65/287] [Batch classify loss: 1.073117]
[Epoch 2/40] [Batch 66/287] [Batch classify loss: 1.077724]
[Epoch 2/40] [Batch 67/287] [Batch classify loss: 1.074094]
[Epoch 2/40] [Batch 68/287] [Batch classify loss: 1.103059]
[Epoch 2/40] [Batch 69/287] [Batch classify loss: 1.042901]
[Epoch 2/40] [Batch 70/287] [Batch classify loss: 1.063304]
[Epoch 2/40] [Batch 71/287] [Batch classify loss: 1.076044]
[Epoch 2/40] [Batch 72/287] [Batch classify loss: 1.189869]
[Epoch 2/40] [Batch 73/287] [Batch classify loss: 1.095124]
[Epoch 2/40] [Batch 74/287] [Batch classify loss: 1.137942]
[Epoch 2/40] [Batch 75/287] [Batch classify loss: 1.092863]
[Epoch 2/40] [Batch 76/287] [Batch classify loss: 1.115832]
[Epoch 2/40] [Batch 77/287] [Batch classify loss: 1.092209]
[Epoch 2/40] [Batch 78/287] [Batch classify loss: 1.052593]
[Epoch 2/40] [Batch 79/287] [Batch classify loss: 1.113595]
[Epoch 2/40] [Batch 80/287] [Batch classify loss: 1.114188]
[Epoch 2/40] [Batch 81/287] [Batch classify loss: 1.093533]
[Epoch 2/40] [Batch 82/287] [Batch classify loss: 1.151392]
[Epoch 2/40] [Batch 83/287] [Batch classify loss: 1.085773]
[Epoch 2/40] [Batch 84/287] [Batch classify loss: 1.110809]
[Epoch 2/40] [Batch 85/287] [Batch classify loss: 1.068993]
[Epoch 2/40] [Batch 86/287] [Batch classify loss: 1.050076]
[Epoch 2/40] [Batch 87/287] [Batch classify loss: 1.013598]
[Epoch 2/40] [Batch 88/287] [Batch classify loss: 1.151359]
[Epoch 2/40] [Batch 89/287] [Batch classify loss: 1.075508]
[Epoch 2/40] [Batch 90/287] [Batch classify loss: 1.142905]
[Epoch 2/40] [Batch 91/287] [Batch classify loss: 1.094147]
[Epoch 2/40] [Batch 92/287] [Batch classify loss: 1.099538]
[Epoch 2/40] [Batch 93/287] [Batch classify loss: 1.106175]
[Epoch 2/40] [Batch 94/287] [Batch classify loss: 0.962500]
[Epoch 2/40] [Batch 95/287] [Batch classify loss: 1.019524]
[Epoch 2/40] [Batch 96/287] [Batch classify loss: 1.057855]
[Epoch 2/40] [Batch 97/287] [Batch classify loss: 1.038794]
[Epoch 2/40] [Batch 98/287] [Batch classify loss: 1.010935]
[Epoch 2/40] [Batch 99/287] [Batch classify loss: 1.007986]
[Epoch 2/40] [Batch 100/287] [Batch classify loss: 1.006958]
[Epoch 2/40] [Batch 101/287] [Batch classify loss: 1.055920]
[Epoch 2/40] [Batch 102/287] [Batch classify loss: 1.052377]
[Epoch 2/40] [Batch 103/287] [Batch classify loss: 1.042377]
[Epoch 2/40] [Batch 104/287] [Batch classify loss: 1.085490]
[Epoch 2/40] [Batch 105/287] [Batch classify loss: 1.009507]
[Epoch 2/40] [Batch 106/287] [Batch classify loss: 1.128080]
[Epoch 2/40] [Batch 107/287] [Batch classify loss: 1.053844]
[Epoch 2/40] [Batch 108/287] [Batch classify loss: 1.094653]
[Epoch 2/40] [Batch 109/287] [Batch classify loss: 1.073310]
[Epoch 2/40] [Batch 110/287] [Batch classify loss: 1.094529]
[Epoch 2/40] [Batch 111/287] [Batch classify loss: 1.047842]
[Epoch 2/40] [Batch 112/287] [Batch classify loss: 1.046044]
[Epoch 2/40] [Batch 113/287] [Batch classify loss: 1.095407]
[Epoch 2/40] [Batch 114/287] [Batch classify loss: 1.118820]
[Epoch 2/40] [Batch 115/287] [Batch classify loss: 1.102324]
[Epoch 2/40] [Batch 116/287] [Batch classify loss: 1.048917]
[Epoch 2/40] [Batch 117/287] [Batch classify loss: 1.053816]
[Epoch 2/40] [Batch 118/287] [Batch classify loss: 1.098190]
[Epoch 2/40] [Batch 119/287] [Batch classify loss: 1.017061]
[Epoch 2/40] [Batch 120/287] [Batch classify loss: 1.030125]
[Epoch 2/40] [Batch 121/287] [Batch classify loss: 1.090979]
[Epoch 2/40] [Batch 122/287] [Batch classify loss: 1.006788]
[Epoch 2/40] [Batch 123/287] [Batch classify loss: 1.025245]
[Epoch 2/40] [Batch 124/287] [Batch classify loss: 1.110187]
[Epoch 2/40] [Batch 125/287] [Batch classify loss: 1.011288]
[Epoch 2/40] [Batch 126/287] [Batch classify loss: 1.086524]
[Epoch 2/40] [Batch 127/287] [Batch classify loss: 1.013023]
[Epoch 2/40] [Batch 128/287] [Batch classify loss: 1.011779]
[Epoch 2/40] [Batch 129/287] [Batch classify loss: 1.103835]
[Epoch 2/40] [Batch 130/287] [Batch classify loss: 1.055321]
[Epoch 2/40] [Batch 131/287] [Batch classify loss: 1.034044]
[Epoch 2/40] [Batch 132/287] [Batch classify loss: 1.100282]
[Epoch 2/40] [Batch 133/287] [Batch classify loss: 1.125203]
[Epoch 2/40] [Batch 134/287] [Batch classify loss: 1.108670]
[Epoch 2/40] [Batch 135/287] [Batch classify loss: 1.078206]
[Epoch 2/40] [Batch 136/287] [Batch classify loss: 1.031687]
[Epoch 2/40] [Batch 137/287] [Batch classify loss: 1.070330]
[Epoch 2/40] [Batch 138/287] [Batch classify loss: 1.046320]
[Epoch 2/40] [Batch 139/287] [Batch classify loss: 1.073533]
[Epoch 2/40] [Batch 140/287] [Batch classify loss: 1.070657]
[Epoch 2/40] [Batch 141/287] [Batch classify loss: 1.002560]
[Epoch 2/40] [Batch 142/287] [Batch classify loss: 1.055129]
[Epoch 2/40] [Batch 143/287] [Batch classify loss: 1.052572]
[Epoch 2/40] [Batch 144/287] [Batch classify loss: 1.007951]
[Epoch 2/40] [Batch 145/287] [Batch classify loss: 1.082674]
[Epoch 2/40] [Batch 146/287] [Batch classify loss: 1.061527]
[Epoch 2/40] [Batch 147/287] [Batch classify loss: 1.079994]
[Epoch 2/40] [Batch 148/287] [Batch classify loss: 1.057889]
[Epoch 2/40] [Batch 149/287] [Batch classify loss: 1.068835]
[Epoch 2/40] [Batch 150/287] [Batch classify loss: 1.102034]
[Epoch 2/40] [Batch 151/287] [Batch classify loss: 1.056936]
[Epoch 2/40] [Batch 152/287] [Batch classify loss: 1.073102]
[Epoch 2/40] [Batch 153/287] [Batch classify loss: 1.066914]
[Epoch 2/40] [Batch 154/287] [Batch classify loss: 1.060867]
[Epoch 2/40] [Batch 155/287] [Batch classify loss: 1.071518]
[Epoch 2/40] [Batch 156/287] [Batch classify loss: 1.110751]
[Epoch 2/40] [Batch 157/287] [Batch classify loss: 1.048422]
[Epoch 2/40] [Batch 158/287] [Batch classify loss: 1.018524]
[Epoch 2/40] [Batch 159/287] [Batch classify loss: 1.099864]
[Epoch 2/40] [Batch 160/287] [Batch classify loss: 1.007305]
[Epoch 2/40] [Batch 161/287] [Batch classify loss: 1.010498]
[Epoch 2/40] [Batch 162/287] [Batch classify loss: 1.106682]
[Epoch 2/40] [Batch 163/287] [Batch classify loss: 1.024304]
[Epoch 2/40] [Batch 164/287] [Batch classify loss: 1.005432]
[Epoch 2/40] [Batch 165/287] [Batch classify loss: 1.029377]
[Epoch 2/40] [Batch 166/287] [Batch classify loss: 1.068412]
[Epoch 2/40] [Batch 167/287] [Batch classify loss: 1.012171]
[Epoch 2/40] [Batch 168/287] [Batch classify loss: 1.095806]
[Epoch 2/40] [Batch 169/287] [Batch classify loss: 1.074903]
[Epoch 2/40] [Batch 170/287] [Batch classify loss: 0.997065]
[Epoch 2/40] [Batch 171/287] [Batch classify loss: 1.063753]
[Epoch 2/40] [Batch 172/287] [Batch classify loss: 1.060528]
[Epoch 2/40] [Batch 173/287] [Batch classify loss: 1.100367]
[Epoch 2/40] [Batch 174/287] [Batch classify loss: 1.055089]
[Epoch 2/40] [Batch 175/287] [Batch classify loss: 1.062281]
[Epoch 2/40] [Batch 176/287] [Batch classify loss: 1.086438]
[Epoch 2/40] [Batch 177/287] [Batch classify loss: 1.045609]
[Epoch 2/40] [Batch 178/287] [Batch classify loss: 1.086780]
[Epoch 2/40] [Batch 179/287] [Batch classify loss: 1.067475]
[Epoch 2/40] [Batch 180/287] [Batch classify loss: 1.055800]
[Epoch 2/40] [Batch 181/287] [Batch classify loss: 1.056033]
[Epoch 2/40] [Batch 182/287] [Batch classify loss: 1.052031]
[Epoch 2/40] [Batch 183/287] [Batch classify loss: 1.066131]
[Epoch 2/40] [Batch 184/287] [Batch classify loss: 1.135409]
[Epoch 2/40] [Batch 185/287] [Batch classify loss: 1.038080]
[Epoch 2/40] [Batch 186/287] [Batch classify loss: 1.085091]
[Epoch 2/40] [Batch 187/287] [Batch classify loss: 1.005747]
[Epoch 2/40] [Batch 188/287] [Batch classify loss: 0.968133]
[Epoch 2/40] [Batch 189/287] [Batch classify loss: 0.987330]
[Epoch 2/40] [Batch 190/287] [Batch classify loss: 1.034104]
[Epoch 2/40] [Batch 191/287] [Batch classify loss: 0.989188]
[Epoch 2/40] [Batch 192/287] [Batch classify loss: 0.954304]
[Epoch 2/40] [Batch 193/287] [Batch classify loss: 0.971961]
[Epoch 2/40] [Batch 194/287] [Batch classify loss: 0.986930]
[Epoch 2/40] [Batch 195/287] [Batch classify loss: 1.020278]
[Epoch 2/40] [Batch 196/287] [Batch classify loss: 1.096135]
[Epoch 2/40] [Batch 197/287] [Batch classify loss: 0.985570]
[Epoch 2/40] [Batch 198/287] [Batch classify loss: 0.987160]
[Epoch 2/40] [Batch 199/287] [Batch classify loss: 1.044764]
[Epoch 2/40] [Batch 200/287] [Batch classify loss: 1.002152]
[Epoch 2/40] [Batch 201/287] [Batch classify loss: 1.033896]
[Epoch 2/40] [Batch 202/287] [Batch classify loss: 1.044054]
[Epoch 2/40] [Batch 203/287] [Batch classify loss: 0.976666]
[Epoch 2/40] [Batch 204/287] [Batch classify loss: 0.998945]
[Epoch 2/40] [Batch 205/287] [Batch classify loss: 1.065307]
[Epoch 2/40] [Batch 206/287] [Batch classify loss: 1.021753]
[Epoch 2/40] [Batch 207/287] [Batch classify loss: 1.010600]
[Epoch 2/40] [Batch 208/287] [Batch classify loss: 1.051119]
[Epoch 2/40] [Batch 209/287] [Batch classify loss: 1.026570]
[Epoch 2/40] [Batch 210/287] [Batch classify loss: 1.095930]
[Epoch 2/40] [Batch 211/287] [Batch classify loss: 1.066764]
[Epoch 2/40] [Batch 212/287] [Batch classify loss: 1.020260]
[Epoch 2/40] [Batch 213/287] [Batch classify loss: 1.006393]
[Epoch 2/40] [Batch 214/287] [Batch classify loss: 1.054723]
[Epoch 2/40] [Batch 215/287] [Batch classify loss: 1.026628]
[Epoch 2/40] [Batch 216/287] [Batch classify loss: 1.052853]
[Epoch 2/40] [Batch 217/287] [Batch classify loss: 1.031736]
[Epoch 2/40] [Batch 218/287] [Batch classify loss: 1.014492]
[Epoch 2/40] [Batch 219/287] [Batch classify loss: 1.028106]
[Epoch 2/40] [Batch 220/287] [Batch classify loss: 1.094936]
[Epoch 2/40] [Batch 221/287] [Batch classify loss: 1.037913]
[Epoch 2/40] [Batch 222/287] [Batch classify loss: 1.010518]
[Epoch 2/40] [Batch 223/287] [Batch classify loss: 1.073626]
[Epoch 2/40] [Batch 224/287] [Batch classify loss: 1.029827]
[Epoch 2/40] [Batch 225/287] [Batch classify loss: 1.085704]
[Epoch 2/40] [Batch 226/287] [Batch classify loss: 1.095610]
[Epoch 2/40] [Batch 227/287] [Batch classify loss: 1.094570]
[Epoch 2/40] [Batch 228/287] [Batch classify loss: 1.066040]
[Epoch 2/40] [Batch 229/287] [Batch classify loss: 1.053321]
[Epoch 2/40] [Batch 230/287] [Batch classify loss: 1.075297]
[Epoch 2/40] [Batch 231/287] [Batch classify loss: 1.020534]
[Epoch 2/40] [Batch 232/287] [Batch classify loss: 1.033641]
[Epoch 2/40] [Batch 233/287] [Batch classify loss: 1.046174]
[Epoch 2/40] [Batch 234/287] [Batch classify loss: 1.064046]
[Epoch 2/40] [Batch 235/287] [Batch classify loss: 1.052750]
[Epoch 2/40] [Batch 236/287] [Batch classify loss: 1.018913]
[Epoch 2/40] [Batch 237/287] [Batch classify loss: 1.102064]
[Epoch 2/40] [Batch 238/287] [Batch classify loss: 0.966948]
[Epoch 2/40] [Batch 239/287] [Batch classify loss: 1.042892]
[Epoch 2/40] [Batch 240/287] [Batch classify loss: 1.068387]
[Epoch 2/40] [Batch 241/287] [Batch classify loss: 1.049589]
[Epoch 2/40] [Batch 242/287] [Batch classify loss: 1.008117]
[Epoch 2/40] [Batch 243/287] [Batch classify loss: 1.018774]
[Epoch 2/40] [Batch 244/287] [Batch classify loss: 1.069529]
[Epoch 2/40] [Batch 245/287] [Batch classify loss: 1.048154]
[Epoch 2/40] [Batch 246/287] [Batch classify loss: 1.106919]
[Epoch 2/40] [Batch 247/287] [Batch classify loss: 1.089022]
[Epoch 2/40] [Batch 248/287] [Batch classify loss: 1.038499]
[Epoch 2/40] [Batch 249/287] [Batch classify loss: 0.974157]
[Epoch 2/40] [Batch 250/287] [Batch classify loss: 1.053516]
[Epoch 2/40] [Batch 251/287] [Batch classify loss: 1.057167]
[Epoch 2/40] [Batch 252/287] [Batch classify loss: 1.071090]
[Epoch 2/40] [Batch 253/287] [Batch classify loss: 1.062378]
[Epoch 2/40] [Batch 254/287] [Batch classify loss: 1.037538]
[Epoch 2/40] [Batch 255/287] [Batch classify loss: 1.001196]
[Epoch 2/40] [Batch 256/287] [Batch classify loss: 1.051259]
[Epoch 2/40] [Batch 257/287] [Batch classify loss: 1.025795]
[Epoch 2/40] [Batch 258/287] [Batch classify loss: 1.011092]
[Epoch 2/40] [Batch 259/287] [Batch classify loss: 1.077159]
[Epoch 2/40] [Batch 260/287] [Batch classify loss: 1.052706]
[Epoch 2/40] [Batch 261/287] [Batch classify loss: 1.006100]
[Epoch 2/40] [Batch 262/287] [Batch classify loss: 1.128788]
[Epoch 2/40] [Batch 263/287] [Batch classify loss: 1.036232]
[Epoch 2/40] [Batch 264/287] [Batch classify loss: 1.098461]
[Epoch 2/40] [Batch 265/287] [Batch classify loss: 1.064881]
[Epoch 2/40] [Batch 266/287] [Batch classify loss: 1.020135]
[Epoch 2/40] [Batch 267/287] [Batch classify loss: 1.066340]
[Epoch 2/40] [Batch 268/287] [Batch classify loss: 1.031365]
[Epoch 2/40] [Batch 269/287] [Batch classify loss: 1.087406]
[Epoch 2/40] [Batch 270/287] [Batch classify loss: 1.082831]
[Epoch 2/40] [Batch 271/287] [Batch classify loss: 1.087337]
[Epoch 2/40] [Batch 272/287] [Batch classify loss: 1.078483]
[Epoch 2/40] [Batch 273/287] [Batch classify loss: 1.100978]
[Epoch 2/40] [Batch 274/287] [Batch classify loss: 1.120779]
[Epoch 2/40] [Batch 275/287] [Batch classify loss: 1.043093]
[Epoch 2/40] [Batch 276/287] [Batch classify loss: 1.106309]
[Epoch 2/40] [Batch 277/287] [Batch classify loss: 1.056511]
[Epoch 2/40] [Batch 278/287] [Batch classify loss: 1.045280]
[Epoch 2/40] [Batch 279/287] [Batch classify loss: 1.063507]
[Epoch 2/40] [Batch 280/287] [Batch classify loss: 1.084950]
[Epoch 2/40] [Batch 281/287] [Batch classify loss: 1.036294]
[Epoch 2/40] [Batch 282/287] [Batch classify loss: 1.026264]
[Epoch 2/40] [Batch 283/287] [Batch classify loss: 0.959883]
[Epoch 2/40] [Batch 284/287] [Batch classify loss: 1.100150]
[Epoch 2/40] [Batch 285/287] [Batch classify loss: 0.998289]
[Epoch 2/40] [Batch 286/287] [Batch classify loss: 1.043820]
[Epoch 2/40] [Batch 287/287] [Batch classify loss: 1.544692]
0002 epoch rmt trained classifier accuary on the clean testing examples:90.2274%
0002 epoch rmt trained classifier loss on the clean testing examples:0.4265
0002 epoch rmt trained classifier accuary on adversarial testset:15.3311%
0002 epoch rmt trained classifier loss on adversarial testset:4.729541301727295


2epoch learning rate:0.001
[Epoch 3/40] [Batch 1/287] [Batch classify loss: 0.823286]
[Epoch 3/40] [Batch 2/287] [Batch classify loss: 0.904892]
[Epoch 3/40] [Batch 3/287] [Batch classify loss: 0.970790]
[Epoch 3/40] [Batch 4/287] [Batch classify loss: 0.962347]
[Epoch 3/40] [Batch 5/287] [Batch classify loss: 0.947024]
[Epoch 3/40] [Batch 6/287] [Batch classify loss: 0.879282]
[Epoch 3/40] [Batch 7/287] [Batch classify loss: 0.922992]
[Epoch 3/40] [Batch 8/287] [Batch classify loss: 1.018781]
[Epoch 3/40] [Batch 9/287] [Batch classify loss: 0.940215]
[Epoch 3/40] [Batch 10/287] [Batch classify loss: 0.960494]
[Epoch 3/40] [Batch 11/287] [Batch classify loss: 0.912410]
[Epoch 3/40] [Batch 12/287] [Batch classify loss: 0.945594]
[Epoch 3/40] [Batch 13/287] [Batch classify loss: 0.906939]
[Epoch 3/40] [Batch 14/287] [Batch classify loss: 1.053330]
[Epoch 3/40] [Batch 15/287] [Batch classify loss: 0.952588]
[Epoch 3/40] [Batch 16/287] [Batch classify loss: 0.952465]
[Epoch 3/40] [Batch 17/287] [Batch classify loss: 0.920357]
[Epoch 3/40] [Batch 18/287] [Batch classify loss: 0.969387]
[Epoch 3/40] [Batch 19/287] [Batch classify loss: 0.999431]
[Epoch 3/40] [Batch 20/287] [Batch classify loss: 0.973986]
[Epoch 3/40] [Batch 21/287] [Batch classify loss: 1.025337]
[Epoch 3/40] [Batch 22/287] [Batch classify loss: 0.960768]
[Epoch 3/40] [Batch 23/287] [Batch classify loss: 0.977990]
[Epoch 3/40] [Batch 24/287] [Batch classify loss: 0.958178]
[Epoch 3/40] [Batch 25/287] [Batch classify loss: 0.958093]
[Epoch 3/40] [Batch 26/287] [Batch classify loss: 1.009342]
[Epoch 3/40] [Batch 27/287] [Batch classify loss: 0.964075]
[Epoch 3/40] [Batch 28/287] [Batch classify loss: 1.023659]
[Epoch 3/40] [Batch 29/287] [Batch classify loss: 0.956128]
[Epoch 3/40] [Batch 30/287] [Batch classify loss: 1.006578]
[Epoch 3/40] [Batch 31/287] [Batch classify loss: 0.989392]
[Epoch 3/40] [Batch 32/287] [Batch classify loss: 0.973675]
[Epoch 3/40] [Batch 33/287] [Batch classify loss: 0.977763]
[Epoch 3/40] [Batch 34/287] [Batch classify loss: 0.978175]
[Epoch 3/40] [Batch 35/287] [Batch classify loss: 0.988026]
[Epoch 3/40] [Batch 36/287] [Batch classify loss: 1.063791]
[Epoch 3/40] [Batch 37/287] [Batch classify loss: 0.988351]
[Epoch 3/40] [Batch 38/287] [Batch classify loss: 0.946912]
[Epoch 3/40] [Batch 39/287] [Batch classify loss: 0.972472]
[Epoch 3/40] [Batch 40/287] [Batch classify loss: 0.976774]
[Epoch 3/40] [Batch 41/287] [Batch classify loss: 0.972246]
[Epoch 3/40] [Batch 42/287] [Batch classify loss: 0.948656]
[Epoch 3/40] [Batch 43/287] [Batch classify loss: 0.961799]
[Epoch 3/40] [Batch 44/287] [Batch classify loss: 1.036797]
[Epoch 3/40] [Batch 45/287] [Batch classify loss: 0.988429]
[Epoch 3/40] [Batch 46/287] [Batch classify loss: 0.964880]
[Epoch 3/40] [Batch 47/287] [Batch classify loss: 0.937286]
[Epoch 3/40] [Batch 48/287] [Batch classify loss: 0.952454]
[Epoch 3/40] [Batch 49/287] [Batch classify loss: 1.031263]
[Epoch 3/40] [Batch 50/287] [Batch classify loss: 1.013780]
[Epoch 3/40] [Batch 51/287] [Batch classify loss: 0.945692]
[Epoch 3/40] [Batch 52/287] [Batch classify loss: 1.017494]
[Epoch 3/40] [Batch 53/287] [Batch classify loss: 1.025595]
[Epoch 3/40] [Batch 54/287] [Batch classify loss: 1.009313]
[Epoch 3/40] [Batch 55/287] [Batch classify loss: 0.980068]
[Epoch 3/40] [Batch 56/287] [Batch classify loss: 1.052150]
[Epoch 3/40] [Batch 57/287] [Batch classify loss: 0.937656]
[Epoch 3/40] [Batch 58/287] [Batch classify loss: 0.995307]
[Epoch 3/40] [Batch 59/287] [Batch classify loss: 1.044237]
[Epoch 3/40] [Batch 60/287] [Batch classify loss: 0.974980]
[Epoch 3/40] [Batch 61/287] [Batch classify loss: 0.924750]
[Epoch 3/40] [Batch 62/287] [Batch classify loss: 1.022710]
[Epoch 3/40] [Batch 63/287] [Batch classify loss: 0.996267]
[Epoch 3/40] [Batch 64/287] [Batch classify loss: 1.041385]
[Epoch 3/40] [Batch 65/287] [Batch classify loss: 1.006366]
[Epoch 3/40] [Batch 66/287] [Batch classify loss: 0.929727]
[Epoch 3/40] [Batch 67/287] [Batch classify loss: 1.026736]
[Epoch 3/40] [Batch 68/287] [Batch classify loss: 1.047124]
[Epoch 3/40] [Batch 69/287] [Batch classify loss: 1.001652]
[Epoch 3/40] [Batch 70/287] [Batch classify loss: 1.038429]
[Epoch 3/40] [Batch 71/287] [Batch classify loss: 0.976040]
[Epoch 3/40] [Batch 72/287] [Batch classify loss: 1.061993]
[Epoch 3/40] [Batch 73/287] [Batch classify loss: 0.970031]
[Epoch 3/40] [Batch 74/287] [Batch classify loss: 1.031444]
[Epoch 3/40] [Batch 75/287] [Batch classify loss: 1.007463]
[Epoch 3/40] [Batch 76/287] [Batch classify loss: 0.958262]
[Epoch 3/40] [Batch 77/287] [Batch classify loss: 1.007933]
[Epoch 3/40] [Batch 78/287] [Batch classify loss: 1.039459]
[Epoch 3/40] [Batch 79/287] [Batch classify loss: 1.006893]
[Epoch 3/40] [Batch 80/287] [Batch classify loss: 1.045338]
[Epoch 3/40] [Batch 81/287] [Batch classify loss: 1.021014]
[Epoch 3/40] [Batch 82/287] [Batch classify loss: 0.973025]
[Epoch 3/40] [Batch 83/287] [Batch classify loss: 0.989608]
[Epoch 3/40] [Batch 84/287] [Batch classify loss: 1.023983]
[Epoch 3/40] [Batch 85/287] [Batch classify loss: 1.051045]
[Epoch 3/40] [Batch 86/287] [Batch classify loss: 1.075903]
[Epoch 3/40] [Batch 87/287] [Batch classify loss: 0.979819]
[Epoch 3/40] [Batch 88/287] [Batch classify loss: 1.038395]
[Epoch 3/40] [Batch 89/287] [Batch classify loss: 0.988084]
[Epoch 3/40] [Batch 90/287] [Batch classify loss: 0.925463]
[Epoch 3/40] [Batch 91/287] [Batch classify loss: 1.017237]
[Epoch 3/40] [Batch 92/287] [Batch classify loss: 0.959983]
[Epoch 3/40] [Batch 93/287] [Batch classify loss: 1.031480]
[Epoch 3/40] [Batch 94/287] [Batch classify loss: 1.014923]
[Epoch 3/40] [Batch 95/287] [Batch classify loss: 0.833201]
[Epoch 3/40] [Batch 96/287] [Batch classify loss: 0.877899]
[Epoch 3/40] [Batch 97/287] [Batch classify loss: 0.986082]
[Epoch 3/40] [Batch 98/287] [Batch classify loss: 0.852772]
[Epoch 3/40] [Batch 99/287] [Batch classify loss: 0.862622]
[Epoch 3/40] [Batch 100/287] [Batch classify loss: 0.893965]
[Epoch 3/40] [Batch 101/287] [Batch classify loss: 0.914155]
[Epoch 3/40] [Batch 102/287] [Batch classify loss: 0.975258]
[Epoch 3/40] [Batch 103/287] [Batch classify loss: 0.867723]
[Epoch 3/40] [Batch 104/287] [Batch classify loss: 0.908441]
[Epoch 3/40] [Batch 105/287] [Batch classify loss: 0.952051]
[Epoch 3/40] [Batch 106/287] [Batch classify loss: 0.960647]
[Epoch 3/40] [Batch 107/287] [Batch classify loss: 0.917867]
[Epoch 3/40] [Batch 108/287] [Batch classify loss: 0.972151]
[Epoch 3/40] [Batch 109/287] [Batch classify loss: 0.941291]
[Epoch 3/40] [Batch 110/287] [Batch classify loss: 0.981713]
[Epoch 3/40] [Batch 111/287] [Batch classify loss: 0.906865]
[Epoch 3/40] [Batch 112/287] [Batch classify loss: 0.908599]
[Epoch 3/40] [Batch 113/287] [Batch classify loss: 1.000988]
[Epoch 3/40] [Batch 114/287] [Batch classify loss: 0.979066]
[Epoch 3/40] [Batch 115/287] [Batch classify loss: 1.032679]
[Epoch 3/40] [Batch 116/287] [Batch classify loss: 0.933341]
[Epoch 3/40] [Batch 117/287] [Batch classify loss: 0.982551]
[Epoch 3/40] [Batch 118/287] [Batch classify loss: 0.995416]
[Epoch 3/40] [Batch 119/287] [Batch classify loss: 0.927941]
[Epoch 3/40] [Batch 120/287] [Batch classify loss: 0.937035]
[Epoch 3/40] [Batch 121/287] [Batch classify loss: 0.942408]
[Epoch 3/40] [Batch 122/287] [Batch classify loss: 1.022991]
[Epoch 3/40] [Batch 123/287] [Batch classify loss: 0.959584]
[Epoch 3/40] [Batch 124/287] [Batch classify loss: 1.041528]
[Epoch 3/40] [Batch 125/287] [Batch classify loss: 0.923775]
[Epoch 3/40] [Batch 126/287] [Batch classify loss: 0.964998]
[Epoch 3/40] [Batch 127/287] [Batch classify loss: 0.956317]
[Epoch 3/40] [Batch 128/287] [Batch classify loss: 0.929885]
[Epoch 3/40] [Batch 129/287] [Batch classify loss: 0.958195]
[Epoch 3/40] [Batch 130/287] [Batch classify loss: 1.022687]
[Epoch 3/40] [Batch 131/287] [Batch classify loss: 1.059682]
[Epoch 3/40] [Batch 132/287] [Batch classify loss: 0.991298]
[Epoch 3/40] [Batch 133/287] [Batch classify loss: 1.079512]
[Epoch 3/40] [Batch 134/287] [Batch classify loss: 0.979755]
[Epoch 3/40] [Batch 135/287] [Batch classify loss: 0.969737]
[Epoch 3/40] [Batch 136/287] [Batch classify loss: 0.985882]
[Epoch 3/40] [Batch 137/287] [Batch classify loss: 0.943110]
[Epoch 3/40] [Batch 138/287] [Batch classify loss: 0.965702]
[Epoch 3/40] [Batch 139/287] [Batch classify loss: 0.979145]
[Epoch 3/40] [Batch 140/287] [Batch classify loss: 0.948408]
[Epoch 3/40] [Batch 141/287] [Batch classify loss: 1.060068]
[Epoch 3/40] [Batch 142/287] [Batch classify loss: 0.919370]
[Epoch 3/40] [Batch 143/287] [Batch classify loss: 0.982460]
[Epoch 3/40] [Batch 144/287] [Batch classify loss: 0.968575]
[Epoch 3/40] [Batch 145/287] [Batch classify loss: 0.957538]
[Epoch 3/40] [Batch 146/287] [Batch classify loss: 0.966224]
[Epoch 3/40] [Batch 147/287] [Batch classify loss: 0.980838]
[Epoch 3/40] [Batch 148/287] [Batch classify loss: 1.026890]
[Epoch 3/40] [Batch 149/287] [Batch classify loss: 1.015722]
[Epoch 3/40] [Batch 150/287] [Batch classify loss: 1.017303]
[Epoch 3/40] [Batch 151/287] [Batch classify loss: 1.073649]
[Epoch 3/40] [Batch 152/287] [Batch classify loss: 0.983756]
[Epoch 3/40] [Batch 153/287] [Batch classify loss: 1.017267]
[Epoch 3/40] [Batch 154/287] [Batch classify loss: 0.871054]
[Epoch 3/40] [Batch 155/287] [Batch classify loss: 0.968419]
[Epoch 3/40] [Batch 156/287] [Batch classify loss: 1.053054]
[Epoch 3/40] [Batch 157/287] [Batch classify loss: 0.976739]
[Epoch 3/40] [Batch 158/287] [Batch classify loss: 0.956860]
[Epoch 3/40] [Batch 159/287] [Batch classify loss: 1.038532]
[Epoch 3/40] [Batch 160/287] [Batch classify loss: 0.978351]
[Epoch 3/40] [Batch 161/287] [Batch classify loss: 0.970479]
[Epoch 3/40] [Batch 162/287] [Batch classify loss: 1.039890]
[Epoch 3/40] [Batch 163/287] [Batch classify loss: 1.089046]
[Epoch 3/40] [Batch 164/287] [Batch classify loss: 0.977856]
[Epoch 3/40] [Batch 165/287] [Batch classify loss: 0.976202]
[Epoch 3/40] [Batch 166/287] [Batch classify loss: 1.023638]
[Epoch 3/40] [Batch 167/287] [Batch classify loss: 0.979078]
[Epoch 3/40] [Batch 168/287] [Batch classify loss: 1.005563]
[Epoch 3/40] [Batch 169/287] [Batch classify loss: 1.020072]
[Epoch 3/40] [Batch 170/287] [Batch classify loss: 0.960692]
[Epoch 3/40] [Batch 171/287] [Batch classify loss: 1.031933]
[Epoch 3/40] [Batch 172/287] [Batch classify loss: 1.036900]
[Epoch 3/40] [Batch 173/287] [Batch classify loss: 1.021327]
[Epoch 3/40] [Batch 174/287] [Batch classify loss: 1.014462]
[Epoch 3/40] [Batch 175/287] [Batch classify loss: 0.955543]
[Epoch 3/40] [Batch 176/287] [Batch classify loss: 1.046191]
[Epoch 3/40] [Batch 177/287] [Batch classify loss: 1.015605]
[Epoch 3/40] [Batch 178/287] [Batch classify loss: 0.970514]
[Epoch 3/40] [Batch 179/287] [Batch classify loss: 1.031870]
[Epoch 3/40] [Batch 180/287] [Batch classify loss: 1.027522]
[Epoch 3/40] [Batch 181/287] [Batch classify loss: 1.018759]
[Epoch 3/40] [Batch 182/287] [Batch classify loss: 1.033955]
[Epoch 3/40] [Batch 183/287] [Batch classify loss: 1.035106]
[Epoch 3/40] [Batch 184/287] [Batch classify loss: 1.023632]
[Epoch 3/40] [Batch 185/287] [Batch classify loss: 0.980693]
[Epoch 3/40] [Batch 186/287] [Batch classify loss: 0.956512]
[Epoch 3/40] [Batch 187/287] [Batch classify loss: 0.980734]
[Epoch 3/40] [Batch 188/287] [Batch classify loss: 0.950105]
[Epoch 3/40] [Batch 189/287] [Batch classify loss: 0.792865]
[Epoch 3/40] [Batch 190/287] [Batch classify loss: 0.878751]
[Epoch 3/40] [Batch 191/287] [Batch classify loss: 0.908704]
[Epoch 3/40] [Batch 192/287] [Batch classify loss: 0.912915]
[Epoch 3/40] [Batch 193/287] [Batch classify loss: 0.909496]
[Epoch 3/40] [Batch 194/287] [Batch classify loss: 0.820181]
[Epoch 3/40] [Batch 195/287] [Batch classify loss: 0.853769]
[Epoch 3/40] [Batch 196/287] [Batch classify loss: 0.933751]
[Epoch 3/40] [Batch 197/287] [Batch classify loss: 0.880491]
[Epoch 3/40] [Batch 198/287] [Batch classify loss: 0.943258]
[Epoch 3/40] [Batch 199/287] [Batch classify loss: 0.864466]
[Epoch 3/40] [Batch 200/287] [Batch classify loss: 0.873161]
[Epoch 3/40] [Batch 201/287] [Batch classify loss: 0.891916]
[Epoch 3/40] [Batch 202/287] [Batch classify loss: 0.902970]
[Epoch 3/40] [Batch 203/287] [Batch classify loss: 0.910183]
[Epoch 3/40] [Batch 204/287] [Batch classify loss: 0.926484]
[Epoch 3/40] [Batch 205/287] [Batch classify loss: 0.859833]
[Epoch 3/40] [Batch 206/287] [Batch classify loss: 0.949811]
[Epoch 3/40] [Batch 207/287] [Batch classify loss: 0.967267]
[Epoch 3/40] [Batch 208/287] [Batch classify loss: 0.909354]
[Epoch 3/40] [Batch 209/287] [Batch classify loss: 0.986877]
[Epoch 3/40] [Batch 210/287] [Batch classify loss: 0.926955]
[Epoch 3/40] [Batch 211/287] [Batch classify loss: 0.937294]
[Epoch 3/40] [Batch 212/287] [Batch classify loss: 0.958062]
[Epoch 3/40] [Batch 213/287] [Batch classify loss: 0.916756]
[Epoch 3/40] [Batch 214/287] [Batch classify loss: 0.983082]
[Epoch 3/40] [Batch 215/287] [Batch classify loss: 0.966411]
[Epoch 3/40] [Batch 216/287] [Batch classify loss: 0.961427]
[Epoch 3/40] [Batch 217/287] [Batch classify loss: 0.968396]
[Epoch 3/40] [Batch 218/287] [Batch classify loss: 1.008354]
[Epoch 3/40] [Batch 219/287] [Batch classify loss: 0.972383]
[Epoch 3/40] [Batch 220/287] [Batch classify loss: 0.923078]
[Epoch 3/40] [Batch 221/287] [Batch classify loss: 0.946989]
[Epoch 3/40] [Batch 222/287] [Batch classify loss: 1.017985]
[Epoch 3/40] [Batch 223/287] [Batch classify loss: 0.995261]
[Epoch 3/40] [Batch 224/287] [Batch classify loss: 0.961903]
[Epoch 3/40] [Batch 225/287] [Batch classify loss: 0.962506]
[Epoch 3/40] [Batch 226/287] [Batch classify loss: 0.928842]
[Epoch 3/40] [Batch 227/287] [Batch classify loss: 0.953867]
[Epoch 3/40] [Batch 228/287] [Batch classify loss: 0.978906]
[Epoch 3/40] [Batch 229/287] [Batch classify loss: 1.001561]
[Epoch 3/40] [Batch 230/287] [Batch classify loss: 0.940543]
[Epoch 3/40] [Batch 231/287] [Batch classify loss: 0.977004]
[Epoch 3/40] [Batch 232/287] [Batch classify loss: 0.957170]
[Epoch 3/40] [Batch 233/287] [Batch classify loss: 0.928647]
[Epoch 3/40] [Batch 234/287] [Batch classify loss: 0.929987]
[Epoch 3/40] [Batch 235/287] [Batch classify loss: 1.045387]
[Epoch 3/40] [Batch 236/287] [Batch classify loss: 0.995265]
[Epoch 3/40] [Batch 237/287] [Batch classify loss: 0.990508]
[Epoch 3/40] [Batch 238/287] [Batch classify loss: 0.959127]
[Epoch 3/40] [Batch 239/287] [Batch classify loss: 0.940220]
[Epoch 3/40] [Batch 240/287] [Batch classify loss: 0.953354]
[Epoch 3/40] [Batch 241/287] [Batch classify loss: 1.041195]
[Epoch 3/40] [Batch 242/287] [Batch classify loss: 1.007027]
[Epoch 3/40] [Batch 243/287] [Batch classify loss: 1.011765]
[Epoch 3/40] [Batch 244/287] [Batch classify loss: 0.988027]
[Epoch 3/40] [Batch 245/287] [Batch classify loss: 0.990827]
[Epoch 3/40] [Batch 246/287] [Batch classify loss: 1.053471]
[Epoch 3/40] [Batch 247/287] [Batch classify loss: 0.979786]
[Epoch 3/40] [Batch 248/287] [Batch classify loss: 0.978841]
[Epoch 3/40] [Batch 249/287] [Batch classify loss: 0.939533]
[Epoch 3/40] [Batch 250/287] [Batch classify loss: 0.916754]
[Epoch 3/40] [Batch 251/287] [Batch classify loss: 0.980549]
[Epoch 3/40] [Batch 252/287] [Batch classify loss: 1.027768]
[Epoch 3/40] [Batch 253/287] [Batch classify loss: 1.038324]
[Epoch 3/40] [Batch 254/287] [Batch classify loss: 1.034608]
[Epoch 3/40] [Batch 255/287] [Batch classify loss: 0.935483]
[Epoch 3/40] [Batch 256/287] [Batch classify loss: 1.004153]
[Epoch 3/40] [Batch 257/287] [Batch classify loss: 1.041211]
[Epoch 3/40] [Batch 258/287] [Batch classify loss: 1.005891]
[Epoch 3/40] [Batch 259/287] [Batch classify loss: 0.951347]
[Epoch 3/40] [Batch 260/287] [Batch classify loss: 0.986415]
[Epoch 3/40] [Batch 261/287] [Batch classify loss: 1.017446]
[Epoch 3/40] [Batch 262/287] [Batch classify loss: 1.043597]
[Epoch 3/40] [Batch 263/287] [Batch classify loss: 1.026972]
[Epoch 3/40] [Batch 264/287] [Batch classify loss: 0.910669]
[Epoch 3/40] [Batch 265/287] [Batch classify loss: 1.021051]
[Epoch 3/40] [Batch 266/287] [Batch classify loss: 1.077416]
[Epoch 3/40] [Batch 267/287] [Batch classify loss: 0.966726]
[Epoch 3/40] [Batch 268/287] [Batch classify loss: 0.963759]
[Epoch 3/40] [Batch 269/287] [Batch classify loss: 0.937826]
[Epoch 3/40] [Batch 270/287] [Batch classify loss: 0.934283]
[Epoch 3/40] [Batch 271/287] [Batch classify loss: 0.992445]
[Epoch 3/40] [Batch 272/287] [Batch classify loss: 1.017455]
[Epoch 3/40] [Batch 273/287] [Batch classify loss: 1.019557]
[Epoch 3/40] [Batch 274/287] [Batch classify loss: 1.028665]
[Epoch 3/40] [Batch 275/287] [Batch classify loss: 0.974963]
[Epoch 3/40] [Batch 276/287] [Batch classify loss: 1.054874]
[Epoch 3/40] [Batch 277/287] [Batch classify loss: 1.017537]
[Epoch 3/40] [Batch 278/287] [Batch classify loss: 1.002634]
[Epoch 3/40] [Batch 279/287] [Batch classify loss: 0.987378]
[Epoch 3/40] [Batch 280/287] [Batch classify loss: 0.994746]
[Epoch 3/40] [Batch 281/287] [Batch classify loss: 0.976201]
[Epoch 3/40] [Batch 282/287] [Batch classify loss: 0.931896]
[Epoch 3/40] [Batch 283/287] [Batch classify loss: 0.807082]
[Epoch 3/40] [Batch 284/287] [Batch classify loss: 0.832005]
[Epoch 3/40] [Batch 285/287] [Batch classify loss: 0.836174]
[Epoch 3/40] [Batch 286/287] [Batch classify loss: 0.865777]
[Epoch 3/40] [Batch 287/287] [Batch classify loss: 1.419117]
0003 epoch rmt trained classifier accuary on the clean testing examples:88.5257%
0003 epoch rmt trained classifier loss on the clean testing examples:0.4561
0003 epoch rmt trained classifier accuary on adversarial testset:14.8817%
0003 epoch rmt trained classifier loss on adversarial testset:4.9383463859558105


3epoch learning rate:0.001
[Epoch 4/40] [Batch 1/287] [Batch classify loss: 0.598702]
[Epoch 4/40] [Batch 2/287] [Batch classify loss: 0.708575]
[Epoch 4/40] [Batch 3/287] [Batch classify loss: 0.704900]
[Epoch 4/40] [Batch 4/287] [Batch classify loss: 0.772339]
[Epoch 4/40] [Batch 5/287] [Batch classify loss: 0.780879]
[Epoch 4/40] [Batch 6/287] [Batch classify loss: 0.808931]
[Epoch 4/40] [Batch 7/287] [Batch classify loss: 0.752163]
[Epoch 4/40] [Batch 8/287] [Batch classify loss: 0.818711]
[Epoch 4/40] [Batch 9/287] [Batch classify loss: 0.789261]
[Epoch 4/40] [Batch 10/287] [Batch classify loss: 0.802056]
[Epoch 4/40] [Batch 11/287] [Batch classify loss: 0.781342]
[Epoch 4/40] [Batch 12/287] [Batch classify loss: 0.819508]
[Epoch 4/40] [Batch 13/287] [Batch classify loss: 0.808174]
[Epoch 4/40] [Batch 14/287] [Batch classify loss: 0.811111]
[Epoch 4/40] [Batch 15/287] [Batch classify loss: 0.853380]
[Epoch 4/40] [Batch 16/287] [Batch classify loss: 0.791784]
[Epoch 4/40] [Batch 17/287] [Batch classify loss: 0.803990]
[Epoch 4/40] [Batch 18/287] [Batch classify loss: 0.838154]
[Epoch 4/40] [Batch 19/287] [Batch classify loss: 0.864831]
[Epoch 4/40] [Batch 20/287] [Batch classify loss: 0.829257]
[Epoch 4/40] [Batch 21/287] [Batch classify loss: 0.814264]
[Epoch 4/40] [Batch 22/287] [Batch classify loss: 0.821438]
[Epoch 4/40] [Batch 23/287] [Batch classify loss: 0.875536]
[Epoch 4/40] [Batch 24/287] [Batch classify loss: 0.930444]
[Epoch 4/40] [Batch 25/287] [Batch classify loss: 0.859240]
[Epoch 4/40] [Batch 26/287] [Batch classify loss: 0.857395]
[Epoch 4/40] [Batch 27/287] [Batch classify loss: 0.877046]
[Epoch 4/40] [Batch 28/287] [Batch classify loss: 0.849886]
[Epoch 4/40] [Batch 29/287] [Batch classify loss: 0.831682]
[Epoch 4/40] [Batch 30/287] [Batch classify loss: 0.898839]
[Epoch 4/40] [Batch 31/287] [Batch classify loss: 0.856766]
[Epoch 4/40] [Batch 32/287] [Batch classify loss: 0.936253]
[Epoch 4/40] [Batch 33/287] [Batch classify loss: 0.880347]
[Epoch 4/40] [Batch 34/287] [Batch classify loss: 0.891288]
[Epoch 4/40] [Batch 35/287] [Batch classify loss: 0.874879]
[Epoch 4/40] [Batch 36/287] [Batch classify loss: 0.885578]
[Epoch 4/40] [Batch 37/287] [Batch classify loss: 0.943177]
[Epoch 4/40] [Batch 38/287] [Batch classify loss: 0.821161]
[Epoch 4/40] [Batch 39/287] [Batch classify loss: 0.943428]
[Epoch 4/40] [Batch 40/287] [Batch classify loss: 0.849736]
[Epoch 4/40] [Batch 41/287] [Batch classify loss: 0.851806]
[Epoch 4/40] [Batch 42/287] [Batch classify loss: 0.856313]
[Epoch 4/40] [Batch 43/287] [Batch classify loss: 0.894314]
[Epoch 4/40] [Batch 44/287] [Batch classify loss: 0.853669]
[Epoch 4/40] [Batch 45/287] [Batch classify loss: 0.858639]
[Epoch 4/40] [Batch 46/287] [Batch classify loss: 0.849170]
[Epoch 4/40] [Batch 47/287] [Batch classify loss: 0.924034]
[Epoch 4/40] [Batch 48/287] [Batch classify loss: 0.931541]
[Epoch 4/40] [Batch 49/287] [Batch classify loss: 0.877372]
[Epoch 4/40] [Batch 50/287] [Batch classify loss: 0.873828]
[Epoch 4/40] [Batch 51/287] [Batch classify loss: 0.951939]
[Epoch 4/40] [Batch 52/287] [Batch classify loss: 0.888331]
[Epoch 4/40] [Batch 53/287] [Batch classify loss: 0.882847]
[Epoch 4/40] [Batch 54/287] [Batch classify loss: 0.852367]
[Epoch 4/40] [Batch 55/287] [Batch classify loss: 0.897873]
[Epoch 4/40] [Batch 56/287] [Batch classify loss: 0.946385]
[Epoch 4/40] [Batch 57/287] [Batch classify loss: 0.836493]
[Epoch 4/40] [Batch 58/287] [Batch classify loss: 0.923970]
[Epoch 4/40] [Batch 59/287] [Batch classify loss: 0.890096]
[Epoch 4/40] [Batch 60/287] [Batch classify loss: 0.893557]
[Epoch 4/40] [Batch 61/287] [Batch classify loss: 0.900363]
[Epoch 4/40] [Batch 62/287] [Batch classify loss: 0.873866]
[Epoch 4/40] [Batch 63/287] [Batch classify loss: 0.911332]
[Epoch 4/40] [Batch 64/287] [Batch classify loss: 1.013834]
[Epoch 4/40] [Batch 65/287] [Batch classify loss: 0.951726]
[Epoch 4/40] [Batch 66/287] [Batch classify loss: 0.867736]
[Epoch 4/40] [Batch 67/287] [Batch classify loss: 0.914462]
[Epoch 4/40] [Batch 68/287] [Batch classify loss: 0.867750]
[Epoch 4/40] [Batch 69/287] [Batch classify loss: 0.894186]
[Epoch 4/40] [Batch 70/287] [Batch classify loss: 0.928434]
[Epoch 4/40] [Batch 71/287] [Batch classify loss: 0.862271]
[Epoch 4/40] [Batch 72/287] [Batch classify loss: 0.899240]
[Epoch 4/40] [Batch 73/287] [Batch classify loss: 0.979872]
[Epoch 4/40] [Batch 74/287] [Batch classify loss: 0.912554]
[Epoch 4/40] [Batch 75/287] [Batch classify loss: 0.975438]
[Epoch 4/40] [Batch 76/287] [Batch classify loss: 0.890526]
[Epoch 4/40] [Batch 77/287] [Batch classify loss: 0.891363]
[Epoch 4/40] [Batch 78/287] [Batch classify loss: 0.901604]
[Epoch 4/40] [Batch 79/287] [Batch classify loss: 0.905404]
[Epoch 4/40] [Batch 80/287] [Batch classify loss: 0.876327]
[Epoch 4/40] [Batch 81/287] [Batch classify loss: 0.897749]
[Epoch 4/40] [Batch 82/287] [Batch classify loss: 0.993853]
[Epoch 4/40] [Batch 83/287] [Batch classify loss: 0.870117]
[Epoch 4/40] [Batch 84/287] [Batch classify loss: 0.905303]
[Epoch 4/40] [Batch 85/287] [Batch classify loss: 0.940726]
[Epoch 4/40] [Batch 86/287] [Batch classify loss: 0.929460]
[Epoch 4/40] [Batch 87/287] [Batch classify loss: 0.900451]
[Epoch 4/40] [Batch 88/287] [Batch classify loss: 0.874695]
[Epoch 4/40] [Batch 89/287] [Batch classify loss: 0.930059]
[Epoch 4/40] [Batch 90/287] [Batch classify loss: 0.944990]
[Epoch 4/40] [Batch 91/287] [Batch classify loss: 0.958437]
[Epoch 4/40] [Batch 92/287] [Batch classify loss: 0.947829]
[Epoch 4/40] [Batch 93/287] [Batch classify loss: 0.957219]
[Epoch 4/40] [Batch 94/287] [Batch classify loss: 0.825899]
[Epoch 4/40] [Batch 95/287] [Batch classify loss: 0.616890]
[Epoch 4/40] [Batch 96/287] [Batch classify loss: 0.633171]
[Epoch 4/40] [Batch 97/287] [Batch classify loss: 0.716748]
[Epoch 4/40] [Batch 98/287] [Batch classify loss: 0.718305]
[Epoch 4/40] [Batch 99/287] [Batch classify loss: 0.765946]
[Epoch 4/40] [Batch 100/287] [Batch classify loss: 0.825338]
[Epoch 4/40] [Batch 101/287] [Batch classify loss: 0.721825]
[Epoch 4/40] [Batch 102/287] [Batch classify loss: 0.809189]
[Epoch 4/40] [Batch 103/287] [Batch classify loss: 0.807999]
[Epoch 4/40] [Batch 104/287] [Batch classify loss: 0.793340]
[Epoch 4/40] [Batch 105/287] [Batch classify loss: 0.819561]
[Epoch 4/40] [Batch 106/287] [Batch classify loss: 0.813489]
[Epoch 4/40] [Batch 107/287] [Batch classify loss: 0.797578]
[Epoch 4/40] [Batch 108/287] [Batch classify loss: 0.793518]
[Epoch 4/40] [Batch 109/287] [Batch classify loss: 0.771481]
[Epoch 4/40] [Batch 110/287] [Batch classify loss: 0.745846]
[Epoch 4/40] [Batch 111/287] [Batch classify loss: 0.895860]
[Epoch 4/40] [Batch 112/287] [Batch classify loss: 0.823718]
[Epoch 4/40] [Batch 113/287] [Batch classify loss: 0.879076]
[Epoch 4/40] [Batch 114/287] [Batch classify loss: 0.845554]
[Epoch 4/40] [Batch 115/287] [Batch classify loss: 0.882884]
[Epoch 4/40] [Batch 116/287] [Batch classify loss: 0.758296]
[Epoch 4/40] [Batch 117/287] [Batch classify loss: 0.875175]
[Epoch 4/40] [Batch 118/287] [Batch classify loss: 0.861081]
[Epoch 4/40] [Batch 119/287] [Batch classify loss: 0.821238]
[Epoch 4/40] [Batch 120/287] [Batch classify loss: 0.818512]
[Epoch 4/40] [Batch 121/287] [Batch classify loss: 0.840461]
[Epoch 4/40] [Batch 122/287] [Batch classify loss: 0.818528]
[Epoch 4/40] [Batch 123/287] [Batch classify loss: 0.843350]
[Epoch 4/40] [Batch 124/287] [Batch classify loss: 0.897121]
[Epoch 4/40] [Batch 125/287] [Batch classify loss: 0.817852]
[Epoch 4/40] [Batch 126/287] [Batch classify loss: 0.856066]
[Epoch 4/40] [Batch 127/287] [Batch classify loss: 0.918502]
[Epoch 4/40] [Batch 128/287] [Batch classify loss: 0.884257]
[Epoch 4/40] [Batch 129/287] [Batch classify loss: 0.892846]
[Epoch 4/40] [Batch 130/287] [Batch classify loss: 0.899362]
[Epoch 4/40] [Batch 131/287] [Batch classify loss: 0.869874]
[Epoch 4/40] [Batch 132/287] [Batch classify loss: 0.845157]
[Epoch 4/40] [Batch 133/287] [Batch classify loss: 0.854502]
[Epoch 4/40] [Batch 134/287] [Batch classify loss: 0.857173]
[Epoch 4/40] [Batch 135/287] [Batch classify loss: 0.959470]
[Epoch 4/40] [Batch 136/287] [Batch classify loss: 0.910920]
[Epoch 4/40] [Batch 137/287] [Batch classify loss: 0.891700]
[Epoch 4/40] [Batch 138/287] [Batch classify loss: 0.872308]
[Epoch 4/40] [Batch 139/287] [Batch classify loss: 0.891919]
[Epoch 4/40] [Batch 140/287] [Batch classify loss: 0.899120]
[Epoch 4/40] [Batch 141/287] [Batch classify loss: 0.873577]
[Epoch 4/40] [Batch 142/287] [Batch classify loss: 0.906556]
[Epoch 4/40] [Batch 143/287] [Batch classify loss: 0.926153]
[Epoch 4/40] [Batch 144/287] [Batch classify loss: 0.861444]
[Epoch 4/40] [Batch 145/287] [Batch classify loss: 0.877314]
[Epoch 4/40] [Batch 146/287] [Batch classify loss: 0.912742]
[Epoch 4/40] [Batch 147/287] [Batch classify loss: 0.846918]
[Epoch 4/40] [Batch 148/287] [Batch classify loss: 0.877794]
[Epoch 4/40] [Batch 149/287] [Batch classify loss: 0.938421]
[Epoch 4/40] [Batch 150/287] [Batch classify loss: 0.867336]
[Epoch 4/40] [Batch 151/287] [Batch classify loss: 0.876207]
[Epoch 4/40] [Batch 152/287] [Batch classify loss: 0.930508]
[Epoch 4/40] [Batch 153/287] [Batch classify loss: 0.867007]
[Epoch 4/40] [Batch 154/287] [Batch classify loss: 0.879958]
[Epoch 4/40] [Batch 155/287] [Batch classify loss: 0.929201]
[Epoch 4/40] [Batch 156/287] [Batch classify loss: 0.945004]
[Epoch 4/40] [Batch 157/287] [Batch classify loss: 0.863355]
[Epoch 4/40] [Batch 158/287] [Batch classify loss: 0.938214]
[Epoch 4/40] [Batch 159/287] [Batch classify loss: 0.948076]
[Epoch 4/40] [Batch 160/287] [Batch classify loss: 0.840221]
[Epoch 4/40] [Batch 161/287] [Batch classify loss: 0.952040]
[Epoch 4/40] [Batch 162/287] [Batch classify loss: 0.907968]
[Epoch 4/40] [Batch 163/287] [Batch classify loss: 0.933931]
[Epoch 4/40] [Batch 164/287] [Batch classify loss: 0.932254]
[Epoch 4/40] [Batch 165/287] [Batch classify loss: 0.946976]
[Epoch 4/40] [Batch 166/287] [Batch classify loss: 0.910896]
[Epoch 4/40] [Batch 167/287] [Batch classify loss: 0.924993]
[Epoch 4/40] [Batch 168/287] [Batch classify loss: 0.916134]
[Epoch 4/40] [Batch 169/287] [Batch classify loss: 0.881342]
[Epoch 4/40] [Batch 170/287] [Batch classify loss: 1.005476]
[Epoch 4/40] [Batch 171/287] [Batch classify loss: 0.869248]
[Epoch 4/40] [Batch 172/287] [Batch classify loss: 0.968118]
[Epoch 4/40] [Batch 173/287] [Batch classify loss: 0.901020]
[Epoch 4/40] [Batch 174/287] [Batch classify loss: 1.005945]
[Epoch 4/40] [Batch 175/287] [Batch classify loss: 0.965753]
[Epoch 4/40] [Batch 176/287] [Batch classify loss: 0.884850]
[Epoch 4/40] [Batch 177/287] [Batch classify loss: 0.915386]
[Epoch 4/40] [Batch 178/287] [Batch classify loss: 0.913863]
[Epoch 4/40] [Batch 179/287] [Batch classify loss: 0.911504]
[Epoch 4/40] [Batch 180/287] [Batch classify loss: 0.957925]
[Epoch 4/40] [Batch 181/287] [Batch classify loss: 0.972912]
[Epoch 4/40] [Batch 182/287] [Batch classify loss: 0.935718]
[Epoch 4/40] [Batch 183/287] [Batch classify loss: 0.957120]
[Epoch 4/40] [Batch 184/287] [Batch classify loss: 1.008980]
[Epoch 4/40] [Batch 185/287] [Batch classify loss: 0.987508]
[Epoch 4/40] [Batch 186/287] [Batch classify loss: 0.953547]
[Epoch 4/40] [Batch 187/287] [Batch classify loss: 0.951953]
[Epoch 4/40] [Batch 188/287] [Batch classify loss: 0.845822]
[Epoch 4/40] [Batch 189/287] [Batch classify loss: 0.616808]
[Epoch 4/40] [Batch 190/287] [Batch classify loss: 0.637867]
[Epoch 4/40] [Batch 191/287] [Batch classify loss: 0.729588]
[Epoch 4/40] [Batch 192/287] [Batch classify loss: 0.742121]
[Epoch 4/40] [Batch 193/287] [Batch classify loss: 0.773323]
[Epoch 4/40] [Batch 194/287] [Batch classify loss: 0.781426]
[Epoch 4/40] [Batch 195/287] [Batch classify loss: 0.732918]
[Epoch 4/40] [Batch 196/287] [Batch classify loss: 0.800528]
[Epoch 4/40] [Batch 197/287] [Batch classify loss: 0.782541]
[Epoch 4/40] [Batch 198/287] [Batch classify loss: 0.773020]
[Epoch 4/40] [Batch 199/287] [Batch classify loss: 0.752122]
[Epoch 4/40] [Batch 200/287] [Batch classify loss: 0.838388]
[Epoch 4/40] [Batch 201/287] [Batch classify loss: 0.789035]
[Epoch 4/40] [Batch 202/287] [Batch classify loss: 0.812823]
[Epoch 4/40] [Batch 203/287] [Batch classify loss: 0.769297]
[Epoch 4/40] [Batch 204/287] [Batch classify loss: 0.771977]
[Epoch 4/40] [Batch 205/287] [Batch classify loss: 0.757950]
[Epoch 4/40] [Batch 206/287] [Batch classify loss: 0.791078]
[Epoch 4/40] [Batch 207/287] [Batch classify loss: 0.795749]
[Epoch 4/40] [Batch 208/287] [Batch classify loss: 0.817002]
[Epoch 4/40] [Batch 209/287] [Batch classify loss: 0.812722]
[Epoch 4/40] [Batch 210/287] [Batch classify loss: 0.887448]
[Epoch 4/40] [Batch 211/287] [Batch classify loss: 0.761395]
[Epoch 4/40] [Batch 212/287] [Batch classify loss: 0.789499]
[Epoch 4/40] [Batch 213/287] [Batch classify loss: 0.839867]
[Epoch 4/40] [Batch 214/287] [Batch classify loss: 0.890981]
[Epoch 4/40] [Batch 215/287] [Batch classify loss: 0.818453]
[Epoch 4/40] [Batch 216/287] [Batch classify loss: 0.826020]
[Epoch 4/40] [Batch 217/287] [Batch classify loss: 0.828095]
[Epoch 4/40] [Batch 218/287] [Batch classify loss: 0.859901]
[Epoch 4/40] [Batch 219/287] [Batch classify loss: 0.831686]
[Epoch 4/40] [Batch 220/287] [Batch classify loss: 0.866844]
[Epoch 4/40] [Batch 221/287] [Batch classify loss: 0.882618]
[Epoch 4/40] [Batch 222/287] [Batch classify loss: 0.815872]
[Epoch 4/40] [Batch 223/287] [Batch classify loss: 0.879257]
[Epoch 4/40] [Batch 224/287] [Batch classify loss: 0.897627]
[Epoch 4/40] [Batch 225/287] [Batch classify loss: 0.896141]
[Epoch 4/40] [Batch 226/287] [Batch classify loss: 0.861727]
[Epoch 4/40] [Batch 227/287] [Batch classify loss: 0.844776]
[Epoch 4/40] [Batch 228/287] [Batch classify loss: 0.927514]
[Epoch 4/40] [Batch 229/287] [Batch classify loss: 0.829435]
[Epoch 4/40] [Batch 230/287] [Batch classify loss: 0.866818]
[Epoch 4/40] [Batch 231/287] [Batch classify loss: 0.921804]
[Epoch 4/40] [Batch 232/287] [Batch classify loss: 0.891050]
[Epoch 4/40] [Batch 233/287] [Batch classify loss: 0.885767]
[Epoch 4/40] [Batch 234/287] [Batch classify loss: 0.887081]
[Epoch 4/40] [Batch 235/287] [Batch classify loss: 0.872714]
[Epoch 4/40] [Batch 236/287] [Batch classify loss: 0.907184]
[Epoch 4/40] [Batch 237/287] [Batch classify loss: 0.905864]
[Epoch 4/40] [Batch 238/287] [Batch classify loss: 0.848973]
[Epoch 4/40] [Batch 239/287] [Batch classify loss: 0.868832]
[Epoch 4/40] [Batch 240/287] [Batch classify loss: 0.892867]
[Epoch 4/40] [Batch 241/287] [Batch classify loss: 0.933044]
[Epoch 4/40] [Batch 242/287] [Batch classify loss: 0.906391]
[Epoch 4/40] [Batch 243/287] [Batch classify loss: 0.859558]
[Epoch 4/40] [Batch 244/287] [Batch classify loss: 0.965056]
[Epoch 4/40] [Batch 245/287] [Batch classify loss: 0.842580]
[Epoch 4/40] [Batch 246/287] [Batch classify loss: 0.890283]
[Epoch 4/40] [Batch 247/287] [Batch classify loss: 0.891820]
[Epoch 4/40] [Batch 248/287] [Batch classify loss: 0.880931]
[Epoch 4/40] [Batch 249/287] [Batch classify loss: 0.963988]
[Epoch 4/40] [Batch 250/287] [Batch classify loss: 0.974259]
[Epoch 4/40] [Batch 251/287] [Batch classify loss: 0.926703]
[Epoch 4/40] [Batch 252/287] [Batch classify loss: 0.984091]
[Epoch 4/40] [Batch 253/287] [Batch classify loss: 0.869162]
[Epoch 4/40] [Batch 254/287] [Batch classify loss: 0.910997]
[Epoch 4/40] [Batch 255/287] [Batch classify loss: 0.917286]
[Epoch 4/40] [Batch 256/287] [Batch classify loss: 0.919052]
[Epoch 4/40] [Batch 257/287] [Batch classify loss: 0.880817]
[Epoch 4/40] [Batch 258/287] [Batch classify loss: 0.996469]
[Epoch 4/40] [Batch 259/287] [Batch classify loss: 0.920216]
[Epoch 4/40] [Batch 260/287] [Batch classify loss: 0.894076]
[Epoch 4/40] [Batch 261/287] [Batch classify loss: 0.924099]
[Epoch 4/40] [Batch 262/287] [Batch classify loss: 0.938908]
[Epoch 4/40] [Batch 263/287] [Batch classify loss: 0.922220]
[Epoch 4/40] [Batch 264/287] [Batch classify loss: 0.948622]
[Epoch 4/40] [Batch 265/287] [Batch classify loss: 0.911797]
[Epoch 4/40] [Batch 266/287] [Batch classify loss: 0.938893]
[Epoch 4/40] [Batch 267/287] [Batch classify loss: 0.939258]
[Epoch 4/40] [Batch 268/287] [Batch classify loss: 0.918742]
[Epoch 4/40] [Batch 269/287] [Batch classify loss: 0.836203]
[Epoch 4/40] [Batch 270/287] [Batch classify loss: 0.878559]
[Epoch 4/40] [Batch 271/287] [Batch classify loss: 0.912530]
[Epoch 4/40] [Batch 272/287] [Batch classify loss: 0.925982]
[Epoch 4/40] [Batch 273/287] [Batch classify loss: 0.956877]
[Epoch 4/40] [Batch 274/287] [Batch classify loss: 1.033588]
[Epoch 4/40] [Batch 275/287] [Batch classify loss: 0.916115]
[Epoch 4/40] [Batch 276/287] [Batch classify loss: 0.930329]
[Epoch 4/40] [Batch 277/287] [Batch classify loss: 0.900815]
[Epoch 4/40] [Batch 278/287] [Batch classify loss: 0.988111]
[Epoch 4/40] [Batch 279/287] [Batch classify loss: 0.922925]
[Epoch 4/40] [Batch 280/287] [Batch classify loss: 0.915546]
[Epoch 4/40] [Batch 281/287] [Batch classify loss: 0.913758]
[Epoch 4/40] [Batch 282/287] [Batch classify loss: 0.867683]
[Epoch 4/40] [Batch 283/287] [Batch classify loss: 0.562737]
[Epoch 4/40] [Batch 284/287] [Batch classify loss: 0.631403]
[Epoch 4/40] [Batch 285/287] [Batch classify loss: 0.670951]
[Epoch 4/40] [Batch 286/287] [Batch classify loss: 0.698137]
[Epoch 4/40] [Batch 287/287] [Batch classify loss: 1.292046]
0004 epoch rmt trained classifier accuary on the clean testing examples:88.7638%
0004 epoch rmt trained classifier loss on the clean testing examples:0.4567
0004 epoch rmt trained classifier accuary on adversarial testset:13.8176%
0004 epoch rmt trained classifier loss on adversarial testset:5.342087268829346


4epoch learning rate:0.001
[Epoch 5/40] [Batch 1/287] [Batch classify loss: 0.422720]
[Epoch 5/40] [Batch 2/287] [Batch classify loss: 0.519405]
[Epoch 5/40] [Batch 3/287] [Batch classify loss: 0.526859]
[Epoch 5/40] [Batch 4/287] [Batch classify loss: 0.554447]
[Epoch 5/40] [Batch 5/287] [Batch classify loss: 0.608614]
[Epoch 5/40] [Batch 6/287] [Batch classify loss: 0.628982]
[Epoch 5/40] [Batch 7/287] [Batch classify loss: 0.627701]
[Epoch 5/40] [Batch 8/287] [Batch classify loss: 0.651576]
[Epoch 5/40] [Batch 9/287] [Batch classify loss: 0.690747]
[Epoch 5/40] [Batch 10/287] [Batch classify loss: 0.718303]
[Epoch 5/40] [Batch 11/287] [Batch classify loss: 0.733421]
[Epoch 5/40] [Batch 12/287] [Batch classify loss: 0.713898]
[Epoch 5/40] [Batch 13/287] [Batch classify loss: 0.716650]
[Epoch 5/40] [Batch 14/287] [Batch classify loss: 0.702920]
[Epoch 5/40] [Batch 15/287] [Batch classify loss: 0.680353]
[Epoch 5/40] [Batch 16/287] [Batch classify loss: 0.696954]
[Epoch 5/40] [Batch 17/287] [Batch classify loss: 0.700002]
[Epoch 5/40] [Batch 18/287] [Batch classify loss: 0.708293]
[Epoch 5/40] [Batch 19/287] [Batch classify loss: 0.761785]
[Epoch 5/40] [Batch 20/287] [Batch classify loss: 0.733675]
[Epoch 5/40] [Batch 21/287] [Batch classify loss: 0.697054]
[Epoch 5/40] [Batch 22/287] [Batch classify loss: 0.732616]
[Epoch 5/40] [Batch 23/287] [Batch classify loss: 0.779514]
[Epoch 5/40] [Batch 24/287] [Batch classify loss: 0.745610]
[Epoch 5/40] [Batch 25/287] [Batch classify loss: 0.718462]
[Epoch 5/40] [Batch 26/287] [Batch classify loss: 0.688172]
[Epoch 5/40] [Batch 27/287] [Batch classify loss: 0.784815]
[Epoch 5/40] [Batch 28/287] [Batch classify loss: 0.742097]
[Epoch 5/40] [Batch 29/287] [Batch classify loss: 0.726590]
[Epoch 5/40] [Batch 30/287] [Batch classify loss: 0.724999]
[Epoch 5/40] [Batch 31/287] [Batch classify loss: 0.799747]
[Epoch 5/40] [Batch 32/287] [Batch classify loss: 0.767489]
[Epoch 5/40] [Batch 33/287] [Batch classify loss: 0.714373]
[Epoch 5/40] [Batch 34/287] [Batch classify loss: 0.738023]
[Epoch 5/40] [Batch 35/287] [Batch classify loss: 0.715339]
[Epoch 5/40] [Batch 36/287] [Batch classify loss: 0.782220]
[Epoch 5/40] [Batch 37/287] [Batch classify loss: 0.783029]
[Epoch 5/40] [Batch 38/287] [Batch classify loss: 0.710943]
[Epoch 5/40] [Batch 39/287] [Batch classify loss: 0.713779]
[Epoch 5/40] [Batch 40/287] [Batch classify loss: 0.710962]
[Epoch 5/40] [Batch 41/287] [Batch classify loss: 0.783495]
[Epoch 5/40] [Batch 42/287] [Batch classify loss: 0.760572]
[Epoch 5/40] [Batch 43/287] [Batch classify loss: 0.756829]
[Epoch 5/40] [Batch 44/287] [Batch classify loss: 0.718167]
[Epoch 5/40] [Batch 45/287] [Batch classify loss: 0.796149]
[Epoch 5/40] [Batch 46/287] [Batch classify loss: 0.753069]
[Epoch 5/40] [Batch 47/287] [Batch classify loss: 0.796194]
[Epoch 5/40] [Batch 48/287] [Batch classify loss: 0.734757]
[Epoch 5/40] [Batch 49/287] [Batch classify loss: 0.716409]
[Epoch 5/40] [Batch 50/287] [Batch classify loss: 0.783740]
[Epoch 5/40] [Batch 51/287] [Batch classify loss: 0.770256]
[Epoch 5/40] [Batch 52/287] [Batch classify loss: 0.794623]
[Epoch 5/40] [Batch 53/287] [Batch classify loss: 0.775069]
[Epoch 5/40] [Batch 54/287] [Batch classify loss: 0.817872]
[Epoch 5/40] [Batch 55/287] [Batch classify loss: 0.769883]
[Epoch 5/40] [Batch 56/287] [Batch classify loss: 0.784159]
[Epoch 5/40] [Batch 57/287] [Batch classify loss: 0.714861]
[Epoch 5/40] [Batch 58/287] [Batch classify loss: 0.796096]
[Epoch 5/40] [Batch 59/287] [Batch classify loss: 0.839027]
[Epoch 5/40] [Batch 60/287] [Batch classify loss: 0.760535]
[Epoch 5/40] [Batch 61/287] [Batch classify loss: 0.771878]
[Epoch 5/40] [Batch 62/287] [Batch classify loss: 0.803130]
[Epoch 5/40] [Batch 63/287] [Batch classify loss: 0.761634]
[Epoch 5/40] [Batch 64/287] [Batch classify loss: 0.869916]
[Epoch 5/40] [Batch 65/287] [Batch classify loss: 0.847635]
[Epoch 5/40] [Batch 66/287] [Batch classify loss: 0.871029]
[Epoch 5/40] [Batch 67/287] [Batch classify loss: 0.770981]
[Epoch 5/40] [Batch 68/287] [Batch classify loss: 0.826437]
[Epoch 5/40] [Batch 69/287] [Batch classify loss: 0.802596]
[Epoch 5/40] [Batch 70/287] [Batch classify loss: 0.835697]
[Epoch 5/40] [Batch 71/287] [Batch classify loss: 0.794723]
[Epoch 5/40] [Batch 72/287] [Batch classify loss: 0.864841]
[Epoch 5/40] [Batch 73/287] [Batch classify loss: 0.802235]
[Epoch 5/40] [Batch 74/287] [Batch classify loss: 0.808132]
[Epoch 5/40] [Batch 75/287] [Batch classify loss: 0.836994]
[Epoch 5/40] [Batch 76/287] [Batch classify loss: 0.854569]
[Epoch 5/40] [Batch 77/287] [Batch classify loss: 0.872744]
[Epoch 5/40] [Batch 78/287] [Batch classify loss: 0.792193]
[Epoch 5/40] [Batch 79/287] [Batch classify loss: 0.835128]
[Epoch 5/40] [Batch 80/287] [Batch classify loss: 0.808407]
[Epoch 5/40] [Batch 81/287] [Batch classify loss: 0.748352]
[Epoch 5/40] [Batch 82/287] [Batch classify loss: 0.770415]
[Epoch 5/40] [Batch 83/287] [Batch classify loss: 0.808574]
[Epoch 5/40] [Batch 84/287] [Batch classify loss: 0.881005]
[Epoch 5/40] [Batch 85/287] [Batch classify loss: 0.808661]
[Epoch 5/40] [Batch 86/287] [Batch classify loss: 0.889438]
[Epoch 5/40] [Batch 87/287] [Batch classify loss: 0.757169]
[Epoch 5/40] [Batch 88/287] [Batch classify loss: 0.870933]
[Epoch 5/40] [Batch 89/287] [Batch classify loss: 0.824355]
[Epoch 5/40] [Batch 90/287] [Batch classify loss: 0.797573]
[Epoch 5/40] [Batch 91/287] [Batch classify loss: 0.841476]
[Epoch 5/40] [Batch 92/287] [Batch classify loss: 0.843522]
[Epoch 5/40] [Batch 93/287] [Batch classify loss: 0.822150]
[Epoch 5/40] [Batch 94/287] [Batch classify loss: 0.728417]
[Epoch 5/40] [Batch 95/287] [Batch classify loss: 0.472526]
[Epoch 5/40] [Batch 96/287] [Batch classify loss: 0.484920]
[Epoch 5/40] [Batch 97/287] [Batch classify loss: 0.517642]
[Epoch 5/40] [Batch 98/287] [Batch classify loss: 0.514037]
[Epoch 5/40] [Batch 99/287] [Batch classify loss: 0.575009]
[Epoch 5/40] [Batch 100/287] [Batch classify loss: 0.653483]
[Epoch 5/40] [Batch 101/287] [Batch classify loss: 0.615607]
[Epoch 5/40] [Batch 102/287] [Batch classify loss: 0.636575]
[Epoch 5/40] [Batch 103/287] [Batch classify loss: 0.694316]
[Epoch 5/40] [Batch 104/287] [Batch classify loss: 0.661503]
[Epoch 5/40] [Batch 105/287] [Batch classify loss: 0.665005]
[Epoch 5/40] [Batch 106/287] [Batch classify loss: 0.662062]
[Epoch 5/40] [Batch 107/287] [Batch classify loss: 0.649009]
[Epoch 5/40] [Batch 108/287] [Batch classify loss: 0.700529]
[Epoch 5/40] [Batch 109/287] [Batch classify loss: 0.748556]
[Epoch 5/40] [Batch 110/287] [Batch classify loss: 0.663021]
[Epoch 5/40] [Batch 111/287] [Batch classify loss: 0.679252]
[Epoch 5/40] [Batch 112/287] [Batch classify loss: 0.660440]
[Epoch 5/40] [Batch 113/287] [Batch classify loss: 0.691325]
[Epoch 5/40] [Batch 114/287] [Batch classify loss: 0.729677]
[Epoch 5/40] [Batch 115/287] [Batch classify loss: 0.721095]
[Epoch 5/40] [Batch 116/287] [Batch classify loss: 0.719703]
[Epoch 5/40] [Batch 117/287] [Batch classify loss: 0.794778]
[Epoch 5/40] [Batch 118/287] [Batch classify loss: 0.726181]
[Epoch 5/40] [Batch 119/287] [Batch classify loss: 0.699318]
[Epoch 5/40] [Batch 120/287] [Batch classify loss: 0.743405]
[Epoch 5/40] [Batch 121/287] [Batch classify loss: 0.767974]
[Epoch 5/40] [Batch 122/287] [Batch classify loss: 0.761276]
[Epoch 5/40] [Batch 123/287] [Batch classify loss: 0.714254]
[Epoch 5/40] [Batch 124/287] [Batch classify loss: 0.704725]
[Epoch 5/40] [Batch 125/287] [Batch classify loss: 0.750778]
[Epoch 5/40] [Batch 126/287] [Batch classify loss: 0.743000]
[Epoch 5/40] [Batch 127/287] [Batch classify loss: 0.742570]
[Epoch 5/40] [Batch 128/287] [Batch classify loss: 0.686793]
[Epoch 5/40] [Batch 129/287] [Batch classify loss: 0.726746]
[Epoch 5/40] [Batch 130/287] [Batch classify loss: 0.797345]
[Epoch 5/40] [Batch 131/287] [Batch classify loss: 0.766740]
[Epoch 5/40] [Batch 132/287] [Batch classify loss: 0.730998]
[Epoch 5/40] [Batch 133/287] [Batch classify loss: 0.728432]
[Epoch 5/40] [Batch 134/287] [Batch classify loss: 0.716940]
[Epoch 5/40] [Batch 135/287] [Batch classify loss: 0.722890]
[Epoch 5/40] [Batch 136/287] [Batch classify loss: 0.773418]
[Epoch 5/40] [Batch 137/287] [Batch classify loss: 0.785360]
[Epoch 5/40] [Batch 138/287] [Batch classify loss: 0.767765]
[Epoch 5/40] [Batch 139/287] [Batch classify loss: 0.740562]
[Epoch 5/40] [Batch 140/287] [Batch classify loss: 0.763696]
[Epoch 5/40] [Batch 141/287] [Batch classify loss: 0.725814]
[Epoch 5/40] [Batch 142/287] [Batch classify loss: 0.737607]
[Epoch 5/40] [Batch 143/287] [Batch classify loss: 0.807856]
[Epoch 5/40] [Batch 144/287] [Batch classify loss: 0.780149]
[Epoch 5/40] [Batch 145/287] [Batch classify loss: 0.822489]
[Epoch 5/40] [Batch 146/287] [Batch classify loss: 0.801780]
[Epoch 5/40] [Batch 147/287] [Batch classify loss: 0.774666]
[Epoch 5/40] [Batch 148/287] [Batch classify loss: 0.785280]
[Epoch 5/40] [Batch 149/287] [Batch classify loss: 0.810966]
[Epoch 5/40] [Batch 150/287] [Batch classify loss: 0.790099]
[Epoch 5/40] [Batch 151/287] [Batch classify loss: 0.802089]
[Epoch 5/40] [Batch 152/287] [Batch classify loss: 0.796007]
[Epoch 5/40] [Batch 153/287] [Batch classify loss: 0.794078]
[Epoch 5/40] [Batch 154/287] [Batch classify loss: 0.790101]
[Epoch 5/40] [Batch 155/287] [Batch classify loss: 0.805739]
[Epoch 5/40] [Batch 156/287] [Batch classify loss: 0.805274]
[Epoch 5/40] [Batch 157/287] [Batch classify loss: 0.748775]
[Epoch 5/40] [Batch 158/287] [Batch classify loss: 0.787278]
[Epoch 5/40] [Batch 159/287] [Batch classify loss: 0.854018]
[Epoch 5/40] [Batch 160/287] [Batch classify loss: 0.819699]
[Epoch 5/40] [Batch 161/287] [Batch classify loss: 0.796341]
[Epoch 5/40] [Batch 162/287] [Batch classify loss: 0.784523]
[Epoch 5/40] [Batch 163/287] [Batch classify loss: 0.802666]
[Epoch 5/40] [Batch 164/287] [Batch classify loss: 0.808032]
[Epoch 5/40] [Batch 165/287] [Batch classify loss: 0.850241]
[Epoch 5/40] [Batch 166/287] [Batch classify loss: 0.840415]
[Epoch 5/40] [Batch 167/287] [Batch classify loss: 0.819220]
[Epoch 5/40] [Batch 168/287] [Batch classify loss: 0.813640]
[Epoch 5/40] [Batch 169/287] [Batch classify loss: 0.815653]
[Epoch 5/40] [Batch 170/287] [Batch classify loss: 0.744840]
[Epoch 5/40] [Batch 171/287] [Batch classify loss: 0.834677]
[Epoch 5/40] [Batch 172/287] [Batch classify loss: 0.790014]
[Epoch 5/40] [Batch 173/287] [Batch classify loss: 0.824683]
[Epoch 5/40] [Batch 174/287] [Batch classify loss: 0.847781]
[Epoch 5/40] [Batch 175/287] [Batch classify loss: 0.813074]
[Epoch 5/40] [Batch 176/287] [Batch classify loss: 0.820168]
[Epoch 5/40] [Batch 177/287] [Batch classify loss: 0.848544]
[Epoch 5/40] [Batch 178/287] [Batch classify loss: 0.836638]
[Epoch 5/40] [Batch 179/287] [Batch classify loss: 0.786193]
[Epoch 5/40] [Batch 180/287] [Batch classify loss: 0.852264]
[Epoch 5/40] [Batch 181/287] [Batch classify loss: 0.825047]
[Epoch 5/40] [Batch 182/287] [Batch classify loss: 0.902547]
[Epoch 5/40] [Batch 183/287] [Batch classify loss: 0.803324]
[Epoch 5/40] [Batch 184/287] [Batch classify loss: 0.834251]
[Epoch 5/40] [Batch 185/287] [Batch classify loss: 0.828058]
[Epoch 5/40] [Batch 186/287] [Batch classify loss: 0.789983]
[Epoch 5/40] [Batch 187/287] [Batch classify loss: 0.829849]
[Epoch 5/40] [Batch 188/287] [Batch classify loss: 0.687183]
[Epoch 5/40] [Batch 189/287] [Batch classify loss: 0.402571]
[Epoch 5/40] [Batch 190/287] [Batch classify loss: 0.468657]
[Epoch 5/40] [Batch 191/287] [Batch classify loss: 0.505191]
[Epoch 5/40] [Batch 192/287] [Batch classify loss: 0.528363]
[Epoch 5/40] [Batch 193/287] [Batch classify loss: 0.580538]
[Epoch 5/40] [Batch 194/287] [Batch classify loss: 0.571873]
[Epoch 5/40] [Batch 195/287] [Batch classify loss: 0.556332]
[Epoch 5/40] [Batch 196/287] [Batch classify loss: 0.595207]
[Epoch 5/40] [Batch 197/287] [Batch classify loss: 0.615181]
[Epoch 5/40] [Batch 198/287] [Batch classify loss: 0.595727]
[Epoch 5/40] [Batch 199/287] [Batch classify loss: 0.680029]
[Epoch 5/40] [Batch 200/287] [Batch classify loss: 0.600742]
[Epoch 5/40] [Batch 201/287] [Batch classify loss: 0.700805]
[Epoch 5/40] [Batch 202/287] [Batch classify loss: 0.746175]
[Epoch 5/40] [Batch 203/287] [Batch classify loss: 0.654877]
[Epoch 5/40] [Batch 204/287] [Batch classify loss: 0.646959]
[Epoch 5/40] [Batch 205/287] [Batch classify loss: 0.623408]
[Epoch 5/40] [Batch 206/287] [Batch classify loss: 0.634626]
[Epoch 5/40] [Batch 207/287] [Batch classify loss: 0.712736]
[Epoch 5/40] [Batch 208/287] [Batch classify loss: 0.631116]
[Epoch 5/40] [Batch 209/287] [Batch classify loss: 0.741110]
[Epoch 5/40] [Batch 210/287] [Batch classify loss: 0.734301]
[Epoch 5/40] [Batch 211/287] [Batch classify loss: 0.699752]
[Epoch 5/40] [Batch 212/287] [Batch classify loss: 0.681131]
[Epoch 5/40] [Batch 213/287] [Batch classify loss: 0.728029]
[Epoch 5/40] [Batch 214/287] [Batch classify loss: 0.758619]
[Epoch 5/40] [Batch 215/287] [Batch classify loss: 0.696630]
[Epoch 5/40] [Batch 216/287] [Batch classify loss: 0.778583]
[Epoch 5/40] [Batch 217/287] [Batch classify loss: 0.690997]
[Epoch 5/40] [Batch 218/287] [Batch classify loss: 0.706332]
[Epoch 5/40] [Batch 219/287] [Batch classify loss: 0.739534]
[Epoch 5/40] [Batch 220/287] [Batch classify loss: 0.699369]
[Epoch 5/40] [Batch 221/287] [Batch classify loss: 0.704465]
[Epoch 5/40] [Batch 222/287] [Batch classify loss: 0.790910]
[Epoch 5/40] [Batch 223/287] [Batch classify loss: 0.753038]
[Epoch 5/40] [Batch 224/287] [Batch classify loss: 0.708383]
[Epoch 5/40] [Batch 225/287] [Batch classify loss: 0.789960]
[Epoch 5/40] [Batch 226/287] [Batch classify loss: 0.764157]
[Epoch 5/40] [Batch 227/287] [Batch classify loss: 0.763610]
[Epoch 5/40] [Batch 228/287] [Batch classify loss: 0.720466]
[Epoch 5/40] [Batch 229/287] [Batch classify loss: 0.798541]
[Epoch 5/40] [Batch 230/287] [Batch classify loss: 0.720942]
[Epoch 5/40] [Batch 231/287] [Batch classify loss: 0.774257]
[Epoch 5/40] [Batch 232/287] [Batch classify loss: 0.708363]
[Epoch 5/40] [Batch 233/287] [Batch classify loss: 0.741722]
[Epoch 5/40] [Batch 234/287] [Batch classify loss: 0.773930]
[Epoch 5/40] [Batch 235/287] [Batch classify loss: 0.739145]
[Epoch 5/40] [Batch 236/287] [Batch classify loss: 0.776896]
[Epoch 5/40] [Batch 237/287] [Batch classify loss: 0.802423]
[Epoch 5/40] [Batch 238/287] [Batch classify loss: 0.809880]
[Epoch 5/40] [Batch 239/287] [Batch classify loss: 0.797584]
[Epoch 5/40] [Batch 240/287] [Batch classify loss: 0.812501]
[Epoch 5/40] [Batch 241/287] [Batch classify loss: 0.737419]
[Epoch 5/40] [Batch 242/287] [Batch classify loss: 0.753654]
[Epoch 5/40] [Batch 243/287] [Batch classify loss: 0.827841]
[Epoch 5/40] [Batch 244/287] [Batch classify loss: 0.785291]
[Epoch 5/40] [Batch 245/287] [Batch classify loss: 0.773668]
[Epoch 5/40] [Batch 246/287] [Batch classify loss: 0.796198]
[Epoch 5/40] [Batch 247/287] [Batch classify loss: 0.756640]
[Epoch 5/40] [Batch 248/287] [Batch classify loss: 0.769232]
[Epoch 5/40] [Batch 249/287] [Batch classify loss: 0.804344]
[Epoch 5/40] [Batch 250/287] [Batch classify loss: 0.812505]
[Epoch 5/40] [Batch 251/287] [Batch classify loss: 0.763274]
[Epoch 5/40] [Batch 252/287] [Batch classify loss: 0.828094]
[Epoch 5/40] [Batch 253/287] [Batch classify loss: 0.793269]
[Epoch 5/40] [Batch 254/287] [Batch classify loss: 0.807623]
[Epoch 5/40] [Batch 255/287] [Batch classify loss: 0.781128]
[Epoch 5/40] [Batch 256/287] [Batch classify loss: 0.763970]
[Epoch 5/40] [Batch 257/287] [Batch classify loss: 0.797219]
[Epoch 5/40] [Batch 258/287] [Batch classify loss: 0.822079]
[Epoch 5/40] [Batch 259/287] [Batch classify loss: 0.861350]
[Epoch 5/40] [Batch 260/287] [Batch classify loss: 0.717834]
[Epoch 5/40] [Batch 261/287] [Batch classify loss: 0.773613]
[Epoch 5/40] [Batch 262/287] [Batch classify loss: 0.767915]
[Epoch 5/40] [Batch 263/287] [Batch classify loss: 0.823602]
[Epoch 5/40] [Batch 264/287] [Batch classify loss: 0.832744]
[Epoch 5/40] [Batch 265/287] [Batch classify loss: 0.813354]
[Epoch 5/40] [Batch 266/287] [Batch classify loss: 0.823622]
[Epoch 5/40] [Batch 267/287] [Batch classify loss: 0.831732]
[Epoch 5/40] [Batch 268/287] [Batch classify loss: 0.768285]
[Epoch 5/40] [Batch 269/287] [Batch classify loss: 0.743875]
[Epoch 5/40] [Batch 270/287] [Batch classify loss: 0.841902]
[Epoch 5/40] [Batch 271/287] [Batch classify loss: 0.780964]
[Epoch 5/40] [Batch 272/287] [Batch classify loss: 0.822059]
[Epoch 5/40] [Batch 273/287] [Batch classify loss: 0.852410]
[Epoch 5/40] [Batch 274/287] [Batch classify loss: 0.788762]
[Epoch 5/40] [Batch 275/287] [Batch classify loss: 0.835893]
[Epoch 5/40] [Batch 276/287] [Batch classify loss: 0.853529]
[Epoch 5/40] [Batch 277/287] [Batch classify loss: 0.790568]
[Epoch 5/40] [Batch 278/287] [Batch classify loss: 0.798642]
[Epoch 5/40] [Batch 279/287] [Batch classify loss: 0.808369]
[Epoch 5/40] [Batch 280/287] [Batch classify loss: 0.866063]
[Epoch 5/40] [Batch 281/287] [Batch classify loss: 0.848046]
[Epoch 5/40] [Batch 282/287] [Batch classify loss: 0.763923]
[Epoch 5/40] [Batch 283/287] [Batch classify loss: 0.422755]
[Epoch 5/40] [Batch 284/287] [Batch classify loss: 0.488227]
[Epoch 5/40] [Batch 285/287] [Batch classify loss: 0.531430]
[Epoch 5/40] [Batch 286/287] [Batch classify loss: 0.515353]
[Epoch 5/40] [Batch 287/287] [Batch classify loss: 0.890670]
0005 epoch rmt trained classifier accuary on the clean testing examples:90.3465%
0005 epoch rmt trained classifier loss on the clean testing examples:0.3926
0005 epoch rmt trained classifier accuary on adversarial testset:14.1480%
0005 epoch rmt trained classifier loss on adversarial testset:5.581326007843018


5epoch learning rate:0.001
[Epoch 6/40] [Batch 1/287] [Batch classify loss: 0.275457]
[Epoch 6/40] [Batch 2/287] [Batch classify loss: 0.352833]
[Epoch 6/40] [Batch 3/287] [Batch classify loss: 0.397545]
[Epoch 6/40] [Batch 4/287] [Batch classify loss: 0.442900]
[Epoch 6/40] [Batch 5/287] [Batch classify loss: 0.426317]
[Epoch 6/40] [Batch 6/287] [Batch classify loss: 0.459678]
[Epoch 6/40] [Batch 7/287] [Batch classify loss: 0.483514]
[Epoch 6/40] [Batch 8/287] [Batch classify loss: 0.468109]
[Epoch 6/40] [Batch 9/287] [Batch classify loss: 0.499655]
[Epoch 6/40] [Batch 10/287] [Batch classify loss: 0.514106]
[Epoch 6/40] [Batch 11/287] [Batch classify loss: 0.510591]
[Epoch 6/40] [Batch 12/287] [Batch classify loss: 0.511977]
[Epoch 6/40] [Batch 13/287] [Batch classify loss: 0.524716]
[Epoch 6/40] [Batch 14/287] [Batch classify loss: 0.508499]
[Epoch 6/40] [Batch 15/287] [Batch classify loss: 0.522274]
[Epoch 6/40] [Batch 16/287] [Batch classify loss: 0.577827]
[Epoch 6/40] [Batch 17/287] [Batch classify loss: 0.549038]
[Epoch 6/40] [Batch 18/287] [Batch classify loss: 0.477151]
[Epoch 6/40] [Batch 19/287] [Batch classify loss: 0.548410]
[Epoch 6/40] [Batch 20/287] [Batch classify loss: 0.613645]
[Epoch 6/40] [Batch 21/287] [Batch classify loss: 0.553952]
[Epoch 6/40] [Batch 22/287] [Batch classify loss: 0.554733]
[Epoch 6/40] [Batch 23/287] [Batch classify loss: 0.612559]
[Epoch 6/40] [Batch 24/287] [Batch classify loss: 0.607562]
[Epoch 6/40] [Batch 25/287] [Batch classify loss: 0.652436]
[Epoch 6/40] [Batch 26/287] [Batch classify loss: 0.574650]
[Epoch 6/40] [Batch 27/287] [Batch classify loss: 0.592795]
[Epoch 6/40] [Batch 28/287] [Batch classify loss: 0.535299]
[Epoch 6/40] [Batch 29/287] [Batch classify loss: 0.577501]
[Epoch 6/40] [Batch 30/287] [Batch classify loss: 0.621778]
[Epoch 6/40] [Batch 31/287] [Batch classify loss: 0.626715]
[Epoch 6/40] [Batch 32/287] [Batch classify loss: 0.562047]
[Epoch 6/40] [Batch 33/287] [Batch classify loss: 0.589670]
[Epoch 6/40] [Batch 34/287] [Batch classify loss: 0.560717]
[Epoch 6/40] [Batch 35/287] [Batch classify loss: 0.599108]
[Epoch 6/40] [Batch 36/287] [Batch classify loss: 0.582595]
[Epoch 6/40] [Batch 37/287] [Batch classify loss: 0.606239]
[Epoch 6/40] [Batch 38/287] [Batch classify loss: 0.616711]
[Epoch 6/40] [Batch 39/287] [Batch classify loss: 0.593843]
[Epoch 6/40] [Batch 40/287] [Batch classify loss: 0.604360]
[Epoch 6/40] [Batch 41/287] [Batch classify loss: 0.622707]
[Epoch 6/40] [Batch 42/287] [Batch classify loss: 0.638036]
[Epoch 6/40] [Batch 43/287] [Batch classify loss: 0.606940]
[Epoch 6/40] [Batch 44/287] [Batch classify loss: 0.611531]
[Epoch 6/40] [Batch 45/287] [Batch classify loss: 0.631838]
[Epoch 6/40] [Batch 46/287] [Batch classify loss: 0.672174]
[Epoch 6/40] [Batch 47/287] [Batch classify loss: 0.654886]
[Epoch 6/40] [Batch 48/287] [Batch classify loss: 0.588624]
[Epoch 6/40] [Batch 49/287] [Batch classify loss: 0.642557]
[Epoch 6/40] [Batch 50/287] [Batch classify loss: 0.623800]
[Epoch 6/40] [Batch 51/287] [Batch classify loss: 0.599082]
[Epoch 6/40] [Batch 52/287] [Batch classify loss: 0.657797]
[Epoch 6/40] [Batch 53/287] [Batch classify loss: 0.667406]
[Epoch 6/40] [Batch 54/287] [Batch classify loss: 0.632266]
[Epoch 6/40] [Batch 55/287] [Batch classify loss: 0.646310]
[Epoch 6/40] [Batch 56/287] [Batch classify loss: 0.659209]
[Epoch 6/40] [Batch 57/287] [Batch classify loss: 0.633154]
[Epoch 6/40] [Batch 58/287] [Batch classify loss: 0.664490]
[Epoch 6/40] [Batch 59/287] [Batch classify loss: 0.690306]
[Epoch 6/40] [Batch 60/287] [Batch classify loss: 0.657887]
[Epoch 6/40] [Batch 61/287] [Batch classify loss: 0.678926]
[Epoch 6/40] [Batch 62/287] [Batch classify loss: 0.683634]
[Epoch 6/40] [Batch 63/287] [Batch classify loss: 0.664848]
[Epoch 6/40] [Batch 64/287] [Batch classify loss: 0.664386]
[Epoch 6/40] [Batch 65/287] [Batch classify loss: 0.656479]
[Epoch 6/40] [Batch 66/287] [Batch classify loss: 0.690638]
[Epoch 6/40] [Batch 67/287] [Batch classify loss: 0.656760]
[Epoch 6/40] [Batch 68/287] [Batch classify loss: 0.653525]
[Epoch 6/40] [Batch 69/287] [Batch classify loss: 0.704927]
[Epoch 6/40] [Batch 70/287] [Batch classify loss: 0.675781]
[Epoch 6/40] [Batch 71/287] [Batch classify loss: 0.694815]
[Epoch 6/40] [Batch 72/287] [Batch classify loss: 0.639583]
[Epoch 6/40] [Batch 73/287] [Batch classify loss: 0.644224]
[Epoch 6/40] [Batch 74/287] [Batch classify loss: 0.671983]
[Epoch 6/40] [Batch 75/287] [Batch classify loss: 0.637544]
[Epoch 6/40] [Batch 76/287] [Batch classify loss: 0.642994]
[Epoch 6/40] [Batch 77/287] [Batch classify loss: 0.659183]
[Epoch 6/40] [Batch 78/287] [Batch classify loss: 0.658442]
[Epoch 6/40] [Batch 79/287] [Batch classify loss: 0.686793]
[Epoch 6/40] [Batch 80/287] [Batch classify loss: 0.698769]
[Epoch 6/40] [Batch 81/287] [Batch classify loss: 0.750913]
[Epoch 6/40] [Batch 82/287] [Batch classify loss: 0.672381]
[Epoch 6/40] [Batch 83/287] [Batch classify loss: 0.697181]
[Epoch 6/40] [Batch 84/287] [Batch classify loss: 0.712963]
[Epoch 6/40] [Batch 85/287] [Batch classify loss: 0.692165]
[Epoch 6/40] [Batch 86/287] [Batch classify loss: 0.704747]
[Epoch 6/40] [Batch 87/287] [Batch classify loss: 0.675309]
[Epoch 6/40] [Batch 88/287] [Batch classify loss: 0.662827]
[Epoch 6/40] [Batch 89/287] [Batch classify loss: 0.696375]
[Epoch 6/40] [Batch 90/287] [Batch classify loss: 0.695720]
[Epoch 6/40] [Batch 91/287] [Batch classify loss: 0.705044]
[Epoch 6/40] [Batch 92/287] [Batch classify loss: 0.736229]
[Epoch 6/40] [Batch 93/287] [Batch classify loss: 0.737359]
[Epoch 6/40] [Batch 94/287] [Batch classify loss: 0.630302]
[Epoch 6/40] [Batch 95/287] [Batch classify loss: 0.331219]
[Epoch 6/40] [Batch 96/287] [Batch classify loss: 0.365637]
[Epoch 6/40] [Batch 97/287] [Batch classify loss: 0.439662]
[Epoch 6/40] [Batch 98/287] [Batch classify loss: 0.391763]
[Epoch 6/40] [Batch 99/287] [Batch classify loss: 0.377186]
[Epoch 6/40] [Batch 100/287] [Batch classify loss: 0.459407]
[Epoch 6/40] [Batch 101/287] [Batch classify loss: 0.457954]
[Epoch 6/40] [Batch 102/287] [Batch classify loss: 0.443844]
[Epoch 6/40] [Batch 103/287] [Batch classify loss: 0.480582]
[Epoch 6/40] [Batch 104/287] [Batch classify loss: 0.479602]
[Epoch 6/40] [Batch 105/287] [Batch classify loss: 0.513649]
[Epoch 6/40] [Batch 106/287] [Batch classify loss: 0.530183]
[Epoch 6/40] [Batch 107/287] [Batch classify loss: 0.470981]
[Epoch 6/40] [Batch 108/287] [Batch classify loss: 0.465295]
[Epoch 6/40] [Batch 109/287] [Batch classify loss: 0.558021]
[Epoch 6/40] [Batch 110/287] [Batch classify loss: 0.487414]
[Epoch 6/40] [Batch 111/287] [Batch classify loss: 0.478026]
[Epoch 6/40] [Batch 112/287] [Batch classify loss: 0.552367]
[Epoch 6/40] [Batch 113/287] [Batch classify loss: 0.573654]
[Epoch 6/40] [Batch 114/287] [Batch classify loss: 0.531039]
[Epoch 6/40] [Batch 115/287] [Batch classify loss: 0.489942]
[Epoch 6/40] [Batch 116/287] [Batch classify loss: 0.550632]
[Epoch 6/40] [Batch 117/287] [Batch classify loss: 0.629354]
[Epoch 6/40] [Batch 118/287] [Batch classify loss: 0.621079]
[Epoch 6/40] [Batch 119/287] [Batch classify loss: 0.528376]
[Epoch 6/40] [Batch 120/287] [Batch classify loss: 0.644759]
[Epoch 6/40] [Batch 121/287] [Batch classify loss: 0.555770]
[Epoch 6/40] [Batch 122/287] [Batch classify loss: 0.568490]
[Epoch 6/40] [Batch 123/287] [Batch classify loss: 0.664965]
[Epoch 6/40] [Batch 124/287] [Batch classify loss: 0.594586]
[Epoch 6/40] [Batch 125/287] [Batch classify loss: 0.674322]
[Epoch 6/40] [Batch 126/287] [Batch classify loss: 0.602818]
[Epoch 6/40] [Batch 127/287] [Batch classify loss: 0.571041]
[Epoch 6/40] [Batch 128/287] [Batch classify loss: 0.611462]
[Epoch 6/40] [Batch 129/287] [Batch classify loss: 0.589355]
[Epoch 6/40] [Batch 130/287] [Batch classify loss: 0.582588]
[Epoch 6/40] [Batch 131/287] [Batch classify loss: 0.568198]
[Epoch 6/40] [Batch 132/287] [Batch classify loss: 0.621220]
[Epoch 6/40] [Batch 133/287] [Batch classify loss: 0.603156]
[Epoch 6/40] [Batch 134/287] [Batch classify loss: 0.570972]
[Epoch 6/40] [Batch 135/287] [Batch classify loss: 0.593979]
[Epoch 6/40] [Batch 136/287] [Batch classify loss: 0.621663]
[Epoch 6/40] [Batch 137/287] [Batch classify loss: 0.602090]
[Epoch 6/40] [Batch 138/287] [Batch classify loss: 0.682691]
[Epoch 6/40] [Batch 139/287] [Batch classify loss: 0.639049]
[Epoch 6/40] [Batch 140/287] [Batch classify loss: 0.608240]
[Epoch 6/40] [Batch 141/287] [Batch classify loss: 0.681507]
[Epoch 6/40] [Batch 142/287] [Batch classify loss: 0.611238]
[Epoch 6/40] [Batch 143/287] [Batch classify loss: 0.707497]
[Epoch 6/40] [Batch 144/287] [Batch classify loss: 0.625076]
[Epoch 6/40] [Batch 145/287] [Batch classify loss: 0.682321]
[Epoch 6/40] [Batch 146/287] [Batch classify loss: 0.705953]
[Epoch 6/40] [Batch 147/287] [Batch classify loss: 0.672594]
[Epoch 6/40] [Batch 148/287] [Batch classify loss: 0.628869]
[Epoch 6/40] [Batch 149/287] [Batch classify loss: 0.660246]
[Epoch 6/40] [Batch 150/287] [Batch classify loss: 0.665365]
[Epoch 6/40] [Batch 151/287] [Batch classify loss: 0.669860]
[Epoch 6/40] [Batch 152/287] [Batch classify loss: 0.672453]
[Epoch 6/40] [Batch 153/287] [Batch classify loss: 0.632792]
[Epoch 6/40] [Batch 154/287] [Batch classify loss: 0.689199]
[Epoch 6/40] [Batch 155/287] [Batch classify loss: 0.640007]
[Epoch 6/40] [Batch 156/287] [Batch classify loss: 0.651979]
[Epoch 6/40] [Batch 157/287] [Batch classify loss: 0.629748]
[Epoch 6/40] [Batch 158/287] [Batch classify loss: 0.641371]
[Epoch 6/40] [Batch 159/287] [Batch classify loss: 0.696170]
[Epoch 6/40] [Batch 160/287] [Batch classify loss: 0.718408]
[Epoch 6/40] [Batch 161/287] [Batch classify loss: 0.679033]
[Epoch 6/40] [Batch 162/287] [Batch classify loss: 0.700771]
[Epoch 6/40] [Batch 163/287] [Batch classify loss: 0.668714]
[Epoch 6/40] [Batch 164/287] [Batch classify loss: 0.671598]
[Epoch 6/40] [Batch 165/287] [Batch classify loss: 0.613714]
[Epoch 6/40] [Batch 166/287] [Batch classify loss: 0.612814]
[Epoch 6/40] [Batch 167/287] [Batch classify loss: 0.658300]
[Epoch 6/40] [Batch 168/287] [Batch classify loss: 0.711221]
[Epoch 6/40] [Batch 169/287] [Batch classify loss: 0.657186]
[Epoch 6/40] [Batch 170/287] [Batch classify loss: 0.654304]
[Epoch 6/40] [Batch 171/287] [Batch classify loss: 0.687944]
[Epoch 6/40] [Batch 172/287] [Batch classify loss: 0.708275]
[Epoch 6/40] [Batch 173/287] [Batch classify loss: 0.663514]
[Epoch 6/40] [Batch 174/287] [Batch classify loss: 0.658146]
[Epoch 6/40] [Batch 175/287] [Batch classify loss: 0.703100]
[Epoch 6/40] [Batch 176/287] [Batch classify loss: 0.679186]
[Epoch 6/40] [Batch 177/287] [Batch classify loss: 0.755355]
[Epoch 6/40] [Batch 178/287] [Batch classify loss: 0.711177]
[Epoch 6/40] [Batch 179/287] [Batch classify loss: 0.671749]
[Epoch 6/40] [Batch 180/287] [Batch classify loss: 0.701699]
[Epoch 6/40] [Batch 181/287] [Batch classify loss: 0.653426]
[Epoch 6/40] [Batch 182/287] [Batch classify loss: 0.708693]
[Epoch 6/40] [Batch 183/287] [Batch classify loss: 0.672590]
[Epoch 6/40] [Batch 184/287] [Batch classify loss: 0.659048]
[Epoch 6/40] [Batch 185/287] [Batch classify loss: 0.726193]
[Epoch 6/40] [Batch 186/287] [Batch classify loss: 0.729575]
[Epoch 6/40] [Batch 187/287] [Batch classify loss: 0.728457]
[Epoch 6/40] [Batch 188/287] [Batch classify loss: 0.654287]
[Epoch 6/40] [Batch 189/287] [Batch classify loss: 0.351463]
[Epoch 6/40] [Batch 190/287] [Batch classify loss: 0.341890]
[Epoch 6/40] [Batch 191/287] [Batch classify loss: 0.393246]
[Epoch 6/40] [Batch 192/287] [Batch classify loss: 0.429398]
[Epoch 6/40] [Batch 193/287] [Batch classify loss: 0.375231]
[Epoch 6/40] [Batch 194/287] [Batch classify loss: 0.383094]
[Epoch 6/40] [Batch 195/287] [Batch classify loss: 0.456282]
[Epoch 6/40] [Batch 196/287] [Batch classify loss: 0.467830]
[Epoch 6/40] [Batch 197/287] [Batch classify loss: 0.483588]
[Epoch 6/40] [Batch 198/287] [Batch classify loss: 0.438867]
[Epoch 6/40] [Batch 199/287] [Batch classify loss: 0.558296]
[Epoch 6/40] [Batch 200/287] [Batch classify loss: 0.480367]
[Epoch 6/40] [Batch 201/287] [Batch classify loss: 0.437584]
[Epoch 6/40] [Batch 202/287] [Batch classify loss: 0.476420]
[Epoch 6/40] [Batch 203/287] [Batch classify loss: 0.489342]
[Epoch 6/40] [Batch 204/287] [Batch classify loss: 0.491386]
[Epoch 6/40] [Batch 205/287] [Batch classify loss: 0.464965]
[Epoch 6/40] [Batch 206/287] [Batch classify loss: 0.506265]
[Epoch 6/40] [Batch 207/287] [Batch classify loss: 0.596723]
[Epoch 6/40] [Batch 208/287] [Batch classify loss: 0.574967]
[Epoch 6/40] [Batch 209/287] [Batch classify loss: 0.515150]
[Epoch 6/40] [Batch 210/287] [Batch classify loss: 0.531297]
[Epoch 6/40] [Batch 211/287] [Batch classify loss: 0.591024]
[Epoch 6/40] [Batch 212/287] [Batch classify loss: 0.575604]
[Epoch 6/40] [Batch 213/287] [Batch classify loss: 0.584855]
[Epoch 6/40] [Batch 214/287] [Batch classify loss: 0.630550]
[Epoch 6/40] [Batch 215/287] [Batch classify loss: 0.526648]
[Epoch 6/40] [Batch 216/287] [Batch classify loss: 0.550036]
[Epoch 6/40] [Batch 217/287] [Batch classify loss: 0.542899]
[Epoch 6/40] [Batch 218/287] [Batch classify loss: 0.613224]
[Epoch 6/40] [Batch 219/287] [Batch classify loss: 0.644314]
[Epoch 6/40] [Batch 220/287] [Batch classify loss: 0.607604]
[Epoch 6/40] [Batch 221/287] [Batch classify loss: 0.616977]
[Epoch 6/40] [Batch 222/287] [Batch classify loss: 0.533013]
[Epoch 6/40] [Batch 223/287] [Batch classify loss: 0.632666]
[Epoch 6/40] [Batch 224/287] [Batch classify loss: 0.625204]
[Epoch 6/40] [Batch 225/287] [Batch classify loss: 0.579726]
[Epoch 6/40] [Batch 226/287] [Batch classify loss: 0.539324]
[Epoch 6/40] [Batch 227/287] [Batch classify loss: 0.641946]
[Epoch 6/40] [Batch 228/287] [Batch classify loss: 0.600696]
[Epoch 6/40] [Batch 229/287] [Batch classify loss: 0.579302]
[Epoch 6/40] [Batch 230/287] [Batch classify loss: 0.600293]
[Epoch 6/40] [Batch 231/287] [Batch classify loss: 0.625217]
[Epoch 6/40] [Batch 232/287] [Batch classify loss: 0.637952]
[Epoch 6/40] [Batch 233/287] [Batch classify loss: 0.632365]
[Epoch 6/40] [Batch 234/287] [Batch classify loss: 0.618484]
[Epoch 6/40] [Batch 235/287] [Batch classify loss: 0.682467]
[Epoch 6/40] [Batch 236/287] [Batch classify loss: 0.658846]
[Epoch 6/40] [Batch 237/287] [Batch classify loss: 0.620422]
[Epoch 6/40] [Batch 238/287] [Batch classify loss: 0.664881]
[Epoch 6/40] [Batch 239/287] [Batch classify loss: 0.655349]
[Epoch 6/40] [Batch 240/287] [Batch classify loss: 0.694513]
[Epoch 6/40] [Batch 241/287] [Batch classify loss: 0.646887]
[Epoch 6/40] [Batch 242/287] [Batch classify loss: 0.648671]
[Epoch 6/40] [Batch 243/287] [Batch classify loss: 0.621676]
[Epoch 6/40] [Batch 244/287] [Batch classify loss: 0.578816]
[Epoch 6/40] [Batch 245/287] [Batch classify loss: 0.615392]
[Epoch 6/40] [Batch 246/287] [Batch classify loss: 0.617284]
[Epoch 6/40] [Batch 247/287] [Batch classify loss: 0.627772]
[Epoch 6/40] [Batch 248/287] [Batch classify loss: 0.686427]
[Epoch 6/40] [Batch 249/287] [Batch classify loss: 0.633698]
[Epoch 6/40] [Batch 250/287] [Batch classify loss: 0.664572]
[Epoch 6/40] [Batch 251/287] [Batch classify loss: 0.670935]
[Epoch 6/40] [Batch 252/287] [Batch classify loss: 0.626994]
[Epoch 6/40] [Batch 253/287] [Batch classify loss: 0.669208]
[Epoch 6/40] [Batch 254/287] [Batch classify loss: 0.673056]
[Epoch 6/40] [Batch 255/287] [Batch classify loss: 0.662086]
[Epoch 6/40] [Batch 256/287] [Batch classify loss: 0.677638]
[Epoch 6/40] [Batch 257/287] [Batch classify loss: 0.663961]
[Epoch 6/40] [Batch 258/287] [Batch classify loss: 0.642480]
[Epoch 6/40] [Batch 259/287] [Batch classify loss: 0.632445]
[Epoch 6/40] [Batch 260/287] [Batch classify loss: 0.653446]
[Epoch 6/40] [Batch 261/287] [Batch classify loss: 0.659619]
[Epoch 6/40] [Batch 262/287] [Batch classify loss: 0.652341]
[Epoch 6/40] [Batch 263/287] [Batch classify loss: 0.663282]
[Epoch 6/40] [Batch 264/287] [Batch classify loss: 0.722241]
[Epoch 6/40] [Batch 265/287] [Batch classify loss: 0.672157]
[Epoch 6/40] [Batch 266/287] [Batch classify loss: 0.621236]
[Epoch 6/40] [Batch 267/287] [Batch classify loss: 0.651855]
[Epoch 6/40] [Batch 268/287] [Batch classify loss: 0.644973]
[Epoch 6/40] [Batch 269/287] [Batch classify loss: 0.652944]
[Epoch 6/40] [Batch 270/287] [Batch classify loss: 0.621004]
[Epoch 6/40] [Batch 271/287] [Batch classify loss: 0.627744]
[Epoch 6/40] [Batch 272/287] [Batch classify loss: 0.736632]
[Epoch 6/40] [Batch 273/287] [Batch classify loss: 0.645711]
[Epoch 6/40] [Batch 274/287] [Batch classify loss: 0.714446]
[Epoch 6/40] [Batch 275/287] [Batch classify loss: 0.648857]
[Epoch 6/40] [Batch 276/287] [Batch classify loss: 0.693116]
[Epoch 6/40] [Batch 277/287] [Batch classify loss: 0.667988]
[Epoch 6/40] [Batch 278/287] [Batch classify loss: 0.705828]
[Epoch 6/40] [Batch 279/287] [Batch classify loss: 0.674917]
[Epoch 6/40] [Batch 280/287] [Batch classify loss: 0.739871]
[Epoch 6/40] [Batch 281/287] [Batch classify loss: 0.735886]
[Epoch 6/40] [Batch 282/287] [Batch classify loss: 0.646587]
[Epoch 6/40] [Batch 283/287] [Batch classify loss: 0.326433]
[Epoch 6/40] [Batch 284/287] [Batch classify loss: 0.357605]
[Epoch 6/40] [Batch 285/287] [Batch classify loss: 0.362713]
[Epoch 6/40] [Batch 286/287] [Batch classify loss: 0.371322]
[Epoch 6/40] [Batch 287/287] [Batch classify loss: 0.632044]
0006 epoch rmt trained classifier accuary on the clean testing examples:89.1096%
0006 epoch rmt trained classifier loss on the clean testing examples:0.4200
0006 epoch rmt trained classifier accuary on adversarial testset:14.8202%
0006 epoch rmt trained classifier loss on adversarial testset:5.698030471801758


6epoch learning rate:0.001
[Epoch 7/40] [Batch 1/287] [Batch classify loss: 0.164531]
[Epoch 7/40] [Batch 2/287] [Batch classify loss: 0.245506]
[Epoch 7/40] [Batch 3/287] [Batch classify loss: 0.255581]
[Epoch 7/40] [Batch 4/287] [Batch classify loss: 0.286129]
[Epoch 7/40] [Batch 5/287] [Batch classify loss: 0.321568]
[Epoch 7/40] [Batch 6/287] [Batch classify loss: 0.307894]
[Epoch 7/40] [Batch 7/287] [Batch classify loss: 0.358167]
[Epoch 7/40] [Batch 8/287] [Batch classify loss: 0.336079]
[Epoch 7/40] [Batch 9/287] [Batch classify loss: 0.353025]
[Epoch 7/40] [Batch 10/287] [Batch classify loss: 0.348130]
[Epoch 7/40] [Batch 11/287] [Batch classify loss: 0.369268]
[Epoch 7/40] [Batch 12/287] [Batch classify loss: 0.337348]
[Epoch 7/40] [Batch 13/287] [Batch classify loss: 0.448567]
[Epoch 7/40] [Batch 14/287] [Batch classify loss: 0.384989]
[Epoch 7/40] [Batch 15/287] [Batch classify loss: 0.336040]
[Epoch 7/40] [Batch 16/287] [Batch classify loss: 0.406046]
[Epoch 7/40] [Batch 17/287] [Batch classify loss: 0.408676]
[Epoch 7/40] [Batch 18/287] [Batch classify loss: 0.400297]
[Epoch 7/40] [Batch 19/287] [Batch classify loss: 0.389149]
[Epoch 7/40] [Batch 20/287] [Batch classify loss: 0.419547]
[Epoch 7/40] [Batch 21/287] [Batch classify loss: 0.420190]
[Epoch 7/40] [Batch 22/287] [Batch classify loss: 0.412318]
[Epoch 7/40] [Batch 23/287] [Batch classify loss: 0.433450]
[Epoch 7/40] [Batch 24/287] [Batch classify loss: 0.400286]
[Epoch 7/40] [Batch 25/287] [Batch classify loss: 0.445579]
[Epoch 7/40] [Batch 26/287] [Batch classify loss: 0.422126]
[Epoch 7/40] [Batch 27/287] [Batch classify loss: 0.468293]
[Epoch 7/40] [Batch 28/287] [Batch classify loss: 0.488975]
[Epoch 7/40] [Batch 29/287] [Batch classify loss: 0.476587]
[Epoch 7/40] [Batch 30/287] [Batch classify loss: 0.475433]
[Epoch 7/40] [Batch 31/287] [Batch classify loss: 0.428565]
[Epoch 7/40] [Batch 32/287] [Batch classify loss: 0.426807]
[Epoch 7/40] [Batch 33/287] [Batch classify loss: 0.500548]
[Epoch 7/40] [Batch 34/287] [Batch classify loss: 0.429182]
[Epoch 7/40] [Batch 35/287] [Batch classify loss: 0.446039]
[Epoch 7/40] [Batch 36/287] [Batch classify loss: 0.394455]
[Epoch 7/40] [Batch 37/287] [Batch classify loss: 0.456178]
[Epoch 7/40] [Batch 38/287] [Batch classify loss: 0.436405]
[Epoch 7/40] [Batch 39/287] [Batch classify loss: 0.439492]
[Epoch 7/40] [Batch 40/287] [Batch classify loss: 0.481338]
[Epoch 7/40] [Batch 41/287] [Batch classify loss: 0.385395]
[Epoch 7/40] [Batch 42/287] [Batch classify loss: 0.457199]
[Epoch 7/40] [Batch 43/287] [Batch classify loss: 0.478482]
[Epoch 7/40] [Batch 44/287] [Batch classify loss: 0.475681]
[Epoch 7/40] [Batch 45/287] [Batch classify loss: 0.464965]
[Epoch 7/40] [Batch 46/287] [Batch classify loss: 0.460060]
[Epoch 7/40] [Batch 47/287] [Batch classify loss: 0.509099]
[Epoch 7/40] [Batch 48/287] [Batch classify loss: 0.515537]
[Epoch 7/40] [Batch 49/287] [Batch classify loss: 0.479741]
[Epoch 7/40] [Batch 50/287] [Batch classify loss: 0.450466]
[Epoch 7/40] [Batch 51/287] [Batch classify loss: 0.522860]
[Epoch 7/40] [Batch 52/287] [Batch classify loss: 0.547163]
[Epoch 7/40] [Batch 53/287] [Batch classify loss: 0.516939]
[Epoch 7/40] [Batch 54/287] [Batch classify loss: 0.517314]
[Epoch 7/40] [Batch 55/287] [Batch classify loss: 0.507665]
[Epoch 7/40] [Batch 56/287] [Batch classify loss: 0.453961]
[Epoch 7/40] [Batch 57/287] [Batch classify loss: 0.576979]
[Epoch 7/40] [Batch 58/287] [Batch classify loss: 0.496184]
[Epoch 7/40] [Batch 59/287] [Batch classify loss: 0.569449]
[Epoch 7/40] [Batch 60/287] [Batch classify loss: 0.508328]
[Epoch 7/40] [Batch 61/287] [Batch classify loss: 0.534711]
[Epoch 7/40] [Batch 62/287] [Batch classify loss: 0.539845]
[Epoch 7/40] [Batch 63/287] [Batch classify loss: 0.549244]
[Epoch 7/40] [Batch 64/287] [Batch classify loss: 0.532260]
[Epoch 7/40] [Batch 65/287] [Batch classify loss: 0.533601]
[Epoch 7/40] [Batch 66/287] [Batch classify loss: 0.571792]
[Epoch 7/40] [Batch 67/287] [Batch classify loss: 0.492091]
[Epoch 7/40] [Batch 68/287] [Batch classify loss: 0.532616]
[Epoch 7/40] [Batch 69/287] [Batch classify loss: 0.509729]
[Epoch 7/40] [Batch 70/287] [Batch classify loss: 0.513810]
[Epoch 7/40] [Batch 71/287] [Batch classify loss: 0.530803]
[Epoch 7/40] [Batch 72/287] [Batch classify loss: 0.523427]
[Epoch 7/40] [Batch 73/287] [Batch classify loss: 0.562012]
[Epoch 7/40] [Batch 74/287] [Batch classify loss: 0.516005]
[Epoch 7/40] [Batch 75/287] [Batch classify loss: 0.596769]
[Epoch 7/40] [Batch 76/287] [Batch classify loss: 0.529025]
[Epoch 7/40] [Batch 77/287] [Batch classify loss: 0.565976]
[Epoch 7/40] [Batch 78/287] [Batch classify loss: 0.544903]
[Epoch 7/40] [Batch 79/287] [Batch classify loss: 0.519631]
[Epoch 7/40] [Batch 80/287] [Batch classify loss: 0.549657]
[Epoch 7/40] [Batch 81/287] [Batch classify loss: 0.578798]
[Epoch 7/40] [Batch 82/287] [Batch classify loss: 0.536689]
[Epoch 7/40] [Batch 83/287] [Batch classify loss: 0.577037]
[Epoch 7/40] [Batch 84/287] [Batch classify loss: 0.566685]
[Epoch 7/40] [Batch 85/287] [Batch classify loss: 0.588450]
[Epoch 7/40] [Batch 86/287] [Batch classify loss: 0.546441]
[Epoch 7/40] [Batch 87/287] [Batch classify loss: 0.637920]
[Epoch 7/40] [Batch 88/287] [Batch classify loss: 0.620811]
[Epoch 7/40] [Batch 89/287] [Batch classify loss: 0.545099]
[Epoch 7/40] [Batch 90/287] [Batch classify loss: 0.633647]
[Epoch 7/40] [Batch 91/287] [Batch classify loss: 0.556079]
[Epoch 7/40] [Batch 92/287] [Batch classify loss: 0.602977]
[Epoch 7/40] [Batch 93/287] [Batch classify loss: 0.578022]
[Epoch 7/40] [Batch 94/287] [Batch classify loss: 0.487158]
[Epoch 7/40] [Batch 95/287] [Batch classify loss: 0.221528]
[Epoch 7/40] [Batch 96/287] [Batch classify loss: 0.248191]
[Epoch 7/40] [Batch 97/287] [Batch classify loss: 0.277832]
[Epoch 7/40] [Batch 98/287] [Batch classify loss: 0.272094]
[Epoch 7/40] [Batch 99/287] [Batch classify loss: 0.349408]
[Epoch 7/40] [Batch 100/287] [Batch classify loss: 0.315045]
[Epoch 7/40] [Batch 101/287] [Batch classify loss: 0.344149]
[Epoch 7/40] [Batch 102/287] [Batch classify loss: 0.313415]
[Epoch 7/40] [Batch 103/287] [Batch classify loss: 0.382365]
[Epoch 7/40] [Batch 104/287] [Batch classify loss: 0.321313]
[Epoch 7/40] [Batch 105/287] [Batch classify loss: 0.328983]
[Epoch 7/40] [Batch 106/287] [Batch classify loss: 0.335840]
[Epoch 7/40] [Batch 107/287] [Batch classify loss: 0.415311]
[Epoch 7/40] [Batch 108/287] [Batch classify loss: 0.369044]
[Epoch 7/40] [Batch 109/287] [Batch classify loss: 0.349674]
[Epoch 7/40] [Batch 110/287] [Batch classify loss: 0.419695]
[Epoch 7/40] [Batch 111/287] [Batch classify loss: 0.407106]
[Epoch 7/40] [Batch 112/287] [Batch classify loss: 0.354607]
[Epoch 7/40] [Batch 113/287] [Batch classify loss: 0.393271]
[Epoch 7/40] [Batch 114/287] [Batch classify loss: 0.412721]
[Epoch 7/40] [Batch 115/287] [Batch classify loss: 0.386242]
[Epoch 7/40] [Batch 116/287] [Batch classify loss: 0.404153]
[Epoch 7/40] [Batch 117/287] [Batch classify loss: 0.422419]
[Epoch 7/40] [Batch 118/287] [Batch classify loss: 0.374791]
[Epoch 7/40] [Batch 119/287] [Batch classify loss: 0.436437]
[Epoch 7/40] [Batch 120/287] [Batch classify loss: 0.412108]
[Epoch 7/40] [Batch 121/287] [Batch classify loss: 0.456135]
[Epoch 7/40] [Batch 122/287] [Batch classify loss: 0.437051]
[Epoch 7/40] [Batch 123/287] [Batch classify loss: 0.459948]
[Epoch 7/40] [Batch 124/287] [Batch classify loss: 0.447393]
[Epoch 7/40] [Batch 125/287] [Batch classify loss: 0.421105]
[Epoch 7/40] [Batch 126/287] [Batch classify loss: 0.471235]
[Epoch 7/40] [Batch 127/287] [Batch classify loss: 0.448442]
[Epoch 7/40] [Batch 128/287] [Batch classify loss: 0.447112]
[Epoch 7/40] [Batch 129/287] [Batch classify loss: 0.463750]
[Epoch 7/40] [Batch 130/287] [Batch classify loss: 0.426956]
[Epoch 7/40] [Batch 131/287] [Batch classify loss: 0.440992]
[Epoch 7/40] [Batch 132/287] [Batch classify loss: 0.479407]
[Epoch 7/40] [Batch 133/287] [Batch classify loss: 0.477328]
[Epoch 7/40] [Batch 134/287] [Batch classify loss: 0.500320]
[Epoch 7/40] [Batch 135/287] [Batch classify loss: 0.415942]
[Epoch 7/40] [Batch 136/287] [Batch classify loss: 0.466999]
[Epoch 7/40] [Batch 137/287] [Batch classify loss: 0.483371]
[Epoch 7/40] [Batch 138/287] [Batch classify loss: 0.540514]
[Epoch 7/40] [Batch 139/287] [Batch classify loss: 0.464382]
[Epoch 7/40] [Batch 140/287] [Batch classify loss: 0.470189]
[Epoch 7/40] [Batch 141/287] [Batch classify loss: 0.475575]
[Epoch 7/40] [Batch 142/287] [Batch classify loss: 0.485205]
[Epoch 7/40] [Batch 143/287] [Batch classify loss: 0.476576]
[Epoch 7/40] [Batch 144/287] [Batch classify loss: 0.483465]
[Epoch 7/40] [Batch 145/287] [Batch classify loss: 0.505111]
[Epoch 7/40] [Batch 146/287] [Batch classify loss: 0.560953]
[Epoch 7/40] [Batch 147/287] [Batch classify loss: 0.519175]
[Epoch 7/40] [Batch 148/287] [Batch classify loss: 0.493577]
[Epoch 7/40] [Batch 149/287] [Batch classify loss: 0.528382]
[Epoch 7/40] [Batch 150/287] [Batch classify loss: 0.524451]
[Epoch 7/40] [Batch 151/287] [Batch classify loss: 0.544345]
[Epoch 7/40] [Batch 152/287] [Batch classify loss: 0.521297]
[Epoch 7/40] [Batch 153/287] [Batch classify loss: 0.532839]
[Epoch 7/40] [Batch 154/287] [Batch classify loss: 0.514011]
[Epoch 7/40] [Batch 155/287] [Batch classify loss: 0.478586]
[Epoch 7/40] [Batch 156/287] [Batch classify loss: 0.533154]
[Epoch 7/40] [Batch 157/287] [Batch classify loss: 0.574581]
[Epoch 7/40] [Batch 158/287] [Batch classify loss: 0.506088]
[Epoch 7/40] [Batch 159/287] [Batch classify loss: 0.528773]
[Epoch 7/40] [Batch 160/287] [Batch classify loss: 0.517328]
[Epoch 7/40] [Batch 161/287] [Batch classify loss: 0.559648]
[Epoch 7/40] [Batch 162/287] [Batch classify loss: 0.515907]
[Epoch 7/40] [Batch 163/287] [Batch classify loss: 0.524731]
[Epoch 7/40] [Batch 164/287] [Batch classify loss: 0.553090]
[Epoch 7/40] [Batch 165/287] [Batch classify loss: 0.543667]
[Epoch 7/40] [Batch 166/287] [Batch classify loss: 0.523186]
[Epoch 7/40] [Batch 167/287] [Batch classify loss: 0.550140]
[Epoch 7/40] [Batch 168/287] [Batch classify loss: 0.536008]
[Epoch 7/40] [Batch 169/287] [Batch classify loss: 0.540178]
[Epoch 7/40] [Batch 170/287] [Batch classify loss: 0.522857]
[Epoch 7/40] [Batch 171/287] [Batch classify loss: 0.583830]
[Epoch 7/40] [Batch 172/287] [Batch classify loss: 0.569287]
[Epoch 7/40] [Batch 173/287] [Batch classify loss: 0.497421]
[Epoch 7/40] [Batch 174/287] [Batch classify loss: 0.524344]
[Epoch 7/40] [Batch 175/287] [Batch classify loss: 0.536272]
[Epoch 7/40] [Batch 176/287] [Batch classify loss: 0.537228]
[Epoch 7/40] [Batch 177/287] [Batch classify loss: 0.550404]
[Epoch 7/40] [Batch 178/287] [Batch classify loss: 0.558157]
[Epoch 7/40] [Batch 179/287] [Batch classify loss: 0.603289]
[Epoch 7/40] [Batch 180/287] [Batch classify loss: 0.552391]
[Epoch 7/40] [Batch 181/287] [Batch classify loss: 0.646450]
[Epoch 7/40] [Batch 182/287] [Batch classify loss: 0.595167]
[Epoch 7/40] [Batch 183/287] [Batch classify loss: 0.564945]
[Epoch 7/40] [Batch 184/287] [Batch classify loss: 0.608207]
[Epoch 7/40] [Batch 185/287] [Batch classify loss: 0.623036]
[Epoch 7/40] [Batch 186/287] [Batch classify loss: 0.634705]
[Epoch 7/40] [Batch 187/287] [Batch classify loss: 0.586824]
[Epoch 7/40] [Batch 188/287] [Batch classify loss: 0.480890]
[Epoch 7/40] [Batch 189/287] [Batch classify loss: 0.258842]
[Epoch 7/40] [Batch 190/287] [Batch classify loss: 0.240736]
[Epoch 7/40] [Batch 191/287] [Batch classify loss: 0.271216]
[Epoch 7/40] [Batch 192/287] [Batch classify loss: 0.283578]
[Epoch 7/40] [Batch 193/287] [Batch classify loss: 0.317189]
[Epoch 7/40] [Batch 194/287] [Batch classify loss: 0.311913]
[Epoch 7/40] [Batch 195/287] [Batch classify loss: 0.340901]
[Epoch 7/40] [Batch 196/287] [Batch classify loss: 0.342617]
[Epoch 7/40] [Batch 197/287] [Batch classify loss: 0.406712]
[Epoch 7/40] [Batch 198/287] [Batch classify loss: 0.371350]
[Epoch 7/40] [Batch 199/287] [Batch classify loss: 0.357439]
[Epoch 7/40] [Batch 200/287] [Batch classify loss: 0.391699]
[Epoch 7/40] [Batch 201/287] [Batch classify loss: 0.390350]
[Epoch 7/40] [Batch 202/287] [Batch classify loss: 0.353921]
[Epoch 7/40] [Batch 203/287] [Batch classify loss: 0.387445]
[Epoch 7/40] [Batch 204/287] [Batch classify loss: 0.406598]
[Epoch 7/40] [Batch 205/287] [Batch classify loss: 0.418598]
[Epoch 7/40] [Batch 206/287] [Batch classify loss: 0.401294]
[Epoch 7/40] [Batch 207/287] [Batch classify loss: 0.346533]
[Epoch 7/40] [Batch 208/287] [Batch classify loss: 0.439302]
[Epoch 7/40] [Batch 209/287] [Batch classify loss: 0.400204]
[Epoch 7/40] [Batch 210/287] [Batch classify loss: 0.421543]
[Epoch 7/40] [Batch 211/287] [Batch classify loss: 0.386462]
[Epoch 7/40] [Batch 212/287] [Batch classify loss: 0.379902]
[Epoch 7/40] [Batch 213/287] [Batch classify loss: 0.391666]
[Epoch 7/40] [Batch 214/287] [Batch classify loss: 0.430916]
[Epoch 7/40] [Batch 215/287] [Batch classify loss: 0.444971]
[Epoch 7/40] [Batch 216/287] [Batch classify loss: 0.450537]
[Epoch 7/40] [Batch 217/287] [Batch classify loss: 0.416543]
[Epoch 7/40] [Batch 218/287] [Batch classify loss: 0.417486]
[Epoch 7/40] [Batch 219/287] [Batch classify loss: 0.437742]
[Epoch 7/40] [Batch 220/287] [Batch classify loss: 0.416031]
[Epoch 7/40] [Batch 221/287] [Batch classify loss: 0.474845]
[Epoch 7/40] [Batch 222/287] [Batch classify loss: 0.453755]
[Epoch 7/40] [Batch 223/287] [Batch classify loss: 0.501497]
[Epoch 7/40] [Batch 224/287] [Batch classify loss: 0.443255]
[Epoch 7/40] [Batch 225/287] [Batch classify loss: 0.482561]
[Epoch 7/40] [Batch 226/287] [Batch classify loss: 0.436710]
[Epoch 7/40] [Batch 227/287] [Batch classify loss: 0.438762]
[Epoch 7/40] [Batch 228/287] [Batch classify loss: 0.463037]
[Epoch 7/40] [Batch 229/287] [Batch classify loss: 0.492421]
[Epoch 7/40] [Batch 230/287] [Batch classify loss: 0.522079]
[Epoch 7/40] [Batch 231/287] [Batch classify loss: 0.457462]
[Epoch 7/40] [Batch 232/287] [Batch classify loss: 0.446448]
[Epoch 7/40] [Batch 233/287] [Batch classify loss: 0.481725]
[Epoch 7/40] [Batch 234/287] [Batch classify loss: 0.493081]
[Epoch 7/40] [Batch 235/287] [Batch classify loss: 0.468835]
[Epoch 7/40] [Batch 236/287] [Batch classify loss: 0.530277]
[Epoch 7/40] [Batch 237/287] [Batch classify loss: 0.461145]
[Epoch 7/40] [Batch 238/287] [Batch classify loss: 0.495035]
[Epoch 7/40] [Batch 239/287] [Batch classify loss: 0.526198]
[Epoch 7/40] [Batch 240/287] [Batch classify loss: 0.554455]
[Epoch 7/40] [Batch 241/287] [Batch classify loss: 0.476833]
[Epoch 7/40] [Batch 242/287] [Batch classify loss: 0.505244]
[Epoch 7/40] [Batch 243/287] [Batch classify loss: 0.541603]
[Epoch 7/40] [Batch 244/287] [Batch classify loss: 0.507216]
[Epoch 7/40] [Batch 245/287] [Batch classify loss: 0.553349]
[Epoch 7/40] [Batch 246/287] [Batch classify loss: 0.527765]
[Epoch 7/40] [Batch 247/287] [Batch classify loss: 0.523530]
[Epoch 7/40] [Batch 248/287] [Batch classify loss: 0.468256]
[Epoch 7/40] [Batch 249/287] [Batch classify loss: 0.571733]
[Epoch 7/40] [Batch 250/287] [Batch classify loss: 0.507454]
[Epoch 7/40] [Batch 251/287] [Batch classify loss: 0.542079]
[Epoch 7/40] [Batch 252/287] [Batch classify loss: 0.551401]
[Epoch 7/40] [Batch 253/287] [Batch classify loss: 0.550183]
[Epoch 7/40] [Batch 254/287] [Batch classify loss: 0.520364]
[Epoch 7/40] [Batch 255/287] [Batch classify loss: 0.478432]
[Epoch 7/40] [Batch 256/287] [Batch classify loss: 0.512893]
[Epoch 7/40] [Batch 257/287] [Batch classify loss: 0.543363]
[Epoch 7/40] [Batch 258/287] [Batch classify loss: 0.549255]
[Epoch 7/40] [Batch 259/287] [Batch classify loss: 0.457482]
[Epoch 7/40] [Batch 260/287] [Batch classify loss: 0.569473]
[Epoch 7/40] [Batch 261/287] [Batch classify loss: 0.522307]
[Epoch 7/40] [Batch 262/287] [Batch classify loss: 0.497024]
[Epoch 7/40] [Batch 263/287] [Batch classify loss: 0.527516]
[Epoch 7/40] [Batch 264/287] [Batch classify loss: 0.534326]
[Epoch 7/40] [Batch 265/287] [Batch classify loss: 0.562729]
[Epoch 7/40] [Batch 266/287] [Batch classify loss: 0.552611]
[Epoch 7/40] [Batch 267/287] [Batch classify loss: 0.520383]
[Epoch 7/40] [Batch 268/287] [Batch classify loss: 0.532747]
[Epoch 7/40] [Batch 269/287] [Batch classify loss: 0.598119]
[Epoch 7/40] [Batch 270/287] [Batch classify loss: 0.536231]
[Epoch 7/40] [Batch 271/287] [Batch classify loss: 0.531127]
[Epoch 7/40] [Batch 272/287] [Batch classify loss: 0.508790]
[Epoch 7/40] [Batch 273/287] [Batch classify loss: 0.602072]
[Epoch 7/40] [Batch 274/287] [Batch classify loss: 0.597625]
[Epoch 7/40] [Batch 275/287] [Batch classify loss: 0.602990]
[Epoch 7/40] [Batch 276/287] [Batch classify loss: 0.507721]
[Epoch 7/40] [Batch 277/287] [Batch classify loss: 0.551660]
[Epoch 7/40] [Batch 278/287] [Batch classify loss: 0.660438]
[Epoch 7/40] [Batch 279/287] [Batch classify loss: 0.618552]
[Epoch 7/40] [Batch 280/287] [Batch classify loss: 0.580275]
[Epoch 7/40] [Batch 281/287] [Batch classify loss: 0.585698]
[Epoch 7/40] [Batch 282/287] [Batch classify loss: 0.538711]
[Epoch 7/40] [Batch 283/287] [Batch classify loss: 0.225768]
[Epoch 7/40] [Batch 284/287] [Batch classify loss: 0.265334]
[Epoch 7/40] [Batch 285/287] [Batch classify loss: 0.261520]
[Epoch 7/40] [Batch 286/287] [Batch classify loss: 0.287745]
[Epoch 7/40] [Batch 287/287] [Batch classify loss: 0.503363]
0007 epoch rmt trained classifier accuary on the clean testing examples:90.0738%
0007 epoch rmt trained classifier loss on the clean testing examples:0.3940
0007 epoch rmt trained classifier accuary on adversarial testset:14.5744%
0007 epoch rmt trained classifier loss on adversarial testset:7.474037170410156


7epoch learning rate:0.001
[Epoch 8/40] [Batch 1/287] [Batch classify loss: 0.095585]
[Epoch 8/40] [Batch 2/287] [Batch classify loss: 0.153416]
[Epoch 8/40] [Batch 3/287] [Batch classify loss: 0.154815]
[Epoch 8/40] [Batch 4/287] [Batch classify loss: 0.215214]
[Epoch 8/40] [Batch 5/287] [Batch classify loss: 0.206412]
[Epoch 8/40] [Batch 6/287] [Batch classify loss: 0.232944]
[Epoch 8/40] [Batch 7/287] [Batch classify loss: 0.251564]
[Epoch 8/40] [Batch 8/287] [Batch classify loss: 0.231822]
[Epoch 8/40] [Batch 9/287] [Batch classify loss: 0.270917]
[Epoch 8/40] [Batch 10/287] [Batch classify loss: 0.263273]
[Epoch 8/40] [Batch 11/287] [Batch classify loss: 0.264837]
[Epoch 8/40] [Batch 12/287] [Batch classify loss: 0.283935]
[Epoch 8/40] [Batch 13/287] [Batch classify loss: 0.330553]
[Epoch 8/40] [Batch 14/287] [Batch classify loss: 0.301533]
[Epoch 8/40] [Batch 15/287] [Batch classify loss: 0.321568]
[Epoch 8/40] [Batch 16/287] [Batch classify loss: 0.295039]
[Epoch 8/40] [Batch 17/287] [Batch classify loss: 0.306982]
[Epoch 8/40] [Batch 18/287] [Batch classify loss: 0.334113]
[Epoch 8/40] [Batch 19/287] [Batch classify loss: 0.299651]
[Epoch 8/40] [Batch 20/287] [Batch classify loss: 0.317416]
[Epoch 8/40] [Batch 21/287] [Batch classify loss: 0.336425]
[Epoch 8/40] [Batch 22/287] [Batch classify loss: 0.318937]
[Epoch 8/40] [Batch 23/287] [Batch classify loss: 0.349398]
[Epoch 8/40] [Batch 24/287] [Batch classify loss: 0.325994]
[Epoch 8/40] [Batch 25/287] [Batch classify loss: 0.303899]
[Epoch 8/40] [Batch 26/287] [Batch classify loss: 0.293224]
[Epoch 8/40] [Batch 27/287] [Batch classify loss: 0.330334]
[Epoch 8/40] [Batch 28/287] [Batch classify loss: 0.355464]
[Epoch 8/40] [Batch 29/287] [Batch classify loss: 0.339042]
[Epoch 8/40] [Batch 30/287] [Batch classify loss: 0.340119]
[Epoch 8/40] [Batch 31/287] [Batch classify loss: 0.320064]
[Epoch 8/40] [Batch 32/287] [Batch classify loss: 0.374119]
[Epoch 8/40] [Batch 33/287] [Batch classify loss: 0.348220]
[Epoch 8/40] [Batch 34/287] [Batch classify loss: 0.302354]
[Epoch 8/40] [Batch 35/287] [Batch classify loss: 0.383932]
[Epoch 8/40] [Batch 36/287] [Batch classify loss: 0.348988]
[Epoch 8/40] [Batch 37/287] [Batch classify loss: 0.329742]
[Epoch 8/40] [Batch 38/287] [Batch classify loss: 0.384984]
[Epoch 8/40] [Batch 39/287] [Batch classify loss: 0.314528]
[Epoch 8/40] [Batch 40/287] [Batch classify loss: 0.363509]
[Epoch 8/40] [Batch 41/287] [Batch classify loss: 0.356394]
[Epoch 8/40] [Batch 42/287] [Batch classify loss: 0.380750]
[Epoch 8/40] [Batch 43/287] [Batch classify loss: 0.359419]
[Epoch 8/40] [Batch 44/287] [Batch classify loss: 0.349393]
[Epoch 8/40] [Batch 45/287] [Batch classify loss: 0.353759]
[Epoch 8/40] [Batch 46/287] [Batch classify loss: 0.319525]
[Epoch 8/40] [Batch 47/287] [Batch classify loss: 0.359618]
[Epoch 8/40] [Batch 48/287] [Batch classify loss: 0.365864]
[Epoch 8/40] [Batch 49/287] [Batch classify loss: 0.392191]
[Epoch 8/40] [Batch 50/287] [Batch classify loss: 0.403584]
[Epoch 8/40] [Batch 51/287] [Batch classify loss: 0.342100]
[Epoch 8/40] [Batch 52/287] [Batch classify loss: 0.384634]
[Epoch 8/40] [Batch 53/287] [Batch classify loss: 0.357802]
[Epoch 8/40] [Batch 54/287] [Batch classify loss: 0.376951]
[Epoch 8/40] [Batch 55/287] [Batch classify loss: 0.364770]
[Epoch 8/40] [Batch 56/287] [Batch classify loss: 0.340271]
[Epoch 8/40] [Batch 57/287] [Batch classify loss: 0.409430]
[Epoch 8/40] [Batch 58/287] [Batch classify loss: 0.359162]
[Epoch 8/40] [Batch 59/287] [Batch classify loss: 0.354785]
[Epoch 8/40] [Batch 60/287] [Batch classify loss: 0.374884]
[Epoch 8/40] [Batch 61/287] [Batch classify loss: 0.396573]
[Epoch 8/40] [Batch 62/287] [Batch classify loss: 0.406422]
[Epoch 8/40] [Batch 63/287] [Batch classify loss: 0.391192]
[Epoch 8/40] [Batch 64/287] [Batch classify loss: 0.411741]
[Epoch 8/40] [Batch 65/287] [Batch classify loss: 0.391761]
[Epoch 8/40] [Batch 66/287] [Batch classify loss: 0.405017]
[Epoch 8/40] [Batch 67/287] [Batch classify loss: 0.450990]
[Epoch 8/40] [Batch 68/287] [Batch classify loss: 0.384617]
[Epoch 8/40] [Batch 69/287] [Batch classify loss: 0.430549]
[Epoch 8/40] [Batch 70/287] [Batch classify loss: 0.412943]
[Epoch 8/40] [Batch 71/287] [Batch classify loss: 0.389317]
[Epoch 8/40] [Batch 72/287] [Batch classify loss: 0.407564]
[Epoch 8/40] [Batch 73/287] [Batch classify loss: 0.368482]
[Epoch 8/40] [Batch 74/287] [Batch classify loss: 0.435138]
[Epoch 8/40] [Batch 75/287] [Batch classify loss: 0.437121]
[Epoch 8/40] [Batch 76/287] [Batch classify loss: 0.381026]
[Epoch 8/40] [Batch 77/287] [Batch classify loss: 0.388629]
[Epoch 8/40] [Batch 78/287] [Batch classify loss: 0.458636]
[Epoch 8/40] [Batch 79/287] [Batch classify loss: 0.384045]
[Epoch 8/40] [Batch 80/287] [Batch classify loss: 0.439353]
[Epoch 8/40] [Batch 81/287] [Batch classify loss: 0.389898]
[Epoch 8/40] [Batch 82/287] [Batch classify loss: 0.428117]
[Epoch 8/40] [Batch 83/287] [Batch classify loss: 0.410701]
[Epoch 8/40] [Batch 84/287] [Batch classify loss: 0.404692]
[Epoch 8/40] [Batch 85/287] [Batch classify loss: 0.459848]
[Epoch 8/40] [Batch 86/287] [Batch classify loss: 0.440993]
[Epoch 8/40] [Batch 87/287] [Batch classify loss: 0.423275]
[Epoch 8/40] [Batch 88/287] [Batch classify loss: 0.423059]
[Epoch 8/40] [Batch 89/287] [Batch classify loss: 0.479239]
[Epoch 8/40] [Batch 90/287] [Batch classify loss: 0.407043]
[Epoch 8/40] [Batch 91/287] [Batch classify loss: 0.434253]
[Epoch 8/40] [Batch 92/287] [Batch classify loss: 0.436215]
[Epoch 8/40] [Batch 93/287] [Batch classify loss: 0.489596]
[Epoch 8/40] [Batch 94/287] [Batch classify loss: 0.408124]
[Epoch 8/40] [Batch 95/287] [Batch classify loss: 0.132370]
[Epoch 8/40] [Batch 96/287] [Batch classify loss: 0.158035]
[Epoch 8/40] [Batch 97/287] [Batch classify loss: 0.141528]
[Epoch 8/40] [Batch 98/287] [Batch classify loss: 0.189042]
[Epoch 8/40] [Batch 99/287] [Batch classify loss: 0.209960]
[Epoch 8/40] [Batch 100/287] [Batch classify loss: 0.251266]
[Epoch 8/40] [Batch 101/287] [Batch classify loss: 0.241956]
[Epoch 8/40] [Batch 102/287] [Batch classify loss: 0.236603]
[Epoch 8/40] [Batch 103/287] [Batch classify loss: 0.285899]
[Epoch 8/40] [Batch 104/287] [Batch classify loss: 0.260949]
[Epoch 8/40] [Batch 105/287] [Batch classify loss: 0.289583]
[Epoch 8/40] [Batch 106/287] [Batch classify loss: 0.302276]
[Epoch 8/40] [Batch 107/287] [Batch classify loss: 0.288855]
[Epoch 8/40] [Batch 108/287] [Batch classify loss: 0.284350]
[Epoch 8/40] [Batch 109/287] [Batch classify loss: 0.284317]
[Epoch 8/40] [Batch 110/287] [Batch classify loss: 0.291813]
[Epoch 8/40] [Batch 111/287] [Batch classify loss: 0.279573]
[Epoch 8/40] [Batch 112/287] [Batch classify loss: 0.324070]
[Epoch 8/40] [Batch 113/287] [Batch classify loss: 0.287945]
[Epoch 8/40] [Batch 114/287] [Batch classify loss: 0.319075]
[Epoch 8/40] [Batch 115/287] [Batch classify loss: 0.310622]
[Epoch 8/40] [Batch 116/287] [Batch classify loss: 0.309613]
[Epoch 8/40] [Batch 117/287] [Batch classify loss: 0.326364]
[Epoch 8/40] [Batch 118/287] [Batch classify loss: 0.326576]
[Epoch 8/40] [Batch 119/287] [Batch classify loss: 0.275119]
[Epoch 8/40] [Batch 120/287] [Batch classify loss: 0.330321]
[Epoch 8/40] [Batch 121/287] [Batch classify loss: 0.304892]
[Epoch 8/40] [Batch 122/287] [Batch classify loss: 0.334248]
[Epoch 8/40] [Batch 123/287] [Batch classify loss: 0.339431]
[Epoch 8/40] [Batch 124/287] [Batch classify loss: 0.319836]
[Epoch 8/40] [Batch 125/287] [Batch classify loss: 0.318786]
[Epoch 8/40] [Batch 126/287] [Batch classify loss: 0.338544]
[Epoch 8/40] [Batch 127/287] [Batch classify loss: 0.354451]
[Epoch 8/40] [Batch 128/287] [Batch classify loss: 0.366896]
[Epoch 8/40] [Batch 129/287] [Batch classify loss: 0.355047]
[Epoch 8/40] [Batch 130/287] [Batch classify loss: 0.381471]
[Epoch 8/40] [Batch 131/287] [Batch classify loss: 0.338953]
[Epoch 8/40] [Batch 132/287] [Batch classify loss: 0.340545]
[Epoch 8/40] [Batch 133/287] [Batch classify loss: 0.336757]
[Epoch 8/40] [Batch 134/287] [Batch classify loss: 0.355453]
[Epoch 8/40] [Batch 135/287] [Batch classify loss: 0.347392]
[Epoch 8/40] [Batch 136/287] [Batch classify loss: 0.365754]
[Epoch 8/40] [Batch 137/287] [Batch classify loss: 0.372873]
[Epoch 8/40] [Batch 138/287] [Batch classify loss: 0.361527]
[Epoch 8/40] [Batch 139/287] [Batch classify loss: 0.344840]
[Epoch 8/40] [Batch 140/287] [Batch classify loss: 0.330791]
[Epoch 8/40] [Batch 141/287] [Batch classify loss: 0.370386]
[Epoch 8/40] [Batch 142/287] [Batch classify loss: 0.374880]
[Epoch 8/40] [Batch 143/287] [Batch classify loss: 0.378848]
[Epoch 8/40] [Batch 144/287] [Batch classify loss: 0.399328]
[Epoch 8/40] [Batch 145/287] [Batch classify loss: 0.323378]
[Epoch 8/40] [Batch 146/287] [Batch classify loss: 0.375301]
[Epoch 8/40] [Batch 147/287] [Batch classify loss: 0.361817]
[Epoch 8/40] [Batch 148/287] [Batch classify loss: 0.395865]
[Epoch 8/40] [Batch 149/287] [Batch classify loss: 0.396133]
[Epoch 8/40] [Batch 150/287] [Batch classify loss: 0.354561]
[Epoch 8/40] [Batch 151/287] [Batch classify loss: 0.399277]
[Epoch 8/40] [Batch 152/287] [Batch classify loss: 0.368972]
[Epoch 8/40] [Batch 153/287] [Batch classify loss: 0.415825]
[Epoch 8/40] [Batch 154/287] [Batch classify loss: 0.363652]
[Epoch 8/40] [Batch 155/287] [Batch classify loss: 0.416524]
[Epoch 8/40] [Batch 156/287] [Batch classify loss: 0.388428]
[Epoch 8/40] [Batch 157/287] [Batch classify loss: 0.425095]
[Epoch 8/40] [Batch 158/287] [Batch classify loss: 0.399519]
[Epoch 8/40] [Batch 159/287] [Batch classify loss: 0.381198]
[Epoch 8/40] [Batch 160/287] [Batch classify loss: 0.422868]
[Epoch 8/40] [Batch 161/287] [Batch classify loss: 0.377573]
[Epoch 8/40] [Batch 162/287] [Batch classify loss: 0.378305]
[Epoch 8/40] [Batch 163/287] [Batch classify loss: 0.421381]
[Epoch 8/40] [Batch 164/287] [Batch classify loss: 0.386723]
[Epoch 8/40] [Batch 165/287] [Batch classify loss: 0.397874]
[Epoch 8/40] [Batch 166/287] [Batch classify loss: 0.385274]
[Epoch 8/40] [Batch 167/287] [Batch classify loss: 0.415407]
[Epoch 8/40] [Batch 168/287] [Batch classify loss: 0.387949]
[Epoch 8/40] [Batch 169/287] [Batch classify loss: 0.446608]
[Epoch 8/40] [Batch 170/287] [Batch classify loss: 0.378164]
[Epoch 8/40] [Batch 171/287] [Batch classify loss: 0.430721]
[Epoch 8/40] [Batch 172/287] [Batch classify loss: 0.391221]
[Epoch 8/40] [Batch 173/287] [Batch classify loss: 0.383197]
[Epoch 8/40] [Batch 174/287] [Batch classify loss: 0.447485]
[Epoch 8/40] [Batch 175/287] [Batch classify loss: 0.505912]
[Epoch 8/40] [Batch 176/287] [Batch classify loss: 0.381075]
[Epoch 8/40] [Batch 177/287] [Batch classify loss: 0.428372]
[Epoch 8/40] [Batch 178/287] [Batch classify loss: 0.413605]
[Epoch 8/40] [Batch 179/287] [Batch classify loss: 0.409039]
[Epoch 8/40] [Batch 180/287] [Batch classify loss: 0.430216]
[Epoch 8/40] [Batch 181/287] [Batch classify loss: 0.412012]
[Epoch 8/40] [Batch 182/287] [Batch classify loss: 0.475144]
[Epoch 8/40] [Batch 183/287] [Batch classify loss: 0.463958]
[Epoch 8/40] [Batch 184/287] [Batch classify loss: 0.410049]
[Epoch 8/40] [Batch 185/287] [Batch classify loss: 0.459731]
[Epoch 8/40] [Batch 186/287] [Batch classify loss: 0.465454]
[Epoch 8/40] [Batch 187/287] [Batch classify loss: 0.535784]
[Epoch 8/40] [Batch 188/287] [Batch classify loss: 0.413017]
[Epoch 8/40] [Batch 189/287] [Batch classify loss: 0.119135]
[Epoch 8/40] [Batch 190/287] [Batch classify loss: 0.170656]
[Epoch 8/40] [Batch 191/287] [Batch classify loss: 0.177957]
[Epoch 8/40] [Batch 192/287] [Batch classify loss: 0.198825]
[Epoch 8/40] [Batch 193/287] [Batch classify loss: 0.220913]
[Epoch 8/40] [Batch 194/287] [Batch classify loss: 0.238804]
[Epoch 8/40] [Batch 195/287] [Batch classify loss: 0.262041]
[Epoch 8/40] [Batch 196/287] [Batch classify loss: 0.240343]
[Epoch 8/40] [Batch 197/287] [Batch classify loss: 0.244027]
[Epoch 8/40] [Batch 198/287] [Batch classify loss: 0.281488]
[Epoch 8/40] [Batch 199/287] [Batch classify loss: 0.276319]
[Epoch 8/40] [Batch 200/287] [Batch classify loss: 0.292128]
[Epoch 8/40] [Batch 201/287] [Batch classify loss: 0.303514]
[Epoch 8/40] [Batch 202/287] [Batch classify loss: 0.295515]
[Epoch 8/40] [Batch 203/287] [Batch classify loss: 0.289020]
[Epoch 8/40] [Batch 204/287] [Batch classify loss: 0.266582]
[Epoch 8/40] [Batch 205/287] [Batch classify loss: 0.314908]
[Epoch 8/40] [Batch 206/287] [Batch classify loss: 0.283199]
[Epoch 8/40] [Batch 207/287] [Batch classify loss: 0.290643]
[Epoch 8/40] [Batch 208/287] [Batch classify loss: 0.306481]
[Epoch 8/40] [Batch 209/287] [Batch classify loss: 0.341145]
[Epoch 8/40] [Batch 210/287] [Batch classify loss: 0.344109]
[Epoch 8/40] [Batch 211/287] [Batch classify loss: 0.293460]
[Epoch 8/40] [Batch 212/287] [Batch classify loss: 0.346209]
[Epoch 8/40] [Batch 213/287] [Batch classify loss: 0.283663]
[Epoch 8/40] [Batch 214/287] [Batch classify loss: 0.288441]
[Epoch 8/40] [Batch 215/287] [Batch classify loss: 0.304164]
[Epoch 8/40] [Batch 216/287] [Batch classify loss: 0.322387]
[Epoch 8/40] [Batch 217/287] [Batch classify loss: 0.348730]
[Epoch 8/40] [Batch 218/287] [Batch classify loss: 0.335013]
[Epoch 8/40] [Batch 219/287] [Batch classify loss: 0.312890]
[Epoch 8/40] [Batch 220/287] [Batch classify loss: 0.362506]
[Epoch 8/40] [Batch 221/287] [Batch classify loss: 0.336581]
[Epoch 8/40] [Batch 222/287] [Batch classify loss: 0.321100]
[Epoch 8/40] [Batch 223/287] [Batch classify loss: 0.356651]
[Epoch 8/40] [Batch 224/287] [Batch classify loss: 0.377218]
[Epoch 8/40] [Batch 225/287] [Batch classify loss: 0.342291]
[Epoch 8/40] [Batch 226/287] [Batch classify loss: 0.347850]
[Epoch 8/40] [Batch 227/287] [Batch classify loss: 0.333500]
[Epoch 8/40] [Batch 228/287] [Batch classify loss: 0.362331]
[Epoch 8/40] [Batch 229/287] [Batch classify loss: 0.353608]
[Epoch 8/40] [Batch 230/287] [Batch classify loss: 0.355307]
[Epoch 8/40] [Batch 231/287] [Batch classify loss: 0.364448]
[Epoch 8/40] [Batch 232/287] [Batch classify loss: 0.366715]
[Epoch 8/40] [Batch 233/287] [Batch classify loss: 0.382822]
[Epoch 8/40] [Batch 234/287] [Batch classify loss: 0.294702]
[Epoch 8/40] [Batch 235/287] [Batch classify loss: 0.422696]
[Epoch 8/40] [Batch 236/287] [Batch classify loss: 0.369043]
[Epoch 8/40] [Batch 237/287] [Batch classify loss: 0.374208]
[Epoch 8/40] [Batch 238/287] [Batch classify loss: 0.417295]
[Epoch 8/40] [Batch 239/287] [Batch classify loss: 0.338484]
[Epoch 8/40] [Batch 240/287] [Batch classify loss: 0.355511]
[Epoch 8/40] [Batch 241/287] [Batch classify loss: 0.358817]
[Epoch 8/40] [Batch 242/287] [Batch classify loss: 0.425240]
[Epoch 8/40] [Batch 243/287] [Batch classify loss: 0.388927]
[Epoch 8/40] [Batch 244/287] [Batch classify loss: 0.371771]
[Epoch 8/40] [Batch 245/287] [Batch classify loss: 0.401363]
[Epoch 8/40] [Batch 246/287] [Batch classify loss: 0.351077]
[Epoch 8/40] [Batch 247/287] [Batch classify loss: 0.399042]
[Epoch 8/40] [Batch 248/287] [Batch classify loss: 0.379754]
[Epoch 8/40] [Batch 249/287] [Batch classify loss: 0.410704]
[Epoch 8/40] [Batch 250/287] [Batch classify loss: 0.397427]
[Epoch 8/40] [Batch 251/287] [Batch classify loss: 0.385345]
[Epoch 8/40] [Batch 252/287] [Batch classify loss: 0.420380]
[Epoch 8/40] [Batch 253/287] [Batch classify loss: 0.403502]
[Epoch 8/40] [Batch 254/287] [Batch classify loss: 0.391265]
[Epoch 8/40] [Batch 255/287] [Batch classify loss: 0.456339]
[Epoch 8/40] [Batch 256/287] [Batch classify loss: 0.356766]
[Epoch 8/40] [Batch 257/287] [Batch classify loss: 0.435911]
[Epoch 8/40] [Batch 258/287] [Batch classify loss: 0.449229]
[Epoch 8/40] [Batch 259/287] [Batch classify loss: 0.402252]
[Epoch 8/40] [Batch 260/287] [Batch classify loss: 0.413887]
[Epoch 8/40] [Batch 261/287] [Batch classify loss: 0.383694]
[Epoch 8/40] [Batch 262/287] [Batch classify loss: 0.465815]
[Epoch 8/40] [Batch 263/287] [Batch classify loss: 0.428662]
[Epoch 8/40] [Batch 264/287] [Batch classify loss: 0.384792]
[Epoch 8/40] [Batch 265/287] [Batch classify loss: 0.406120]
[Epoch 8/40] [Batch 266/287] [Batch classify loss: 0.435917]
[Epoch 8/40] [Batch 267/287] [Batch classify loss: 0.428527]
[Epoch 8/40] [Batch 268/287] [Batch classify loss: 0.483673]
[Epoch 8/40] [Batch 269/287] [Batch classify loss: 0.401366]
[Epoch 8/40] [Batch 270/287] [Batch classify loss: 0.435094]
[Epoch 8/40] [Batch 271/287] [Batch classify loss: 0.404815]
[Epoch 8/40] [Batch 272/287] [Batch classify loss: 0.372369]
[Epoch 8/40] [Batch 273/287] [Batch classify loss: 0.448033]
[Epoch 8/40] [Batch 274/287] [Batch classify loss: 0.438141]
